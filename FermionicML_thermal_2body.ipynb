{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguschanchu/FermionicML/blob/main/FermionicML_thermal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXz5cOlVwrzZ"
      },
      "source": [
        "# FermionicML:\n",
        "\n",
        "Code based on aguschanchu/Bosonic.py\n",
        "\n",
        "A diferencia del código anterior, este modelo trabaja sobre estados térmicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD2Yai55rMm"
      },
      "source": [
        "## Código base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgf9ExZN4jA7"
      },
      "source": [
        "Cargamos el código de Bosonic.py básico, branch fermionic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gydz4kCH4l5w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-04 21:14:24.163258: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-04 21:14:24.212341: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-04 21:14:24.212374: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-04 21:14:24.212399: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-04 21:14:24.220984: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/var/tmp/ipykernel_33987/3693791191.py:326: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  def gamma_lamba_inv(x):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import binom\n",
        "from scipy.sparse import dok_matrix, linalg\n",
        "from scipy import linalg as linalg_d\n",
        "from joblib import Memory\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from joblib import Parallel, delayed\n",
        "from numba import jit, prange, njit\n",
        "import numba as nb\n",
        "import pickle\n",
        "import math\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from itertools import combinations\n",
        "\n",
        "\n",
        "# Funciones auxiliares optimiadas\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def int_to_tuple_arr(ni,nf, b, digits=None):\n",
        "    sol = np.zeros((nf-ni, digits), dtype=np.int64)\n",
        "    for n in prange(ni, nf):\n",
        "        r = np.zeros(digits, dtype=np.int64)\n",
        "        ncop = n\n",
        "        idx = 0\n",
        "        while n != 0:\n",
        "            r[idx] = n % b\n",
        "            n = n // b\n",
        "            idx += 1\n",
        "        if digits is not None:\n",
        "            if idx < digits:\n",
        "                for i in range(idx, digits):\n",
        "                    r[i] = 0\n",
        "                idx = digits\n",
        "        sol[ncop-ni,:] = r[:idx]\n",
        "    return sol\n",
        "\n",
        "def tuple_to_int(t, d):\n",
        "    b = d-1\n",
        "    l = len(t)\n",
        "    s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "    return sum(s)\n",
        "\n",
        "def create_basis_(m, d, size):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 1000000\n",
        "    for x in range(0,(m+1)**d, chunk_size):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        arr = int_to_tuple_arr(start_index, end_index, m+1, d)\n",
        "        sums = np.sum(arr, axis=1)\n",
        "        rows = np.where(sums == m)[0]\n",
        "        for row in [arr[i] for i in rows]:\n",
        "            if np.all(np.logical_or(row == 0, row == 1)):\n",
        "                base.append(row)\n",
        "\n",
        "    # Como consecuencia de la paralelizacion, es necesario reordenar la base\n",
        "    sorted_base = sorted(base, key=lambda x: tuple_to_int(x, d), reverse=True)\n",
        "    assert len(base) == size\n",
        "\n",
        "    return sorted_base\n",
        "\n",
        "def custom_base_representation_tf(n_min, n_max, base, num_digits):\n",
        "    # Generate a range of numbers from n_min to n_max\n",
        "    numbers = tf.range(n_min, n_max + 1, dtype=tf.int64)\n",
        "    \n",
        "    # Calculate the digits in the custom base using broadcasting\n",
        "    digits = tf.pow(tf.cast(base, dtype=tf.float64), tf.cast(tf.range(num_digits), dtype=tf.float64))\n",
        "    \n",
        "    # Reshape the digits to [1, num_digits] for broadcasting\n",
        "    digits = tf.reshape(digits, [1, -1])\n",
        "    \n",
        "    # Reshape numbers to [batch_size, 1]\n",
        "    numbers = tf.reshape(tf.cast(numbers, dtype=tf.float64), [-1, 1])\n",
        "    \n",
        "    # Calculate the digits in the custom base for each number using broadcasting\n",
        "    result = tf.cast(tf.math.floormod(tf.math.floordiv(numbers, digits), base), dtype=tf.int32)\n",
        "    \n",
        "    # Pad the result to have exactly num_digits columns\n",
        "    result = tf.pad(result, paddings=[[0, 0], [0, num_digits - tf.shape(result)[1]]], constant_values=0)\n",
        "    \n",
        "    # Reverse the order of columns\n",
        "    #result = tf.reverse(result, axis=[1])\n",
        "\n",
        "    return result\n",
        "\n",
        "def select_rows_with_sum(arr, m):\n",
        "    # Create a mask based on the criteria\n",
        "    mask = tf.reduce_all(tf.math.logical_or(tf.equal(arr, 0), tf.equal(arr, 1)), axis=1) & (tf.reduce_sum(arr, axis=1) == m)\n",
        "    \n",
        "    # Use the mask to select the rows\n",
        "    result = tf.boolean_mask(arr, mask, axis=0)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def create_basis_tf_(m, d):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 10000000\n",
        "    for x in tqdm(range(0,(m+1)**d, chunk_size)):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        res = custom_base_representation_tf(start_index, end_index, m+1, d)\n",
        "        arr = select_rows_with_sum(res, m)\n",
        "        base.append(arr.numpy())\n",
        "\n",
        "    return np.concatenate(base)\n",
        "\n",
        "def create_fermionic_base_(m, d):\n",
        "    indices = list(range(d))\n",
        "    combinations_list = list(combinations(indices, m))\n",
        "    \n",
        "    vectors = []\n",
        "    for combo in combinations_list:\n",
        "        vector = [1 if i in combo else 0 for i in indices]\n",
        "        vectors.append(vector)\n",
        "    \n",
        "    return vectors\n",
        "\n",
        "# Dada una base, devuelve los vectores que estan dados de a pares\n",
        "def get_kkbar_indices_(base):\n",
        "    indices = []\n",
        "    for i, v in enumerate(base):\n",
        "        if np.all(v[::2] == v[1::2]):\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "class fixed_basis:\n",
        "\n",
        "    # Convierte a un enterno n a su escritura en base b\n",
        "    def _int_to_tuple(self, n, b, digits = None):\n",
        "        rep = np.base_repr(n, b)\n",
        "        rep_int = [int(x,b) for x in rep]\n",
        "        if digits is not None:\n",
        "            zeros = [0 for i in range(0,digits-len(rep))]\n",
        "            return zeros + rep_int\n",
        "        else:\n",
        "            return rep_int\n",
        "\n",
        "    # Revierte la transformacion anterior\n",
        "    def tuple_to_int(self, t):\n",
        "        b = self.d-1\n",
        "        l = len(t)\n",
        "        s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "        return sum(s)\n",
        "\n",
        "    # Convierte el vector en su representacion\n",
        "    def vect_to_repr(self, vect):\n",
        "        for i, k in enumerate(vect):\n",
        "            if k == 1. or k == 1:\n",
        "                break\n",
        "        else:\n",
        "            return 0\n",
        "        return self.base[i,:]\n",
        "\n",
        "    def rep_to_vect(self, rep):\n",
        "        rep = list(rep)\n",
        "        for i, r in [(j, self.base[j,:]) for j in range(0,self.size)]:\n",
        "            if list(r) == rep:\n",
        "                return self.canonicals[:,i]\n",
        "        else:\n",
        "            None\n",
        "\n",
        "    def rep_to_index(self, rep):\n",
        "        try:\n",
        "            return self.base.tolist().index(list(rep))\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def rep_to_exi(rep):\n",
        "        r = []\n",
        "        for i, k in enumerate(rep):\n",
        "            r += [i for x in range(0,k)]\n",
        "        return r\n",
        "\n",
        "    # Crea base de M particulas en D estados (repr y base canonica)\n",
        "    def create_basis(self, m, d, pairs = False):\n",
        "        #print(\"Creating basis: \", m, d)\n",
        "        #base = np.array(create_basis_tf_(m, d)) CASO GENERICO\n",
        "        base = np.array(create_fermionic_base_(m,d)) # UNICAMENTE FERMIONICO\n",
        "        if pairs:\n",
        "            base = base[get_kkbar_indices_(base)]\n",
        "        length = base.shape[0]\n",
        "        # Asignamos a cada uno de ellos un canónico\n",
        "        canonicals = np.eye(length)\n",
        "        return base, canonicals\n",
        "    \n",
        "    def __init__(self, m, d, pairs = False):\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        (self.base, self.canonicals) = self.create_basis(m, d, pairs)\n",
        "        self.size = self.base.shape[0]\n",
        "\n",
        "# Matrices de aniquilación y creación endomórficas. Estan fuera de la clase para poder ser cacheadas\n",
        "#@memory.cache\n",
        "def bdb(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0 and v[i] != 1:\n",
        "                #print(v)\n",
        "                dest = list(v.copy())\n",
        "                dest[j] -= 1\n",
        "                dest[i] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                if tar is None:\n",
        "                    pass\n",
        "                else:\n",
        "                    mat[tar, k] = np.sqrt(v[i]+1)*np.sqrt(v[j])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0:\n",
        "                mat[k, k] = v[i] \n",
        "    return mat\n",
        "\n",
        "#@memory.cache\n",
        "def bbd(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 0 and v[j] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[i] -= 1\n",
        "                dest[j] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[j]+1)*np.sqrt(v[i])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 1:\n",
        "                mat[k, k] = v[i]+1\n",
        "    return mat\n",
        "\n",
        "# Matrices de aniquilación y creación.Toman la base de origen y destino (basis_o, basis_d) resp\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def b_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 0:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] -= 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i])\n",
        "    return mat\n",
        "\n",
        "def b(basis_o, basis_d, i):\n",
        "    return b_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def bd_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 1:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd(basis_o, basis_d, i):\n",
        "    return bd_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "\n",
        "# Acepta una lista de indices a crear\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def bd_gen_aux(basis_o, basis_d, gen_list):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        conds = np.zeros(len(gen_list), dtype=np.int64)\n",
        "        for i in range(len(gen_list)):\n",
        "            if basis_o[k][gen_list[i]] != 1:\n",
        "                conds[i] = 1\n",
        "        if np.all(conds):\n",
        "            dest = list(basis_o[k].copy())\n",
        "            for i in gen_list:\n",
        "                dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd_gen(basis_o, basis_d, i):\n",
        "    return bd_gen_aux(basis_o.base, basis_d.base, np.array(i))\n",
        "\n",
        "def b_gen(basis_o, basis_d, i):\n",
        "    return np.transpose(bd_gen(basis_d, basis_o, i))\n",
        "\n",
        "# Volvemos a definir la función para compilarla\n",
        "@nb.jit(forceobj=True)\n",
        "def _rep_to_index(base, rep):\n",
        "    return base.tolist().index(list(rep))\n",
        "\n",
        "# Funciones auxiliares para calcular rho2kkbar y gamma_p\n",
        "@nb.jit(nopython=True)\n",
        "def rep_to_exi(rep):\n",
        "    r = []\n",
        "    for i in range(len(rep)):\n",
        "        for j in range(rep[i]):\n",
        "            r.append(i)\n",
        "    return r\n",
        "\n",
        "@nb.njit\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "@nb.njit\n",
        "def gamma_lamba(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.jit\n",
        "def gamma_lamba_inv(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / np.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.njit\n",
        "def rep_to_index_np(base, rep):\n",
        "    for i in range(len(base)):\n",
        "        if np.all(base[i] == rep):\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "\n",
        "def gamma_p(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    return gamma_p_aux(basis.base, vect, m_basis.base, nm_basis.base)\n",
        "\n",
        "@nb.njit()\n",
        "def gamma_p_aux(basis, vect, m_basis, nm_basis):\n",
        "    mat = np.zeros((len(m_basis), len(nm_basis)), dtype=np.float32)\n",
        "    for i in prange(len(m_basis)):\n",
        "        v = m_basis[i]\n",
        "        for j in prange(len(nm_basis)):\n",
        "            w = nm_basis[j]\n",
        "            targ = v + w\n",
        "            index = rep_to_index_np(basis, targ)\n",
        "            if index != -1:\n",
        "                coef = vect[index]\n",
        "                if coef != 0:\n",
        "                    coef = coef * gamma_lamba_inv(v) * gamma_lamba_inv(w) * gamma_lamba(targ)\n",
        "                mat[i, j] = coef\n",
        "    return mat\n",
        "# Devuelve la matriz rho M asociada al vector\n",
        "def rho_m(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    g = gamma_p(basis, m, vect, m_basis, nm_basis)\n",
        "    return np.dot(g,np.transpose(g))\n",
        "\n",
        "# Devuelve la matriz gamma asociada a la descomposición (M,N-M) del vector\n",
        "@jit(forceobj=True)\n",
        "def gamma(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    mat = dok_matrix((m_basis.size, nm_basis.size), dtype=np.float32)\n",
        "    for i, v in enumerate(m_basis.base):\n",
        "        for j, w in enumerate(nm_basis.base):\n",
        "            targ = v+w\n",
        "            # Revisamos que sea un estado fermionico valido\n",
        "            arr = np.asarray(targ)\n",
        "            if not np.all(np.logical_or(arr == 0, arr == 1)):\n",
        "                continue\n",
        "            index = _rep_to_index(basis.base, targ)\n",
        "            coef = vect[index]\n",
        "            if coef != 0:\n",
        "                aux = lambda x: np.prod(np.reciprocal(np.sqrt([np.math.factorial(o) for o in x])))\n",
        "                aux_inv = lambda x: np.prod(np.sqrt([np.math.factorial(o) for o in x]))\n",
        "                coef = coef * aux(v) * aux(w) * aux_inv(targ)\n",
        "                #coef = coef\n",
        "                #print(v,w,coef)\n",
        "            mat[i,j] = coef\n",
        "    return mat\n",
        "\n",
        "# Genera las matrices de rho1\n",
        "def rho_1_gen(basis):\n",
        "    d = basis.d\n",
        "    s = basis.size\n",
        "    mat = np.empty((d,d,s,s), dtype=np.float32)\n",
        "    for i in range(0, d):\n",
        "        for j in range(0, d):\n",
        "            mat[i,j,:,:] = np.array(bdb(basis,j, i).todense())\n",
        "    return mat\n",
        "\n",
        "#@jit(parallel=True, nopython=True)\n",
        "def rho_1(d, state, rho_1_arrays):\n",
        "    state_expanded = state[np.newaxis, np.newaxis, :, :]\n",
        "    product = state_expanded * rho_1_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "\n",
        "    return mat\n",
        "\n",
        "\n",
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "\n",
        "    return mat\n",
        "\n",
        "def rho_2(size, state, rho_2_arrays):\n",
        "    state_expanded = np.expand_dims(state, axis=1)\n",
        "    state_expanded = np.expand_dims(state_expanded, axis=1)\n",
        "    rho_2_arrays = rho_2_arrays[np.newaxis, :, :, :, :]\n",
        "    print(state_expanded.shape, rho_2_arrays.shape)\n",
        "    product = state_expanded * rho_2_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "    return mat\n",
        "\n",
        "def get_kkbar_indices(t_basis):\n",
        "    indices = []\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        if np.all(v[::2] == v[1::2]):\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def rho_2_kkbar_gen(t_basis, rho_2_arrays):\n",
        "    indices = get_kkbar_indices(t_basis)\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "\n",
        "    rho_2_arrays_kkbar = rho_2_arrays[i, j, :, :]\n",
        "\n",
        "    return rho_2_arrays_kkbar\n",
        "\n",
        "# Devuelve la matriz rho 2 asociada al bloque kkbar\n",
        "def rho_2_kkbar(basis, vect, ml_basis = None, mll_basis = None, t_basis = None):\n",
        "    d = basis.d\n",
        "    # Creo las bases si no están dadas\n",
        "    if ml_basis == None or mll_basis == None or t_basis == None:\n",
        "        ml_basis = fixed_basis(m-1,d)\n",
        "        mll_basis = fixed_basis(m-2,d)\n",
        "        t_basis = fixed_basis(2,d)\n",
        "    diag = []\n",
        "    for v in t_basis.base:\n",
        "        for j in range(0, d, 2):\n",
        "            if v[j] == v[j+1]:\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            diag.append(v)\n",
        "    diag = np.array(diag)\n",
        "    return rho_2_kkbar_aux(diag, vect, basis.base, ml_basis.base, mll_basis.base, t_basis.base)\n",
        "\n",
        "@nb.njit\n",
        "def rho_2_kkbar_lambda(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "#@nb.njit(parallel=True)\n",
        "def rho_2_kkbar_aux(diag, vect, basis, ml_basis, mll_basis, t_basis):\n",
        "    mat = np.zeros((len(diag), len(diag)), dtype=np.float32)\n",
        "    for i in prange(len(diag)):\n",
        "        for j in prange(len(diag)):\n",
        "            v = diag[i]\n",
        "            w = diag[j]\n",
        "            # Creacion de los a\n",
        "            i_set = rep_to_exi(v)\n",
        "            b_m = b_aux(ml_basis, mll_basis, i_set[1]) @ b_aux(basis, ml_basis, i_set[0])\n",
        "            # Creacion de los ad\n",
        "            i_set = rep_to_exi(w)\n",
        "            bd_m = bd_aux(ml_basis, basis, i_set[1]) @ bd_aux(mll_basis, ml_basis, i_set[0])\n",
        "            # v1 = vect @ bd_m @ b_m @ vect Para estados puros\n",
        "            # Mult de b's y filleo de mat\n",
        "            coef = np.trace(vect @ bd_m @ b_m)\n",
        "            mat[i,j] = coef * rho_2_kkbar_lambda(v) * rho_2_kkbar_lambda(w)\n",
        "    return mat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dga5Xx_5vDf"
      },
      "source": [
        "## Definicion de Hamiltoniano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiTq53L5E1U"
      },
      "source": [
        "Cargamos el código de creación y resolución de Hamiltonianos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h5FXWv849Mq",
        "outputId": "49dd47b5-8c16-4ad4-92e7-e172462229b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "924\n"
          ]
        }
      ],
      "source": [
        "m = 6\n",
        "d = 2*m\n",
        "pairs = False # Usar solo para estados puros\n",
        "# Creo las bases para no tener que recrearlas luego\n",
        "basis = fixed_basis(m, d, pairs = pairs)\n",
        "#basis_m1 = fixed_basis(m-1, d, pairs = True)\n",
        "basis_m2 = fixed_basis(m-2, d, pairs = pairs)\n",
        "print(basis.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PToiSs915TXw"
      },
      "outputs": [],
      "source": [
        "## Usamos este approach si queremos guardar los generadores\n",
        "# Dados 1/2 (d^2+d) elementos, genera una mat de dxd:\n",
        "eps = 0.00001\n",
        "\n",
        "def sym_mat_gen(vect, d):\n",
        "    matrix = fill_matrix(vect, d)\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "@jit(nopython=True)\n",
        "def fill_matrix(vect, d):\n",
        "    matrix = np.zeros((d, d))\n",
        "    idx = 0\n",
        "    for i in prange(d):\n",
        "        for j in prange(i, d):\n",
        "            matrix[i, j] = vect[idx]\n",
        "            idx += 1\n",
        "    return matrix\n",
        "\n",
        "# Generamos una matrix aleatoria. Cuidado con la distribución, ver https://stackoverflow.com/questions/56605189/is-there-an-efficient-way-to-generate-a-symmetric-random-matrix\n",
        "def hamil_base_gen(d):\n",
        "    U = np.random.uniform(low=0, high=1.0, size=(d, d))\n",
        "    hamil_base = np.tril(U) + np.tril(U, -1).T\n",
        "    return hamil_base\n",
        "\n",
        "# Dada un a mat dxd simetrica, contruye el hamiltoniano de un cuerpo a_{ij} c^{dag}_i c_j\n",
        "# Alternativamente podemos construirlo a partir de rho_1_gen\n",
        "def base_hamiltonian_aux(mat, size, d, rho_1_gen):\n",
        "    # Construccion de H\n",
        "    rho_1_gen_transposed = rho_1_gen.transpose(1, 0, 2, 3)\n",
        "    mat_expanded = mat[:, :, np.newaxis, np.newaxis]\n",
        "    h = np.sum(mat_expanded * rho_1_gen_transposed[:, :, :, :], axis=(0, 1))\n",
        "    return h.astype(np.float32)\n",
        "\n",
        "def base_hamiltonian(mat, basis, rho_1_gen):\n",
        "    return base_hamiltonian_aux(mat, basis.size, basis.d, rho_1_gen)\n",
        "\n",
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2))) + eps * np.random.random((2*m,2*m))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    rho_1_arrays_t = tf.transpose(rho_1_arrays,perm=[1, 0, 2, 3])\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    rho_2_arrays_t = tf.transpose(rho_2_arrays,perm=[1, 0, 2, 3])\n",
        "\n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "    hi = np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "    return (h0, hi)\n",
        "\n",
        "def solve(h, last_step = None):\n",
        "    sol = linalg.eigsh(h, which='SA',k=19)\n",
        "    eigenspace_tol = 0.0001\n",
        "    if type(last_step) != type(None):\n",
        "        # Seleccionamos todos los autovects que difieren sus autovalores menos que tol (mismo autoespacio)\n",
        "        # y tomamos la proyección en el autoespacio de la solución del paso anterior (last_step)\n",
        "        eig = sol[0].real\n",
        "        eigv = sol[1]\n",
        "        cand = [eigv[:,i].real  for (i, x) in enumerate(eig) if abs(x-min(eig)) < eigenspace_tol]\n",
        "        cand_norm = [x/np.linalg.norm(x) for x in cand]\n",
        "        fund = np.zeros(len(cand[0]))\n",
        "        for x in cand_norm:\n",
        "            fund += np.dot(last_step,x) * x\n",
        "    else:\n",
        "        argmin = np.argmin(sol[0].real)\n",
        "        fund = sol[1][:,argmin]\n",
        "    fund = fund.real / np.linalg.norm(fund)\n",
        "    return fund\n",
        "\n",
        "# Generacion de H basada en TF\n",
        "\n",
        "# Funciones auxiliares de gen de H basado en TF\n",
        "## Dada matrix de indices, genera los indices de updates de TF\n",
        "def gen_update_indices(t_basis, batch_size):\n",
        "    # Calculamos los indices de kkbar en t_basis\n",
        "    indices = tf.constant(get_kkbar_indices(t_basis))\n",
        "    # Creamos el array de indices x indices\n",
        "    i, j = tf.meshgrid(indices, indices, indexing='ij')\n",
        "    matrix = tf.reshape(tf.stack([i, j], axis=-1), (-1, 2))\n",
        "\n",
        "    # Repeat the matrix along the first axis (axis=0) 'b' times\n",
        "    repeated_matrix = tf.repeat(tf.expand_dims(matrix, axis=0), repeats=batch_size, axis=0)\n",
        "\n",
        "    # Create an index array from 0 to b-1\n",
        "    indices = tf.range(batch_size, dtype=tf.int32)\n",
        "\n",
        "    # Expand the index array to have the same shape as the repeated matrix\n",
        "    indices = tf.expand_dims(indices, axis=-1)\n",
        "    indices = tf.expand_dims(indices, axis=-1)\n",
        "    indices = tf.tile(indices, multiples=[1,matrix.shape[0],1]) \n",
        "\n",
        "    # Concatenate the index array to the repeated matrix along a new axis\n",
        "    tiled_matrix = tf.concat([indices, repeated_matrix], axis=-1)\n",
        "    tiled_matrix = tf.reshape(tiled_matrix, [-1,3])\n",
        "    return tiled_matrix\n",
        "\n",
        "\n",
        "def two_body_hamiltonian_tf(t_basis, m, energy_batch, G_batched, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # SECCIÓN ENERGIAS\n",
        "    ## Dado un batch de niveles, lo pasamos a TF\n",
        "    energy_matrix = tf.constant(energy_batch, dtype=tf.float32)\n",
        "    ## Repetimos los niveles para cada uno de los pares (por el nivel k y kbar)\n",
        "    energy_matrix = tf.repeat(energy_matrix, repeats=2, axis=1)\n",
        "    ## Generamos la matrix diagonal y expandimos\n",
        "    energy_matrix_expanded = tf.linalg.diag(energy_matrix)\n",
        "    energy_matrix_expanded = energy_matrix_expanded[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    # Multiplicamos por los operadores C^dag C\n",
        "    h0_arr = tf.reduce_sum(energy_matrix_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    # SECCIÓN INTERACCIÓN\n",
        "    # Ya tenemos los indices de updates, ahora tomamos la mat en t_basis (una de zeros)\n",
        "    # y updateamos de acuerdo a la lista de G's cada uno flatteneados\n",
        "    G_flatten = np.ndarray.flatten(np.array([np.ndarray.flatten(G) for G in G_batched]))\n",
        "    # Creamos la mat de t_basis y updateamos a partir de los indices de kkbar\n",
        "    mat = tf.zeros((len(energy_batch), t_basis.size, t_basis.size), dtype=tf.float32)\n",
        "    mat = tf.tensor_scatter_nd_update(mat, indices, G_flatten)\n",
        "    # Preparamos las dimensiones y multiplicamos\n",
        "    mat_expanded = mat[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_2_gen_transposed = tf.transpose(rho_2_arrays, perm=[1, 0, 2, 3])\n",
        "    hi_arr = tf.reduce_sum(mat_expanded * rho_2_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    return h0_arr - hi_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emVBTg2QD-Fg"
      },
      "source": [
        "## Modelo de ML\n",
        "Basado en matrices densidad de 1 y 2 cuerpos como input, con hamiltoniano como salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aF_Ec_mCGX96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-04 21:14:28.078464: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.test.gpu_device_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDoa6LUJJ8O",
        "outputId": "73481454-fbcb-469f-d72f-cd0f8d534808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "66\n",
            "[[1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " [1 1 1 ... 0 0 0]\n",
            " ...\n",
            " [0 0 0 ... 0 1 1]\n",
            " [0 0 0 ... 1 1 1]\n",
            " [0 0 0 ... 1 1 1]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nm = 1\\nm1_basis = fixed_basis(m, d)\\nprint(m1_basis.size)\\nprint(m1_basis.base)\\nnm1_basis = fixed_basis(basis.m-m, d)\\n'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Construccion de bases para calculo de rho1 y rho2\n",
        "# rho2\n",
        "m = 2\n",
        "m2_basis = fixed_basis(m, d, pairs=pairs)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-m, d, pairs=pairs)\n",
        "print(nm2_basis.base)\n",
        "t_basis = fixed_basis(2, basis.d, pairs=pairs)\n",
        "# rho1\n",
        "\"\"\"\n",
        "m = 1\n",
        "m1_basis = fixed_basis(m, d)\n",
        "print(m1_basis.size)\n",
        "print(m1_basis.base)\n",
        "nm1_basis = fixed_basis(basis.m-m, d)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapxWkD16fHg"
      },
      "source": [
        "### Algunos benchmarks y funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "umCIrxCZKXQd"
      },
      "outputs": [],
      "source": [
        "# Given h calculo en rho2 y rho1 máximo\n",
        "def rho1_rho2(h, beta):\n",
        "    fund = thermal_state(h, beta)\n",
        "    rho2 = np.array(rho_2(basis, m2_basis.size, state, rho_2_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho2).real)\n",
        "    rho_2_max = r[0]\n",
        "    rho1 = np.array(rho_1(basis, state, rho_1_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho1).real)\n",
        "    rho_1_max = r[0]\n",
        "\n",
        "    return (rho_1_max, rho_2_max)\n",
        "\n",
        "def fill_triangular_np(x):\n",
        "    m = x.shape[0]\n",
        "    n = np.int32(np.sqrt(.25 + 2 * m) - .5)\n",
        "    x_tail = x[(m - (n**2 - m)):]\n",
        "    return np.triu(np.concatenate([x, x_tail[::-1]], 0).reshape(n, n))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QaNnIIc5bZux"
      },
      "outputs": [],
      "source": [
        "# TEST: Las funciones de TF y comunes coinciden\n",
        "\n",
        "# Dado h, \\beta, construyo el estado térmico\n",
        "from scipy.linalg import expm\n",
        "\n",
        "def thermal_state(h, beta):\n",
        "    quotient = expm(-beta*h)\n",
        "    return quotient / np.trace(quotient)\n",
        "\n",
        "## NO usar para mat no hermiticas\n",
        "@nb.jit(nopython=True)\n",
        "def thermal_state_eig(h, beta):\n",
        "    w, v = np.linalg.eigh(-beta*h)\n",
        "    D = np.diag(np.exp(w))\n",
        "    mat = v @ D @ v.T\n",
        "    mat = mat / np.trace(mat)\n",
        "    return mat\n",
        "    \n",
        "def gen_to_h(base, rho_1_arrays):\n",
        "    triag = fill_triangular_np(base)\n",
        "    body_gen = triag + np.transpose(triag)-np.diag(np.diag(triag))\n",
        "    h = np.array(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
        "    return h \n",
        "\n",
        "def gen_to_h_1b(hamil_base):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "    return body_gen\n",
        "\n",
        "def gen_to_h_tf(hamil_base, rho_1_arrays):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag)) # Simetrizamos y generamos la matriz de h\n",
        "    hamil_expanded = body_gen[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    h_arr = tf.reduce_sum(hamil_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "    return h_arr\n",
        "\n",
        "def thermal_state_tf(h):\n",
        "    # Assume beta=1\n",
        "    exp_hamiltonian = tf.linalg.expm(-h)\n",
        "    partition_function = tf.linalg.trace(exp_hamiltonian)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    \n",
        "    rho = exp_hamiltonian / partition_function\n",
        "\n",
        "    return rho\n",
        "\n",
        "def rho_1_tf(state, rho_1_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_1_arrays_expanded = tf.expand_dims(rho_1_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_1_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "def rho_2_tf(state, rho_2_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_2_arrays_expanded = tf.expand_dims(rho_2_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_2_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "# NOTA: para calcular el bloque rho2kkbar, utilizar en lugar\n",
        "\n",
        "def rho_1_gc_tf(hamil_base):\n",
        "    e, v = tf.linalg.eigh(gen_to_h_1b(hamil_base))\n",
        "    result = 1 / (1 + tf.exp(e))\n",
        "    result = tf.linalg.diag(result)\n",
        "    res = tf.linalg.matmul(v,result)\n",
        "    res = tf.linalg.matmul(res,v,adjoint_b=True)\n",
        "    \n",
        "    return tf.cast(res, tf.float32)\n",
        "\n",
        "# Aux function\n",
        "def outer_product(vector):\n",
        "    return tf.einsum('i,j->ij', vector, vector)\n",
        "\n",
        "def pure_state(h):\n",
        "    e, v = tf.linalg.eigh(h)\n",
        "    fund = v[:,:,0]\n",
        "    d = tf.map_fn(outer_product, fund)\n",
        "    return d\n",
        "\n",
        "# Casos de entrenamiento tipo mat gaussianas\n",
        "def gen_gauss_mat(G, sigma_sq, size):\n",
        "    indices = np.arange(size)\n",
        "    mat = G * np.exp(-((indices - indices[:, np.newaxis])**2) / (2 * sigma_sq))\n",
        "    return mat\n",
        "\n",
        "def gen_gauss_mat_np(G_values, sigma_sq_values, size):\n",
        "    indices = np.arange(size, dtype=np.float32)\n",
        "    indices_diff = indices - indices[:, np.newaxis]\n",
        "\n",
        "    mat = G_values[:, np.newaxis, np.newaxis] * np.exp(-np.square(indices_diff) / (2 * sigma_sq_values[:, np.newaxis, np.newaxis]))\n",
        "\n",
        "    return mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylpy_BCw6jxF"
      },
      "source": [
        "### Construccion de dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Version sincrónica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2is_Eo_qGpEz",
        "outputId": "9a968190-59f2-4695-ef18-b99ff5b4a212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-04 21:14:40.735135: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n",
            "2024-01-04 21:23:29.202826: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                                                                                                                                    | 0/31251 [00:00<?, ?it/s]2024-01-04 21:23:48.817808: W tensorflow/tsl/framework/bfc_allocator.cc:485] Allocator (GPU_0_bfc) ran out of memory trying to allocate 13.85GiB (rounded to 14876193024)requested by op _EagerConst\n",
            "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
            "Current allocation summary follows.\n",
            "Current allocation summary follows.\n",
            "2024-01-04 21:23:48.817848: I tensorflow/tsl/framework/bfc_allocator.cc:1039] BFCAllocator dump for GPU_0_bfc\n",
            "2024-01-04 21:23:48.817859: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (256): \tTotal Chunks: 4, Chunks in use: 4. 1.0KiB allocated for chunks. 1.0KiB in use in bin. 76B client-requested in use in bin.\n",
            "  0%|                                                                                                                                                                                    | 0/31251 [00:19<?, ?it/s]\n",
            "2024-01-04 21:23:48.817864: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (512): \tTotal Chunks: 1, Chunks in use: 1. 512B allocated for chunks. 512B in use in bin. 384B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817870: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1024): \tTotal Chunks: 2, Chunks in use: 2. 2.5KiB allocated for chunks. 2.5KiB in use in bin. 2.1KiB client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817875: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2048): \tTotal Chunks: 1, Chunks in use: 1. 3.5KiB allocated for chunks. 3.5KiB in use in bin. 3.4KiB client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817880: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4096): \tTotal Chunks: 1, Chunks in use: 1. 4.5KiB allocated for chunks. 4.5KiB in use in bin. 4.5KiB client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817885: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817889: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817894: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817898: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817904: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (131072): \tTotal Chunks: 2, Chunks in use: 1. 273.8KiB allocated for chunks. 136.2KiB in use in bin. 136.1KiB client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817909: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817914: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817918: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817922: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817927: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817931: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817937: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (16777216): \tTotal Chunks: 1, Chunks in use: 1. 26.05MiB allocated for chunks. 26.05MiB in use in bin. 26.05MiB client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817941: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (33554432): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817947: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 117.25MiB allocated for chunks. 117.25MiB in use in bin. 117.25MiB client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817952: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817958: I tensorflow/tsl/framework/bfc_allocator.cc:1046] Bin (268435456): \tTotal Chunks: 5, Chunks in use: 3. 19.99GiB allocated for chunks. 14.77GiB in use in bin. 14.77GiB client-requested in use in bin.\n",
            "2024-01-04 21:23:48.817966: I tensorflow/tsl/framework/bfc_allocator.cc:1062] Bin for 13.85GiB was 256.00MiB, Chunk State: \n",
            "2024-01-04 21:23:48.817977: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 442.67MiB | Requested Size: 0B | in_use: 0 | bin_num: 20, prev:   Size: 136.2KiB | Requested Size: 136.1KiB | in_use: 1 | bin_num: -1, next:   Size: 468.99MiB | Requested Size: 468.99MiB | in_use: 1 | bin_num: -1\n",
            "2024-01-04 21:23:48.817984: I tensorflow/tsl/framework/bfc_allocator.cc:1068]   Size: 4.78GiB | Requested Size: 3.66GiB | in_use: 0 | bin_num: 20, prev:   Size: 468.99MiB | Requested Size: 468.99MiB | in_use: 1 | bin_num: -1\n",
            "2024-01-04 21:23:48.817988: I tensorflow/tsl/framework/bfc_allocator.cc:1075] Next region of size 21610823680\n",
            "2024-01-04 21:23:48.817993: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4582000000 of size 491774976 next 1\n",
            "2024-01-04 21:23:48.817997: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f459f4fe400 of size 1280 next 2\n",
            "2024-01-04 21:23:48.818001: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f459f4fe900 of size 14876193024 next 3\n",
            "2024-01-04 21:23:48.818005: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f4916009a00 of size 122943744 next 4\n",
            "2024-01-04 21:23:48.818008: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491d549300 of size 256 next 5\n",
            "2024-01-04 21:23:48.818012: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491d549400 of size 256 next 6\n",
            "2024-01-04 21:23:48.818015: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491d549500 of size 1280 next 7\n",
            "2024-01-04 21:23:48.818018: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491d549a00 of size 256 next 8\n",
            "2024-01-04 21:23:48.818022: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491d549b00 of size 256 next 9\n",
            "2024-01-04 21:23:48.818025: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491d549c00 of size 512 next 10\n",
            "2024-01-04 21:23:48.818029: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491d549e00 of size 4608 next 11\n",
            "2024-01-04 21:23:48.818033: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491d54b000 of size 27320832 next 15\n",
            "2024-01-04 21:23:48.818037: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f491ef59200 of size 140800 next 16\n",
            "2024-01-04 21:23:48.818040: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491ef7b800 of size 3584 next 17\n",
            "2024-01-04 21:23:48.818044: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f491ef7c600 of size 139520 next 18\n",
            "2024-01-04 21:23:48.818048: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f491ef9e700 of size 464170240 next 12\n",
            "2024-01-04 21:23:48.818052: I tensorflow/tsl/framework/bfc_allocator.cc:1095] InUse at 7f493aa49400 of size 491774976 next 13\n",
            "2024-01-04 21:23:48.818056: I tensorflow/tsl/framework/bfc_allocator.cc:1095] Free  at 7f4957f47800 of size 5136353280 next 18446744073709551615\n",
            "2024-01-04 21:23:48.818060: I tensorflow/tsl/framework/bfc_allocator.cc:1100]      Summary of in-use Chunks by size: \n",
            "2024-01-04 21:23:48.818065: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 4 Chunks of size 256 totalling 1.0KiB\n",
            "2024-01-04 21:23:48.818069: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 512 totalling 512B\n",
            "2024-01-04 21:23:48.818073: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 1280 totalling 2.5KiB\n",
            "2024-01-04 21:23:48.818076: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 3584 totalling 3.5KiB\n",
            "2024-01-04 21:23:48.818080: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 4608 totalling 4.5KiB\n",
            "2024-01-04 21:23:48.818084: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 139520 totalling 136.2KiB\n",
            "2024-01-04 21:23:48.818089: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 27320832 totalling 26.05MiB\n",
            "2024-01-04 21:23:48.818095: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 122943744 totalling 117.25MiB\n",
            "2024-01-04 21:23:48.818099: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 2 Chunks of size 491774976 totalling 937.99MiB\n",
            "2024-01-04 21:23:48.818104: I tensorflow/tsl/framework/bfc_allocator.cc:1103] 1 Chunks of size 14876193024 totalling 13.85GiB\n",
            "2024-01-04 21:23:48.818108: I tensorflow/tsl/framework/bfc_allocator.cc:1107] Sum Total of in-use chunks: 14.91GiB\n",
            "2024-01-04 21:23:48.818112: I tensorflow/tsl/framework/bfc_allocator.cc:1109] Total bytes in pool: 21610823680 memory_limit_: 21610823680 available bytes: 0 curr_region_allocation_bytes_: 43221647360\n",
            "2024-01-04 21:23:48.818119: I tensorflow/tsl/framework/bfc_allocator.cc:1114] Stats: \n",
            "Limit:                     21610823680\n",
            "InUse:                     16010159360\n",
            "MaxInUse:                  19944216064\n",
            "NumAllocs:                          24\n",
            "MaxAllocSize:              14876193024\n",
            "Reserved:                            0\n",
            "PeakReserved:                        0\n",
            "LargestFreeBlock:                    0\n",
            "\n",
            "2024-01-04 21:23:48.818125: W tensorflow/tsl/framework/bfc_allocator.cc:497] ************************************************************************_****_______________________\n"
          ]
        },
        {
          "ename": "InternalError",
          "evalue": "Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized.",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[8], line 52\u001b[0m\n\u001b[1;32m     50\u001b[0m g_arr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mconstant(g_arr, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# Construimos los hamiltonianos basados en g_arr\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m h_arr \u001b[38;5;241m=\u001b[39m \u001b[43mtwo_body_hamiltonian_tf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt_basis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43men_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mg_arr\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho_1_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho_2_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mk_indices_tf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# Estados térmicos\u001b[39;00m\n\u001b[1;32m     54\u001b[0m state \u001b[38;5;241m=\u001b[39m thermal_state_tf(h_arr\u001b[38;5;241m*\u001b[39mbeta) \n",
            "Cell \u001b[0;32mIn[3], line 133\u001b[0m, in \u001b[0;36mtwo_body_hamiltonian_tf\u001b[0;34m(t_basis, m, energy_batch, G_batched, rho_1_arrays, rho_2_arrays, indices)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# Preparamos las dimensiones y multiplicamos\u001b[39;00m\n\u001b[1;32m    132\u001b[0m mat_expanded \u001b[38;5;241m=\u001b[39m mat[:, :, :, np\u001b[38;5;241m.\u001b[39mnewaxis, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m--> 133\u001b[0m rho_2_gen_transposed \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrho_2_arrays\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mperm\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m hi_arr \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mreduce_sum(mat_expanded \u001b[38;5;241m*\u001b[39m rho_2_gen_transposed[np\u001b[38;5;241m.\u001b[39mnewaxis,:,:,:,:], axis\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m])\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h0_arr \u001b[38;5;241m-\u001b[39m hi_arr\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/constant_op.py:102\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m    100\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m dtypes\u001b[38;5;241m.\u001b[39mas_dtype(dtype)\u001b[38;5;241m.\u001b[39mas_datatype_enum\n\u001b[1;32m    101\u001b[0m ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m--> 102\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mEagerTensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[0;31mInternalError\u001b[0m: Failed copying input tensor from /job:localhost/replica:0/task:0/device:CPU:0 to /job:localhost/replica:0/task:0/device:GPU:0 in order to run _EagerConst: Dst tensor is not initialized."
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "# Config\n",
        "num_samples = 250000\n",
        "use_gpu = True\n",
        "gpu_batch_size = 8\n",
        "\n",
        "# Beta\n",
        "beta = 1\n",
        "\n",
        "# Construccion de parametros y matrices auxiliares\n",
        "#rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "rho2kkbar_size = basis.m\n",
        "fund_size = basis.size\n",
        "hamil_base_size = basis.d*(basis.d+1)//2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_1_arrays_tf = tf.constant(rho_1_arrays, dtype=tf.float32)\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "rho_2_arrays_kkbar = rho_2_kkbar_gen(t_basis, rho_2_arrays)\n",
        "rho_2_arrays_kkbar_tf = tf.constant(rho_2_arrays_kkbar, dtype=tf.float32)\n",
        "k_indices = get_kkbar_indices(t_basis)\n",
        "k_indices_tf = gen_update_indices(t_basis, gpu_batch_size)\n",
        "\n",
        "# Generacion de hamiltoniano\n",
        "# (h0, hi) = two_body_hamiltonian(t_basis.size, basis.m, np.arange(0, basis.m), np.ones((basis.m,basis.m)), rho_1_arrays_tf, rho_2_arrays_tf) esto es para g cte\n",
        "\n",
        "\n",
        "if use_gpu:\n",
        "    print(tf.test.gpu_device_name())\n",
        "    datasets = []\n",
        "    for i in tqdm(range(num_samples//gpu_batch_size+1)):\n",
        "        size = basis.m*(basis.m+1)//2\n",
        "        # En una primera versión vamos a pasar una mat proporcional a range(0,m) para energias\n",
        "        en_batch = [np.arange(0, basis.m) for _ in range(0,gpu_batch_size)] \n",
        "        # Como interacción una matriz G semidefinida positiva\n",
        "        # Primero creamos las semillas, es decir, la diagonal superior de la matrix g\n",
        "        # Caso generico\n",
        "        #label_size = basis.m*(basis.m+1)// 2 # CASO GENERICO elementos independientes de una mat de m x m\n",
        "        #h_labels = [np.random.random(label_size) for _ in range(0,gpu_batch_size)] # TODO: Aumentar la amplitud de la interacción\n",
        "        # Construimos la mat G\n",
        "        #triag = tfp.math.fill_triangular(h_labels, upper=True)\n",
        "        #g_arr = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "        # Caso reducido\n",
        "        label_size = 2\n",
        "        h_labels = np.array([[np.random.random(), np.random.random()] for _ in range(0, gpu_batch_size)])\n",
        "        g_arr = gen_gauss_mat_np(h_labels[:,0], h_labels[:,1], basis.m)\n",
        "        h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "        g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "        # Construimos los hamiltonianos basados en g_arr\n",
        "        h_arr = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, g_arr.numpy(), rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "        # Estados térmicos\n",
        "        state = thermal_state_tf(h_arr*beta) \n",
        "        state = tf.cast(state, dtype=tf.float32)\n",
        "        # Estados puros\n",
        "        #state = pure_state(h_arr)\n",
        "        #rho_2_input = rho_2_tf(state, rho_2_arrays_tf)\n",
        "        rho_2_input = rho_2_tf(state, rho_2_arrays_kkbar_tf)\n",
        "\n",
        "        datasets.append(tf.data.Dataset.from_tensor_slices(((rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input, state), h_labels)))\n",
        "    ds = tf.data.Dataset.from_tensor_slices(datasets)\n",
        "    dataset = ds.interleave(\n",
        "        lambda x: x,\n",
        "        cycle_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "\n",
        "\n",
        "#batch_size = 32\n",
        "#dataset = dataset.shuffle(buffer_size=num_samples).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Filleo de dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Save and load dataset\n",
        "save_dataset = False\n",
        "load_dataset = False\n",
        "path = \"/home/agus/TF\"\n",
        "#num_samples = 5000000\n",
        "if save_dataset:\n",
        "    tf.data.Dataset.save(dataset, path)\n",
        "    with open(\"/home/agus/\"+'/file.pkl', 'wb') as file:\n",
        "        pickle.dump(beta_input, file)\n",
        "if load_dataset:\n",
        "    dataset = tf.data.Dataset.load(path)\n",
        "    with open(\"/home/agus/\"+'file.pkl', 'rb') as file:\n",
        "        beta_input = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8moZIlfabZuy"
      },
      "outputs": [],
      "source": [
        "# Dividimos los datasets\n",
        "train_size = int(0.8 * num_samples)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "\n",
        "batch_size = 256\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "#beta_val = beta_input[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Dataset Size: -2\n"
          ]
        }
      ],
      "source": [
        "# Cardinality no funciona con los datasets generados por GPU\n",
        "val_size = tf.data.experimental.cardinality(val_dataset).numpy()\n",
        "print(\"Validation Dataset Size:\", val_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYEEjNB-7b8y"
      },
      "source": [
        "### Definición de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8kkhJr5K0ZQ",
        "outputId": "f1b731f1-6a02-4181-f0b5-5677a2a85784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 10, 10, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 9, 9, 1024)        5120      \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 9, 9, 1024)        4096      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 8, 8, 992)         4064224   \n",
            "                                                                 \n",
            " batch_normalization_3 (Bat  (None, 8, 8, 992)         3968      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 7, 960)         3810240   \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 7, 7, 960)         3840      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 6, 6, 896)         3441536   \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 6, 6, 896)         3584      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_6 (Conv2D)           (None, 5, 5, 768)         2753280   \n",
            "                                                                 \n",
            " batch_normalization_6 (Bat  (None, 5, 5, 768)         3072      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 4, 4, 512)         1573376   \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 4, 4, 512)         2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 8192)              0         \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 2048)              16779264  \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 2)                 4098      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32451746 (123.79 MB)\n",
            "Trainable params: 32441442 (123.75 MB)\n",
            "Non-trainable params: 10304 (40.25 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Definicion de layers basado en Conv 2D\n",
        "\n",
        "# Factor de cantidad de filtros\n",
        "lf = 16 \n",
        "conv_limit = (rho2kkbar_size - 4)\n",
        "initial_dense = (lf*2**(conv_limit-1)*((rho2kkbar_size-(conv_limit-1))//2)**2)\n",
        "## rho 1\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(rho2kkbar_size,rho2kkbar_size, 1), name='rho2')\n",
        "\n",
        "# Procesamos el primer input\n",
        "conv_rho2 = tf.keras.layers.Conv2D(lf*2**conv_limit, (2, 2), activation='relu')(rho2_layer)\n",
        "conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "for j in [(2**conv_limit - 2**k) for k in range(1,conv_limit)]:\n",
        "    conv_rho2 = tf.keras.layers.Conv2D(lf*j, (2, 2), activation='relu')(conv_rho2 if 2**j != 1 else rho1_layer)\n",
        "    conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "\n",
        "#conv_rho2 = tf.keras.layers.MaxPooling2D((2, 2))(conv_rho2)\n",
        "\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(conv_rho2)\n",
        "#flatten_rho1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(flatten_rho1)\n",
        "\n",
        "#local_size = basis.size*basis.size\n",
        "local_size = label_size\n",
        "\n",
        "#dense1 = tf.keras.layers.Dense(8*8*4*4, activation='relu')(dense1)\n",
        "#dense1 = tf.keras.layers.Dense(512, activation='relu')(flatten_rho1)\n",
        "#dense1 = tf.keras.layers.Dense(128, activation='relu')(flatten_rho1)\n",
        "dense1 = tf.keras.layers.Dense(initial_dense, activation='relu')(flatten_rho2)\n",
        "#dense1 = tf.keras.layers.Dense(initial_dense//2, activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "\n",
        "\n",
        "# Creamos el modelo y compulamos\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer, fund_layer], outputs=output)\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer], outputs=output)\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZBtonvGbZuz",
        "outputId": "f197277e-a84b-4ffd-c81f-c81581707fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 10, 10, 1)]       0         \n",
            "                                                                 \n",
            " flatten_6 (Flatten)         (None, 100)               0         \n",
            "                                                                 \n",
            " concatenate_4 (Concatenate  (None, 100)               0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_20 (Dense)            (None, 42)                4242      \n",
            "                                                                 \n",
            " dense_21 (Dense)            (None, 64)                2752      \n",
            "                                                                 \n",
            " dense_22 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_23 (Dense)            (None, 2)                 258       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 15572 (60.83 KB)\n",
            "Trainable params: 15572 (60.83 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Modelo denso + fundamental\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(basis.m,basis.m, 1), name='rho2')\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#rho2_layer =  tf.keras.layers.Input(shape=(rho2_size,rho2_size, 1), name='rho2')\n",
        "#flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#fund_layer =  tf.keras.layers.Input(shape=(fund_size, fund_size, 1 ), name='fund')\n",
        "#flatten_fund = tf.keras.layers.Flatten()(fund_layer)\n",
        "\n",
        "dense1 = tf.keras.layers.concatenate([flatten_rho2])\n",
        "#dense1 = tf.keras.layers.concatenate([dense1, flatten_fund])\n",
        "#dense1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(dense1)\n",
        "\n",
        "local_size = label_size\n",
        "l=4\n",
        "layer_s = [64//i*2 for i in reversed(range(1,l))]\n",
        "for i in range(0,l-1):\n",
        "    dense1 = tf.keras.layers.Dense(layer_s[i], activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "# Creamos el modelo y compulamos\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RgoMlCyyfBe-"
      },
      "outputs": [],
      "source": [
        "# LOSS FUNCTIONS\n",
        "r_size = basis.size\n",
        "\n",
        "# Custom loss function based on GS MSE\n",
        "def gs_loss(h_pred, h_true):\n",
        "    h_pred = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_pred)\n",
        "    gs_pred = v[:, 0]\n",
        "\n",
        "    h_true = tf.reshape(h_true, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_true)\n",
        "    gs_true = v[:, 0]\n",
        "\n",
        "    gs_diff = tf.norm(gs_true - gs_pred)\n",
        "\n",
        "    return gs_diff + tf.reduce_mean(tf.square(h_true - h_pred)) * 100\n",
        "\n",
        "def distance_to_hermitian(matrix):\n",
        "    hermitian_part = 0.5 * (matrix + tf.linalg.adjoint(matrix))\n",
        "    distance = tf.norm(matrix - hermitian_part, ord='euclidean')\n",
        "    return distance\n",
        "\n",
        "# Custom loss function based on MSE + non-hermitian penalization\n",
        "def herm_loss(h_pred, h_true):\n",
        "    h_pred_arr = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred)) + distance_to_hermitian(h_pred_arr)\n",
        "\n",
        "# Custom loss function based on h eigenvalues\n",
        "def eig_loss(h_pred, h_true):\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# MSE with a factor\n",
        "def mse_f(h_pred, h_true):\n",
        "    f = 1000\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred))*f\n",
        "\n",
        "# Spectral radius loss\n",
        "def spectral_loss(h_pred, h_true):\n",
        "    eig = tf.math.real(tf.linalg.eigvals(tf.reshape(h_true-h_pred, (-1, fund_size, fund_size))))\n",
        "    return tf.math.reduce_max(tf.abs(eig))\n",
        "\n",
        "# Hamiltonian MSE loss (using generators)\n",
        "def base_mse_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    mat = tf.reshape(h_pred-h_true, (-1, fund_size, fund_size))\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on h eigenvalues (using generators)\n",
        "def base_eig_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals\n",
        "## Auxiliary function\n",
        "def base_to_rho_1_tf(base_pred):\n",
        "    h = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h = tf.reshape(h, (-1, fund_size, fund_size))\n",
        "    state = thermal_state_tf(h)\n",
        "    rho1 = rho_1_tf(state, rho_1_arrays_tf)\n",
        "    return rho1\n",
        "    \n",
        "def rho1_loss(base_pred, base_true):\n",
        "    mat = base_to_rho_1_tf(base_pred) - base_to_rho_1_tf(base_true)\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals (using generators)\n",
        "def base_rho1_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    return tf.reduce_mean(tf.square(rho_1_eig_tf(h_pred) - rho_1_eig_tf(h_true)))*1000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWk9piJtNIZ"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhJCHf0fQdRl",
        "outputId": "1821cf27-9ff5-4d67-e9f5-956d20eda5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-04 20:33:35.776332: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "782/782 [==============================] - 5s 5ms/step - loss: 0.0136 - accuracy: 0.9157 - mean_squared_error: 0.0136 - val_loss: 0.0150 - val_accuracy: 0.8981 - val_mean_squared_error: 0.0150\n",
            "Epoch 2/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0122 - accuracy: 0.9239 - mean_squared_error: 0.0122 - val_loss: 0.0170 - val_accuracy: 0.9127 - val_mean_squared_error: 0.0170\n",
            "Epoch 3/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0119 - accuracy: 0.9250 - mean_squared_error: 0.0119 - val_loss: 0.0150 - val_accuracy: 0.9129 - val_mean_squared_error: 0.0150\n",
            "Epoch 4/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0119 - accuracy: 0.9249 - mean_squared_error: 0.0119 - val_loss: 0.0144 - val_accuracy: 0.9160 - val_mean_squared_error: 0.0144\n",
            "Epoch 5/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0118 - accuracy: 0.9247 - mean_squared_error: 0.0118 - val_loss: 0.0156 - val_accuracy: 0.9158 - val_mean_squared_error: 0.0156\n",
            "Epoch 6/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0118 - accuracy: 0.9255 - mean_squared_error: 0.0118 - val_loss: 0.0117 - val_accuracy: 0.9226 - val_mean_squared_error: 0.0117\n",
            "Epoch 7/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0117 - accuracy: 0.9258 - mean_squared_error: 0.0117 - val_loss: 0.0161 - val_accuracy: 0.9134 - val_mean_squared_error: 0.0161\n",
            "Epoch 8/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0118 - accuracy: 0.9253 - mean_squared_error: 0.0118 - val_loss: 0.0123 - val_accuracy: 0.9151 - val_mean_squared_error: 0.0123\n",
            "Epoch 9/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0117 - accuracy: 0.9265 - mean_squared_error: 0.0117 - val_loss: 0.0141 - val_accuracy: 0.9137 - val_mean_squared_error: 0.0141\n",
            "Epoch 10/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0116 - accuracy: 0.9268 - mean_squared_error: 0.0116 - val_loss: 0.0135 - val_accuracy: 0.9067 - val_mean_squared_error: 0.0135\n",
            "Epoch 11/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0116 - accuracy: 0.9268 - mean_squared_error: 0.0116 - val_loss: 0.0153 - val_accuracy: 0.9162 - val_mean_squared_error: 0.0153\n",
            "Epoch 12/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0117 - accuracy: 0.9262 - mean_squared_error: 0.0117 - val_loss: 0.0135 - val_accuracy: 0.9037 - val_mean_squared_error: 0.0135\n",
            "Epoch 13/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0115 - accuracy: 0.9271 - mean_squared_error: 0.0115 - val_loss: 0.0153 - val_accuracy: 0.9140 - val_mean_squared_error: 0.0153\n",
            "Epoch 14/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0116 - accuracy: 0.9269 - mean_squared_error: 0.0116 - val_loss: 0.0141 - val_accuracy: 0.9162 - val_mean_squared_error: 0.0141\n",
            "Epoch 15/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0117 - accuracy: 0.9262 - mean_squared_error: 0.0117 - val_loss: 0.0115 - val_accuracy: 0.9178 - val_mean_squared_error: 0.0115\n",
            "Epoch 16/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0115 - accuracy: 0.9280 - mean_squared_error: 0.0115 - val_loss: 0.0115 - val_accuracy: 0.9129 - val_mean_squared_error: 0.0115\n",
            "Epoch 17/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0115 - accuracy: 0.9268 - mean_squared_error: 0.0115 - val_loss: 0.0113 - val_accuracy: 0.9223 - val_mean_squared_error: 0.0113\n",
            "Epoch 18/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0115 - accuracy: 0.9273 - mean_squared_error: 0.0115 - val_loss: 0.0114 - val_accuracy: 0.9221 - val_mean_squared_error: 0.0114\n",
            "Epoch 19/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0113 - accuracy: 0.9278 - mean_squared_error: 0.0113 - val_loss: 0.0134 - val_accuracy: 0.9276 - val_mean_squared_error: 0.0134\n",
            "Epoch 20/20\n",
            "782/782 [==============================] - 4s 5ms/step - loss: 0.0114 - accuracy: 0.9291 - mean_squared_error: 0.0114 - val_loss: 0.0120 - val_accuracy: 0.9278 - val_mean_squared_error: 0.0120\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam, Lion\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='MSE',  \n",
        "              metrics=['accuracy', 'mean_squared_error'])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 20\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    history = model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)\n",
        "\n",
        "# Dense: 1.3\n",
        "# CNN: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "cvpE_X1iTXcB",
        "outputId": "eff0e5f5-5b26-46ea-ec6b-491d1de9944c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkgAAAHHCAYAAABEEKc/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAACSXklEQVR4nO3deZhT1fnA8W8y+z4wW4Z12PddQJCKC7JoVdxAVBZFaVWslmoVawFLf6Vad7FSrYC2RRErlLpgEcUFUBQYAVlkX2dhGJh9Te7vjzs3k8xkhmQmyb3JvJ/nyZOb5OTmXMIwL+e85z0mRVEUhBBCCCGEnVnvDgghhBBCGI0ESEIIIYQQdUiAJIQQQghRhwRIQgghhBB1SIAkhBBCCFGHBEhCCCGEEHVIgCSEEEIIUYcESEIIIYQQdUiAJIQQQghRhwRIQggR5C677DL69u2rdzeECCgSIAkh3LZ8+XJMJhMmk4mvv/663uuKotC+fXtMJhM///nPnV4rLi5m/vz59O3bl5iYGJKSkhg4cCAPPvggp0+ftrdbsGCB/TNc3bKzs31+nZ667LLLGuxvz5499e6eEKIJQvXugBAi8ERGRrJixQpGjRrl9PwXX3zByZMniYiIcHq+qqqKSy+9lH379jF9+nQeeOABiouL+fHHH1mxYgU33HADbdq0cXrPq6++SmxsbL3PTkxM9Pr1eEO7du1YtGhRvecTEhJ06I0QorkkQBJCeOzqq69m1apVvPTSS4SG1v4zsmLFCoYMGUJeXp5T+zVr1rBjxw7+9a9/cdtttzm9Vl5eTmVlZb3PuPnmm0lOTvbNBfhAQkICd9xxh97dEEJ4iUyxCSE8NmXKFM6ePcv69evtz1VWVvLee+/VC4AADh06BMAll1xS77XIyEji4+O90q++ffty+eWX13veZrPRtm1bbr75Zvtz77zzDkOGDCEuLo74+Hj69evHiy++6JV+NESbPty3bx+TJk0iPj6epKQkHnzwQcrLy53aVldXs3DhQrp06UJERAQZGRk8/vjjVFRU1Dvvxx9/zOjRo+3XMnToUFasWFGv3Z49e7j88suJjo6mbdu2PP300z67ViECnQRIQgiPZWRkMGLECN5++237cx9//DEFBQXceuut9dp37NgRgLfeegtFUdz6jPz8fPLy8pxu58+fb/Q9kydP5ssvv6yXp/T1119z+vRpe9/Wr1/PlClTaNWqFU899RR//vOfueyyy9i0aZNbfXPFarXW629eXh4lJSX12k6aNIny8nIWLVrE1VdfzUsvvcSsWbOc2tx9993MmzePwYMH8/zzzzN69GgWLVpU7893+fLlXHPNNeTn5zN37lz+/Oc/M3DgQNatW+fU7ty5c4wfP54BAwbw7LPP0rNnTx599FE+/vjjJl+zEEFNEUIINy1btkwBlO+++05ZvHixEhcXp5SWliqKoii33HKLcvnllyuKoigdO3ZUrrnmGvv7SktLlR49eiiA0rFjR2XGjBnKG2+8oeTk5NT7jPnz5yuAy1uPHj0a7d/+/fsVQHn55Zednr/vvvuU2NhYe18ffPBBJT4+Xqmurm7Wn4dm9OjRDfb5F7/4Rb1ru+666+r1D1B++OEHRVEUJTMzUwGUu+++26ndww8/rADKZ599piiKopw/f16Ji4tThg8frpSVlTm1tdls9fr31ltv2Z+rqKhQLBaLctNNN3nlz0CIYCMjSEKIJpk0aRJlZWV88MEHFBUV8cEHH7icXgOIiori22+/5ZFHHgHUUY+ZM2eSnp7OAw884HLa6N///jfr1693ui1btqzRPnXv3p2BAweycuVK+3NWq5X33nuPa6+9lqioKEBN9C4pKXGaImyujIyMev1dv349Dz30UL22999/v9PjBx54AICPPvrI6X7OnDlO7X7zm98A8OGHHwLqSFhRURGPPfYYkZGRTm1NJpPT49jYWKccqfDwcIYNG8bhw4c9vVQhWgRJ0hZCNElKSgpjxoxhxYoVlJaWYrVanXJ86kpISODpp5/m6aef5tixY2zYsIFnnnmGxYsXk5CQwB//+Een9pdeemmTkrQnT57M448/zqlTp2jbti0bN24kNzeXyZMn29vcd999vPvuu0yYMIG2bdsyduxYJk2axPjx4z3+PE1MTAxjxoxxq223bt2cHnfp0gWz2czRo0cBOHbsGGazma5duzq1s1gsJCYmcuzYMaA2t8udGkft2rWrFzS1atWKnTt3utVnIVoaGUESQjTZbbfdxscff8ySJUuYMGGC20vwO3bsyF133cWmTZtITEzkX//6l9f6NHnyZBRFYdWqVQC8++67JCQkOAU/qampZGZmsnbtWq677jo+//xzJkyYwPTp073WD0/UDVwu9HxThISEuHxecTMnTIiWRgIkIUST3XDDDZjNZr755psGp9ca06pVK7p06UJWVpbX+tSpUyeGDRvGypUrqa6u5v3332fixIn1ajOFh4dz7bXX8te//pVDhw7xi1/8grfeeouDBw96rS8NOXDggNPjgwcPYrPZyMjIANQA0maz1WuXk5PD+fPn7UnvXbp0AWD37t0+77MQLY0ESEKIJouNjeXVV19lwYIFXHvttQ22++GHH+rVRgJ1KmnPnj306NHDq/2aPHky33zzDUuXLiUvL89peg3g7NmzTo/NZjP9+/cHsOdDVVVVsW/fPq8Gb5pXXnnF6fHLL78MwIQJEwC1zhTACy+84NTuueeeA+Caa64BYOzYscTFxbFo0aJ6ZQJkZEiI5pEcJCFEs7gzLbV+/Xrmz5/Pddddx8UXX0xsbCyHDx9m6dKlVFRUsGDBgnrvee+991xW0r7qqqtIS0tr9PMmTZrEww8/zMMPP0zr1q3r5Qbdfffd5Ofnc8UVV9CuXTuOHTvGyy+/zMCBA+nVqxcAp06dolevXkyfPp3ly5df8BoLCgr45z//6fK1ugUkjxw5wnXXXcf48ePZsmUL//znP7ntttsYMGAAAAMGDGD69Om89tprnD9/ntGjR7N161befPNNJk6caK/1FB8fz/PPP8/dd9/N0KFDue2222jVqhU//PADpaWlvPnmmxfstxDCNQmQhBA+d9NNN1FUVMT//vc/PvvsM/Lz82nVqhXDhg3jN7/5jcvijvfee6/Lc33++ecXDJDatWvHyJEj2bRpE3fffTdhYWFOr99xxx289tpr/PWvf+X8+fNYLBYmT57MggULMJubNrB+8uRJpk6d6vK1ugHSypUrmTdvHo899hihoaHMnj2bv/zlL05t/v73v9O5c2eWL1/O6tWrsVgszJ07l/nz5zu1mzlzJqmpqfz5z39m4cKFhIWF0bNnT37961836TqEECqTIuOwQgjhFwsWLODJJ5/kzJkzAbWNihAtkeQgCSGEEELUIQGSEEIIIUQdEiAJIYQQQtQhOUhCCCGEEHXICJIQQgghRB0SIAkhhBBC1CF1kJrIZrNx+vRp4uLivLpfkhBCCCF8R1EUioqKaNOmTaN1zyRAaqLTp0/Tvn17vbshhBBCiCY4ceIE7dq1a/B1CZCaKC4uDlD/gOPj43XujRBCCCHcUVhYSPv27e2/xxsiAVITadNq8fHxEiAJIYQQAeZC6TGSpC2EEEIIUYcESEIIIYQQdUiAJIQQQghRh+QgCSGE0I3VaqWqqkrvboggEhYWRkhISLPPIwGSEEIIv1MUhezsbM6fP693V0QQSkxMxGKxNKtOoQRIQggh/E4LjlJTU4mOjpaCu8IrFEWhtLSU3NxcANLT05t8LgmQhBBC+JXVarUHR0lJSXp3RwSZqKgoAHJzc0lNTW3ydJskaQshhPArLecoOjpa556IYKX93WpOfpsESEIIIXQh02rCV7zxd0sCJCGEEEKIOgwRIL3yyitkZGQQGRnJ8OHD2bp1a6PtV61aRc+ePYmMjKRfv3589NFHTq+///77jB07lqSkJEwmE5mZmU6vHz16FJPJ5PK2atUqb1+eEEII0aCMjAxeeOEFt9tv3LgRk8kkKwB9TPcAaeXKlcyZM4f58+ezfft2BgwYwLhx4+wZ6HVt3ryZKVOmMHPmTHbs2MHEiROZOHEiu3fvtrcpKSlh1KhRPPXUUy7P0b59e7KyspxuTz75JLGxsUyYMMEn1ymEECKwNfQfa+22YMGCJp33u+++Y9asWW63HzlyJFlZWSQkJDTp89ylBWKtWrWivLzc6bXvvvvOft2OXn/9dQYMGEBsbCyJiYkMGjSIRYsW2V9fsGCByz+7nj17+vRamkL3VWzPPfcc99xzD3feeScAS5Ys4cMPP2Tp0qU89thj9dq/+OKLjB8/nkceeQSAhQsXsn79ehYvXsySJUsAmDp1KqCOFLkSEhKCxWJxem716tVMmjSJ2NhYb12aMSmKejPrHhsLIURAycrKsh+vXLmSefPmsX//fvtzjr8/FEXBarUSGnrhX7MpKSke9SM8PLze7zBfiouLY/Xq1UyZMsX+3BtvvEGHDh04fvy4/bmlS5fy0EMP8dJLLzF69GgqKirYuXOn0wAGQJ8+ffj000+dnnPnz8nfdP0tWVlZybZt2xgzZoz9ObPZzJgxY9iyZYvL92zZssWpPcC4ceMabO+Obdu2kZmZycyZM5t8joDx75nwly5QlKN3T4QQIqBYLBb7LSEhAZPJZH+8b98+4uLi+PjjjxkyZAgRERF8/fXXHDp0iOuvv560tDRiY2MZOnRoveCg7hSbyWTi73//OzfccAPR0dF069aNtWvX2l+vO8W2fPlyEhMT+eSTT+jVqxexsbGMHz/eKaCrrq7mV7/6FYmJiSQlJfHoo48yffp0Jk6ceMHrnj59OkuXLrU/Lisr45133mH69OlO7dauXcukSZOYOXMmXbt2pU+fPkyZMoX/+7//c2oXGhrq9GdpsVhITk6+YD/8TdcAKS8vD6vVSlpamtPzaWlpZGdnu3xPdna2R+3d8cYbb9CrVy9GjhzZYJuKigoKCwudbgGnugL2rIWyfDi8Ue/eCCGEnaIolFZW63JTFMVr1/HYY4/x5z//mb1799K/f3+Ki4u5+uqr2bBhAzt27GD8+PFce+21TiMvrjz55JNMmjSJnTt3cvXVV3P77beTn5/fYPvS0lKeeeYZ/vGPf/Dll19y/PhxHn74YfvrTz31FP/6179YtmwZmzZtorCwkDVr1rh1TVOnTuWrr76y9/nf//43GRkZDB482KmdxWLhm2++4dixY26d1+iMN6blZ2VlZaxYsYLf//73jbZbtGgRTz75pJ965SM5u8FWUxPi9A4YMFnf/gghRI2yKiu9532iy2fv+cM4osO98+vwD3/4A1dddZX9cevWrRkwYID98cKFC1m9ejVr165l9uzZDZ5nxowZ9imtP/3pT7z00kts3bqV8ePHu2xfVVXFkiVL6NKlCwCzZ8/mD3/4g/31l19+mblz53LDDTcAsHjx4noLnBqSmprKhAkTWL58OfPmzWPp0qXcdddd9drNnz+fG2+8kYyMDLp3786IESO4+uqrufnmmzE7pHXs2rWrXjrLHXfcYU+TMQpdR5CSk5MJCQkhJ8d5uicnJ6fB+VWLxeJR+wt57733KC0tZdq0aY22mzt3LgUFBfbbiRMnmvR5ujq9w+F4u379EEKIIHXRRRc5PS4uLubhhx+mV69eJCYmEhsby969ey84gtS/f3/7cUxMDPHx8Q0uXgK1MKIWHIG6xYbWvqCggJycHIYNG2Z/PSQkhCFDhrh9XXfddRfLly/n8OHDbNmyhdtvv71em/T0dLZs2cKuXbt48MEHqa6uZvr06YwfPx6bzWZv16NHDzIzM51ujsGcUeg6ghQeHs6QIUPYsGGDfR7UZrOxYcOGBiPrESNGsGHDBh566CH7c+vXr2fEiBFN6sMbb7zBddddd8EkuYiICCIiIpr0GYbhGCBl7QRrNYS0+EFEIYQBRIWFsOcP43T7bG+JiYlxevzwww+zfv16nnnmGbp27UpUVBQ333wzlZWVjZ4nLCzM6bHJZHIKMtxp782pwwkTJjBr1ixmzpzJtdde2+gWMX379qVv377cd999/PKXv+RnP/sZX3zxBZdffjmg/u7v2rWr1/rmK7r/dpwzZw7Tp0/noosuYtiwYbzwwguUlJTYV7VNmzaNtm3b2pcJPvjgg4wePZpnn32Wa665hnfeeYfvv/+e1157zX7O/Px8jh8/zunTpwHsqwy0ZDDNwYMH+fLLL90eZgx4pxwCpOoyyNsPaX30648QQtQwmUxem+Yykk2bNjFjxgz71FZxcXGDK6x9JSEhgbS0NL777jsuvfRSQN0Pb/v27QwcONCtc4SGhjJt2jSefvppPv74Y7c/u3fv3oBafifQ6P63cfLkyZw5c4Z58+aRnZ3NwIEDWbdunT0R+/jx405zlyNHjmTFihU88cQTPP7443Tr1o01a9bQt29fe5u1a9faAyyAW2+9FVDnRx3rVCxdupR27doxduxYH1+lAVSWwpm96nFSVzh7EE5tlwBJCCF8qFu3brz//vtce+21mEwmfv/73zc6EuQrDzzwAIsWLaJr16707NmTl19+mXPnznm0JcfChQt55JFHGhw9uvfee2nTpg1XXHEF7dq1Iysriz/+8Y+kpKQ4zfJUV1fXW1hlMpnqLcDSm+4BEqjJZA1NqW3cuLHec7fccgu33HJLg+ebMWMGM2bMuODn/ulPf+JPf/qTu90MbNm7QLFBrAV6TIDNL6tTboOn6t0zIYQIWs899xx33XUXI0eOJDk5mUcffVSXVdCPPvoo2dnZTJs2jZCQEGbNmsW4ceM82uk+PDy80eX4Y8aMYenSpbz66qucPXuW5ORke1qMY1D1448/kp6e7vTeiIiIesUo9WZSvDlJ2YIUFhaSkJBAQUEB8fHxenfnwr55FdY9Bt0nQP9J8N6d0GYwzPpc754JIVqY8vJyjhw5QqdOnYiMjNS7Oy2SzWajV69eTJo0iYULF+rdHa9r7O+Yu7+/DTGCJPxAS9BuOxjaDFKPc3ZDdSWEhuvXLyGEED537Ngx/ve//9krXC9evJgjR45w22236d01w5L9JloKLUBqMwhaZUBUK7BWQu6PunZLCCGE75nNZpYvX87QoUO55JJL2LVrF59++im9evXSu2uGJSNILUF5IeQdUI/bDAKTSb0/9JmaqK2NKAkhhAhK7du3Z9OmTXp3I6DICFJLkPUDoEBCB4ipSbDTgiLH2khCCCGEACRAahns02sDa59rU7OHzulMf/dGCCGEMDwJkFoCx/wjjXacu0etkSSEEEIIOwmQWgJXAVJ8G4hJBcWqrmYTQgghhJ0ESMGuNB/OHVGPHafYTCZ1yT9IHpIQQghRhwRIwS4rU71v3Vld2u9IG1E6td2vXRJCCCGMTgKkYOdqek0jK9mEEMLvLrvsMh566CH744yMDF544YVG32MymVizZk2zP9tb52kJJEAKdtroUGMBUt5PUFHkvz4JIUQAuvbaaxk/frzL17766itMJhM7d+70+Lzfffcds2bNam73nCxYsICBAwfWez4rK4sJEyZ49bPqWr58OSaTyWURylWrVmEymcjIyLA/Z7Va+fOf/0zPnj2JioqidevWDB8+nL///e/2NjNmzMBkMtW7NfR9eIMUigx22jJ+bVm/o9hUiG8HhSfVWkkZo/zaNSGECCQzZ87kpptu4uTJk7Rr187ptWXLlnHRRRfRv39/j8+bkpLirS5ekMVi8cvnxMTEkJuby5YtWxgxYoT9+TfeeIMOHTo4tX3yySf529/+xuLFi7nooosoLCzk+++/59y5c07txo8fz7Jly5yei4iI8Nk1yAhSMCvOVYMfTJDewA+tlrgt02xCCNGon//856SkpLB8+XKn54uLi1m1ahUzZ87k7NmzTJkyhbZt2xIdHU2/fv14++23Gz1v3Sm2AwcOcOmllxIZGUnv3r1Zv359vfc8+uijdO/enejoaDp37szvf/97qqqqAHUE58knn+SHH36wj7Rofa47xbZr1y6uuOIKoqKiSEpKYtasWRQXF9tfnzFjBhMnTuSZZ54hPT2dpKQk7r//fvtnNSQ0NJTbbruNpUuX2p87efIkGzdurLf/29q1a7nvvvu45ZZb6NSpEwMGDGDmzJk8/PDDTu0iIiKwWCxOt1at6uTWepEESMFMGz1K7g4Rca7baCvZJFFbCKEnRYHKEn1uiuJWF0NDQ5k2bRrLly9HcXjPqlWrsFqtTJkyhfLycoYMGcKHH37I7t27mTVrFlOnTmXr1q1ufYbNZuPGG28kPDycb7/9liVLlvDoo4/WaxcXF8fy5cvZs2cPL774Iq+//jrPP/88AJMnT+Y3v/kNffr0ISsri6ysLCZPnlzvHCUlJYwbN45WrVrx3XffsWrVKj799FNmz57t1O7zzz/n0KFDfP7557z55pssX768XpDoyl133cW7775Laalaa2/58uWMHz+etLQ0p3YWi4XPPvuMM2fOuPVn5C8yxRbMTjeSf6SRRG0hhBFUlcKf2ujz2Y+fhvAYt5redddd/OUvf+GLL77gsssuA9TptZtuuomEhAQSEhKcRj4eeOABPvnkE959912GDRt2wfN/+umn7Nu3j08++YQ2bdQ/jz/96U/18oaeeOIJ+3FGRgYPP/ww77zzDr/97W+JiooiNjaW0NDQRqfUVqxYQXl5OW+99RYxMer1L168mGuvvZannnrKHsi0atWKxYsXExISQs+ePbnmmmvYsGED99xzT6PXMmjQIDp37sx7773H1KlTWb58Oc899xyHDx92avfcc89x8803Y7FY6NOnDyNHjuT666+vd80ffPABsbGxTs89/vjjPP744432o6lkBCmYaUFPWxf5RxotQDp3RK2ZJIQQokE9e/Zk5MiR9qmjgwcP8tVXXzFz5kxATTheuHAh/fr1o3Xr1sTGxvLJJ59w/Phxt86/d+9e2rdvbw+OAKccHs3KlSu55JJLsFgsxMbG8sQTT7j9GY6fNWDAAHtwBHDJJZdgs9nYv3+//bk+ffoQEhJif5yenk5ubq5bn3HXXXexbNkyvvjiC0pKSrj66qvrtenduze7d+/mm2++4a677iI3N5drr72Wu+++26nd5ZdfTmZmptPtl7/8pUfX7AkZQQpWitL4En9NVCto1UkNkLIyocsVfumeEEI4CYtWR3L0+mwPzJw5kwceeIBXXnmFZcuW0aVLF0aPHg3AX/7yF1588UVeeOEF+vXrR0xMDA899BCVlZVe6+6WLVu4/fbbefLJJxk3bhwJCQm88847PPvss177DEdhYWFOj00mEzabza333n777fz2t79lwYIFTJ06ldBQ12GH2Wxm6NChDB06lIceeoh//vOfTJ06ld/97nd06tQJUBO/u3bt2ryL8YAESMGqKAuKc8AUAml9G2/bZpAaIJ3eIQGSEEIfJpPb01x6mzRpEg8++CArVqzgrbfe4t5778VkMgGwadMmrr/+eu644w5AzSn66aef6N27t1vn7tWrFydOnCArK4v09HQAvvnmG6c2mzdvpmPHjvzud7+zP3fs2DGnNuHh4Vit1gt+1vLlyykpKbGPIm3atAmz2UyPHj3c6u+FtG7dmuuuu453332XJUuWuP0+7c+rpKTEK/1oCpliC1Za0nVqLwi/wP+OJFFbCCHcFhsby+TJk5k7dy5ZWVnMmDHD/lq3bt1Yv349mzdvZu/evfziF78gJyfH7XOPGTOG7t27M336dH744Qe++uorp0BI+4zjx4/zzjvvcOjQIV566SVWr17t1CYjI4MjR46QmZlJXl4eFRUV9T7r9ttvJzIykunTp7N7924+//xzHnjgAaZOnVovkbo5li9fTl5eHj179nT5+s0338zzzz/Pt99+y7Fjx9i4cSP3338/3bt3d3pPRUUF2dnZTre8vDyv9bMuCZCClTvTaxp7onamz7ojhBDBZObMmZw7d45x48Y55Qs98cQTDB48mHHjxnHZZZdhsViYOHGi2+c1m82sXr2asrIyhg0bxt13383//d//ObW57rrr+PWvf83s2bMZOHAgmzdv5ve//71Tm5tuuonx48dz+eWXk5KS4rLUQHR0NJ988gn5+fkMHTqUm2++mSuvvJLFixd79odxAVoJgYaMGzeO//73v1x77bX24LBnz57873//c5qSW7duHenp6U63UaN8V7/PpChurm8UTgoLC0lISKCgoID4+Hi9u1PfP26EQxvgmudg6MzG21YUwaL2gAIPH1ALSAohhI+Ul5dz5MgROnXqRGRkpN7dEUGosb9j7v7+lhGkYKQo7i3x10TEqbWSQJb7CyGEEEiAFJzOH4OycxASDml93HuP1EMSQggh7CRACkZakJPWB0Ld3KdGErWFEEIIOwmQgpEnCdoaxxEkSUsTQgjRwkmAFIxOeZB/pEnrq9ZMKsmFQp2KtQkhWhRZIyR8xRt/tyRACjY2G2T9oB63aWSLkbrCoyG1ppDZaZlmE0L4jlaZWdvEVAhv0/5u1a0C7gmppB1s8g9DRSGERkKK66JcDWozEHJ2qdNsva71SfeEECIkJITExET7fl7R0dH2StRCNIeiKJSWlpKbm0tiYqLTHnKekgAp2Gj5R5b+EOLh19tmEOz4h6xkE0L4nLbLvLubngrhicTERPvfsaaSACnYeFL/qC5tJZuWqC3/oxNC+IjJZCI9PZ3U1FSqqqr07o4IImFhYc0aOdJIgBRstNGfth7kH2lS+6i1k8rOwbmj0LqTV7smhBB1hYSEeOWXmRDeJknawcRmdUjQbsIIUmi4upoNJFFbCCFEiyYBUjA5sx+qSiE8FpK6Nu0cUlFbCCGEkAApqGhBTfoAMDdxyNoeIGV6pUtCCCFEIJIAKZg0pYJ2XfZE7Uy1ppIQQgjRAkmAFEy8ESAl94DQKKgsgrMHvdMvIYQQIsBIgBQsqishe5d63JwAKSQU0vurx5KHJIQQooWSAClYnNkL1gqITIDWnZt3Lm2LElnJJoQQooWSAClYOE6vNbfAo6xkE0II0cJJgBQsvJF/pNHOkbUTrNXNP58QQggRYCRAChanmrHFSF1JXSE8DqrL4My+5p9PCCGECDASIAWDqnLI3aMeeyNAMpuhzUD1WKbZhBBCtEASIAWDnB/BVg3RyZDQ3jvntOchSaK2EEKIlkcCpGBw2mF6rbkJ2hpJ1BZCCNGCSYAUDLyZoK3RzpW9G6orvHdeIYQQIgBIgBQMtABJ2ybEG1plQFQrsFWpU3hCCCFECyIBUqCrLKldaZY+0HvnNZlkmk0IIUSLpXuA9Morr5CRkUFkZCTDhw9n69atjbZftWoVPXv2JDIykn79+vHRRx85vf7+++8zduxYkpKSMJlMZGZmujzPli1buOKKK4iJiSE+Pp5LL72UsrIyb12W/2TtBMUGcekQn+7dc0uidmA5/AWcPaR3L4QQIijoGiCtXLmSOXPmMH/+fLZv386AAQMYN24cubm5Lttv3ryZKVOmMHPmTHbs2MHEiROZOHEiu3fvtrcpKSlh1KhRPPXUUw1+7pYtWxg/fjxjx45l69atfPfdd8yePRuzWfd40XO+yD/S2LccyfT+uYV3nT0Eb10HK6fq3RMhhAgKJkVRFL0+fPjw4QwdOpTFixcDYLPZaN++PQ888ACPPfZYvfaTJ0+mpKSEDz74wP7cxRdfzMCBA1myZIlT26NHj9KpUyd27NjBwIEDnV67+OKLueqqq1i4cGGT+15YWEhCQgIFBQXEx8c3+TzN9u97YNe7cPkTMPoR75674BQ83xtMITD3JIRHe/f8wnsOrId/3QzmMHgiV61lJYQQoh53f3/r9q9oZWUl27ZtY8yYMbWdMZsZM2YMW7ZscfmeLVu2OLUHGDduXIPtXcnNzeXbb78lNTWVkSNHkpaWxujRo/n666+bdiF68+UIUnwbiE0DxQrZu7x/fuE9xTnqva0KSs/q2xchhAgCugVIeXl5WK1W0tLSnJ5PS0sjOzvb5Xuys7M9au/K4cOHAViwYAH33HMP69atY/DgwVx55ZUcOHCgwfdVVFRQWFjodNNdeQGcremzVvnamyRRO3BoARJA0Wn9+iGEEEGixY3D22w2AH7xi19w5513MmjQIJ5//nl69OjB0qVLG3zfokWLSEhIsN/at/dSxermyPpBvU/oADHJvvkMCZACQ7FD3l5hln79EEKIIKFbgJScnExISAg5OTlOz+fk5GCxWFy+x2KxeNTelfR0daVX7969nZ7v1asXx48fb/B9c+fOpaCgwH47ceKE25/pM/b6Rz6YXtPYE7VlJZuhOQVIp/TrhxBCBAndAqTw8HCGDBnChg0b7M/ZbDY2bNjAiBEjXL5nxIgRTu0B1q9f32B7VzIyMmjTpg379+93ev6nn36iY8eODb4vIiKC+Ph4p5vufJl/pNGm7vIOQLkBphWFa44BUpGMIAkhRHOF6vnhc+bMYfr06Vx00UUMGzaMF154gZKSEu68804Apk2bRtu2bVm0aBEADz74IKNHj+bZZ5/lmmuu4Z133uH777/ntddes58zPz+f48ePc/q0moehBUIWiwWLxYLJZOKRRx5h/vz5DBgwgIEDB/Lmm2+yb98+3nvvPT//CTTTKYc92HwlNhXi20HhSXVKr9PPfPdZoukcc5Bkik0IIZpN1wBp8uTJnDlzhnnz5pGdnc3AgQNZt26dPRH7+PHjTrWJRo4cyYoVK3jiiSd4/PHH6datG2vWrKFv3772NmvXrrUHWAC33norAPPnz2fBggUAPPTQQ5SXl/PrX/+a/Px8BgwYwPr16+nSpYsfrtpLSvPh/DH12JsVtF1pO0gNkE7vkADJqEpkik0IIbxJ1zpIgUz3OkgHN8A/b4TWXeBXPs4P+upZ2PAH6HMj3LLMt58lPFdVDv/nsLozpSfc/61+/RFCCAMzfB0k0Uyn/TC9ppEtR4ytpE7leZliE0KIZpMAKVBp23/4M0A6d1Sd2hPGUnxGvY9MVO8rCqCiWLfuCCFEMJAAKVD5YwWbJqoVtOrk/LnCOLQE7aQuEB6nHstKNiGEaBYJkAJRUU5NIq4J0gf45zPbavWQJEAyHC1AiklVt4cBKJRq2kII0RwSIAUiLUhJ6QERsf75TKmobVxaDaTYVIhXC6HKCJIQQjSPrsv8RRP5c3pNIwGScWlJ2rFpYK1Sj2WpvxBCNIuMIAUie4A02H+fmT4AMKm/eItyLthc+JE2xeY4giQr2YQQolkkQAo0iqLPCFJEHCR3V4+zMv33ueLCnKbYanKQZIpNCCGaRQKkQFN4Sp1SMYWApe+F23uTFpCdknpIhlLsMMUWpyVpyxSbEEI0hwRIgUYbPUrtDWFR/v1sWclmTFqAFJMiU2xCCOElkqQdaLTgpK0fp9c0jhW1FQVMJv/3QTirKIaqEvU4Nk2dCgU1L8laBSFh+vVNCCECmIwgBZpTftxipC5LP3Vqr+SMTOEYhbaCLSxGLfkQnQzmMECpTd4WQgjhMQmQAoleCdqasCh1ag9kms0oHBO0AcxmiLOoxzLNJoQQTSYBUiA5dxTKz0NIOKT20acPbQaq95KobQyOS/w19pVsUk1bCCGaSgKkQKKN2qT1hdBwffogidrGUncECSBOS9SWAEkIIZpKAqRAclrH/CONY0VtRdGvH0LluMRfI/uxCSFEs0mAFEhOZ6r3egZIqX3UKb7y83DuiH79ECrHjWo1UixSCCGaTQKkQGGzGSNACg1Xp/hAptmMoNEpNgmQhBCiqSRAChT5h6CyCEKjIKWnvn0J1ora+Ydh41NQWap3T9xX0tgUm5RiEEKIppJCkYFCC0bS+0OIzl+bPQ8pU9dueN1/ZsOxTRCTDENn6t0b97jKQdJGkIqypKCnEEI0kYwgBQo96x/Vpa1ky8pUp/6CwfnjanAEcP6Yvn1xl+JQDDI2pfZ5LUCqLoeyc/7vlxBCBAEJkAKFkQKk5B7qVF9lMZw9oHdvvGPXe7XHgZK7U14A1kr12DFJOywSopPUY1nJJoQQTSIBUiCwVkPWD+pxm8H69gXUKb70AepxMCRqKwrsfLf2caCs/tKm1yIT1KDIUZysZBNCiOaQACkQ5O2H6jIIj4Wkrnr3RuVYDynQ5eyGM3trHwdKUOFqib9GaiEJIUSzSIAUCLQgJH2guteWEQTTSradK9V7rXxBYVZgFMG05x+l1X8tXqppCyFEcxjkt61olD3/aKCu3XCiJWpn71SnAAOVzQq7/q0ej/yVel9VAhWF+vXJXSVn1PtYFyNIcbIfmxBCNIcESIFAG6Vpa4D8I03rLhAep66UcpyeCjTHNqlBRGQC9JkIEQnq80XZunbLLa42qtXYp9gCZLpQCCEMRgIko6uuVHNkwBgr2DRmc+2IViDnIWnTa70nQmhEYE1NuaqirYl3qIUkhBDCYxIgGV3uHnUpd2QitOqkd2+cBXqidlU57FmrHvefpN7HBVBg4apIpCZOqmkLIURzSIBkdI71j4xWETnQE7V/WqfmGsW3gw4j1ecCKkByI0m77BxUlfmvT0IIESQkQDK60zXBh5Gm1zRaTlTOj1BdoW9fmmLXKvW+3821qwPjA2ijV20EKSal/muRiRAWrR4HQrAnhBAGIwGS0RmpgnZdiR0hqhXYqtQgKZCU5sOB/6nH2vQaBM4Iks3msIrNxQiSyVR7LYGQTyWEEAYjAZKRVZVBbs0KMSMGSCaTQx5SgE2z7fmPmtuV1hfS+tQ+HyhBRVk+KFbApG6u64qsZPOPylJ4b6ZzNXYhRMCTAMnIsneDrVqdQklop3dvXNO2Pgm0RG379Notzs/bV38ZfJm/ln8U3RpCwly3iZdaSH6x97+w+z1YP1/vngghvEgCJCMzcoK2xp6oHUAB0vnjav0jTGr+kSNt9VdxjlpE0qgaS9DWBMpoWKA78a16X3QaCmTVoBDBQgIkIzNy/pFG69uZvepUQyDY9Z56nzGq/shcbCqYzOr0lZYEbUTFjVTR1sh+bP5xYmvt8anv9etHU1WWQMFJvXshhOFIgGRkgRAgxbdRRzEUG2Tv0rs3F6YotbkidafXAMwhtaMyRk7UbmyjWo19is3A1xHoKoog12GBwsnv9OtLU70/C14cCKcz9e6JEIYiAZJRVRRD3n712MgBUqAlaufsVke7QsKh9/Wu2wTCSrbGthnRxMkIks+d2qb+50Bzcpt+fWmK6gp1NaetCjL/pXdvhDAUCZCMKnun+g9vXBuIs+jdm8YFUqK2NnrUfRxEJbpuEwhTU40t8dc4JpwbOZ8qkJ2oGTGy9FfvT+8Aa5V+/fFU1g/qak6AH9fI3xMhHEiAZFSBML2mCZQtR2zW2vyj/pMbbqcFpEZeyeZOknaMQz6VFlAJ79IStAferm54XF2mbg8UKBzzp0py4ejX+vVFCIORAMmoAjFAyjsA5YX69qUxxzapK40iE6Db2IbbBcQUm7YPm4sq2pqQUIitCfaMPBoWqGw2OFkTYHQYDm2HqMeBlIekBXihUer97n/r1xchDEYCJKPS9jdrGwABUmwKJLQHFHXI3qi06bXe10NoRMPtAmGKzZ0RJHDYOsXA1xKozh6A8gJ1S5e0vtBuqPr8yQBZyaYotcHcJb9S7/euDawpQiF8SAIkIyo7D/mH1OP0AAiQANoMVO+NmqhdVa5Wz4bGp9fAYYrNoCNI1ip1qxS4cIAUCKNhgUobfWk7RC3W2fYi9XGgBEgFJ9S/F+ZQGPmAOiVbdg4Ob9S7Z0IYggRIRqSNwiR2gJgkffviLqPnIR34BCoKIb4ddBjZeNs4gy+PL8kDFDCFQFTrxtvGt1XvZQTJ+7QASRs5alcTIJ09oAYaRqflH6X1hYi42lWdu9/Xr09CGIgESEakjcIEQv6Rxugr2ey1j24G8wX+2mvTUuUFxix+aa+BlOL+tUiA5H3aCrb2w9X76NbQuot6fCoAlvtrAZLW/743qff7PlBHXIVo4SRAMiJ7gvZgffvhCW2K7dzR2ukfoyg7p9Z6Aeg/6cLtI+IhLEY9NuIoUokbVbQ1cbIfm0+U5tfWKdNGkKB2FCkQptm0BPP2w2ruh6t/XyoK4dAG/folhEFIgGREgbSCTRPVClp1Uo+NNoq05z9qrZfUPpDW58LtTSZj5yG5UyRSY084N+B1BDItAErq6jwNbk/UNvhKtsrS2sr3WoBkNkPfG9VjWc0mhARIhlNyVt1MFSB9gL598VRbbZrNYIna2vSaO6NHGiMHFu6uYAPnFXmK4rs+tTQn60xPaexL/b839p/36R1gq1bLQCS0r31eC5D2f6zu0SZEC2aIAOmVV14hIyODyMhIhg8fztatWxttv2rVKnr27ElkZCT9+vXjo48+cnr9/fffZ+zYsSQlJWEymcjMzKx3jssuuwyTyeR0++Uvf+nNy2oabfQlqWvDlZ6Nyp6onalrN5ycP6HWP8Kk5h+5y776y4BTU+5sVKvRrqOqRJ06Ed5RN0Fbk9YXQiOh/DycPeT3brnNcXrNZKp9vs1gaJUBVaXw0ye6dE0Io9A9QFq5ciVz5sxh/vz5bN++nQEDBjBu3Dhyc13vpL5582amTJnCzJkz2bFjBxMnTmTixIns3r3b3qakpIRRo0bx1FNPNfrZ99xzD1lZWfbb008/7dVra5JAnF7TaDlTJ76FqjJ9+6LZtUq9zxgFCe3cf5+Rq2l7MoIUHg2RieqxEUfDApG1unbPtbojSKHhkD5QPT5l4DykE3XyjzQmE/SRaTYhwAAB0nPPPcc999zDnXfeSe/evVmyZAnR0dEsXbrUZfsXX3yR8ePH88gjj9CrVy8WLlzI4MGDWbx4sb3N1KlTmTdvHmPGjGn0s6Ojo7FYLPZbfHy8V6+tSQI5QGo7WB2yLzkDGxfp3RuVFiD1u8Wz9xm5WKRWRTumkSrajuzXcso3/WlpcveoI3IR8ZDSs/7r9kRtg+YhKUr9FWyOtGm2A+uNXRlfCB/TNUCqrKxk27ZtToGM2WxmzJgxbNmyxeV7tmzZUi/wGTduXIPtG/Ovf/2L5ORk+vbty9y5cyktNcCS7pteh7s+gd4T9e6J58Ki4OfPq8ebX9Z/Z/Ps3eovs5Dw2hov7jJygUVPRpDA2NcSiOzTaxe5LrNg9AAp/zCU5qk/F67yHNP6QnJ3sFbA/o/qvy5EC6FrgJSXl4fVaiUtzfkf+rS0NLKzXU9tZGdne9S+Ibfddhv//Oc/+fzzz5k7dy7/+Mc/uOOOOxpsX1FRQWFhodPNJ8JjoMPFkNDWN+f3tZ5XQ9+bQbHBf+6D6gr9+rJzpXrffZzn+VxGDipKtH3Y3AyQ7LWQDHgtgehknfpHdWkVtXN+NGYdLa3/6QNdb7ljMtXWRJJpNtGC6T7FppdZs2Yxbtw4+vXrx+23385bb73F6tWrOXTIdWLlokWLSEhIsN/at2/vsp0AJjytTv+c2Qdf6JTXZbPBrvfU434erF7TaEFFUbaxViNVlasFLKHxjWodadW0jZhwHogaStDWJLRTp5pt1cbcm1Drf938I0daHtKhz4xX10wIP9E1QEpOTiYkJIScnByn53NycrBYLC7fY7FYPGrvruHD1f8NHjx40OXrc+fOpaCgwH47ceJEsz4vqMUkwdXPqMdfP6/PqrZjX6sBQWQCdBvr+ftja/4+WSuh9Kx3+9Yc2uhRSHht8vWFxEk1ba8pzlWLoWKqnUqry+TwmhETte0VwBsJkFK6Q1o/Ncjb+1//9EsIg9E1QAoPD2fIkCFs2FBbtdVms7FhwwZGjBjh8j0jRoxwag+wfv36Btu7SysFkJ6e7vL1iIgI4uPjnW6iEX0mqnk/ihX+cz9UV/r387XaR72vh7BIz98fGl6bBG2kwMK+xD/NeXl2Y4yccB5otOTm1N5q8N0Qo+YhVRRB7o/qcbtGAiSAvjeo9z/K3myiZdJ9im3OnDm8/vrrvPnmm+zdu5d7772XkpIS7rzzTgCmTZvG3Llz7e0ffPBB1q1bx7PPPsu+fftYsGAB33//PbNnz7a3yc/PJzMzkz179gCwf/9+MjMz7XlKhw4dYuHChWzbto2jR4+ydu1apk2bxqWXXkr//v39ePVB7upn1c1Uc3arI0n+UlUOe9aqx02ZXtMYcam/4z5s7tICJCPmUwUa+/RUA9NrGntFbYONIJ3apuYHJnSonUZuiDbNduTL2pWTQrQgugdIkydP5plnnmHevHkMHDiQzMxM1q1bZ0/EPn78OFlZtf+wjxw5khUrVvDaa68xYMAA3nvvPdasWUPfvn3tbdauXcugQYO45pprALj11lsZNGgQS5YsAdSRq08//ZSxY8fSs2dPfvOb33DTTTfx3//KULJXxabA1X9Rj7/8i5q06g8HPoGKAjX3puMlTT+PEfcx83QFG9ReR8kZfZPmg0Fjy+MdpQ8Ek1ktrWCkkTt7/y8Q4AG07qRWBlds6nY9QrQwoXp3AGD27NlOI0CONm7cWO+5W265hVtuabiuzYwZM5gxY0aDr7dv354vvvjC026Kpuh7E+x+H/Z/CGvug7s3QIiP/9pp02v9br7wbveNMeLqL082qtVEt4aQCHXZdlE2tOrom74Fu+rK2jplFwqQImLVvf9ydqmjSL2v833/3OFugKfpc6M66rT7fRh2j+/6JYQB6T6CJIKcyQQ/f05NKM7KhM0v+vbzys7Bgf+px/0nN+9cRlzq35QRJJPJYVWega4l0GTvVIPM6CRo3fnC7Y2WqG2z1eZENbQCr64+NXlIxzdDgRQaFS2LBEjC9+IsMP7P6vHGP0PuPt991p7/qCvPUvtAWp/mncvQAZIHI0hQO80m1bSbzr68f5h7CfL2RG2DBEhnD6h7xIVGgaWfe+9JaAsdahbA7Fnjq54JYUgSIAn/GHArdL1KDV7+cz/YrL75nJ01W4v093BrEVfsq7+MFCBpRSI9DJCMOF0YaBrav6wh2ijN6R3q/m160/rfdjCEhLn/PikaKVooCZCEf5hMcO2L6v5Vp76Hb/7q/c84f0KtfwSe773min0Vm4GCimIPq2hrjDgaFkgUxb0Ci46SukFEAlSVqlve6O1CBS4b0vt6NeH81DbIP+L9fglhUBIgCf9JaAtj/6gef/ZHyHNdlLPJdtdUzu44Sq1m3FzatFRpnnFWf3m6Ua1Gq6ZtpBVVgaTgpBpcmkKgzWD33mM2q6M1YIx6SBfaIqUhsamQ8TP1+MfV3u2TEAYmAZLwr8HToPPlUF0Oa2eriaPeoq1e69+M2keOtNVfYIxaSBXF6i7y4PkIUrxU026WkzXTU5Z+EB7t/vu00ZpTOm/cXHZO3foHPB9BAodpNikaKVoOCZCEf5lMcN1LEB4Lx7fA1te8c97s3eo0Rki4OiXgDSaTsabZtG1GwmLUZeSeMGJNp0Di6fJ4jVEqap+sCdBad3Z/Dz9Hva4Fc6hatuDMT97tmxAGJQGS8L/EDnDVk+rxhich/3Dzz7mrZvSo21iISmz++TRGyt2x5x814RecvZp2tndH7VoKTxO0NW1rAqS8n9RRHL04rsBriujW0OUK9Vi2HhEthARIQh9D7lLzGqpKYe2vmvdL22aDXTX5R82tfVSXkVZ/NaUGkibOApiMt/luIKgsVWsggecBUkwStOqkHp/a7t1+eeJkEwM8R46r2RSl+X0SwuAkQBL6MJvVqbawaDj6FWxb1vRzHduk1veJSFBHkLzJSFNTTV3iD+qybi2x2wjXEkhO71B3tY9Lh4T2nr9f733ZbNbaz25OgNTjajUnL+8n/20bJISOJEAS+mndGa6cpx6vnwfnjzftPDtXqvd9roewSO/0TWOkDWubusRfY8S6ToHAcfTFnQKRddkTtXUKkHL3QmWxmveX2rvp54mMh25XqcdSE0m0ABIgCX0N+wW0v1j9B3ztrzwfuq8qhz1r1eN+Xlq95shIQYU2xRbThBEkcLgWqabtES3/qKn5O+2GqPcnv9NnakoL8NoOAXNI887V90b1/sf3ZZpNBD0JkIS+zGa4/hUIjYTDn8OOf3j2/gP/g4oCtc5Px0u83z97krYBpqWaM8UGxko4DxROBSI9XMGmSeunTk2VnfPOggRPNXUFnivdx6vT4ueOwmkdc6qE8AMJkIT+krvC5b9Tjz/5nWebYmrTa/1uVoMtb3OcYtP7f8wlzZ1iM1DCeaDIP6wmtYdEQHr/pp0jNBzSB6jHeuQhNXUFnivhMdBjgnosNZFEkJMASRjDiPvVJdEVhfDBQ+4FI2Xn1BEk8M30GtROS1WVQnmBbz7DXc0dQbJX05YpNrdpwUWbgRAa0fTz2BO1/VwPqSQP8g/V9OEi75yzjzbNtlpKRoigJgGSMAZziDrVFhKuBj3ayFBj9vxHXbae2gcsfX3Tr7AoiExUj/WcmlIUh2X+MsXmN57uv9YQLTjxd6K2FpAl94CoVt45Z9cx6p6Khadq/3yECEISIAnjSO0Jlz2mHn/86IVXju1cpd7398LGtI2xJzfrmIdUXqAGg+CFJG0JkNymBRhNTdDWaAFS9i6oKmveuTzhrQDPUVgk9LxGPZaikSKISYAkjGXkg5A+EMrPw4e/aXiq7fwJOPa1etz3Zt/2yQhL/bXptciEppcy0AKkigJ1XzfRuPLC2no/zQ0wEtqruWO2asj6ofl9c9cJbYNaLwZIUFs08sfVYK327rmFMAgJkISxhISqU23mMNj3QcP1VnbXVM7uOAoSm1C8zxNGKBbZ3CX+ABFxEB6nHss024Wd+h5QILFjbZDcVCZT7bYj/krUtlbVbpLb3BGwujpfpk7ZlZyp/Y+KEEFGAiRhPJa+cOnD6vFHj0Dxmfpt/DW9BsZY/dXcFWwa+7UYoGyB0Xl79MXfG9fm7IbqMnXUMbm7d88dEga9rlOPZTWbCFISIAljGjUH0vpCWT589LDza9m7IfdHNaG79/W+74uRptiamqCtsW9aKyNIF9Tc+kd12RO1t3nnfBdiL3A51DclMLRptr1r1dEqIYKMBEjCmELD1ak2UwjsWaOuWNPsele97zbWeytzGmOkKbbmBkhxUk3bLTabd/Yvc9RmEJjMUHDCP6OR3iwQ6UrGKHXKt+wcHN7om88QQkcSIAnjajMQRv1aPf7wN1Car/7i2lWTf9TfR7WP6jLCFJvXRpAMcC2BIG+/msweFqOWkfCGiLjavdD8sdz/pMMIki+YQ6DPRPVY9mYTQUgCJGFso38LKb3UZNCPH4Vjm9TRj4gE6DbOP33Q6geV5Oq3Yqe5G9VqZIrNPdr0WtvB6sIBb2mr7cvm4wCpKFvd/Nlkrv1MX7BPs32g7osoRBCRAEkYW2gETHxF/Yd+17vw8W/V53tf1/Tl7p6KSVGn+hRbbbK0v3ljFRvIFJu77AnaXp6eslfU9nGApE2vpfaGyHjffU67YWqF9soiOPip7z5HCB1IgCSMr+0QGPmAepy7R73vP9l/n28OqU3U1mtqSqbY/MsXBRahNlH79A7fjkb6qv91mc3Q5wb1WKbZRJCRAEkEhsvmQlJX9Ti+LXS8xL+fb9+mQ4dEbZtNnWKE5k+xaSNIek4XGl1pPpw9oB57O38nuYe6TUdVCZzZ691zO/JWBXB3aNNsP62DyhLff54QfiIBkggMYVFw42uQ1A1GP+qbZcuN0XOpf1k+KFbABDHJzTtXTAqYQ9XpQm3aTjjTgoukbhDd2rvnNpvVvCbHz/G26gp1hAp8P4IE6uq8Vhnqhs4/rfP95wnhJxIgicDRdgg88D0Mme7/z9ZzPzYtkIlurRboaw6zuXY0TIpFuubt+kd12Stq+6geUtZOdd++6CRo3dk3n+HIZKodRZKikSKISIAkhDvsU2w65O54awWbRs/pwkBgrx/ko9EXe6K2j0aQHAM8k8k3n1FXnxvV+wPr1Y2VhQgCEiAJ4Q5DBEjNTNDW2EfDJFG7Hmt1baVrnwVINSNIefuh7Lz3z+/r+keupPVR86usFbDvI/99rhA+JAGSEO7Qc/WXt5b4a+JlqX+DcnaruTQRCeovfF+ISVZzdgBOb/fuuRXF9xW0XXGcZvtRptlEcPAoQHr66acpKyuzP960aRMVFRX2x0VFRdx3333e650QRhGnY4FFb20zotFzNMzo7MGFj/Yv0/iqHlLBSfV7NYeqydP+1Ldmmu3QZ+pKQCECnEf/AsydO5eioiL74wkTJnDqVO3/QktLS/nb3/7mvd4JYRTaCFJFIVQU+/ezvbXEXyNTbA2zT0/5ePWXPVHbywGS1n9LPwiP9u65LyS5m/q5tmp1A1shApxHAZKiKI0+FiJoRcRBeKx67O+l/t4eQZIptob5q8CiY6K2N/8dPeGnAK8hWrK2rGYTQUBykIRwl16rv7ydpO04xSb/yaml7V+Gybf7lwFY+kJIuFrj6twR753X1yvwLkSbZjv6Ve3fWyEClARIQrhLr0RtXy3zry6HsnPeOWcw0IKLtD6+3b8M1D0G0weox96aZqsqg+yd6rFeAVKrDHX6ULHBnv/o0wchvMTjbar//ve/ExurTjVUV1ezfPlykpPV6r6O+UlCBB09kputVVB6Vj32VoAUFqkWESw9qxaL9Ha16EDlr+k1Tbuh6hTbye+g/6Tmn+/0DjX/J9YCCe2bf76m6nsjnPpe3Ztt2D369UOIZvIoQOrQoQOvv/66/bHFYuEf//hHvTZCBCU9AqSSPEABUwhEeTGQiWujBkhFWep0j/Dv/mVQO43nrREkxwDPXwUiXelzA3zyOzi+RV1Vl9BOv74I0QweBUhHjx71UTeECAB6bDdir4GU4t1l5/HpkLNLthvR+Hv/MqhN1M7eBVXl6shec5yoCfD0ml7TxLeBDiPg+Gb4cQ2MnK1vf4RoIslBEsJdemxYa1/i76UEbU28jnWdjCjrh5r9y5L9s38ZQGIHNfC1VdXmDjWVovh+DzlPaMnau/+tbz+EaAaPAqQtW7bwwQcfOD331ltv0alTJ1JTU5k1a5ZT4UghgooexSK9vcRfEydL/Z04rv7y1/SUyeS9fdnOHYHSPHVlnJb8rafeE8FkViuF53txlZ4QfuRRgPSHP/yBH3/80f54165dzJw5kzFjxvDYY4/x3//+l0WLFnm9k0IYQrxDDpLN5p/PtAdIXkrQ1ui5dYoR+TtBW6Pty9bcAEkL8NIHqivk9BabAp0uVY9l6xERoDwKkDIzM7nyyivtj9955x2GDx/O66+/zpw5c3jppZd49913vd5JIQwhNg0wqSuFtJVlvlYsU2w+p9f+ZeBQUXtb886jd/0jV7S92aRopAhQHgVI586dIy2t9n+yX3zxBRMmTLA/Hjp0KCdOnPBe74QwkpAwNWcE/Fcs0tsb1WqMNsVWmg/Hv9GncGXBCSjO1mf/sraDARMUHIeinKaf56QBA6SeP1f/THN2w5n9evdGCI95FCClpaVx5Ig6n1xZWcn27du5+OKL7a8XFRURFhbm3R4KYST+nprydhVtjXYdZefUAoN6+++DsHQcfPNX/3+2Nvpi6Q9hUf797Ig4SO2lHp9q4nL/iiLIqUl90GuLEVeiW0OXmhkHGUUSAcijAOnqq6/mscce46uvvmLu3LlER0fzs5/9zP76zp076dKli9c7KYRh2BO1/TSCVOLlKtqayEQIrQkG9J5ms9ng8Bfq8acLan/Z+4te+Uea5uYhndquVq5O6FAb+BqFNs0meUgiAHkUIC1cuJDQ0FBGjx7N66+/zmuvvUZ4eLj99aVLlzJ27Fivd1IIw/D3Un9fJWmbTPrUdXIl7yeoKFCPrZXw73vUukT+onf+jn0lWxNHkOz9H+qd/nhTj/Hqfd5P6jSqEAHEowApOTmZL7/8knPnznHu3DluvPFGp9dXrVrFggULPO7EK6+8QkZGBpGRkQwfPpytW7c22n7VqlX07NmTyMhI+vXrx0cffeT0+vvvv8/YsWNJSkrCZDKRmZnZ4LkURWHChAmYTCbWrFnjcd9FC+PPoKKqHMprAofYFO+f334tOo8gaSMnqX3UOkS5P8JnC/3z2ZUlaqFG0K9+kJaofWo72Kyev/+kTgnm7ohMgPiaStp5B/TtixAe8qiS9l133eVWu6VLl7p9zpUrVzJnzhyWLFnC8OHDeeGFFxg3bhz79+8nNbV+3sXmzZuZMmUKixYt4uc//zkrVqxg4sSJbN++nb591S0TSkpKGDVqFJMmTeKeexrfC+iFF17ApGdZfhFY/LndiDa9FhKuTol5m/1adB5B0gKkbmOg/cXwzhTYvBi6jYNOP2v8vc11egcoVnXqVK8tMVJ6QHgcVBZB7l7Ptn6x2WpHkNoZcAQJILkrFJ5UR5E6GDCIE6IBHo0gLV++nM8//5zz58/bR5Fc3Tzx3HPPcc8993DnnXfSu3dvlixZQnR0dINB1osvvsj48eN55JFH6NWrFwsXLmTw4MEsXrzY3mbq1KnMmzePMWPGNPrZmZmZPPvssx4FdKKFswcVfphisy/xT/NN8UKjTLFpU0vthkLPq2HwNECB1b+EsvO+/Wy9848AzCHQtmb1nKeJ2mcPQvl5NZ/M0s/rXfOK5O7q/VkZQRKBxaMRpHvvvZe3336bI0eOcOedd3LHHXfQunXTN9CsrKxk27ZtzJ071/6c2WxmzJgxbNmyxeV7tmzZwpw5c5yeGzdunMfTY6Wlpdx222288sorWCwWj/suWij7KjY/BBWO+7D5ghECpIoiyN2jHmtTTeMWwZGv1OrQH/8WbnzNd5+vV/2jutoNhSNfqqNpQ2a4/z4twGs7WC1DYURagCRTbCLAeDSC9Morr5CVlcVvf/tb/vvf/9K+fXsmTZrEJ598gtKE+iV5eXlYrVan2kqglhPIznb9P/Ts7GyP2jfk17/+NSNHjuT66693q31FRQWFhYVON9ECaSNIZflqjpAv+SpBW+PP6cKGnNoOKJDQvjb4jIhVgyKTGXau9N0ScacCkTovj29qovZJg0+vASR1Ve/zftK3H0J4yOPNaiMiIpgyZQrr169nz5499OnTh/vuu4+MjAyKi4t90UevW7t2LZ999hkvvPCC2+9ZtGgRCQkJ9lv79u1910FhXFGtILRm1/ViH0+z+WqjWk18W/VezyRtLf9IW+quaT8MfvawevzBr30zynX2kBrohkSoNZD0pI2endlfm5jvDqOMgDVGG0E6dxSsVbp2RQhPeBwgOb3ZbMZkMqEoClar56svkpOTCQkJISfHuYJsTk5Og9NeFovFo/aufPbZZxw6dIjExERCQ0MJDVVnGm+66SYuu+wyl++ZO3cuBQUF9ptUDG+hTKbapf6+Dix8tVGtxmlvuSasnvIGx/yjukb/Vq1sXX4e1tzr/f3vHKenQsMbb+trsSmQ2BFQakbV3FB2Hs7sU4+NPIIU3wbCYtQtemTjWhFAPA6QKioqePvtt7nqqqvo3r07u3btYvHixRw/fpzY2FiPzhUeHs6QIUPYsGGD/TmbzcaGDRsYMWKEy/eMGDHCqT3A+vXrG2zvymOPPcbOnTvJzMy03wCef/55li1b5vI9ERERxMfHO91EC+WvYpG+nmKLSVWnsRRr7WiVPymKwwiSiymukDC48XU1AfnwRtj6N+9+vtGmp7RRNHcTtbXgsnVn35SB8BaTSV3JBpKoLQKKR0na9913H++88w7t27fnrrvu4u233yY5OblZHZgzZw7Tp0/noosuYtiwYbzwwguUlJRw5513AjBt2jTatm3LokWLAHjwwQcZPXo0zz77LNdccw3vvPMO33//Pa+9VpvImZ+fz/Hjxzl9Wv0Ftn+/ug+QxWJxutXVoUMHOnXq1KzrES1AvJ9Wsvlqo1pNSCjEWtRAr/B07ciYv5w7CqV5ahmD9AamuJK7wdiF8NHDsH4+dL6sdmuO5jLa9FS7obD73+7nIdkDPANtL9KQpG6Q9UNNHtI1evdGCLd4FCAtWbKEDh060LlzZ7744gu++OILl+3ef9/9pMrJkydz5swZ5s2bR3Z2NgMHDmTdunX2ROzjx49jNtcOdI0cOZIVK1bwxBNP8Pjjj9OtWzfWrFljr4EEao6RFmAB3HrrrQDMnz+/SYUshXAS56eVbL4eQQI12NMCpLaDffc5rmiBgKU/hEY03G7o3fDTJ3BwPbx/D9z9WfOnxMoL1JpDoH+CtsaeqP2dOrp2odIORkkwd4d9JdtBffshhAc8CpCmTZvmk6KKs2fPZvbs2S5f27hxY73nbrnlFm655ZYGzzdjxgxmzJjhUR+asgpPtFD+Wv2lbVTrq2X+oO9KNvv02gWmuEwmuH4x/HWEWvX68/+Dq55s5md/DyjQKsN3I3SesvRTR9NKz6qja60bGc22WWsDzIAIkGQlmwg8HgVIy5cv91E3hAgg9lpIPgwqKoqhqkQ99ukIko61kBpaweZKnAWuewlW3gGbXoRuYyHjkqZ/ttGm10AdRbP0V3OQTn7feIB0Zp9aeTs8FlJ7+6+PTWUfQfrJvdExIQygWavYhGiR/DHqom0zEhaj1gXyFb0CpKoyyN6pHrubJN3rWhh4B/Yq254sh69LW8FmlARtjbuJ2vYVeEPUStxG17qLel9+Xh0hEyIASIAkhKccAyRfTc1q02u+Xp3krxV5dWXtVJd9x6RCYgf33zfhz+py+ILj8PGjTftsmxVObVOPjTSCBM55SI05UfO60frfkPBoSKj5nmWaTQQICZCE8JQWIFWXQ5lnew+6zR8J2uCf6UJXHPOPPJluiYirrbL9w9vw4xrPP/vMPqgoNOb0lDaClLWz8UrtRthDzlPJ3dR72XJEBAgJkITwVFgkRNXsQeirpf72ESQfJxDbq2mf9t1omCue5B/V1eFiGPVr9fiDhzwP7rT8o7aD1VIHRpLYEaKTwValJqS7UnIW8g+px03589OLPUCSESQRGCRAEqIp7NNsPpqasgdIPh5B0q6jqkQdVfGXxipou2P0Y5A+QB3B+899nlXZNmKCtsZkuvA0m1b/KLmHuvVNoNACpLOy1F8EBgmQhGgKX09NaVNsMT4eQQqPhsgE9dhf02yFp6HwpDpN1mZQ084RGl5TZTsSDn0G373u/nvt01MGDJAA2g1R7xtK1A6k+keOkmQESQQWCZCEaIo4H1fT9vVGtY60aTZ/JWpro0epfZq3Qi+lB1y1UD1ePw9y9134PYEwPXWhEaRADZDsm9Yeg+oKffsihBskQBKiKXw+xeanJG3wX2VwTXPyj+oadg90uVJNmH//HqiuvMBnB8D0VJvBgAnOH6+datVYq+F0zWa2Rh0Ba0icRU2MV6yyaa0ICBIgCdEUPp9i81OSNvh/JVtz848cmUxw/StqsJO9EzYuary9fXrNYPWPHEXGQ0pP9bjuvmw5u6GqVJ0W1aasAoXJ5JCHJCvZhPFJgCREU/iyfpCiOIwg+SFA8mctJGsVnN6hHnurSGN8Olz7onq86QU4tqXhtoFSP0gbXas7zaZNr7UbCuYA/Odb8pBEAAnAnzAhDCDOot77IgepvACsNVNFvk7SBv9W0875EarLakZAunrvvL2vhwG3gWKD1bOg3MWKPGuVcQtE1tVQRe2TBl6B5w7ZtFYEEAmQhGgKLagozlV/8XqTNr0WkaDWXPI1fwZI2ohI24u8PwIy4Sm1Kvf547DusfqvZ+9yCM4MPj2lja6d2q5W/tYYdYsUd0ktJBFAJEASoimik8EcBjhMh3mLP6fXwD97y2m8mX9UV2Q83PA3wASZ/4I9a+t8tpYcPsz401MpPdWE5spitfI3qKOV54+r5RHaDtG3f03lWE3bn4VJhWgCg/8rIYRBmc2+m2Yr8VORSI22zL/kjO+XXztuMeILHUfCqIfU4/8+6PzdGL3+kSNzSG2NKC2o1PKPUnurwWAgat0FMEFFQW0pCyEMSgIkIZpKC5C8PTXlzxVsANGtISRCPfZVXSeA0vzaGkRtB/vucy57HCz9oSwf/nN/7UiFPUE7QKan6tZDOhmg9Y8chUXWbk4s02zC4CRAEqKpfDU15e8pNpPJYTTMh9Ns2khIUjc1KPMVxyrbBz+F7/6uBrEFATY9ZU/Urkkst69gC+AACRwStWWpvzA2CZCEaCotudnrAZIfq2hrHDet9RVfT685Su0JY55Uj//3BOz4V83zfSAizvef7w1tawKk3L1qBfDTmerjQB5BAuc8JCEMTAIkg/nHlqNct/hrPt+fe+HGQl/2KTZfjSD5KQcJHIpF+iNA8tMWH8NmQefL1Srbn/9RfS6Qgou4NEjoACiwbRlYKyA6CVp31rtnzSPFIkWAkADJYPbnFLHzZAGf7vHyyijhfb4qsOivjWod+Xolm81WO1XkryXqZjNM/CtEJtY+FwgJ2o60YHJrzWa87YerU6KBTIpFigAhAZLBXNlLHTXYsDcXRZbBGpuvtujwd5I2+L4WUt5PUFEIYdHqKix/iW8D175Q+ziQRpCgNpgsznZ+HMi0HKTzx6GqXN++CNGIUL07IJyN6JxEdHgI2YXl/Hi6kL5tE/TukmiIfQTJiyu/bLba5c9+nWLzcYCkTa+1GQwhfv5np88NUJIHtmpo3cm/n91cdacjA20EzJXYVLUIakUB5B+GND8GzEJ4QEaQDCYyLIRLu6UAsF6m2YxNy0GqLIKKIu+csyxf3e0cICbZO+d0h6/3Y/N3/lFdw+6Bi+/V57Obw9K/piApYA6trY0UyEwmSK7ZZkam2YSBSYBkQGN6qyMHn+6VAMnQImIhoqZgn7em2bT8o+gkCAnzzjndoU0XFmWro1je5ssK2sEsLBIs/dRjSz8Ij9a3P96iTbNJorYwMAmQDOjyHimYTPDj6UJOny/TuzuiMd5Obi72cxVtTawFMKmb5Jae9e65K4ogd496rNcIUiDrOFK97zBS3354k7ZRsSz1FwYmAZIBJcVGMKRDKwA27JPl/obm7QKLeiRog1pcMUad2vX6NNup7YCiLlnX/ryE+y59BK5aCKN/q3dPvEeKRYoAIAGSQdmn2SQPydi8ndysxxJ/ja9W5emdfxToohLhkl+p98FCNq0NfOUF8OHDkLVT7574jARIBjWml/oLcsuhsxRXVOvcG9GgOIfcHW8o0WkECRyqaZ/y7nkl/0jU1bqzuu1LZVHtfwpEYPl+KXz3Oqx7TO+e+IwESAbVJSWWjKRoKq02vvpJdr02LHuA5K0RJJ1ykMA3xSIVxb9bjIjAEBoBiR3VY1nJFpi0rW9OfKuOJgUhCZAMymQyMaaXtppN8pAMy9vTUv7eqNaRL6bYzh2F0jwICYf0/t47rwh8kocU2LJrptZs1XD4C3374iMSIBmYlof02b4crDaZpzekOC9vWKtXkjb4phaSNnpk6a+OGgihkU1rA1d5TZFPzcFP9euLD0mAZGAXdWxFQlQY50qr2H78nN7dEa54u36QnlNsvqimLdNroiGyaW3gyt7t/Pjgp0GZbC8BkoGFhpi5vIe69FqKRhpUTKqabKpYa7cIaSprVW0NIl1WsWkBkhen2GQFm2iIfYpNcpACTtYP6n2XKyA0Ul3YcWafvn3yAQmQDE6W+xtcSGhtMNPcqamSPEABUwhEt2521zymJWlXFEBFcfPPV1UG2bvUYxlBEnUl1YwgnT+h/l0RgUPLP2o/HDpeoh4fWK9ff3xEAiSDu7R7CqFmE4fOlHD4jBd+aQnvi/fSUn9tiX9MCphDmneupoiMh/A49dgbOVVZP6gJnDGpkNih+ecTwSUmGSITAQXOHtK7N8IT2ghS+gDodpV6HIR5SBIgGVx8ZBgXd04CYIOsZjMmbeSlubk7eiZoa+K9dC3gnH9kMjX/fCK4mEwOidoyzRYwqsrgzH712NIfutYESMe3eGfk2UAkQAoAWtFIyUMyKG/VD9Jzib/Gm7WQJP9IXIh909qD+vZDuC9nj5pzGZ2s5i0mdVFrWlkr4ehXevfOqyRACgBX1tRD+v7YOc6VVOrcG1FPvLcDJB1WsGm8WU1bKmiLC7FvWisjSAEjK1O9Tx+gjgKaTLXTbEGWhyQBUgBo3zqanpY4rDaFjT/JNJvhxHmpwGJxzSo4Q0yxNfNaCk6pQZbJDG0GNb9fIjhJscjAoyVoOxZ+7TpGvT+4PqiW+0uAFCCkqraBeXuKTY8l/hpvXcupmtGj1D4QEdu8c4ngZa+FdDCofrEGNccEbU3Gz9Rq+eePB9V0qQRIAUJb7v/F/jNUVnuhIKHwHm8VWDREkrY2xdbMa5H8I+GOVp3UshaVxd7dA1D4hrVKzUECNUFbExELHUaox0E0zSYBUoDo3zaBlLgIiiuq+fbIWb27Ixxpoy7l55tXz6VExyraGm+tYpP8I+GO0HBo3Uk9ljwk4zuzH6wVEBGvBreOgnC5vwRIAcJsNnFlz5rVbFI00lgiEyA0Sj1uzv+CDbGKrWY0rCQXrNVNO4e1Ck7vUI8lQBIXkiR7sgUMLf/I0g/MdcIHLQ/p6NdQWerffvmIBEgBxDEPSZH5euMwmZqf3FxVrm4ACfoGSDEpYA4FxVYbsHkqZzdUl6uBo7ZKSYiGyKa1gcNV/pEmpSfEt1NHmI5t8m+/fEQCpABySddkIsPMnDpfxr7sIr27IxxpIy9NHUHS9nELCa+pLqwTs7n5hS8dp9fq/i9TiLqkWGTgyNJWsLkIkEwm6FYzihQkeUjyr1cAiQoPYVTXZECm2QwnzqLeNzVAKnbIP9K76rR9JVtTAySHCtpCXIgUiwwMNpvDFFt/123sy/2DIw9JAqQAY59m2yfL/Q2luVNs9iX+Kd7pT3M091pkBZvwhJaDVHACKkv07YtoWP5hdbVhaGRtUFtXp9HqFH3+IbV9gJMAKcBcUbPtyA8nzpNbWK5zb4Rdc6fYjFBFW9OcatolZ2v/YWw7xHt9EsErJgmiWqvHsmmtcWXX5B+l9YGQUNdtIuOh/cXq8YHAH0UyRID0yiuvkJGRQWRkJMOHD2fr1q2Ntl+1ahU9e/YkMjKSfv368dFHHzm9/v777zN27FiSkpIwmUxkZmbWO8cvfvELunTpQlRUFCkpKVx//fXs27fPm5flE6lxkQxonwjABhlFMo7mTrGVGKCKtqY5xSK1ApHJ3SGqlff6JIKb5CEZX2MJ2o66Bc80m+4B0sqVK5kzZw7z589n+/btDBgwgHHjxpGb6/qX/+bNm5kyZQozZ85kx44dTJw4kYkTJ7J79257m5KSEkaNGsVTTz3V4OcOGTKEZcuWsXfvXj755BMURWHs2LFYrVavX6O3XdVLlvsbTnOLRRphib/Gfi1NCJAk/0g0hWNFbWFMWRfIP9JoeUhHvlRX5wYw3QOk5557jnvuuYc777yT3r17s2TJEqKjo1m6dKnL9i+++CLjx4/nkUceoVevXixcuJDBgwezePFie5upU6cyb948xowZ0+Dnzpo1i0svvZSMjAwGDx7MH//4R06cOMHRo0e9fYlep1XV/vpgHmWVxg/oWgT7qEt207ZMMNQUmxYgNWGKTfKPRFPY92STESRDUhT3R5DS+kKsBarL4Phm3/fNh3QNkCorK9m2bZtTIGM2mxkzZgxbtmxx+Z4tW7bUC3zGjRvXYHt3lJSUsGzZMjp16kT79u2bfB5/6ZEWR7tWUVRU2/j6YJ7e3RFQO8VmrYCyc56/3wgb1Wocp9g8CfZsVji5TT2WESThCSkWaWyFp6AsX90WJrV3421NptpRpADPQ9I1QMrLy8NqtZKW5vy/5rS0NLKzs12+Jzs726P2jfnrX/9KbGwssbGxfPzxx6xfv57w8HCXbSsqKigsLHS66cVkMtWuZpNpNmMIjYDoJPW4KdNsRtioVqMFSNXlngV7eT9BZRGExUBKL9/0TQQnx6X+Ntlr0nC00aPUXhAWeeH2QZKHpPsUm55uv/12duzYwRdffEH37t2ZNGkS5eWu50wXLVpEQkKC/ab3SJMWIG3Yl4vNJlW1DaE5K9mMsFGtJiyydlWRJ9eiTa+1HdzwKhchXGnVUV0eXlXatKld4VuNFYh0pfPl6mhT3n44f9x3/fIxXQOk5ORkQkJCyMlxHgXJycnBYrG4fI/FYvGofWMSEhLo1q0bl156Ke+99x779u1j9erVLtvOnTuXgoIC++3EiRMef543DevUmriIUPKKK/jh5Hld+yJqxDdx9VdFMVTV1H8xQg4SOCz192A0TPKPRFOFhEHrzurxWZlmMxxtBOlCCdqaqMTaafYAHkXSNUAKDw9nyJAhbNiwwf6czWZjw4YNjBgxwuV7RowY4dQeYP369Q22d5eiKCiKQkVFhcvXIyIiiI+Pd7rpKTzUzKU91KKCn+6VaTZD0PKQPF39VVIzehQWAxGx3u1TU8U3YbsRxy1GhPCU5CEZl7sJ2o66BX4eku5TbHPmzOH111/nzTffZO/evdx7772UlJRw5513AjBt2jTmzp1rb//ggw+ybt06nn32Wfbt28eCBQv4/vvvmT17tr1Nfn4+mZmZ7NmzB4D9+/eTmZlpz1M6fPgwixYtYtu2bRw/fpzNmzdzyy23EBUVxdVXX+3Hq2+eq+x5SFIPyRDsU2we5iDZp9cMUEVb42ktpPJCyN2rHreVESTRBLJprTEVn6n5N80Elr7uv8++3P8LqK70Sdd8TfcAafLkyTzzzDPMmzePgQMHkpmZybp16+yJ2MePHycrq/Yf6ZEjR7JixQpee+01BgwYwHvvvceaNWvo27f2i1u7di2DBg3immuuAeDWW29l0KBBLFmyBIDIyEi++uorrr76arp27crkyZOJi4tj8+bNpKYaIAfETZf1SCHEbGJ/ThEn8kv17o6Id1jq7wkjLfHXeFpN+/R2QIHEDhBnoOsQgUOKRRqTVkE7qQtExLn/PssAdeukymI48Y1v+uZjhsiknD17ttMIkKONGzfWe+6WW27hlltuafB8M2bMYMaMGQ2+3qZNm3rVtwNRYnQ4QzNa8c3hfD7dm8Odl3TSu0stW1wTpqXAWAnaGk/3Y5MCkaK5ZNNaY3K3QGRdZjN0uRJ2vgMH1kOnS73fNx/TfQRJNI99ub/kIemvqVt0aAGSEZb4azxdkSf5R6K5krqq94Wn1IULwhiakn+k6XaVen9wQ+PtDEoCpAB3ZU2A9O3hfArLq3TuTQunVaAuOePZnLshp9g8qKatKDKCJJovujVEJ6vHMopkHNnaEn8PR5BAXe6PCXJ/hILAK98gAVKA65QcQ9fUWKptCl/sP6N3d1q26CQwh6nHxR6M6Blpo1qNNsVWdg6qyhpve+4IlJ6FkHCw9PN930Twsm85IonahlBeAPmH1WNLE0aQYpKg7RD1+FDgjSJJgBQErtQ2r5VpNn2ZTE2bZjPiCFJkIoRGqccXuhZtei19gFpRXIimSq6ZZpNEbWPIrtkEPqG9Guw0hTbNdmC9d/rkRxIgBQFtuf/n+3KpskqZfl01pX6QEZO0TSb3E7Vlek14iz1RW0aQDMHTApGuaMv9D28Ea2ClgUiAFAQGdWhF65hwCsur+f5oEzZKFd4T5+FSf0UxZoAE7lfTlgrawlukWKSxNCdBW9NmkLp1UUVh7b8VAUICpCAQYjZxRU+ZZjMEe4Dk5ghSeQFYa6q3G2kVG7h3LVVlkL1LPZYRJNFcWi0k2bTWGJqToK0xh0CXK9TjANt2RAKkIDHGIQ9JUWTzWt14Wj9IGz2KSHBvl2x/cudasn4AW7WaP5Wg7wbOIggkdlQXOlSXQ4G++122eFVlcGa/etycESQI2DwkCZCCxM+6pRAeYubY2VIO5koNEd14Wj/InqBtsNEjcK+atmP+kcnk+z6J4BYSqlZsBslD0lvOHlCsaukFbTS5qbQRpOydUBQ4sxwSIAWJmIhQRnZVVxl8ulf2ZtONtmGtuwGStlGtkVawadxZkSf5R8LbtIKRkoekr6xM9T59QPP/8xObCukD1eMAWu4vAVIQkaraBmAvsJilJmBfiBE3qtU4XktDpIK28DaphWQM9vyjZk6vaQJwmk0CpCCi1UPafvwcecUVOvemhdJGXapKoKLowu2NWANJE+8wXWiz1n+94JQ6/WYyqytVhPAGe4AktZB0ZV/B1owEbUfacv9Dn7n+98SAJEAKIukJUfRtG4+iwGf7ZJpNF+HREJmgHrszzVZswCramphUNfhRrLXVvh2dqhk9SusD4TH+7ZsIXo4r2YQ+rFVqDhJ4bwSp7UXqv43l5+HUNu+c08ckQAoy2jTbBplm00+cB8UijTyCFBJa2y9X1yIFIoUvaDlIRVlQXqhvX1qqM/vV8iMR8ZCY4Z1zhoTW7M1GwCz3lwApyGgB0pc/5VFeFRjDmEHHk+1GtADJaDWQNPY8JBcB0gkJkIQPRCXW/jzISjZ9OFbQNnsxTAiwPCQJkIJMnzbxWOIjKauysuXQWb270zLFe7DU34gb1TpqKNirrqxd5SIBkvA2ex6STLPpwhsFIl3pcqV6f3oHlOR599w+IAFSkDGZTIzpLVW1daUt9b9QsUibzWEVmwGn2KDhEaSc3Woxv8hEaN3F790SQU42rdWXN7YYcSU+HdL6AYqarG1wEiAFIcfl/lJVWwfuTrGV5asJ0AAxyb7tU1M1dC325f0XeXcIXgiQTWv1ZLPVbh/UnE1qG9K1ZhQpAPKQ5F+2IHRx5ySiw0PIKaxg9ylJcvQ7d6fYtPyj6CQICfNtn5qqoWrakqAtfEk2rdVP/mGoLIbQyNpA1Zu0PKSDGwy/354ESEEoMiyES7uphQfXyzSb/8W5uR+b0afXoOH92KSCtvAl+1L/QwFTMydoZNdMr6X1VVeeeVv74RAeB6V5kLXD++f3IgmQgtSY3rLcXzdagFSc0/g/7lqAFGPAKtqaOIccJG26tiQPzh1Rj9sO0adfIrgldoCQCHWp+fnjevemZfF2gci6QsKg82j1+KCxtx2RAClIXd4jBZMJfjxdyOnzZXp3p2WJTQVTSMMFFjVGroGkiXesDF4zXavlHyV3h6hW+vRLBDdziMOmtbKSza+yvLzFiCsBstxfAqQglRQbwZAO6i8vGUXyM3NI4wUWNfaNag26xB/UCtlaZXBtmk3yj4Q/aNNsspLNfxTFuQaSr2jbjpz6Hkrzffc5zSQBUhDTptk+3SvbjvidttS/sUTtQMhBgtpptqKaYE/yj4Q/JEmA5HcFJ9XVteZQSO3tu89JaAcpvUCxweHPffc5zSQBUhDTlvtvOXSW4opqnXvTwjRWgVpjn2Iz8AgSOF+LzQqntquPZQRJ+JIUi/Q/rUBkSk8Ii/TtZ9mX+xs3D0kCpCDWJSWGjKRoKq02vvqpkVwY4X32+kHZDbcx8ka1jhxXsp3ZD5VFEBaj/g9QCF+RYpH+56sCka7Yl/t/atjl/hIgBTGTyWQfRZLl/n7m1hRbACRpg/MUmza91nawb5YAC6HRpthKcqHsvK5daTG0BG1f5h9pOoxQ/6NVnKNW5jcgCZCCnJaH9Pm+XKw2qartNxeaYrNWQWnNXnlG3ahWYx9BOi35R8J/IuMhtuY/GrKSzT/8OYIUGgGdLlWPDxpzNZsESEHuoo6tSIgK41xpFduPn9O7Oy3HhabYSvIARS0HEN3ab91qEns17dMOW4xI/pHwg2SpqO03xWdqFmKYwNLXP5/ZrWY1m0HzkCRACnKhIWYu76EWIvx0j0yz+U18nZVfdZU4FIk0h/inT02lBXv5R+DMPvW4rYwgCT+Qpf7+o1XQTuoCEXH++Uxtuf/xb6C8wD+f6QEJkFoAbZpN8pD8SMtBKi+AytL6r9uX+Bu4irZGC/YqiwBFrXIcZ/C8KREcZNNa//FHgci6WmWouWaKFQ5v9N/nukkCpBbg0u4phIWYOHymhMNnivXuTssQEa8mIILrRO1ASdCGms10w2sfy/Sa8BeZYvMffxSIdEUbRTr4qX8/1w0SILUA8ZFhDO+UBMAGKRrpHyZTbXKzywApQIpEgnot2jQbQLth+vVFtCxJDpvWWqWWm0/5M0HbkZaHdODT2v0eDUICpBZiTC91pZRMs/lRnEP9oLqKA2CbEUfaNBvICJLwn4T2EBoJtio4f0zv3gSv8oLaDaj9HSB1vET9jotOQ+5e/372BUiA1EJcWVMPaduxc5wrqdS5Ny2EfSWbi0RtbYrN6Ev8NVqAFBIBln769kW0HGYzJGkFI2WazWeyd6n3Ce39v6o2LAoyfqYeG2y5vwRILUT71tH0tMRhtSls/Emm2fwivpGl/oE2gqQFe+kDIDS88bZCeJOWhySJ2r6jR4K2I8eq2gYiAVILolXV/nSPBEh+EedQYLGukgDKQQJoP1y97zFB336Ilkc2rfU9vRK0NVqi9rEtUFGkTx9ckACpBdGW+3/x0xnKq6w696YFiGssSTtANqrV9L4OHjkEo36td09ESyOb1vpets4jSEldoFUnNdfsyFf69MEFCZBakP5tE0iLj6C4opppS7eSL7lIvmUvFlknQKoqry2KFigBEkBMsrqiTQh/kk1rfauqTN2EGiBdpxEkcFjub5w8JAmQWhCz2cQztwwgNiKUrUfyuW7x1+zPNs5wZtBx3G7EcflqyRn1PiQcIhP93i0hAoo2xVaaB6X5+vYlGOXsUQs1xqQ4l/PwNy0PyUDL/SVAamF+1i2F1feNpGNSNCfPlXHjXzexXrYg8Q0tv8haWbsxLdQmaMekyoiMEBcSEVu7H6BsWut9WZnqvaW/vv8eZYxS/9NYcNwwKxYlQGqBuqXFsea+SxjROYmSSiuz/vE9f914EMUgUXvQCA1X/1cGztNsgZZ/JITeZKm/7+hVILKu8Bi1JhIYZppNAqQWqlVMOG/NHMbUizuiKPD0uv38emWmJG97m6tikYG2gk0IvdkTtSUPyevsCdo65h9pDLbtiARILVhYiJmFE/uycGJfQswm1mSeZvJr35BbWK5314KHq2KRgVYDSQi9yZ5svmGtgpwf1WO9R5CgNg/p6CbXm3z7mQRIgqkXd+QfM4eRGB3GDyfOc93iTew8eV7vbgWHeBcjSDLFJoRnpFikb5zZr+ZIRiSoy+z1ltwdEjqAtQKOfq13byRAEqqRXZL5z/2X0DU1luzCcm5ZsoX//uCiwKHwTJyLpf72AEmm2IRwi7aSLf+wOuohvMNeILKfMRaMmEzQ9Ur12AB5SBIgCbuOSTGsvm8kl/dIoaLaxgNv7+DZ/+3HZpPk7SaLs6j3TgFSzTJ/GUESwj3xbSEsGmzVcE42rfUavQtEumKgbUckQBJO4iLD+Pv0ocy6tDMAL392kHv/tY2SimqdexagtGKRrqbYAmWjWiH0Zjar1ZZBErW9yb6CzQAJ2ppOl4I5TB0tPHtI164YIkB65ZVXyMjIIDIykuHDh7N169ZG269atYqePXsSGRlJv379+Oijj5xef//99xk7dixJSUmYTCYyMzOdXs/Pz+eBBx6gR48eREVF0aFDB371q19RUFDg7UsLSCFmE49f3YtnbhlAeIiZT37M4aZXN3PynP5JcwHH1XYjkqQthOe0lWySh+QdNhtk71KPjTSCFBEHHS5Wjw9u0LUrugdIK1euZM6cOcyfP5/t27czYMAAxo0bR26u6w1VN2/ezJQpU5g5cyY7duxg4sSJTJw4kd27d9vblJSUMGrUKJ566imX5zh9+jSnT5/mmWeeYffu3Sxfvpx169Yxc+ZMn1xjoLp5SDvennUxybER7Msu4vrFm/juqFSy9Yg2glSaB9UVUFEMVSXqc5KDJIT7ZKm/d+UfhspiCI2szfEyCoNsO2JSdK4OOHz4cIYOHcrixYsBsNlstG/fngceeIDHHnusXvvJkydTUlLCBx98YH/u4osvZuDAgSxZssSp7dGjR+nUqRM7duxg4MCBjfZj1apV3HHHHZSUlBAaGnrBfhcWFpKQkEBBQQHx8fFuXGngOn2+jHve+p4fTxcSFmLi/yb2Y9LQ9np3KzAoCvwxTV2V8eBOtaT/S4PUfIrfudjEVgjh2q734N8zof3FMPMTvXsT+LQ/z7YXwT36jtTUk/MjvDoSQqPg0aMQFunV07v7+1vXEaTKykq2bdvGmDFj7M+ZzWbGjBnDli1bXL5ny5YtTu0Bxo0b12B7d2l/UO4ERy1Nm8QoVv1yBFf3s1BlVfjtv3ey8IM9VFttenfN+Ewmh0TtbJleE6KpZATJu4xUILKu1N7qCuDqMji2Sbdu6Bog5eXlYbVaSUtznmpIS0sjOzvb5Xuys7M9au9uPxYuXMisWbMabFNRUUFhYaHTrSWJDg9l8ZTBPDRGHYp94+sj3PXm9xSUyZLbC9Km2YpOOwRIMr0mhEe0JO2yfCg523hbcWFG2WLEFcfl/qe269YN3XOQ9FZYWMg111xD7969WbBgQYPtFi1aREJCgv3Wvn3Lm2Iym008NKY7f719MJFhZr786Qw3/HUTR/JK9O6asWkjSIVZUiRSiKYKj4GEmn93JVG7eRQFsgy4xN/Rz+bAgz/A6Ed064KuAVJycjIhISHk5DjvJp+Tk4PFYnH5HovF4lH7xhQVFTF+/Hji4uJYvXo1YWFhDbadO3cuBQUF9tuJEyc8/rxgcXW/dN775UjaJERy+EwJ1y/+mq8OnNG7W8YV52IESZb4C+E5+6a1Ms3WLAUn1ZE4c6g6nWVErTtDqwxdu6BrgBQeHs6QIUPYsKE2Qcxms7FhwwZGjBjh8j0jRoxwag+wfv36Bts3pLCwkLFjxxIeHs7atWuJjGw8CSwiIoL4+HinW0vWt20Ca2ZfwuAOiRSWVzNj2Xcs33QEnXP+jUnbbqQoW6poC9Ec9jwkGUFqFi3/KKUXhEbo2xcD032Kbc6cObz++uu8+eab7N27l3vvvZeSkhLuvPNOAKZNm8bcuXPt7R988EHWrVvHs88+y759+1iwYAHff/89s2fPtrfJz88nMzOTPXv2ALB//34yMzPteUpacFRSUsIbb7xBYWEh2dnZZGdnY7XKbvbuSo2L5O1ZF3PT4HZYbQoL/ruHx1fvorJakredxDnsx1YiVbSFaDLZtNY7jFgg0oB0X7I1efJkzpw5w7x588jOzmbgwIGsW7fOnoh9/PhxzObaOG7kyJGsWLGCJ554gscff5xu3bqxZs0a+vbta2+zdu1ae4AFcOuttwIwf/58FixYwPbt2/n2228B6Nq1q1N/jhw5QkZGhq8uN+hEhIbwzC396WmJ408f7+XtrSf47w9ZxEWGEhUWQmRYCFHhIUQ53tccR4aFEF3zXGTNvf2xQ/vocOfHIWYD7BnkCXuxyNPqqgyQAEmIppBNa73D6PlHBqF7HaRA1ZLqILnr8325PPjODgrLfbstSeuYcNLiI7HER2BJiMISH4klwfE4kvjIUExG2HwR1IJsWu2j6CQoOAF3b4B2F+ndMyECS8EpeL43mELgd9kQGq53jwLTs73U/7DduQ46epaeEgzc/f2t+wiSCB6X90zlm8ev5PT5csqrrJRWWimrslJWaXV6XF7zXL3HVVbKtffUPOd4r8kvqSS/pJK9jdRZjAoLwZIQaQ+Y0uIjSa+5tySox8mxEf4ZjdJGkKpKobBcPZYRJCE8F98GwmLUavTnjkJKd717FHiKz6jBESaw9L1g85ZMAiThVdHhoXRNjfX6eRVFobzKRkllNWeKKsguKCe7sFy9rznOKSwnq6CcgrIqyqqsHMkrabQEQYjZRGpcRM1olBo4tUmMJCMphs4pMXRoHUN4qBfS9MKiIDIRys+DUpOfJavYhPCcyaROs2VlqivZJEDyXHZN/lFSV3XfM9EgCZBEQDCZTGoOUngIybER9EpveFi0rNJqD5ZyCusHUtkF5eQWlWO1KWQVqO1cCTGbaN8qik7JMXROiaVzSgydkmPokhJLalyEZ1N48W3UAAkgIsHrpfOFaDG0AEnykJpGErTdJgGSCDpR4SFkJMeQkRzTYBurTSGvuIKsmsBJC6hOnS/jSF4xR86UUFJp5ejZUo6eLeXz/c51nmLCQ+iUEkPnZOfAqVNyDDERLn6s4tIhV11VKdNrQjSDLPVvHknQdpsESKJFCjGbSItXc5JwURRdURRyiyo4dKaYI3klHD5TwuGa4+P5pZRUWtl9qpDdp+pvOZMWH1EvcBoanox94lFqIAnRdFIssnm0ESSLjCBdiARIQrhgMtUGUCO7JDu9Vllt43h+TdCUVxs4HT5TwtmSSnIKK8gprGDL4dr9ouaEVvCrmp+2LblmVr2bSXpCJJaEKNJr8p8sCZG0jg7HbJAyBiUV1ZwtruRMcQV5xRUUlVczsH2iT3LMhHCb4wiSoqh5ScI95QVw7oh6LCNIFyQBkhAeCg810zU1jq6p9RMcC0qrOJxXXBM8qfdH8ko4ezbJ3mZfURTvbz/l+twhZtISImqSxqPUIEpbgVez+i4lNoLQEM+Tx202hYKyKvKKK8grrqy5r+Csw7H2/NniSqeVg466pcYyoa+F8X3T6ZUeZ5xyCqJlSOoCmNScvpI8iE3Ru0eBI3uXep/QHqJb69uXACABkhBelBAdxqAOrRjUoZXT87a9xbDyDQCG9evFb9N6OCWOZxWUk1dcQaXVxon8Mk7klwHnXH6G2aRWMU9LiLSPPqXXjEBVWxWnwOeMQwCUX1JJtc2zsmeRYWaSYyNIjo0gPMTMjhPnOJBbzIHPDvLSZwfpmBTN+L4WJvRNZ0C7BAmWhO+FRUFiezh/XE3UlgDJfZJ/5BEJkITwA3NCuv24T7eu9BnctV6bymobuUW1CePZBbX32uq7nMJyqm2K+riwnB+a0JeEqDCSY8NJio0gJTbCfpwcG0FSbHhNQKTe1004LyirYsPeHD7enc2XP53h2NlS/vbFYf72xWHSEyIZ18fChL4WLspoHXgVz0XgSOqmBkh5P0HHkXr3JnBI/pFHJEASwh/i2tQeN5CkHR5qpl2raNq1im7wNFabwtniCvuoU20QVUZ2YTlhIWZSHAKdJIdgJzk2gtYx4c2q7ZQQFcaNg9tx4+B2lFRU8/n+XNbtzubzfblkFZSzfPNRlm8+SnJsBGP7pDGhr4WLOycR1oQpQSEalNwdDm2QlWyesi/xlxEkd0iAJIQ/xKSo2yMo1mYt8w8xm0iNjyQ1PpL+7bzYvyaIiQjl5/3b8PP+bSivsvLVgTw+3p3Fp3tyyCuuYMW3x1nx7XESo8MY00sNlkZ1SyYiNETfjovAJ5vWeq6yFPL2q8cSILlFAiQh/MFshj43QM5uSOmpd2+8LjIshKt6p3FV7zQqq21sOXyWdbuz+N+POZwtqeS9bSd5b9tJYiNCuaJnKhP6WhjdI4XocPknqDHVVhu7ThVw6EwJI7ok0TYxSu8uGYNsWuu53D1qJf+YFIiz6N2bgCD/OgnhLze/0SKWJYeHmhndPYXR3VP440SFrUfyWbc7i3U/ZpNTWMHaH06z9ofTRIap7Sb0TeeKXqnER4bp3XXdWW0Ke7MK2XLoLFsOn2XrkXyKK9TNn80mGNvbwvSRGVzcuXXLTojXlvqfOwrVFRAaoWt3AoLj9FpL/rvjAZOiKJ4taxGA+7sBCyFUNpvCjhPn+eTHbD7enVWzUk8VHmJmWKfWZCRH0yYxiraJUaQnRNEmUa1FFaw5TDabwv6cIntA9O3hsxSWVzu1iY8MpUNStFNR0p6WOKaNyGDioDYtbhSurNLKT9mF9H6rD2HVJTxueZ24Dv24YXBbelrk3+IGrf0VbH8TRs2BMfP17o2u3P39LQFSE0mAJETTKYrCj6cLWbdbDZYOnWl4U2GtrEGbxEiH4Ek91m6tosMCYkRFURQOnSm2B0TfHM4nv6TSqU1sRCjDOrVmROckRnRJold6PCFmE/uzi3hzy1FWbz9lr1EVHxnKpIvaM21EBh2SGk7uD0Q2m8Kp82XszSpkX3YR+7IL2ZdVxJGzJSgKrAl/goHmw/yi8iE+sQ0D1MDxxsFtuX5gW7VKvqj12mVwegfc8ib0mah3b3QlAZKPSYAkhPccyCniu6PnOH2+jNMFZer9eXWVXqXVdsH3R4aZ1WCpZtSp9rj2cWSY/5PDFUXh6NlSh4DoLGeKKpzaRIWFMNQhIOrbJr7RQqAFpVWs2naCt7Yc43h+KaDOmFzRI5XpIzMY1TXZMNXY3VVYXsVP2UXszS5iX01AtD+7yD69WFdSTDgvRrzKqNINbO/2AH+zTeSzfblUWdVfZyYTXNIlmRsGtWVcXwuxrvZHbEmsVfCnNmCthF/tgNad9e6RriRA8jEJkITwPZtNIa+kgtPny8k6X8apmsDp9PkysgrKOHVeLbDpjrjIUBKiwlze4uvcO70WGepR5fIT+aVsOXxWDYoOnSW7sNzp9YhQM0M6trIHRP3bJTap9ILNprDxp1yWbz7Glz/VbqbcOSWGaRd35KYh7YgzWF6X1aZw9GwJ+7LUEaG9Nfcnz5W5bB8eYqZraiw90+PoZYmnZ3ocPS3xpMRFwJd/gc/+CAOmwA1LOF9ayYe7sli9/RTfH6stshoVFsLYPmncMKgto7omN6kKfcDL3gVLRkFEAjx2rMXnIEmA5GMSIAlhDBXVVrILyu3BU1bNKNQp7fh8GSWVrrdNcVdsRKhDAFVzHFkbRMVEhKrJ1YfP1vtlHx5iZmCHRHtANLB9otdHsw6dKeYfW47x3raT9lGX2IhQbhrclmkjM+iS4v/9884UVbA/u4j9ObWjQj/lFFFR7XpEMD0hkp6WOHqmx9PTEkev9Hg6Jcc0nH/24xpYNR3aDoF7PnN66fjZUtZknmL1jlMcyaudvk2OjeC6AW24cXBb+rSJD4hpWa/Y8S/4z33QcRTc+aHevdGdBEg+JgGSEIFBURQKy6rJK6mgoKyKgrIqCmvuC0qr7M853grLqigsr25wiqcxoWYT/dslMKJLEiM6JzOkYyuiwv0zvVdcUc3720/y5uajTnldP+uWzPQRGVzeM9XrFc5LKqr5KUcNfrSpsf3ZRZytk1uliQwz08MSTy9LnFNAlBgd7tkH5+yBV0c0OiqiKAo/nCxg9faT/HdnllO+V7fUWCYOasvEQW2Dv3zCR7+FrX+Di++H8X/Suze6kwDJxyRAEiL4VVttFJZXNxhEaUFWUUUV7VtHM6JzEkMzWtfbosXfFEXh64N5vLn5KBv25aL9K9+hdTRTL+7IpIvakxDt2fRbtdXGkbwS+0iQFgxpeVB1mUzq5/VIi7OPCPVMj6dD62jvBGlV5fCndLW2z29+gjjXFertza02vvzpDO/vOMX6PTlUOoxkDe/UmhsHt2VCn1TiK7Lh7CHIP6zeKgph0FTocHHz+6yXpePh+Ba44TUYMFnv3uhOAiQfkwBJCBEITuSX8o9vjrHyuxMUlFUBal7OxEFtmT6yY72l8YqikFVQbp8e25+tBkOHcosbTJhPjo2ghyWWHmnqaFAPSxzd0mJ9X4LgxQFqLaQZH0LGKPfeY7NSlHuE7du/5+D+nXD2MB1N2XQyZdPelEu4qYHp2D43wlVPQmKHZnfbalMoq7JSVmmlvMpKWVXNfaV2bKO8yvE1m72N1q682kZZpZWKau2xdj6b/X0V1TZ6W2JYXXgrodWlcN83kNqr2f0PdBIg+ZgESEKIQFJWaWVN5ine3HyUfdlF9ueHd2rNmF5pHMsvsU+P1a3FpIkOD6F7zYiQdt/DEkdSrE6FGv91Cxz4H/z8ebjortrnbVYoOAn5h2pGg47UHp87CraqBk9ZoYRxTEnltDmdsNRudIurJOXQ+5hQsIZEcKjrnezudBfFSoQ9oCmrslJec1zqEPSor9vsQU1pZTXlVTa3VmZ6SydTFp9H/IYKItgyOZPRPdNbTu5VAyRA8jEJkIQQgUhR1Ormb245yic/5mC11f8VEGI20Tk5hh4Wx2AonnatooxVQmDd4/DNK9DpUkjrpwZB+YfVIMjqOgcKgJBwaNUJkrqoS95bd0Zp3YWfqlJYdcDGmh9ynFZH9jYdZV7YP7jYvBeAHCWRp6tu5X3bKBSatyouMsxMdHgokaFmIsNDiAoLITJMuzcT6fA4KjzE3i4yVH3ccLsQTCbI/PjvXHvg9+ywdeWGyj8wuEMic67qwSVdk1psoCQBko9JgCSECHSnz5ex4tvj/JRTROeUWHsw1CU1JjA2Ff5+GXzwkOvXXARBtO6sPo5vC+aGr6/aamPTobOs3n6Sb4/kExpiIirUzOXKVu4sXYrFmgXA8cgefNzuQc4kDlKDkrAQosMdghSHgMXpvuY4ItTs+yBl/TzY9CLbUm/k9qxJlFepo1fDOrXmN1d1Z3jnJN9+vgFJgORjEiAJIYTOSvNhzX3qcVIXaN0JWndxKwhqsuoK+OZV+PIZqKyZqvRifpLXvXU9HN4I175Ibvdb+evnh1jx7XH7NN+orsnMGdudwR1a6dtPP5IAycckQBJCiBasOBc+Wwjb/wEoEBoJIx+ASx6CCP/XnXJJUeDpTlB2DmZthDaDAMgqKGPxZwd59/sT9urjl/dIYc5VPejXLkHHDvuHBEg+JgGSEEIIsnbCurlw7Gv1caxF3Qy2/61g1rlq9/kT8EJfMIfC46ch1DmZ/kR+KS9/doB/bz9lz0Ub2zuNX1/VnV7pwft7TQIkH5MASQghBKCO1Oz7AP73hJogDpA+EMb/GTqO0K9fez+AlberCez3ft1gs6N5Jby04QBrMk+h5exf0z+dX4/pRtfUOD911n/c/f3dAjelEUIIIbzIZIJe18L9W2HMkxAeB1mZsGw8rJoB54/r06/snep9+oBGm2Ukx/Dc5IH879eX8vP+6QB8uDOLsc9/ya9XZnLUYbuWlkQCJCGEEMIbQiNg1EPwq+0weBpggh9Xw8sXwYaFUFHs3/5k/aDep/d3q3nX1DgW3zaYdQ/9jHF90rApsHrHKa587gt++94PnGigarovVFRbOXW+jKLyhmtW+ZpMsTWRTLEJIYRolJ75STYbPN8Hik7DXZ80aauU3acKeG79T3y2LxdQ9xmcPLQ9s6/oSnqC5/vX2WwK50orOVNcwZmiCnILK+zH9lvNY63q+/OTB3DDoHYef1ZjJAfJxyRAEkIIcUHeyk+y2aD8PJTkQWmeel9yBkrPOhznQcnZ2ucVK2CCuSebtbJu+/FzPL/+J746kAdAeIiZ24Z34L7LupAaH0lJRbVTcHOmqILcovJ6QU9ecaXLwqQNCQ8x8/trezP14o5N7rsrEiD5mARIQggh3OayftINammA6go1qCnJqwl4zjgEQnUDHg/1uwVu+rtXLmHrkXye/d9+vj2SD6gBTGiIidJKz/qVFBNOSlyEeouNqD2u8zghKswnhTQlQPIxCZCEEEJ4rG79JE9FxENMMkQnq/dOxykQneR8HOrdffIURWHzobM8+7/9bD9+3v58dHgIqQ0EOurjSFLiIkiKDScsRN/0ZwmQfEwCJCGEEE2WtRM+nQ+ntkN065ogJwVikhyOk2sCHodjLwc8TaUoCofOFBNqNpMSF0FMRKjeXXKbu7+/A+eKhBBCiGCR3h+mrta7F01mMpmCskaSI1nmL4QQQghRhwRIQgghhBB1SIAkhBBCCFGHBEhCCCGEEHVIgCSEEEIIUYcESEIIIYQQdUiAJIQQQghRhwRIQgghhBB1SIAkhBBCCFGHBEhCCCGEEHVIgCSEEEIIUYcESEIIIYQQdUiAJIQQQghRhwRIQgghhBB1hOrdgUClKAoAhYWFOvdECCGEEO7Sfm9rv8cbIgFSExUVFQHQvn17nXsihBBCCE8VFRWRkJDQ4Osm5UIhlHDJZrNx+vRp4uLiMJlMXjtvYWEh7du358SJE8THx3vtvEbVkq5XrjV4taTrlWsNXi3lehVFoaioiDZt2mA2N5xpJCNITWQ2m2nXrp3Pzh8fHx/Uf0HraknXK9cavFrS9cq1Bq+WcL2NjRxpJElbCCGEEKIOCZCEEEIIIeqQAMlgIiIimD9/PhEREXp3xS9a0vXKtQavlnS9cq3Bq6Vd74VIkrYQQgghRB0ygiSEEEIIUYcESEIIIYQQdUiAJIQQQghRhwRIQgghhBB1SICkg1deeYWMjAwiIyMZPnw4W7dubbT9qlWr6NmzJ5GRkfTr14+PPvrITz1tnkWLFjF06FDi4uJITU1l4sSJ7N+/v9H3LF++HJPJ5HSLjIz0U4+bbsGCBfX63bNnz0bfE6jfK0BGRka96zWZTNx///0u2wfS9/rll19y7bXX0qZNG0wmE2vWrHF6XVEU5s2bR3p6OlFRUYwZM4YDBw5c8Lye/tz7Q2PXWlVVxaOPPkq/fv2IiYmhTZs2TJs2jdOnTzd6zqb8LPjLhb7bGTNm1Ov7+PHjL3jeQPtuAZc/vyaTib/85S8NntPI360vSIDkZytXrmTOnDnMnz+f7du3M2DAAMaNG0dubq7L9ps3b2bKlCnMnDmTHTt2MHHiRCZOnMju3bv93HPPffHFF9x///188803rF+/nqqqKsaOHUtJSUmj74uPjycrK8t+O3bsmJ963Dx9+vRx6vfXX3/dYNtA/l4BvvvuO6drXb9+PQC33HJLg+8JlO+1pKSEAQMG8Morr7h8/emnn+all15iyZIlfPvtt8TExDBu3DjKy8sbPKenP/f+0ti1lpaWsn37dn7/+9+zfft23n//ffbv38911113wfN68rPgTxf6bgHGjx/v1Pe333670XMG4ncLOF1jVlYWS5cuxWQycdNNNzV6XqN+tz6hCL8aNmyYcv/999sfW61WpU2bNsqiRYtctp80aZJyzTXXOD03fPhw5Re/+IVP++kLubm5CqB88cUXDbZZtmyZkpCQ4L9Oecn8+fOVAQMGuN0+mL5XRVGUBx98UOnSpYtis9lcvh6o3yugrF692v7YZrMpFotF+ctf/mJ/7vz580pERITy9ttvN3geT3/u9VD3Wl3ZunWrAijHjh1rsI2nPwt6cXW906dPV66//nqPzhMs3+3111+vXHHFFY22CZTv1ltkBMmPKisr2bZtG2PGjLE/ZzabGTNmDFu2bHH5ni1btji1Bxg3blyD7Y2soKAAgNatWzfarri4mI4dO9K+fXuuv/56fvzxR390r9kOHDhAmzZt6Ny5M7fffjvHjx9vsG0wfa+VlZX885//5K677mp04+ZA/V4dHTlyhOzsbKfvLiEhgeHDhzf43TXl596oCgoKMJlMJCYmNtrOk58Fo9m4cSOpqan06NGDe++9l7NnzzbYNli+25ycHD788ENmzpx5wbaB/N16SgIkP8rLy8NqtZKWlub0fFpaGtnZ2S7fk52d7VF7o7LZbDz00ENccskl9O3bt8F2PXr0YOnSpfznP//hn//8JzabjZEjR3Ly5Ek/9tZzw4cPZ/ny5axbt45XX32VI0eO8LOf/YyioiKX7YPlewVYs2YN58+fZ8aMGQ22CdTvtS7t+/Hku2vKz70RlZeX8+ijjzJlypRGNzL19GfBSMaPH89bb73Fhg0beOqpp/jiiy+YMGECVqvVZftg+W7ffPNN4uLiuPHGGxttF8jfbVOE6t0B0TLcf//97N69+4Lz1SNGjGDEiBH2xyNHjqRXr1787W9/Y+HChb7uZpNNmDDBfty/f3+GDx9Ox44deffdd936X1kge+ONN5gwYQJt2rRpsE2gfq9CVVVVxaRJk1AUhVdffbXRtoH8s3Drrbfaj/v160f//v3p0qULGzdu5Morr9SxZ761dOlSbr/99gsunAjk77YpZATJj5KTkwkJCSEnJ8fp+ZycHCwWi8v3WCwWj9ob0ezZs/nggw/4/PPPadeunUfvDQsLY9CgQRw8eNBHvfONxMREunfv3mC/g+F7BTh27Biffvopd999t0fvC9TvVft+PPnumvJzbyRacHTs2DHWr1/f6OiRKxf6WTCyzp07k5yc3GDfA/27Bfjqq6/Yv3+/xz/DENjfrTskQPKj8PBwhgwZwoYNG+zP2Ww2NmzY4PS/a0cjRoxwag+wfv36BtsbiaIozJ49m9WrV/PZZ5/RqVMnj89htVrZtWsX6enpPuih7xQXF3Po0KEG+x3I36ujZcuWkZqayjXXXOPR+wL1e+3UqRMWi8XpuyssLOTbb79t8Ltrys+9UWjB0YEDB/j0009JSkry+BwX+lkwspMnT3L27NkG+x7I363mjTfeYMiQIQwYMMDj9wbyd+sWvbPEW5p33nlHiYiIUJYvX67s2bNHmTVrlpKYmKhkZ2criqIoU6dOVR577DF7+02bNimhoaHKM888o+zdu1eZP3++EhYWpuzatUuvS3DbvffeqyQkJCgbN25UsrKy7LfS0lJ7m7rX++STTyqffPKJcujQIWXbtm3KrbfeqkRGRio//vijHpfgtt/85jfKxo0blSNHjiibNm1SxowZoyQnJyu5ubmKogTX96qxWq1Khw4dlEcffbTea4H8vRYVFSk7duxQduzYoQDKc889p+zYscO+cuvPf/6zkpiYqPznP/9Rdu7cqVx//fVKp06dlLKyMvs5rrjiCuXll1+2P77Qz71eGrvWyspK5brrrlPatWunZGZmOv0MV1RU2M9R91ov9LOgp8aut6ioSHn44YeVLVu2KEeOHFE+/fRTZfDgwUq3bt2U8vJy+zmC4bvVFBQUKNHR0cqrr77q8hyB9N36ggRIOnj55ZeVDh06KOHh4cqwYcOUb775xv7a6NGjlenTpzu1f/fdd5Xu3bsr4eHhSp8+fZQPP/zQzz1uGsDlbdmyZfY2da/3oYcesv/ZpKWlKVdffbWyfft2/3feQ5MnT1bS09OV8PBwpW3btsrkyZOVgwcP2l8Ppu9V88knnyiAsn///nqvBfL3+vnnn7v8e6tdj81mU37/+98raWlpSkREhHLllVfW+zPo2LGjMn/+fKfnGvu510tj13rkyJEGf4Y///xz+znqXuuFfhb01Nj1lpaWKmPHjlVSUlKUsLAwpWPHjso999xTL9AJhu9W87e//U2JiopSzp8/7/IcgfTd+oJJURTFp0NUQgghhBABRnKQhBBCCCHqkABJCCGEEKIOCZCEEEIIIeqQAEkIIYQQog4JkIQQQggh6pAASQghhBCiDgmQhBBCCCHqkABJCCG8xGQysWbNGr27IYTwAgmQhBBBYcaMGZhMpnq38ePH6901IUQACtW7A0II4S3jx49n2bJlTs9FRETo1BshRCCTESQhRNCIiIjAYrE43Vq1agWo01+vvvoqEyZMICoqis6dO/Pee+85vX/Xrl1cccUVREVFkZSUxKxZsyguLnZqs3TpUvr06UNERATp6enMnj3b6fW8vDxuuOEGoqOj6datG2vXrvXtRQshfEICJCFEi/H73/+em266iR9++IHbb7+dW2+9lb179wJQUlLCuHHjaNWqFd999x2rVq3i008/dQqAXn31Ve6//35mzZrFrl27WLt2LV27dnX6jCeffJJJkyaxc+dOrr76am6//Xby8/P9ep1CCC/Qe7dcIYTwhunTpyshISFKTEyM0+3//u//FEVRFED55S9/6fSe4cOHK/fee6+iKIry2muvKa1atVKKi4vtr3/44YeK2Wy27+jepk0b5Xe/+12DfQCUJ554wv64uLhYAZSPP/7Ya9cphPAPyUESQgSNyy+/nFdffdXpudatW9uPR4wY4fTaiBEjyMzMBGDv3r0MGDCAmJgY++uXXHIJNpuN/fv3YzKZOH36NFdeeWWjfejfv7/9OCYmhvj4eHJzc5t6SUIInUiAJIQIGjExMfWmvLwlKirKrXZhYWFOj00mEzabzRddEkL4kOQgCSFajG+++abe4169egHQq1cvfvjhB0pKSuyvb9q0CbPZTI8ePYiLiyMjI4MNGzb4tc9CCH3ICJIQImhUVFSQnZ3t9FxoaCjJyckArFq1iosuuohRo0bxr3/9i61bt/LGG28AcPvttzN//nymT5/OggULOHPmDA888ABTp04lLS0NgAULFvDLX/6S1NRUJkyYQFFREZs2beKBBx7w74UKIXxOAiQhRNBYt24d6enpTs/16NGDffv2AeoKs3feeYf77ruP9PR03n77bXr37g1AdHQ0n3zyCQ8++CBDhw4lOjqam266ieeee85+runTp1NeXs7zzz/Pww8/THJyMjfffLP/LlAI4TcmRVEUvTshhBC+ZjKZWL16NRMnTtS7K0KIACA5SEIIIYQQdUiAJIQQQghRh+QgCSFaBMkmEEJ4QkaQhBBCCCHqkABJCCGEEKIOCZCEEEIIIeqQAEkIIYQQog4JkIQQQggh6pAASQghhBCiDgmQhBBCCCHqkABJCCGEEKIOCZCEEEIIIer4f0PEWBFabTU1AAAAAElFTkSuQmCC",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history.history['mean_squared_error'], label='Training MSE')\n",
        "plt.plot(history.history['val_mean_squared_error'], label='Validation MSE')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs. Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# MIN LOSS = 0.0128 c/fund 50epochs MSE\n",
        "##         = 0.0118 s/fund 50epochs MSE\n",
        "##         = 0.0039 s/fund 50epochs MSE m=4 d=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRlZuRUNa6Yb",
        "outputId": "85850559-311b-4cf4-ea5b-465a9ee8a7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a validation dataset (val_dataset)\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "next_sample = next(iterador)\n",
        "input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "actual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.08408859 0.16389884], shape=(2,), dtype=float32)\n",
            "[0.41132706 0.13638312]\n",
            "tf.Tensor([0.24121982 0.12276754], shape=(2,), dtype=float32)\n",
            "[0.41987458 0.13706377]\n",
            "tf.Tensor([0.39854735 0.49847874], shape=(2,), dtype=float32)\n",
            "[0.40183556 0.5056298 ]\n",
            "tf.Tensor([0.04556707 0.87766427], shape=(2,), dtype=float32)\n",
            "[0.06095485 0.84066015]\n",
            "0.10242437 0.42337993\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Vemos algunos valores\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 4):\n",
        "        print(e[1][i])\n",
        "        print(predictions[i])\n",
        "    break\n",
        "    \n",
        "\n",
        "RMSE_pred = mean_squared_error(actual_values, predictions, squared=False)\n",
        "RMSE_rand = mean_squared_error(actual_values, next_sample[1], squared=False)\n",
        "print(RMSE_pred, RMSE_rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "4.662921348314606"
            ]
          },
          "execution_count": 163,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0.415/0.089"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds5iD1OMbZu3"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "operands could not be broadcast together with shapes (4,4,1,1) (8,8,70,70) ",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[164], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m val_dataset:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m printear \u001b[38;5;28;01melse\u001b[39;00m batch_size):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Valores actuales\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m#h = e[1][i].numpy().reshape(basis.size,basis.size)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         h_true \u001b[38;5;241m=\u001b[39m \u001b[43mgen_to_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho_1_arrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m#print(h) if printear else 0\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigvals(e[\u001b[38;5;241m0\u001b[39m][i]))\n",
            "Cell \u001b[0;32mIn[67], line 22\u001b[0m, in \u001b[0;36mgen_to_h\u001b[0;34m(base, rho_1_arrays)\u001b[0m\n\u001b[1;32m     20\u001b[0m triag \u001b[38;5;241m=\u001b[39m fill_triangular_np(base)\n\u001b[1;32m     21\u001b[0m body_gen \u001b[38;5;241m=\u001b[39m triag \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(triag)\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mdiag(np\u001b[38;5;241m.\u001b[39mdiag(triag))\n\u001b[0;32m---> 22\u001b[0m h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(\u001b[43mbase_hamiltonian\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbody_gen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho_1_arrays\u001b[49m\u001b[43m)\u001b[49m)  \n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h\n",
            "Cell \u001b[0;32mIn[3], line 35\u001b[0m, in \u001b[0;36mbase_hamiltonian\u001b[0;34m(mat, basis, rho_1_gen)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mbase_hamiltonian\u001b[39m(mat, basis, rho_1_gen):\n\u001b[0;32m---> 35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase_hamiltonian_aux\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43md\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho_1_gen\u001b[49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[3], line 31\u001b[0m, in \u001b[0;36mbase_hamiltonian_aux\u001b[0;34m(mat, size, d, rho_1_gen)\u001b[0m\n\u001b[1;32m     29\u001b[0m rho_1_gen_transposed \u001b[38;5;241m=\u001b[39m rho_1_gen\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m     30\u001b[0m mat_expanded \u001b[38;5;241m=\u001b[39m mat[:, :, np\u001b[38;5;241m.\u001b[39mnewaxis, np\u001b[38;5;241m.\u001b[39mnewaxis]\n\u001b[0;32m---> 31\u001b[0m h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39msum(\u001b[43mmat_expanded\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrho_1_gen_transposed\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m, axis\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m))\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m h\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mfloat32)\n",
            "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (4,4,1,1) (8,8,70,70) "
          ]
        }
      ],
      "source": [
        "m_size = basis.size\n",
        "rho_1_pred = []\n",
        "rho_1_actual = []\n",
        "norm = []\n",
        "norm_rand = []\n",
        "printear =  False\n",
        "\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 3 if printear else batch_size):\n",
        "        # Valores actuales\n",
        "        #h = e[1][i].numpy().reshape(basis.size,basis.size)\n",
        "        h_true = gen_to_h(e[1][i], rho_1_arrays)\n",
        "        #print(h) if printear else 0\n",
        "        r = max(np.linalg.eigvals(e[0][i]))\n",
        "        rho_1_actual.append(r)\n",
        "\n",
        "        print(h_true) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "\n",
        "        # Valores predichos\n",
        "        #h = predictions[i].reshape(basis.size,basis.size)\n",
        "        h_pred = gen_to_h(predictions[i], rho_1_arrays)\n",
        "        beta = 1\n",
        "        # Estado térmico\n",
        "        state = thermal_state(h_pred, beta)\n",
        "        # Estado puro\n",
        "        #state = pure_state(h_pred)\n",
        "        rho1 = np.array(rho_1(basis.d, state, rho_1_arrays))\n",
        "        r = max(np.sort(linalg_d.eigvals(rho1).real))\n",
        "        rho_1_pred.append(r)\n",
        "\n",
        "        print(h_pred) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "        \n",
        "\n",
        "        # Normas\n",
        "        norm.append(np.linalg.norm(h_true-h_pred, ord='fro'))\n",
        "        print(f'Norma {norm[-1]}') if printear else 0\n",
        "        ## Vamos a comparar con un h aleatorio\n",
        "        size = basis.d*(basis.d+1)//2\n",
        "        base = np.random.uniform(low=0, high=1.0, size=(size,))\n",
        "        h_rand = gen_to_h(base, rho_1_arrays)\n",
        "        norm_rand.append(np.linalg.norm(h_true-h_rand, ord='fro'))\n",
        "        #print(f'Norma random {norm_rand[-1]}') if printear else 0\n",
        "        print('') if printear else 0\n",
        "        \n",
        "\n",
        "\n",
        "    # e contiene todo el batch y nos basta con uno\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(e[1][10])\n",
        "predictions[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "AL2EC9Ci-0HG",
        "outputId": "545ebe57-d3de-490f-f076-709d5c47b5f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f=1\n",
        "rho_1_actual = np.array(rho_1_actual)\n",
        "rho_1_pred = np.array(rho_1_pred)\n",
        "#print(mean_squared_error(rho_1_pred, rho_1_actual))\n",
        "\n",
        "print('Rho1 based statistics')\n",
        "print(np.mean(np.abs(rho_1_actual-rho_1_pred)))\n",
        "print(np.mean(rho_1_actual)*f)\n",
        "print('std')\n",
        "print(np.std(rho_1_actual-rho_1_pred)*f)\n",
        "print(np.std(rho_1_actual)*f)\n",
        "print(np.std(rho_1_pred)*f)\n",
        "plt.hist(np.array(rho_1_pred-rho_1_actual), bins=50)\n",
        "plt.show()\n",
        "print('H based statistics')\n",
        "print(np.mean(norm), np.mean(norm_rand))\n",
        "print(np.mean(norm_rand)/np.mean(norm))\n",
        "\n",
        "\n",
        "# BEST: FACTOR 1/8 c/fund\n",
        "## 500 epochs, 10M dataset\n",
        "# BEST: FACTOR 1/9 s/fund\n",
        "## 50 epochs, 5M dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "6.25/1.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 25 epochs d = m*2\n",
        "res = {}\n",
        "res[5] = 35/8.19 \n",
        "res[4] = 15/2.47\n",
        "res[3] = 6.2/1.73"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YioVllOX3M1N",
        "outputId": "b7715c37-1400-4c04-8be3-dd247b4b9db9"
      },
      "outputs": [],
      "source": [
        "# Get the weights of all dense layers in the model\n",
        "dense_weights = []\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Dense):\n",
        "        weights = layer.get_weights()\n",
        "        if len(weights) > 0:\n",
        "            dense_weights.append(weights[0])\n",
        "\n",
        "# Visualize the weights of each dense layer\n",
        "for i, weights in enumerate(dense_weights):\n",
        "    plt.figure()\n",
        "    plt.imshow(weights, cmap='viridis', aspect='auto')\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"Dense Layer {i+1} Weights Visualization\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 1 1] [0 1 1 0 0 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "            if mat[i,j,0,9] != 0:\n",
        "                print(v,w)\n",
        "\n",
        "    return mat\n",
        "\n",
        "r = rho_2_gen(basis, basis_m2, t_basis)\n",
        "r[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 1],\n",
              "       [1, 0, 1, 1, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 0],\n",
              "       [1, 0, 1, 0, 0, 1],\n",
              "       [1, 0, 0, 1, 1, 0],\n",
              "       [1, 0, 0, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 1],\n",
              "       [0, 1, 1, 1, 0, 0],\n",
              "       [0, 1, 1, 0, 1, 0],\n",
              "       [0, 1, 1, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 0, 1, 1],\n",
              "       [0, 0, 1, 1, 1, 0],\n",
              "       [0, 0, 1, 1, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 1],\n",
              "       [0, 0, 0, 1, 1, 1]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basis.base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 20)\n",
            "[array([0, 1, 0, 1, 1, 0])] [0 1 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "col = 1\n",
        "b = b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0]))\n",
        "print(b.shape)\n",
        "for x in range(0,b.shape[1]):\n",
        "    if b[col,x] != 0:\n",
        "        ind = x\n",
        "        break\n",
        "else:\n",
        "    ind = NaN\n",
        "\n",
        "print([basis.base[ind]], mll_basis.base[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "d = 2*m\n",
        "basis = fixed_basis(m, d)\n",
        "t_basis = fixed_basis(2, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "ml_basis = basis_m1\n",
        "mll_basis = basis_m2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_basis = fixed_basis(2, d)\n",
        "mll_basis = fixed_basis(basis.m-2, d)\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2)))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    offset = 4*m+1\n",
        "    indices = [-(k-1)*(2*k-offset) for k in range(1,m+1)] # Lo saque de Mathmatica, vos confia\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    \n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "\n",
        "    hi = -np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    return (h0, hi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(h02,hi2) = two_body_hamiltonian(t_basis.size, m, [0,1,2], np.ones((3,3)), rho_1_arrays, rho_2_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]]]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "print(rho_2_arrays[9,0,0,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[[0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 2. 0.]\n",
            " [0. 0. 0. 0. 0. 2.]]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "index 6 is out of bounds for axis 1 with size 6",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[78], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md):\n\u001b[0;32m---> 15\u001b[0m         mat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mresult_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m rho_1_arrays[i,j,:,:]\n",
            "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 1 with size 6"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "\n",
        "A = np.array([0, 1, 2])  # Your list with d elements\n",
        "\n",
        "# Create a diagonal matrix with each element repeated twice\n",
        "result_matrix = np.diagflat(np.kron(A, np.ones(2)))\n",
        "\n",
        "print(result_matrix)\n",
        "np.kron(A, np.ones(2))\n",
        "\n",
        "mat = np.zeros((basis.size, basis.size))\n",
        "for i in range(0,2*d):\n",
        "    for j in range(0, 2*d):\n",
        "        mat += result_matrix[i,j] * rho_1_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mat = np.sum(result_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h0 == mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1]\n",
            "[0, 9, 14]\n",
            "[0, 9, 14]\n"
          ]
        }
      ],
      "source": [
        "d = 3\n",
        "t_basis = fixed_basis(2, 2*d)\n",
        "basis = fixed_basis(d, 2*d)\n",
        "size = t_basis.size\n",
        "#basis = fixed_basis(d, 2*d)\n",
        "diag_elem = []\n",
        "for x in t_basis.base:\n",
        "    if all([x[i] == x[i+1] for i in range(0, 2*d, 2)]):\n",
        "        print(x)\n",
        "        diag_elem.append(t_basis.rep_to_index(x))\n",
        "\n",
        "print(diag_elem)\n",
        "# Veamos el GALERAZO de Wolfram\n",
        "n = 4*d+1\n",
        "print([-(k-1)*(2*k-n) for k in range(1,d+1)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m2_basis = fixed_basis(2, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-2, d)\n",
        "print(nm2_basis.base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "index = [0,9,14]\n",
        "mat = np.zeros((size,size))\n",
        "for i in range(0,3):\n",
        "    for j in range(0,3):\n",
        "        mat[index[i], index[j]] = W[i,j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "#rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "\n",
        "W = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "W = np.ones((3,3))\n",
        "index = [0, 9, 14]\n",
        "size = 15  # Assuming size is the size of the matrix\n",
        "\n",
        "# Create a meshgrid of indices\n",
        "i, j = np.meshgrid(index, index, indexing='ij')\n",
        "\n",
        "# Use the meshgrid indices to assign values from W to the specified positions in mat\n",
        "mat = np.zeros((size, size))\n",
        "mat[i, j] = W\n",
        "\n",
        "# La mat... mat corresponde a los coeficientes en t_basis\n",
        "inte = np.zeros((basis.size, basis.size))\n",
        "for i in range(0, t_basis.size):\n",
        "    for j in range(0, t_basis.size):\n",
        "        inte += - mat[i, j] * rho_2_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inte == hi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "\n",
        "from numba import njit\n",
        "\n",
        "# Parametros hamiltoniano\n",
        "e = 1\n",
        "eps = 0\n",
        "e0 = np.zeros(2*d)\n",
        "eigenspace_tol = 0.0001\n",
        "for k in range(0, d):\n",
        "    r = random.random() * eps * 0\n",
        "    e0[2*k] = k*e+r\n",
        "    e0[2*k+1] = k*e+r\n",
        "\n",
        "@njit(parallel=True)\n",
        "def base_hamiltonian_aux(basis, size, d, basis_m1, basis_m2):\n",
        "    # Construccion de H\n",
        "    d = d//2\n",
        "    h0 = np.zeros((size,size), dtype=np.float32)\n",
        "    for k in prange(0,2*d):\n",
        "        h0 += e0[k] * np.dot(bd_aux(basis_m1, basis, k),b_aux(basis, basis_m1, k))\n",
        "    hi = np.zeros((size, size), dtype=np.float32)\n",
        "    for k in prange(0,d):\n",
        "        for kb in prange(0,d):\n",
        "            bd_terms = np.dot(bd_aux(basis_m1, basis, 2*k),bd_aux(basis_m2, basis_m1, 2*k+1))\n",
        "            b_terms = np.dot(b_aux(basis_m1, basis_m2, 2*kb+1),b_aux(basis, basis_m1, 2*kb))\n",
        "            hi += -1*np.dot(bd_terms,b_terms)\n",
        "\n",
        "    return (h0, hi)\n",
        "\n",
        "def base_hamiltonian(basis, basis_m1, basis_m2):\n",
        "    return base_hamiltonian_aux(basis.base, basis.size, basis.d, basis_m1.base, basis_m2.base)\n",
        "\n",
        "h0, hi = base_hamiltonian(basis, basis_m1, basis_m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oapxWkD16fHg"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
