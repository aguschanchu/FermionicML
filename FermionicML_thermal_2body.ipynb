{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguschanchu/FermionicML/blob/main/FermionicML_thermal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXz5cOlVwrzZ"
      },
      "source": [
        "# FermionicML:\n",
        "\n",
        "Code based on aguschanchu/Bosonic.py\n",
        "\n",
        "A diferencia del código anterior, este modelo trabaja sobre estados térmicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD2Yai55rMm"
      },
      "source": [
        "## Código base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgf9ExZN4jA7"
      },
      "source": [
        "Cargamos el código de Bosonic.py básico, branch fermionic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Gydz4kCH4l5w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/tmp/ipykernel_3654/4156838298.py:296: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  def gamma_lamba_inv(x):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import binom\n",
        "from scipy.sparse import dok_matrix, linalg\n",
        "from scipy import linalg as linalg_d\n",
        "from joblib import Memory\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from joblib import Parallel, delayed\n",
        "from numba import jit, prange, njit\n",
        "import numba as nb\n",
        "import pickle\n",
        "import math\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Funciones auxiliares optimiadas\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def int_to_tuple_arr(ni,nf, b, digits=None):\n",
        "    sol = np.zeros((nf-ni, digits), dtype=np.int64)\n",
        "    for n in prange(ni, nf):\n",
        "        r = np.zeros(digits, dtype=np.int64)\n",
        "        ncop = n\n",
        "        idx = 0\n",
        "        while n != 0:\n",
        "            r[idx] = n % b\n",
        "            n = n // b\n",
        "            idx += 1\n",
        "        if digits is not None:\n",
        "            if idx < digits:\n",
        "                for i in range(idx, digits):\n",
        "                    r[i] = 0\n",
        "                idx = digits\n",
        "        sol[ncop-ni,:] = r[:idx]\n",
        "    return sol\n",
        "\n",
        "def tuple_to_int(t, d):\n",
        "    b = d-1\n",
        "    l = len(t)\n",
        "    s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "    return sum(s)\n",
        "\n",
        "def create_basis_(m, d, size):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 1000000\n",
        "    for x in range(0,(m+1)**d, chunk_size):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        arr = int_to_tuple_arr(start_index, end_index, m+1, d)\n",
        "        sums = np.sum(arr, axis=1)\n",
        "        rows = np.where(sums == m)[0]\n",
        "        for row in [arr[i] for i in rows]:\n",
        "            if np.all(np.logical_or(row == 0, row == 1)):\n",
        "                base.append(row)\n",
        "\n",
        "    # Como consecuencia de la paralelizacion, es necesario reordenar la base\n",
        "    sorted_base = sorted(base, key=lambda x: tuple_to_int(x, d), reverse=True)\n",
        "    assert len(base) == size\n",
        "\n",
        "    return sorted_base\n",
        "\n",
        "def custom_base_representation_tf(n_min, n_max, base, num_digits):\n",
        "    # Generate a range of numbers from n_min to n_max\n",
        "    numbers = tf.range(n_min, n_max + 1, dtype=tf.int64)\n",
        "    \n",
        "    # Calculate the digits in the custom base using broadcasting\n",
        "    digits = tf.pow(tf.cast(base, dtype=tf.float64), tf.cast(tf.range(num_digits), dtype=tf.float64))\n",
        "    \n",
        "    # Reshape the digits to [1, num_digits] for broadcasting\n",
        "    digits = tf.reshape(digits, [1, -1])\n",
        "    \n",
        "    # Reshape numbers to [batch_size, 1]\n",
        "    numbers = tf.reshape(tf.cast(numbers, dtype=tf.float64), [-1, 1])\n",
        "    \n",
        "    # Calculate the digits in the custom base for each number using broadcasting\n",
        "    result = tf.cast(tf.math.floormod(tf.math.floordiv(numbers, digits), base), dtype=tf.int32)\n",
        "    \n",
        "    # Pad the result to have exactly num_digits columns\n",
        "    result = tf.pad(result, paddings=[[0, 0], [0, num_digits - tf.shape(result)[1]]], constant_values=0)\n",
        "    \n",
        "    # Reverse the order of columns\n",
        "    #result = tf.reverse(result, axis=[1])\n",
        "\n",
        "    return result\n",
        "\n",
        "def select_rows_with_sum(arr, m):\n",
        "    # Create a mask based on the criteria\n",
        "    mask = tf.reduce_all(tf.math.logical_or(tf.equal(arr, 0), tf.equal(arr, 1)), axis=1) & (tf.reduce_sum(arr, axis=1) == m)\n",
        "    \n",
        "    # Use the mask to select the rows\n",
        "    result = tf.boolean_mask(arr, mask, axis=0)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def create_basis_tf_(m, d):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 10000000\n",
        "    for x in tqdm(range(0,(m+1)**d, chunk_size)):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        res = custom_base_representation_tf(start_index, end_index, m+1, d)\n",
        "        arr = select_rows_with_sum(res, m)\n",
        "        base.append(arr.numpy())\n",
        "\n",
        "    return np.concatenate(base)\n",
        "\n",
        "class fixed_basis:\n",
        "\n",
        "    # Convierte a un enterno n a su escritura en base b\n",
        "    def _int_to_tuple(self, n, b, digits = None):\n",
        "        rep = np.base_repr(n, b)\n",
        "        rep_int = [int(x,b) for x in rep]\n",
        "        if digits is not None:\n",
        "            zeros = [0 for i in range(0,digits-len(rep))]\n",
        "            return zeros + rep_int\n",
        "        else:\n",
        "            return rep_int\n",
        "\n",
        "    # Revierte la transformacion anterior\n",
        "    def tuple_to_int(self, t):\n",
        "        b = self.d-1\n",
        "        l = len(t)\n",
        "        s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "        return sum(s)\n",
        "\n",
        "    # Convierte el vector en su representacion\n",
        "    def vect_to_repr(self, vect):\n",
        "        for i, k in enumerate(vect):\n",
        "            if k == 1. or k == 1:\n",
        "                break\n",
        "        else:\n",
        "            return 0\n",
        "        return self.base[i,:]\n",
        "\n",
        "    def rep_to_vect(self, rep):\n",
        "        rep = list(rep)\n",
        "        for i, r in [(j, self.base[j,:]) for j in range(0,self.size)]:\n",
        "            if list(r) == rep:\n",
        "                return self.canonicals[:,i]\n",
        "        else:\n",
        "            None\n",
        "\n",
        "    def rep_to_index(self, rep):\n",
        "        return self.base.tolist().index(list(rep))\n",
        "\n",
        "    @staticmethod\n",
        "    def rep_to_exi(rep):\n",
        "        r = []\n",
        "        for i, k in enumerate(rep):\n",
        "            r += [i for x in range(0,k)]\n",
        "        return r\n",
        "\n",
        "    # Crea base de M particulas en D estados (repr y base canonica)\n",
        "    def create_basis(self, m, d):\n",
        "        #print(\"Creating basis: \", m, d)\n",
        "        length = int(binom(d,m))\n",
        "        base = np.array(create_basis_tf_(m, d))\n",
        "        # Asignamos a cada uno de ellos un canónico\n",
        "        canonicals = np.eye(length)\n",
        "        return base, canonicals\n",
        "\n",
        "    def __init__(self, m, d):\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        self.size = int(binom(d,m))\n",
        "        (self.base, self.canonicals) = self.create_basis(m, d)\n",
        "\n",
        "\n",
        "# Matrices de aniquilación y creación endomórficas. Estan fuera de la clase para poder ser cacheadas\n",
        "#@memory.cache\n",
        "def bdb(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0 and v[i] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[j] -= 1\n",
        "                dest[i] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[i]+1)*np.sqrt(v[j])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0:\n",
        "                mat[k, k] = v[i]\n",
        "    return mat\n",
        "\n",
        "#@memory.cache\n",
        "def bbd(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 0 and v[j] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[i] -= 1\n",
        "                dest[j] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[j]+1)*np.sqrt(v[i])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 1:\n",
        "                mat[k, k] = v[i]+1\n",
        "    return mat\n",
        "\n",
        "# Matrices de aniquilación y creación.Toman la base de origen y destino (basis_o, basis_d) resp\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def b_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 0:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] -= 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i])\n",
        "    return mat\n",
        "\n",
        "def b(basis_o, basis_d, i):\n",
        "    return b_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def bd_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 1:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd(basis_o, basis_d, i):\n",
        "    return bd_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "\n",
        "# Acepta una lista de indices a crear\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def bd_gen_aux(basis_o, basis_d, gen_list):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        conds = np.zeros(len(gen_list), dtype=np.int64)\n",
        "        for i in range(len(gen_list)):\n",
        "            if basis_o[k][gen_list[i]] != 1:\n",
        "                conds[i] = 1\n",
        "        if np.all(conds):\n",
        "            dest = list(basis_o[k].copy())\n",
        "            for i in gen_list:\n",
        "                dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd_gen(basis_o, basis_d, i):\n",
        "    return bd_gen_aux(basis_o.base, basis_d.base, np.array(i))\n",
        "\n",
        "def b_gen(basis_o, basis_d, i):\n",
        "    return np.transpose(bd_gen(basis_d, basis_o, i))\n",
        "\n",
        "# Volvemos a definir la función para compilarla\n",
        "@nb.jit(forceobj=True)\n",
        "def _rep_to_index(base, rep):\n",
        "    return base.tolist().index(list(rep))\n",
        "\n",
        "# Funciones auxiliares para calcular rho2kkbar y gamma_p\n",
        "@nb.jit(nopython=True)\n",
        "def rep_to_exi(rep):\n",
        "    r = []\n",
        "    for i in range(len(rep)):\n",
        "        for j in range(rep[i]):\n",
        "            r.append(i)\n",
        "    return r\n",
        "\n",
        "@nb.njit\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "@nb.njit\n",
        "def gamma_lamba(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.jit\n",
        "def gamma_lamba_inv(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / np.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.njit\n",
        "def rep_to_index_np(base, rep):\n",
        "    for i in range(len(base)):\n",
        "        if np.all(base[i] == rep):\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "\n",
        "def gamma_p(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    return gamma_p_aux(basis.base, vect, m_basis.base, nm_basis.base)\n",
        "\n",
        "@nb.njit()\n",
        "def gamma_p_aux(basis, vect, m_basis, nm_basis):\n",
        "    mat = np.zeros((len(m_basis), len(nm_basis)), dtype=np.float32)\n",
        "    for i in prange(len(m_basis)):\n",
        "        v = m_basis[i]\n",
        "        for j in prange(len(nm_basis)):\n",
        "            w = nm_basis[j]\n",
        "            targ = v + w\n",
        "            index = rep_to_index_np(basis, targ)\n",
        "            if index != -1:\n",
        "                coef = vect[index]\n",
        "                if coef != 0:\n",
        "                    coef = coef * gamma_lamba_inv(v) * gamma_lamba_inv(w) * gamma_lamba(targ)\n",
        "                mat[i, j] = coef\n",
        "    return mat\n",
        "# Devuelve la matriz rho M asociada al vector\n",
        "def rho_m(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    g = gamma_p(basis, m, vect, m_basis, nm_basis)\n",
        "    return np.dot(g,np.transpose(g))\n",
        "\n",
        "# Devuelve la matriz gamma asociada a la descomposición (M,N-M) del vector\n",
        "@jit(forceobj=True)\n",
        "def gamma(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    mat = dok_matrix((m_basis.size, nm_basis.size), dtype=np.float32)\n",
        "    for i, v in enumerate(m_basis.base):\n",
        "        for j, w in enumerate(nm_basis.base):\n",
        "            targ = v+w\n",
        "            # Revisamos que sea un estado fermionico valido\n",
        "            arr = np.asarray(targ)\n",
        "            if not np.all(np.logical_or(arr == 0, arr == 1)):\n",
        "                continue\n",
        "            index = _rep_to_index(basis.base, targ)\n",
        "            coef = vect[index]\n",
        "            if coef != 0:\n",
        "                aux = lambda x: np.prod(np.reciprocal(np.sqrt([np.math.factorial(o) for o in x])))\n",
        "                aux_inv = lambda x: np.prod(np.sqrt([np.math.factorial(o) for o in x]))\n",
        "                coef = coef * aux(v) * aux(w) * aux_inv(targ)\n",
        "                #coef = coef\n",
        "                #print(v,w,coef)\n",
        "            mat[i,j] = coef\n",
        "    return mat\n",
        "\n",
        "# Genera las matrices de rho1\n",
        "def rho_1_gen(basis):\n",
        "    d = basis.d\n",
        "    s = basis.size\n",
        "    mat = np.empty((d,d,s,s), dtype=np.float32)\n",
        "    for i in range(0, d):\n",
        "        for j in range(0, d):\n",
        "            mat[i,j,:,:] = np.array(bdb(basis,j, i).todense())\n",
        "    return mat\n",
        "\n",
        "#@jit(parallel=True, nopython=True)\n",
        "def rho_1(d, state, rho_1_arrays):\n",
        "    state_expanded = state[np.newaxis, np.newaxis, :, :]\n",
        "    product = state_expanded * rho_1_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "\n",
        "    return mat\n",
        "\n",
        "\n",
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "\n",
        "    return mat\n",
        "\n",
        "def rho_2(size, state, rho_2_arrays):\n",
        "    state_expanded = np.expand_dims(state, axis=1)\n",
        "    state_expanded = np.expand_dims(state_expanded, axis=1)\n",
        "    rho_2_arrays = rho_2_arrays[np.newaxis, :, :, :, :]\n",
        "    print(state_expanded.shape, rho_2_arrays.shape)\n",
        "    product = state_expanded * rho_2_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "    return mat\n",
        "\n",
        "def rho_2_kkbar_gen(m, rho_2_arrays):\n",
        "    offset = 4*m+1\n",
        "    indices = [-(k-1)*(2*k-offset) for k in range(1,m+1)] # Lo saque de Mathmatica, vos confia\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "\n",
        "    rho_2_arrays_kkbar = rho_2_arrays[i, j, :, :]\n",
        "\n",
        "    return rho_2_arrays_kkbar\n",
        "\n",
        "# Devuelve la matriz rho 2 asociada al bloque kkbar\n",
        "def rho_2_kkbar(basis, vect, ml_basis = None, mll_basis = None, t_basis = None):\n",
        "    d = basis.d\n",
        "    # Creo las bases si no están dadas\n",
        "    if ml_basis == None or mll_basis == None or t_basis == None:\n",
        "        ml_basis = fixed_basis(m-1,d)\n",
        "        mll_basis = fixed_basis(m-2,d)\n",
        "        t_basis = fixed_basis(2,d)\n",
        "    diag = []\n",
        "    for v in t_basis.base:\n",
        "        for j in range(0, d, 2):\n",
        "            if v[j] == v[j+1]:\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            diag.append(v)\n",
        "    diag = np.array(diag)\n",
        "    return rho_2_kkbar_aux(diag, vect, basis.base, ml_basis.base, mll_basis.base, t_basis.base)\n",
        "\n",
        "@nb.njit\n",
        "def rho_2_kkbar_lambda(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "#@nb.njit(parallel=True)\n",
        "def rho_2_kkbar_aux(diag, vect, basis, ml_basis, mll_basis, t_basis):\n",
        "    mat = np.zeros((len(diag), len(diag)), dtype=np.float32)\n",
        "    for i in prange(len(diag)):\n",
        "        for j in prange(len(diag)):\n",
        "            v = diag[i]\n",
        "            w = diag[j]\n",
        "            # Creacion de los a\n",
        "            i_set = rep_to_exi(v)\n",
        "            b_m = b_aux(ml_basis, mll_basis, i_set[1]) @ b_aux(basis, ml_basis, i_set[0])\n",
        "            # Creacion de los ad\n",
        "            i_set = rep_to_exi(w)\n",
        "            bd_m = bd_aux(ml_basis, basis, i_set[1]) @ bd_aux(mll_basis, ml_basis, i_set[0])\n",
        "            # v1 = vect @ bd_m @ b_m @ vect Para estados puros\n",
        "            # Mult de b's y filleo de mat\n",
        "            coef = np.trace(vect @ bd_m @ b_m)\n",
        "            mat[i,j] = coef * rho_2_kkbar_lambda(v) * rho_2_kkbar_lambda(w)\n",
        "    return mat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dga5Xx_5vDf"
      },
      "source": [
        "## Definicion de Hamiltoniano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiTq53L5E1U"
      },
      "source": [
        "Cargamos el código de creación y resolución de Hamiltonianos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h5FXWv849Mq",
        "outputId": "49dd47b5-8c16-4ad4-92e7-e172462229b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 62.02it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 123.54it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 159.77it/s]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "m = 4\n",
        "d = 8\n",
        "# Creo las bases para no tener que recrearlas luego\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "PToiSs915TXw"
      },
      "outputs": [],
      "source": [
        "## Usamos este approach si queremos guardar los generadores\n",
        "# Dados 1/2 (d^2+d) elementos, genera una mat de dxd:\n",
        "eps = 0.00001\n",
        "\n",
        "def sym_mat_gen(vect, d):\n",
        "    matrix = fill_matrix(vect, d)\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "@jit(nopython=True)\n",
        "def fill_matrix(vect, d):\n",
        "    matrix = np.zeros((d, d))\n",
        "    idx = 0\n",
        "    for i in prange(d):\n",
        "        for j in prange(i, d):\n",
        "            matrix[i, j] = vect[idx]\n",
        "            idx += 1\n",
        "    return matrix\n",
        "\n",
        "# Generamos una matrix aleatoria. Cuidado con la distribución, ver https://stackoverflow.com/questions/56605189/is-there-an-efficient-way-to-generate-a-symmetric-random-matrix\n",
        "def hamil_base_gen(d):\n",
        "    U = np.random.uniform(low=0, high=1.0, size=(d, d))\n",
        "    hamil_base = np.tril(U) + np.tril(U, -1).T\n",
        "    return hamil_base\n",
        "\n",
        "# Dada un a mat dxd simetrica, contruye el hamiltoniano de un cuerpo a_{ij} c^{dag}_i c_j\n",
        "# Alternativamente podemos construirlo a partir de rho_1_gen\n",
        "def base_hamiltonian_aux(mat, size, d, rho_1_gen):\n",
        "    # Construccion de H\n",
        "    rho_1_gen_transposed = rho_1_gen.transpose(1, 0, 2, 3)\n",
        "    mat_expanded = mat[:, :, np.newaxis, np.newaxis]\n",
        "    h = np.sum(mat_expanded * rho_1_gen_transposed[:, :, :, :], axis=(0, 1))\n",
        "    return h.astype(np.float32)\n",
        "\n",
        "def base_hamiltonian(mat, basis, rho_1_gen):\n",
        "    return base_hamiltonian_aux(mat, basis.size, basis.d, rho_1_gen)\n",
        "\n",
        "def get_kkbar_indices(t_basis):\n",
        "    indices = []\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        if np.all(v[::2] == v[1::2]):\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2))) + eps * np.random.random((2*m,2*m))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    rho_1_arrays_t = tf.transpose(rho_1_arrays,perm=[1, 0, 2, 3])\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    rho_2_arrays_t = tf.transpose(rho_2_arrays,perm=[1, 0, 2, 3])\n",
        "\n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "    hi = np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "    return (h0, hi)\n",
        "\n",
        "def solve(h, last_step = None):\n",
        "    sol = linalg.eigsh(h, which='SA',k=19)\n",
        "    eigenspace_tol = 0.0001\n",
        "    if type(last_step) != type(None):\n",
        "        # Seleccionamos todos los autovects que difieren sus autovalores menos que tol (mismo autoespacio)\n",
        "        # y tomamos la proyección en el autoespacio de la solución del paso anterior (last_step)\n",
        "        eig = sol[0].real\n",
        "        eigv = sol[1]\n",
        "        cand = [eigv[:,i].real  for (i, x) in enumerate(eig) if abs(x-min(eig)) < eigenspace_tol]\n",
        "        cand_norm = [x/np.linalg.norm(x) for x in cand]\n",
        "        fund = np.zeros(len(cand[0]))\n",
        "        for x in cand_norm:\n",
        "            fund += np.dot(last_step,x) * x\n",
        "    else:\n",
        "        argmin = np.argmin(sol[0].real)\n",
        "        fund = sol[1][:,argmin]\n",
        "    fund = fund.real / np.linalg.norm(fund)\n",
        "    return fund"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emVBTg2QD-Fg"
      },
      "source": [
        "## Modelo de ML\n",
        "Basado en matrices densidad de 1 y 2 cuerpos como input, con hamiltoniano como salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "aF_Ec_mCGX96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-15 21:37:34.632815: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.test.gpu_device_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDoa6LUJJ8O",
        "outputId": "73481454-fbcb-469f-d72f-cd0f8d534808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 133.79it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 157.13it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 1 0 0 0 0 0 0]\n",
            " [1 0 1 0 0 0 0 0]\n",
            " [0 1 1 0 0 0 0 0]\n",
            " [1 0 0 1 0 0 0 0]\n",
            " [0 1 0 1 0 0 0 0]\n",
            " [0 0 1 1 0 0 0 0]\n",
            " [1 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0 0]\n",
            " [0 0 0 1 1 0 0 0]\n",
            " [1 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 1 0 0]\n",
            " [0 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 1 1 0 0]\n",
            " [1 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 1 0]\n",
            " [0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 1 1 0]\n",
            " [1 0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 0 1 0 1]\n",
            " [0 0 0 0 0 0 1 1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 154.63it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 172.80it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "[[1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 124.99it/s]\n"
          ]
        }
      ],
      "source": [
        "# Construccion de bases para calculo de rho1 y rho2\n",
        "# rho2\n",
        "m = 2\n",
        "m2_basis = fixed_basis(m, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-m, d)\n",
        "print(nm2_basis.base)\n",
        "t_basis = fixed_basis(2, basis.d)\n",
        "# rho1\n",
        "m = 1\n",
        "m1_basis = fixed_basis(m, d)\n",
        "print(m1_basis.size)\n",
        "print(m1_basis.base)\n",
        "nm1_basis = fixed_basis(basis.m-m, d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapxWkD16fHg"
      },
      "source": [
        "### Algunos benchmarks y funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "umCIrxCZKXQd"
      },
      "outputs": [],
      "source": [
        "# Given h calculo en rho2 y rho1 máximo\n",
        "def rho1_rho2(h, beta):\n",
        "    fund = thermal_state(h, beta)\n",
        "    rho2 = np.array(rho_2(basis, m2_basis.size, state, rho_2_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho2).real)\n",
        "    rho_2_max = r[0]\n",
        "    rho1 = np.array(rho_1(basis, state, rho_1_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho1).real)\n",
        "    rho_1_max = r[0]\n",
        "\n",
        "    return (rho_1_max, rho_2_max)\n",
        "\n",
        "def fill_triangular_np(x):\n",
        "    m = x.shape[0]\n",
        "    n = np.int32(np.sqrt(.25 + 2 * m) - .5)\n",
        "    x_tail = x[(m - (n**2 - m)):]\n",
        "    return np.triu(np.concatenate([x, x_tail[::-1]], 0).reshape(n, n))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "QaNnIIc5bZux"
      },
      "outputs": [],
      "source": [
        "# TEST: Las funciones de TF y comunes coinciden\n",
        "\n",
        "# Dado h, \\beta, construyo el estado térmico\n",
        "from scipy.linalg import expm\n",
        "\n",
        "def thermal_state(h, beta):\n",
        "    quotient = expm(-beta*h)\n",
        "    return quotient / np.trace(quotient)\n",
        "\n",
        "## NO usar para mat no hermiticas\n",
        "@nb.jit(nopython=True)\n",
        "def thermal_state_eig(h, beta):\n",
        "    w, v = np.linalg.eigh(-beta*h)\n",
        "    D = np.diag(np.exp(w))\n",
        "    mat = v @ D @ v.T\n",
        "    mat = mat / np.trace(mat)\n",
        "    return mat\n",
        "    \n",
        "def gen_to_h(base, rho_1_arrays):\n",
        "    triag = fill_triangular_np(base)\n",
        "    body_gen = triag + np.transpose(triag)-np.diag(np.diag(triag))\n",
        "    h = np.array(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
        "    return h \n",
        "\n",
        "def gen_to_h_1b(hamil_base):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "    return body_gen\n",
        "\n",
        "def gen_to_h_tf(hamil_base, rho_1_arrays):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag)) # Simetrizamos y generamos la matriz de h\n",
        "    hamil_expanded = body_gen[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    h_arr = tf.reduce_sum(hamil_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "    return h_arr\n",
        "\n",
        "def thermal_state_tf(h):\n",
        "    # Assume beta=1\n",
        "    exp_hamiltonian = tf.linalg.expm(-h)\n",
        "    partition_function = tf.linalg.trace(exp_hamiltonian)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    \n",
        "    rho = exp_hamiltonian / partition_function\n",
        "\n",
        "    return rho\n",
        "\n",
        "def rho_1_tf(state, rho_1_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_1_arrays_expanded = tf.expand_dims(rho_1_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_1_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "def rho_2_tf(state, rho_2_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_2_arrays_expanded = tf.expand_dims(rho_2_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_2_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "# NOTA: para calcular el bloque rho2kkbar, utilizar en lugar\n",
        "\n",
        "def rho_1_gc_tf(hamil_base):\n",
        "    e, v = tf.linalg.eigh(gen_to_h_1b(hamil_base))\n",
        "    result = 1 / (1 + tf.exp(e))\n",
        "    result = tf.linalg.diag(result)\n",
        "    res = tf.linalg.matmul(v,result)\n",
        "    res = tf.linalg.matmul(res,v,adjoint_b=True)\n",
        "    \n",
        "    return tf.cast(res, tf.float32)\n",
        "\n",
        "# Aux function\n",
        "def outer_product(vector):\n",
        "    return tf.einsum('i,j->ij', vector, vector)\n",
        "\n",
        "def pure_state(h):\n",
        "    e, v = tf.linalg.eigh(h)\n",
        "    fund = v[:,:,0]\n",
        "    d = tf.map_fn(outer_product, fund)\n",
        "    return d\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylpy_BCw6jxF"
      },
      "source": [
        "### Construccion de dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Version sincrónica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2is_Eo_qGpEz",
        "outputId": "9a968190-59f2-4695-ef18-b99ff5b4a212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-15 21:37:37.823212: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                                                                                                                                      | 0/489 [00:00<?, ?it/s]2023-12-15 21:37:47.434673: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x5620f334d6f0\n",
            " 14%|████████████████████████▍                                                                                                                                                    | 69/489 [08:21<50:33,  7.22s/it]"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "# Config\n",
        "num_samples = 500000\n",
        "use_gpu = True\n",
        "gpu_batch_size = 1024\n",
        "\n",
        "# Beta\n",
        "beta = 1\n",
        "\n",
        "# Construccion de parametros y matrices auxiliares\n",
        "rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "fund_size = basis.size\n",
        "hamil_base_size = basis.d*(basis.d+1)//2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_1_arrays_tf = tf.constant(rho_1_arrays, dtype=tf.float32)\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "rho_2_arrays_kkbar = rho_2_kkbar_gen(basis.m, rho_2_arrays)\n",
        "rho_2_arrays_kkbar_tf = tf.constant(rho_2_arrays_kkbar, dtype=tf.float32)\n",
        "k_indices = get_kkbar_indices(t_basis)\n",
        "\n",
        "# Generacion de hamiltoniano\n",
        "# (h0, hi) = two_body_hamiltonian(t_basis.size, basis.m, np.arange(0, basis.m), np.ones((basis.m,basis.m)), rho_1_arrays_tf, rho_2_arrays_tf) esto es para g cte\n",
        "\n",
        "\n",
        "if use_gpu:\n",
        "    print(tf.test.gpu_device_name())\n",
        "    datasets = []\n",
        "    for i in tqdm(range(num_samples//gpu_batch_size+1)):\n",
        "        size = basis.m*(basis.m+1)//2\n",
        "        # En una primera versión vamos a pasar una mat proporcional a range(0,m) para energias\n",
        "        # y como interacción una matriz G semidefinida positiva\n",
        "        # Primero creamos las semillas, es decir, la diagonal superior de la matrix g\n",
        "        label_size = basis.m*(basis.m+1)//2 # elementos independientes de una mat de m x m\n",
        "        h_labels = [np.random.uniform(low=0, high=5.0, size=(size,)) for _ in range(0,gpu_batch_size)] # Generamos los generadores\n",
        "        h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "        # Construimos la mat G\n",
        "        triag = tfp.math.fill_triangular(h_labels, upper=True)\n",
        "        g_arr = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "        # Construimos los hamiltonianos basados en g_arr\n",
        "        h_arr = np.zeros((gpu_batch_size, basis.size, basis.size))\n",
        "        for i, g in enumerate(g_arr):\n",
        "            (h0, hi) = two_body_hamiltonian(t_basis.size, basis.m, np.arange(0, basis.m), g, rho_1_arrays_tf, rho_2_arrays_tf, k_indices)\n",
        "            h_arr[i,:,:] = h0 - hi\n",
        "        # Estados térmicos\n",
        "        state = thermal_state_tf(h_arr*beta) \n",
        "        state = tf.cast(state, dtype=tf.float32)\n",
        "        # Estados puros\n",
        "        #state = pure_state(h_arr)\n",
        "        #rho_2_input = rho_2_tf(state, rho_2_arrays_tf)\n",
        "        rho_2_input = rho_2_tf(state, rho_2_arrays_kkbar_tf)\n",
        "\n",
        "        datasets.append(tf.data.Dataset.from_tensor_slices(((rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input, state), h_labels)))\n",
        "    ds = tf.data.Dataset.from_tensor_slices(datasets)\n",
        "    dataset = ds.interleave(\n",
        "        lambda x: x,\n",
        "        cycle_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "\n",
        "\n",
        "#batch_size = 32\n",
        "#dataset = dataset.shuffle(buffer_size=num_samples).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Filleo de dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Save and load dataset\n",
        "save_dataset = False\n",
        "load_dataset = False\n",
        "path = \"/home/agus/TF\"\n",
        "#num_samples = 5000000\n",
        "if save_dataset:\n",
        "    tf.data.Dataset.save(dataset, path)\n",
        "    with open(\"/home/agus/\"+'/file.pkl', 'wb') as file:\n",
        "        pickle.dump(beta_input, file)\n",
        "if load_dataset:\n",
        "    dataset = tf.data.Dataset.load(path)\n",
        "    with open(\"/home/agus/\"+'file.pkl', 'rb') as file:\n",
        "        beta_input = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "8moZIlfabZuy"
      },
      "outputs": [],
      "source": [
        "# Dividimos los datasets\n",
        "train_size = int(0.8 * num_samples)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "\n",
        "batch_size = 1024\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "#beta_val = beta_input[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Dataset Size: -2\n"
          ]
        }
      ],
      "source": [
        "# Cardinality no funciona con los datasets generados por GPU\n",
        "val_size = tf.data.experimental.cardinality(val_dataset).numpy()\n",
        "print(\"Validation Dataset Size:\", val_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYEEjNB-7b8y"
      },
      "source": [
        "### Definición de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8kkhJr5K0ZQ",
        "outputId": "f1b731f1-6a02-4181-f0b5-5677a2a85784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 15, 15, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 32)        160       \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 14, 14, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 13, 13, 16)        2064      \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 13, 13, 16)        64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 576)               0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 24)                13848     \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 2)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16314 (63.73 KB)\n",
            "Trainable params: 16218 (63.35 KB)\n",
            "Non-trainable params: 96 (384.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Definicion de layers basado en Conv 2D\n",
        "\n",
        "# Factor de cantidad de filtros\n",
        "lf = 8  \n",
        "conv_limit = (rho2_size - 4) // 4 \n",
        "initial_dense = (lf*2**(conv_limit-1)*((rho2_size-(conv_limit-1))//2)**2) // 8\n",
        "## rho 1\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(rho2_size,rho2_size, 1), name='rho2')\n",
        "\n",
        "# Procesamos el primer input\n",
        "conv_rho2 = tf.keras.layers.Conv2D(lf*2**conv_limit, (2, 2), activation='relu')(rho2_layer)\n",
        "conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "for j in [(2**conv_limit - 2**k) for k in range(1,conv_limit)]:\n",
        "    conv_rho2 = tf.keras.layers.Conv2D(lf*j, (2, 2), activation='relu')(conv_rho2 if 2**j != 1 else rho1_layer)\n",
        "    conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "\n",
        "conv_rho2 = tf.keras.layers.MaxPooling2D((2, 2))(conv_rho2)\n",
        "\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(conv_rho2)\n",
        "#flatten_rho1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(flatten_rho1)\n",
        "\n",
        "#local_size = basis.size*basis.size\n",
        "local_size = hamil_base_size\n",
        "\n",
        "#dense1 = tf.keras.layers.Dense(8*8*4*4, activation='relu')(dense1)\n",
        "#dense1 = tf.keras.layers.Dense(512, activation='relu')(flatten_rho1)\n",
        "#dense1 = tf.keras.layers.Dense(128, activation='relu')(flatten_rho1)\n",
        "dense1 = tf.keras.layers.Dense(initial_dense // 4, activation='relu')(flatten_rho2)\n",
        "#dense1 = tf.keras.layers.Dense(initial_dense//2, activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(2)(dense1)\n",
        "\n",
        "\n",
        "# Creamos el modelo y compulamos\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer, fund_layer], outputs=output)\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer], outputs=output)\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZBtonvGbZuz",
        "outputId": "f197277e-a84b-4ffd-c81f-c81581707fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 4, 4, 1)]         0         \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 16)                0         \n",
            "                                                                 \n",
            " concatenate_1 (Concatenate  (None, 16)                0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 32)                544       \n",
            "                                                                 \n",
            " dense_7 (Dense)             (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_8 (Dense)             (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 10)                1290      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12538 (48.98 KB)\n",
            "Trainable params: 12538 (48.98 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Modelo denso + fundamental\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(basis.m,basis.m, 1), name='rho2')\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#rho2_layer =  tf.keras.layers.Input(shape=(rho2_size,rho2_size, 1), name='rho2')\n",
        "#flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#fund_layer =  tf.keras.layers.Input(shape=(fund_size, fund_size, 1 ), name='fund')\n",
        "#flatten_fund = tf.keras.layers.Flatten()(fund_layer)\n",
        "\n",
        "dense1 = tf.keras.layers.concatenate([flatten_rho2])\n",
        "#dense1 = tf.keras.layers.concatenate([dense1, flatten_fund])\n",
        "#dense1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(dense1)\n",
        "\n",
        "local_size = label_size\n",
        "l=5\n",
        "layer_s = [256//2**i for i in reversed(range(1,l))]\n",
        "for i in range(0,l-1):\n",
        "    dense1 = tf.keras.layers.Dense(layer_s[i], activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "# Creamos el modelo y compulamos\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "RgoMlCyyfBe-"
      },
      "outputs": [],
      "source": [
        "# LOSS FUNCTIONS\n",
        "r_size = basis.size\n",
        "\n",
        "# Custom loss function based on GS MSE\n",
        "def gs_loss(h_pred, h_true):\n",
        "    h_pred = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_pred)\n",
        "    gs_pred = v[:, 0]\n",
        "\n",
        "    h_true = tf.reshape(h_true, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_true)\n",
        "    gs_true = v[:, 0]\n",
        "\n",
        "    gs_diff = tf.norm(gs_true - gs_pred)\n",
        "\n",
        "    return gs_diff + tf.reduce_mean(tf.square(h_true - h_pred)) * 100\n",
        "\n",
        "def distance_to_hermitian(matrix):\n",
        "    hermitian_part = 0.5 * (matrix + tf.linalg.adjoint(matrix))\n",
        "    distance = tf.norm(matrix - hermitian_part, ord='euclidean')\n",
        "    return distance\n",
        "\n",
        "# Custom loss function based on MSE + non-hermitian penalization\n",
        "def herm_loss(h_pred, h_true):\n",
        "    h_pred_arr = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred)) + distance_to_hermitian(h_pred_arr)\n",
        "\n",
        "# Custom loss function based on h eigenvalues\n",
        "def eig_loss(h_pred, h_true):\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# MSE with a factor\n",
        "def mse_f(h_pred, h_true):\n",
        "    f = 1000\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred))*f\n",
        "\n",
        "# Spectral radius loss\n",
        "def spectral_loss(h_pred, h_true):\n",
        "    eig = tf.math.real(tf.linalg.eigvals(tf.reshape(h_true-h_pred, (-1, fund_size, fund_size))))\n",
        "    return tf.math.reduce_max(tf.abs(eig))\n",
        "\n",
        "# Hamiltonian MSE loss (using generators)\n",
        "def base_mse_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    mat = tf.reshape(h_pred-h_true, (-1, fund_size, fund_size))\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on h eigenvalues (using generators)\n",
        "def base_eig_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals\n",
        "## Auxiliary function\n",
        "def base_to_rho_1_tf(base_pred):\n",
        "    h = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h = tf.reshape(h, (-1, fund_size, fund_size))\n",
        "    state = thermal_state_tf(h)\n",
        "    rho1 = rho_1_tf(state, rho_1_arrays_tf)\n",
        "    return rho1\n",
        "    \n",
        "def rho1_loss(base_pred, base_true):\n",
        "    mat = base_to_rho_1_tf(base_pred) - base_to_rho_1_tf(base_true)\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals (using generators)\n",
        "def base_rho1_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    return tf.reduce_mean(tf.square(rho_1_eig_tf(h_pred) - rho_1_eig_tf(h_true)))*1000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWk9piJtNIZ"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhJCHf0fQdRl",
        "outputId": "1821cf27-9ff5-4d67-e9f5-956d20eda5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-14 22:55:15.105747: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "    233/Unknown - 2s 5ms/step - loss: 2.5716 - accuracy: 0.1246 - mean_squared_error: 2.5716"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-14 22:55:17.623689: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13228000910284723779\n",
            "2023-12-14 22:55:17.623733: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14303395188622474993\n",
            "2023-12-14 22:55:17.623753: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 3025772164289643490\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "235/235 [==============================] - 4s 12ms/step - loss: 2.5678 - accuracy: 0.1248 - mean_squared_error: 2.5678 - val_loss: 1.9207 - val_accuracy: 0.1719 - val_mean_squared_error: 1.9207\n",
            "Epoch 2/100\n",
            " 32/235 [===>..........................] - ETA: 1s - loss: 1.8935 - accuracy: 0.1739 - mean_squared_error: 1.8935"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-14 22:55:19.303142: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 14303395188622474993\n",
            "2023-12-14 22:55:19.303205: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13694866181304747705\n",
            "2023-12-14 22:55:19.303223: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 13228000910284723779\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "235/235 [==============================] - 3s 12ms/step - loss: 1.6896 - accuracy: 0.2180 - mean_squared_error: 1.6896 - val_loss: 1.4814 - val_accuracy: 0.2632 - val_mean_squared_error: 1.4814\n",
            "Epoch 3/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4592 - accuracy: 0.2673 - mean_squared_error: 1.4592 - val_loss: 1.4373 - val_accuracy: 0.2674 - val_mean_squared_error: 1.4373\n",
            "Epoch 4/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4407 - accuracy: 0.2682 - mean_squared_error: 1.4407 - val_loss: 1.4309 - val_accuracy: 0.2685 - val_mean_squared_error: 1.4309\n",
            "Epoch 5/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4359 - accuracy: 0.2678 - mean_squared_error: 1.4359 - val_loss: 1.4270 - val_accuracy: 0.2680 - val_mean_squared_error: 1.4270\n",
            "Epoch 6/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4321 - accuracy: 0.2678 - mean_squared_error: 1.4321 - val_loss: 1.4237 - val_accuracy: 0.2674 - val_mean_squared_error: 1.4237\n",
            "Epoch 7/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4287 - accuracy: 0.2678 - mean_squared_error: 1.4287 - val_loss: 1.4202 - val_accuracy: 0.2679 - val_mean_squared_error: 1.4202\n",
            "Epoch 8/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4254 - accuracy: 0.2677 - mean_squared_error: 1.4254 - val_loss: 1.4168 - val_accuracy: 0.2674 - val_mean_squared_error: 1.4168\n",
            "Epoch 9/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4224 - accuracy: 0.2684 - mean_squared_error: 1.4224 - val_loss: 1.4136 - val_accuracy: 0.2677 - val_mean_squared_error: 1.4136\n",
            "Epoch 10/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4188 - accuracy: 0.2687 - mean_squared_error: 1.4188 - val_loss: 1.4096 - val_accuracy: 0.2679 - val_mean_squared_error: 1.4096\n",
            "Epoch 11/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4146 - accuracy: 0.2689 - mean_squared_error: 1.4146 - val_loss: 1.4051 - val_accuracy: 0.2693 - val_mean_squared_error: 1.4051\n",
            "Epoch 12/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4098 - accuracy: 0.2699 - mean_squared_error: 1.4098 - val_loss: 1.4020 - val_accuracy: 0.2694 - val_mean_squared_error: 1.4020\n",
            "Epoch 13/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.4039 - accuracy: 0.2710 - mean_squared_error: 1.4039 - val_loss: 1.3949 - val_accuracy: 0.2696 - val_mean_squared_error: 1.3949\n",
            "Epoch 14/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3978 - accuracy: 0.2727 - mean_squared_error: 1.3978 - val_loss: 1.3893 - val_accuracy: 0.2710 - val_mean_squared_error: 1.3893\n",
            "Epoch 15/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3922 - accuracy: 0.2743 - mean_squared_error: 1.3922 - val_loss: 1.3843 - val_accuracy: 0.2726 - val_mean_squared_error: 1.3843\n",
            "Epoch 16/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3875 - accuracy: 0.2750 - mean_squared_error: 1.3875 - val_loss: 1.3782 - val_accuracy: 0.2731 - val_mean_squared_error: 1.3782\n",
            "Epoch 17/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3837 - accuracy: 0.2760 - mean_squared_error: 1.3837 - val_loss: 1.3748 - val_accuracy: 0.2749 - val_mean_squared_error: 1.3748\n",
            "Epoch 18/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3808 - accuracy: 0.2767 - mean_squared_error: 1.3808 - val_loss: 1.3723 - val_accuracy: 0.2755 - val_mean_squared_error: 1.3723\n",
            "Epoch 19/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3782 - accuracy: 0.2772 - mean_squared_error: 1.3782 - val_loss: 1.3700 - val_accuracy: 0.2770 - val_mean_squared_error: 1.3700\n",
            "Epoch 20/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3758 - accuracy: 0.2778 - mean_squared_error: 1.3758 - val_loss: 1.3676 - val_accuracy: 0.2773 - val_mean_squared_error: 1.3676\n",
            "Epoch 21/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3735 - accuracy: 0.2784 - mean_squared_error: 1.3735 - val_loss: 1.3655 - val_accuracy: 0.2774 - val_mean_squared_error: 1.3655\n",
            "Epoch 22/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3715 - accuracy: 0.2789 - mean_squared_error: 1.3715 - val_loss: 1.3636 - val_accuracy: 0.2779 - val_mean_squared_error: 1.3636\n",
            "Epoch 23/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3694 - accuracy: 0.2795 - mean_squared_error: 1.3694 - val_loss: 1.3617 - val_accuracy: 0.2788 - val_mean_squared_error: 1.3617\n",
            "Epoch 24/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3675 - accuracy: 0.2803 - mean_squared_error: 1.3675 - val_loss: 1.3596 - val_accuracy: 0.2799 - val_mean_squared_error: 1.3596\n",
            "Epoch 25/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3658 - accuracy: 0.2811 - mean_squared_error: 1.3658 - val_loss: 1.3580 - val_accuracy: 0.2805 - val_mean_squared_error: 1.3580\n",
            "Epoch 26/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3642 - accuracy: 0.2817 - mean_squared_error: 1.3642 - val_loss: 1.3564 - val_accuracy: 0.2810 - val_mean_squared_error: 1.3564\n",
            "Epoch 27/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3627 - accuracy: 0.2820 - mean_squared_error: 1.3627 - val_loss: 1.3549 - val_accuracy: 0.2821 - val_mean_squared_error: 1.3549\n",
            "Epoch 28/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3614 - accuracy: 0.2822 - mean_squared_error: 1.3614 - val_loss: 1.3537 - val_accuracy: 0.2826 - val_mean_squared_error: 1.3537\n",
            "Epoch 29/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3602 - accuracy: 0.2824 - mean_squared_error: 1.3602 - val_loss: 1.3523 - val_accuracy: 0.2829 - val_mean_squared_error: 1.3523\n",
            "Epoch 30/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3591 - accuracy: 0.2829 - mean_squared_error: 1.3591 - val_loss: 1.3513 - val_accuracy: 0.2828 - val_mean_squared_error: 1.3513\n",
            "Epoch 31/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3580 - accuracy: 0.2830 - mean_squared_error: 1.3580 - val_loss: 1.3502 - val_accuracy: 0.2830 - val_mean_squared_error: 1.3502\n",
            "Epoch 32/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3570 - accuracy: 0.2832 - mean_squared_error: 1.3570 - val_loss: 1.3492 - val_accuracy: 0.2834 - val_mean_squared_error: 1.3492\n",
            "Epoch 33/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3561 - accuracy: 0.2837 - mean_squared_error: 1.3561 - val_loss: 1.3483 - val_accuracy: 0.2836 - val_mean_squared_error: 1.3483\n",
            "Epoch 34/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3552 - accuracy: 0.2840 - mean_squared_error: 1.3552 - val_loss: 1.3474 - val_accuracy: 0.2837 - val_mean_squared_error: 1.3474\n",
            "Epoch 35/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3544 - accuracy: 0.2842 - mean_squared_error: 1.3544 - val_loss: 1.3465 - val_accuracy: 0.2838 - val_mean_squared_error: 1.3465\n",
            "Epoch 36/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3537 - accuracy: 0.2844 - mean_squared_error: 1.3537 - val_loss: 1.3457 - val_accuracy: 0.2836 - val_mean_squared_error: 1.3457\n",
            "Epoch 37/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3528 - accuracy: 0.2845 - mean_squared_error: 1.3528 - val_loss: 1.3451 - val_accuracy: 0.2843 - val_mean_squared_error: 1.3451\n",
            "Epoch 38/100\n",
            "235/235 [==============================] - 3s 11ms/step - loss: 1.3522 - accuracy: 0.2849 - mean_squared_error: 1.3522 - val_loss: 1.3444 - val_accuracy: 0.2845 - val_mean_squared_error: 1.3444\n",
            "Epoch 39/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3514 - accuracy: 0.2851 - mean_squared_error: 1.3514 - val_loss: 1.3440 - val_accuracy: 0.2843 - val_mean_squared_error: 1.3440\n",
            "Epoch 40/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3507 - accuracy: 0.2854 - mean_squared_error: 1.3507 - val_loss: 1.3432 - val_accuracy: 0.2843 - val_mean_squared_error: 1.3432\n",
            "Epoch 41/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3501 - accuracy: 0.2855 - mean_squared_error: 1.3501 - val_loss: 1.3426 - val_accuracy: 0.2847 - val_mean_squared_error: 1.3426\n",
            "Epoch 42/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3494 - accuracy: 0.2857 - mean_squared_error: 1.3494 - val_loss: 1.3419 - val_accuracy: 0.2852 - val_mean_squared_error: 1.3419\n",
            "Epoch 43/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3485 - accuracy: 0.2860 - mean_squared_error: 1.3485 - val_loss: 1.3417 - val_accuracy: 0.2848 - val_mean_squared_error: 1.3417\n",
            "Epoch 44/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3478 - accuracy: 0.2862 - mean_squared_error: 1.3478 - val_loss: 1.3413 - val_accuracy: 0.2846 - val_mean_squared_error: 1.3413\n",
            "Epoch 45/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3471 - accuracy: 0.2863 - mean_squared_error: 1.3471 - val_loss: 1.3406 - val_accuracy: 0.2848 - val_mean_squared_error: 1.3406\n",
            "Epoch 46/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3463 - accuracy: 0.2864 - mean_squared_error: 1.3463 - val_loss: 1.3393 - val_accuracy: 0.2855 - val_mean_squared_error: 1.3393\n",
            "Epoch 47/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3454 - accuracy: 0.2863 - mean_squared_error: 1.3454 - val_loss: 1.3378 - val_accuracy: 0.2856 - val_mean_squared_error: 1.3378\n",
            "Epoch 48/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3446 - accuracy: 0.2865 - mean_squared_error: 1.3446 - val_loss: 1.3368 - val_accuracy: 0.2866 - val_mean_squared_error: 1.3368\n",
            "Epoch 49/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3439 - accuracy: 0.2867 - mean_squared_error: 1.3439 - val_loss: 1.3359 - val_accuracy: 0.2870 - val_mean_squared_error: 1.3359\n",
            "Epoch 50/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3432 - accuracy: 0.2869 - mean_squared_error: 1.3432 - val_loss: 1.3351 - val_accuracy: 0.2871 - val_mean_squared_error: 1.3351\n",
            "Epoch 51/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3426 - accuracy: 0.2868 - mean_squared_error: 1.3426 - val_loss: 1.3342 - val_accuracy: 0.2873 - val_mean_squared_error: 1.3342\n",
            "Epoch 52/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3418 - accuracy: 0.2870 - mean_squared_error: 1.3418 - val_loss: 1.3334 - val_accuracy: 0.2871 - val_mean_squared_error: 1.3334\n",
            "Epoch 53/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3410 - accuracy: 0.2872 - mean_squared_error: 1.3410 - val_loss: 1.3325 - val_accuracy: 0.2876 - val_mean_squared_error: 1.3325\n",
            "Epoch 54/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3402 - accuracy: 0.2871 - mean_squared_error: 1.3402 - val_loss: 1.3315 - val_accuracy: 0.2874 - val_mean_squared_error: 1.3315\n",
            "Epoch 55/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3394 - accuracy: 0.2873 - mean_squared_error: 1.3394 - val_loss: 1.3306 - val_accuracy: 0.2873 - val_mean_squared_error: 1.3306\n",
            "Epoch 56/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3385 - accuracy: 0.2873 - mean_squared_error: 1.3385 - val_loss: 1.3296 - val_accuracy: 0.2873 - val_mean_squared_error: 1.3296\n",
            "Epoch 57/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3376 - accuracy: 0.2872 - mean_squared_error: 1.3376 - val_loss: 1.3287 - val_accuracy: 0.2875 - val_mean_squared_error: 1.3287\n",
            "Epoch 58/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3367 - accuracy: 0.2873 - mean_squared_error: 1.3367 - val_loss: 1.3277 - val_accuracy: 0.2877 - val_mean_squared_error: 1.3277\n",
            "Epoch 59/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3357 - accuracy: 0.2874 - mean_squared_error: 1.3357 - val_loss: 1.3268 - val_accuracy: 0.2879 - val_mean_squared_error: 1.3268\n",
            "Epoch 60/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3348 - accuracy: 0.2873 - mean_squared_error: 1.3348 - val_loss: 1.3258 - val_accuracy: 0.2879 - val_mean_squared_error: 1.3258\n",
            "Epoch 61/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3338 - accuracy: 0.2872 - mean_squared_error: 1.3338 - val_loss: 1.3246 - val_accuracy: 0.2882 - val_mean_squared_error: 1.3246\n",
            "Epoch 62/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3328 - accuracy: 0.2872 - mean_squared_error: 1.3328 - val_loss: 1.3238 - val_accuracy: 0.2880 - val_mean_squared_error: 1.3238\n",
            "Epoch 63/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3319 - accuracy: 0.2871 - mean_squared_error: 1.3319 - val_loss: 1.3226 - val_accuracy: 0.2882 - val_mean_squared_error: 1.3226\n",
            "Epoch 64/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3310 - accuracy: 0.2872 - mean_squared_error: 1.3310 - val_loss: 1.3215 - val_accuracy: 0.2886 - val_mean_squared_error: 1.3215\n",
            "Epoch 65/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3301 - accuracy: 0.2875 - mean_squared_error: 1.3301 - val_loss: 1.3205 - val_accuracy: 0.2884 - val_mean_squared_error: 1.3205\n",
            "Epoch 66/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3291 - accuracy: 0.2877 - mean_squared_error: 1.3291 - val_loss: 1.3195 - val_accuracy: 0.2888 - val_mean_squared_error: 1.3195\n",
            "Epoch 67/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3278 - accuracy: 0.2880 - mean_squared_error: 1.3278 - val_loss: 1.3216 - val_accuracy: 0.2888 - val_mean_squared_error: 1.3216\n",
            "Epoch 68/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3268 - accuracy: 0.2880 - mean_squared_error: 1.3268 - val_loss: 1.3224 - val_accuracy: 0.2892 - val_mean_squared_error: 1.3224\n",
            "Epoch 69/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3259 - accuracy: 0.2883 - mean_squared_error: 1.3259 - val_loss: 1.3200 - val_accuracy: 0.2893 - val_mean_squared_error: 1.3200\n",
            "Epoch 70/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3249 - accuracy: 0.2881 - mean_squared_error: 1.3249 - val_loss: 1.3215 - val_accuracy: 0.2893 - val_mean_squared_error: 1.3215\n",
            "Epoch 71/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3236 - accuracy: 0.2880 - mean_squared_error: 1.3236 - val_loss: 1.3239 - val_accuracy: 0.2888 - val_mean_squared_error: 1.3239\n",
            "Epoch 72/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3217 - accuracy: 0.2882 - mean_squared_error: 1.3217 - val_loss: 1.3286 - val_accuracy: 0.2881 - val_mean_squared_error: 1.3286\n",
            "Epoch 73/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3205 - accuracy: 0.2883 - mean_squared_error: 1.3205 - val_loss: 1.3156 - val_accuracy: 0.2890 - val_mean_squared_error: 1.3156\n",
            "Epoch 74/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3211 - accuracy: 0.2877 - mean_squared_error: 1.3211 - val_loss: 1.3251 - val_accuracy: 0.2883 - val_mean_squared_error: 1.3251\n",
            "Epoch 75/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3200 - accuracy: 0.2879 - mean_squared_error: 1.3200 - val_loss: 1.3263 - val_accuracy: 0.2880 - val_mean_squared_error: 1.3263\n",
            "Epoch 76/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3186 - accuracy: 0.2882 - mean_squared_error: 1.3186 - val_loss: 1.3237 - val_accuracy: 0.2885 - val_mean_squared_error: 1.3237\n",
            "Epoch 77/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3177 - accuracy: 0.2883 - mean_squared_error: 1.3177 - val_loss: 1.3258 - val_accuracy: 0.2875 - val_mean_squared_error: 1.3258\n",
            "Epoch 78/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3168 - accuracy: 0.2884 - mean_squared_error: 1.3168 - val_loss: 1.3239 - val_accuracy: 0.2880 - val_mean_squared_error: 1.3239\n",
            "Epoch 79/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3153 - accuracy: 0.2885 - mean_squared_error: 1.3153 - val_loss: 1.3083 - val_accuracy: 0.2885 - val_mean_squared_error: 1.3083\n",
            "Epoch 80/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3140 - accuracy: 0.2887 - mean_squared_error: 1.3140 - val_loss: 1.3087 - val_accuracy: 0.2885 - val_mean_squared_error: 1.3087\n",
            "Epoch 81/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3138 - accuracy: 0.2888 - mean_squared_error: 1.3138 - val_loss: 1.3083 - val_accuracy: 0.2887 - val_mean_squared_error: 1.3083\n",
            "Epoch 82/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3129 - accuracy: 0.2891 - mean_squared_error: 1.3129 - val_loss: 1.3029 - val_accuracy: 0.2880 - val_mean_squared_error: 1.3029\n",
            "Epoch 83/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3131 - accuracy: 0.2887 - mean_squared_error: 1.3131 - val_loss: 1.3028 - val_accuracy: 0.2886 - val_mean_squared_error: 1.3028\n",
            "Epoch 84/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3107 - accuracy: 0.2892 - mean_squared_error: 1.3107 - val_loss: 1.3062 - val_accuracy: 0.2887 - val_mean_squared_error: 1.3062\n",
            "Epoch 85/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3105 - accuracy: 0.2890 - mean_squared_error: 1.3105 - val_loss: 1.3011 - val_accuracy: 0.2881 - val_mean_squared_error: 1.3011\n",
            "Epoch 86/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3103 - accuracy: 0.2893 - mean_squared_error: 1.3103 - val_loss: 1.3031 - val_accuracy: 0.2885 - val_mean_squared_error: 1.3031\n",
            "Epoch 87/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3099 - accuracy: 0.2890 - mean_squared_error: 1.3099 - val_loss: 1.2999 - val_accuracy: 0.2880 - val_mean_squared_error: 1.2999\n",
            "Epoch 88/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3080 - accuracy: 0.2896 - mean_squared_error: 1.3080 - val_loss: 1.3007 - val_accuracy: 0.2884 - val_mean_squared_error: 1.3007\n",
            "Epoch 89/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3076 - accuracy: 0.2894 - mean_squared_error: 1.3076 - val_loss: 1.2978 - val_accuracy: 0.2882 - val_mean_squared_error: 1.2978\n",
            "Epoch 90/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3065 - accuracy: 0.2896 - mean_squared_error: 1.3065 - val_loss: 1.2958 - val_accuracy: 0.2887 - val_mean_squared_error: 1.2958\n",
            "Epoch 91/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3068 - accuracy: 0.2901 - mean_squared_error: 1.3068 - val_loss: 1.3058 - val_accuracy: 0.2890 - val_mean_squared_error: 1.3058\n",
            "Epoch 92/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3059 - accuracy: 0.2899 - mean_squared_error: 1.3059 - val_loss: 1.2948 - val_accuracy: 0.2874 - val_mean_squared_error: 1.2948\n",
            "Epoch 93/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3043 - accuracy: 0.2900 - mean_squared_error: 1.3043 - val_loss: 1.2971 - val_accuracy: 0.2857 - val_mean_squared_error: 1.2971\n",
            "Epoch 94/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3046 - accuracy: 0.2901 - mean_squared_error: 1.3046 - val_loss: 1.2960 - val_accuracy: 0.2858 - val_mean_squared_error: 1.2960\n",
            "Epoch 95/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3062 - accuracy: 0.2893 - mean_squared_error: 1.3062 - val_loss: 1.3029 - val_accuracy: 0.2895 - val_mean_squared_error: 1.3029\n",
            "Epoch 96/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3074 - accuracy: 0.2904 - mean_squared_error: 1.3074 - val_loss: 1.2950 - val_accuracy: 0.2894 - val_mean_squared_error: 1.2950\n",
            "Epoch 97/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3056 - accuracy: 0.2902 - mean_squared_error: 1.3056 - val_loss: 1.2984 - val_accuracy: 0.2900 - val_mean_squared_error: 1.2984\n",
            "Epoch 98/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3007 - accuracy: 0.2903 - mean_squared_error: 1.3007 - val_loss: 1.2929 - val_accuracy: 0.2865 - val_mean_squared_error: 1.2929\n",
            "Epoch 99/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3038 - accuracy: 0.2901 - mean_squared_error: 1.3038 - val_loss: 1.3109 - val_accuracy: 0.2902 - val_mean_squared_error: 1.3109\n",
            "Epoch 100/100\n",
            "235/235 [==============================] - 3s 12ms/step - loss: 1.3029 - accuracy: 0.2906 - mean_squared_error: 1.3029 - val_loss: 1.2943 - val_accuracy: 0.2903 - val_mean_squared_error: 1.2943\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam, Lion\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='MSE',  \n",
        "              metrics=['accuracy', 'mean_squared_error'])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    history = model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "cvpE_X1iTXcB",
        "outputId": "eff0e5f5-5b26-46ea-ec6b-491d1de9944c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history.history['mean_squared_error'], label='Training MSE')\n",
        "plt.plot(history.history['val_mean_squared_error'], label='Validation MSE')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs. Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# MIN LOSS = 0.0128 c/fund 50epochs MSE\n",
        "##         = 0.0118 s/fund 50epochs MSE\n",
        "##         = 0.0039 s/fund 50epochs MSE m=4 d=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRlZuRUNa6Yb",
        "outputId": "85850559-311b-4cf4-ea5b-465a9ee8a7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "32/32 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a validation dataset (val_dataset)\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "next_sample = next(iterador)\n",
        "input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "actual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[1.7137067  1.171018   0.5682487  3.8084078  1.1915913  2.3734944\n",
            " 0.6522312  4.5120063  2.8695629  0.84520704], shape=(10,), dtype=float32)\n",
            "[2.9195604 1.7477375 1.2812412 2.8431218 2.93484   1.6323265 2.6676645\n",
            " 3.0988877 2.6486843 1.455066 ]\n",
            "tf.Tensor(\n",
            "[0.78949726 2.1318066  1.6933547  4.9248457  4.926792   2.080616\n",
            " 1.2753456  0.88185567 3.8862987  0.434491  ], shape=(10,), dtype=float32)\n",
            "[0.5512332 3.5620673 1.8526183 4.264167  4.6612797 2.18766   2.933126\n",
            " 1.7504969 2.799177  1.2111226]\n",
            "tf.Tensor(\n",
            "[2.4309952  2.778026   4.7853374  0.05796783 0.61760634 3.5502195\n",
            " 2.9812016  1.7073765  1.935172   0.3910768 ], shape=(10,), dtype=float32)\n",
            "[3.6144528  2.9474635  3.5477262  0.42238414 1.2372508  2.969038\n",
            " 2.2474794  1.5752778  1.5430353  3.0132473 ]\n",
            "tf.Tensor(\n",
            "[2.6021852  4.243155   0.13436554 2.3768675  2.0893676  2.1197922\n",
            " 2.6852403  1.7702268  1.6016392  1.6753825 ], shape=(10,), dtype=float32)\n",
            "[2.6237319 1.9891487 1.9486084 2.8158548 1.9312884 2.2249036 2.9680364\n",
            " 2.6222525 2.395026  2.0778353]\n",
            "1.1260808 2.0633147\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Vemos algunos valores\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 4):\n",
        "        print(e[1][i])\n",
        "        print(predictions[i])\n",
        "    break\n",
        "    \n",
        "\n",
        "RMSE_pred = mean_squared_error(actual_values, predictions, squared=False)\n",
        "RMSE_rand = mean_squared_error(actual_values, next_sample[1], squared=False)\n",
        "print(RMSE_pred, RMSE_rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "ds5iD1OMbZu3"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 2 into shape (1,1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m val_dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m \u001b[39mif\u001b[39;00m printear \u001b[39melse\u001b[39;00m batch_size):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m# Valores actuales\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m#h = e[1][i].numpy().reshape(basis.size,basis.size)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         h_true \u001b[39m=\u001b[39m gen_to_h(e[\u001b[39m1\u001b[39;49m][i], rho_1_arrays)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m#print(h) if printear else 0\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         r \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39meigvals(e[\u001b[39m0\u001b[39m][i]))\n",
            "\u001b[1;32m/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen_to_h\u001b[39m(base, rho_1_arrays):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     triag \u001b[39m=\u001b[39m fill_triangular_np(base)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     body_gen \u001b[39m=\u001b[39m triag \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mtranspose(triag)\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mdiag(np\u001b[39m.\u001b[39mdiag(triag))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     h \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
            "\u001b[1;32m/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m n \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mint32(np\u001b[39m.\u001b[39msqrt(\u001b[39m.25\u001b[39m \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m m) \u001b[39m-\u001b[39m \u001b[39m.5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m x_tail \u001b[39m=\u001b[39m x[(m \u001b[39m-\u001b[39m (n\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m-\u001b[39m m)):]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mtriu(np\u001b[39m.\u001b[39;49mconcatenate([x, x_tail[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]], \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mreshape(n, n))\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (1,1)"
          ]
        }
      ],
      "source": [
        "m_size = basis.size\n",
        "rho_1_pred = []\n",
        "rho_1_actual = []\n",
        "norm = []\n",
        "norm_rand = []\n",
        "printear =  False\n",
        "\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 3 if printear else batch_size):\n",
        "        # Valores actuales\n",
        "        #h = e[1][i].numpy().reshape(basis.size,basis.size)\n",
        "        h_true = gen_to_h(e[1][i], rho_1_arrays)\n",
        "        #print(h) if printear else 0\n",
        "        r = max(np.linalg.eigvals(e[0][i]))\n",
        "        rho_1_actual.append(r)\n",
        "\n",
        "        print(h_true) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "\n",
        "        # Valores predichos\n",
        "        #h = predictions[i].reshape(basis.size,basis.size)\n",
        "        h_pred = gen_to_h(predictions[i], rho_1_arrays)\n",
        "        beta = 1\n",
        "        # Estado térmico\n",
        "        state = thermal_state(h_pred, beta)\n",
        "        # Estado puro\n",
        "        #state = pure_state(h_pred)\n",
        "        rho1 = np.array(rho_1(basis.d, state, rho_1_arrays))\n",
        "        r = max(np.sort(linalg_d.eigvals(rho1).real))\n",
        "        rho_1_pred.append(r)\n",
        "\n",
        "        print(h_pred) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "        \n",
        "\n",
        "        # Normas\n",
        "        norm.append(np.linalg.norm(h_true-h_pred, ord='fro'))\n",
        "        print(f'Norma {norm[-1]}') if printear else 0\n",
        "        ## Vamos a comparar con un h aleatorio\n",
        "        size = basis.d*(basis.d+1)//2\n",
        "        base = np.random.uniform(low=0, high=1.0, size=(size,))\n",
        "        h_rand = gen_to_h(base, rho_1_arrays)\n",
        "        norm_rand.append(np.linalg.norm(h_true-h_rand, ord='fro'))\n",
        "        #print(f'Norma random {norm_rand[-1]}') if printear else 0\n",
        "        print('') if printear else 0\n",
        "        \n",
        "\n",
        "\n",
        "    # e contiene todo el batch y nos basta con uno\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(e[1][10])\n",
        "predictions[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "AL2EC9Ci-0HG",
        "outputId": "545ebe57-d3de-490f-f076-709d5c47b5f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f=1\n",
        "rho_1_actual = np.array(rho_1_actual)\n",
        "rho_1_pred = np.array(rho_1_pred)\n",
        "#print(mean_squared_error(rho_1_pred, rho_1_actual))\n",
        "\n",
        "print('Rho1 based statistics')\n",
        "print(np.mean(np.abs(rho_1_actual-rho_1_pred)))\n",
        "print(np.mean(rho_1_actual)*f)\n",
        "print('std')\n",
        "print(np.std(rho_1_actual-rho_1_pred)*f)\n",
        "print(np.std(rho_1_actual)*f)\n",
        "print(np.std(rho_1_pred)*f)\n",
        "plt.hist(np.array(rho_1_pred-rho_1_actual), bins=50)\n",
        "plt.show()\n",
        "print('H based statistics')\n",
        "print(np.mean(norm), np.mean(norm_rand))\n",
        "print(np.mean(norm_rand)/np.mean(norm))\n",
        "\n",
        "\n",
        "# BEST: FACTOR 1/8 c/fund\n",
        "## 500 epochs, 10M dataset\n",
        "# BEST: FACTOR 1/9 s/fund\n",
        "## 50 epochs, 5M dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "6.25/1.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 25 epochs d = m*2\n",
        "res = {}\n",
        "res[5] = 35/8.19 \n",
        "res[4] = 15/2.47\n",
        "res[3] = 6.2/1.73"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YioVllOX3M1N",
        "outputId": "b7715c37-1400-4c04-8be3-dd247b4b9db9"
      },
      "outputs": [],
      "source": [
        "# Get the weights of all dense layers in the model\n",
        "dense_weights = []\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Dense):\n",
        "        weights = layer.get_weights()\n",
        "        if len(weights) > 0:\n",
        "            dense_weights.append(weights[0])\n",
        "\n",
        "# Visualize the weights of each dense layer\n",
        "for i, weights in enumerate(dense_weights):\n",
        "    plt.figure()\n",
        "    plt.imshow(weights, cmap='viridis', aspect='auto')\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"Dense Layer {i+1} Weights Visualization\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 1 1] [0 1 1 0 0 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "            if mat[i,j,0,9] != 0:\n",
        "                print(v,w)\n",
        "\n",
        "    return mat\n",
        "\n",
        "r = rho_2_gen(basis, basis_m2, t_basis)\n",
        "r[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 1],\n",
              "       [1, 0, 1, 1, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 0],\n",
              "       [1, 0, 1, 0, 0, 1],\n",
              "       [1, 0, 0, 1, 1, 0],\n",
              "       [1, 0, 0, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 1],\n",
              "       [0, 1, 1, 1, 0, 0],\n",
              "       [0, 1, 1, 0, 1, 0],\n",
              "       [0, 1, 1, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 0, 1, 1],\n",
              "       [0, 0, 1, 1, 1, 0],\n",
              "       [0, 0, 1, 1, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 1],\n",
              "       [0, 0, 0, 1, 1, 1]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basis.base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 20)\n",
            "[array([0, 1, 0, 1, 1, 0])] [0 1 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "col = 1\n",
        "b = b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0]))\n",
        "print(b.shape)\n",
        "for x in range(0,b.shape[1]):\n",
        "    if b[col,x] != 0:\n",
        "        ind = x\n",
        "        break\n",
        "else:\n",
        "    ind = NaN\n",
        "\n",
        "print([basis.base[ind]], mll_basis.base[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "d = 2*m\n",
        "basis = fixed_basis(m, d)\n",
        "t_basis = fixed_basis(2, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "ml_basis = basis_m1\n",
        "mll_basis = basis_m2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_basis = fixed_basis(2, d)\n",
        "mll_basis = fixed_basis(basis.m-2, d)\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2)))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    offset = 4*m+1\n",
        "    indices = [-(k-1)*(2*k-offset) for k in range(1,m+1)] # Lo saque de Mathmatica, vos confia\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    \n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "\n",
        "    hi = -np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    return (h0, hi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(h02,hi2) = two_body_hamiltonian(t_basis.size, m, [0,1,2], np.ones((3,3)), rho_1_arrays, rho_2_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]]]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "print(rho_2_arrays[9,0,0,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "\n",
        "A = np.array([0, 1, 2])  # Your list with d elements\n",
        "\n",
        "# Create a diagonal matrix with each element repeated twice\n",
        "result_matrix = np.diagflat(np.kron(A, np.ones(2)))\n",
        "\n",
        "print(result_matrix)\n",
        "np.kron(A, np.ones(2))\n",
        "\n",
        "mat = np.zeros((basis.size, basis.size))\n",
        "for i in range(0,2*d):\n",
        "    for j in range(0, 2*d):\n",
        "        mat += result_matrix[i,j] * rho_1_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mat = np.sum(result_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h0 == mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1]\n",
            "[0, 9, 14]\n",
            "[0, 9, 14]\n"
          ]
        }
      ],
      "source": [
        "d = 3\n",
        "t_basis = fixed_basis(2, 2*d)\n",
        "basis = fixed_basis(d, 2*d)\n",
        "size = t_basis.size\n",
        "#basis = fixed_basis(d, 2*d)\n",
        "diag_elem = []\n",
        "for x in t_basis.base:\n",
        "    if all([x[i] == x[i+1] for i in range(0, 2*d, 2)]):\n",
        "        print(x)\n",
        "        diag_elem.append(t_basis.rep_to_index(x))\n",
        "\n",
        "print(diag_elem)\n",
        "# Veamos el GALERAZO de Wolfram\n",
        "n = 4*d+1\n",
        "print([-(k-1)*(2*k-n) for k in range(1,d+1)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m2_basis = fixed_basis(2, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-2, d)\n",
        "print(nm2_basis.base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "index = [0,9,14]\n",
        "mat = np.zeros((size,size))\n",
        "for i in range(0,3):\n",
        "    for j in range(0,3):\n",
        "        mat[index[i], index[j]] = W[i,j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "#rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "\n",
        "W = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "W = np.ones((3,3))\n",
        "index = [0, 9, 14]\n",
        "size = 15  # Assuming size is the size of the matrix\n",
        "\n",
        "# Create a meshgrid of indices\n",
        "i, j = np.meshgrid(index, index, indexing='ij')\n",
        "\n",
        "# Use the meshgrid indices to assign values from W to the specified positions in mat\n",
        "mat = np.zeros((size, size))\n",
        "mat[i, j] = W\n",
        "\n",
        "# La mat... mat corresponde a los coeficientes en t_basis\n",
        "inte = np.zeros((basis.size, basis.size))\n",
        "for i in range(0, t_basis.size):\n",
        "    for j in range(0, t_basis.size):\n",
        "        inte += - mat[i, j] * rho_2_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inte == hi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "\n",
        "from numba import njit\n",
        "\n",
        "# Parametros hamiltoniano\n",
        "e = 1\n",
        "eps = 0\n",
        "e0 = np.zeros(2*d)\n",
        "eigenspace_tol = 0.0001\n",
        "for k in range(0, d):\n",
        "    r = random.random() * eps * 0\n",
        "    e0[2*k] = k*e+r\n",
        "    e0[2*k+1] = k*e+r\n",
        "\n",
        "@njit(parallel=True)\n",
        "def base_hamiltonian_aux(basis, size, d, basis_m1, basis_m2):\n",
        "    # Construccion de H\n",
        "    d = d//2\n",
        "    h0 = np.zeros((size,size), dtype=np.float32)\n",
        "    for k in prange(0,2*d):\n",
        "        h0 += e0[k] * np.dot(bd_aux(basis_m1, basis, k),b_aux(basis, basis_m1, k))\n",
        "    hi = np.zeros((size, size), dtype=np.float32)\n",
        "    for k in prange(0,d):\n",
        "        for kb in prange(0,d):\n",
        "            bd_terms = np.dot(bd_aux(basis_m1, basis, 2*k),bd_aux(basis_m2, basis_m1, 2*k+1))\n",
        "            b_terms = np.dot(b_aux(basis_m1, basis_m2, 2*kb+1),b_aux(basis, basis_m1, 2*kb))\n",
        "            hi += -1*np.dot(bd_terms,b_terms)\n",
        "\n",
        "    return (h0, hi)\n",
        "\n",
        "def base_hamiltonian(basis, basis_m1, basis_m2):\n",
        "    return base_hamiltonian_aux(basis.base, basis.size, basis.d, basis_m1.base, basis_m2.base)\n",
        "\n",
        "h0, hi = base_hamiltonian(basis, basis_m1, basis_m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oapxWkD16fHg"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
