{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguschanchu/FermionicML/blob/main/FermionicML_thermal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXz5cOlVwrzZ"
      },
      "source": [
        "# FermionicML:\n",
        "\n",
        "Code based on aguschanchu/Bosonic.py\n",
        "\n",
        "A diferencia del código anterior, este modelo trabaja sobre estados térmicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD2Yai55rMm"
      },
      "source": [
        "## Código base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "3.10.14 | packaged by conda-forge | (main, Mar 20 2024, 12:45:18) [GCC 12.3.0]\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "num_gpus = tf.config.list_physical_devices('GPU')\n",
        "#tf.config.experimental.set_memory_growth(num_gpus[0],True)\n",
        "import sys\n",
        "import platform\n",
        "print(sys.version)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgf9ExZN4jA7"
      },
      "source": [
        "Cargamos el código de Bosonic.py básico, branch fermionic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "Gydz4kCH4l5w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_2766/1952354829.py:326: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  def gamma_lamba_inv(x):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import binom\n",
        "from scipy.sparse import dok_matrix, linalg\n",
        "from scipy import linalg as linalg_d\n",
        "from joblib import Memory\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from joblib import Parallel, delayed\n",
        "from numba import jit, prange, njit\n",
        "import numba as nb\n",
        "import pickle\n",
        "import math\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from itertools import combinations\n",
        "import scipy\n",
        "\n",
        "# Funciones auxiliares optimiadas\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def int_to_tuple_arr(ni,nf, b, digits=None):\n",
        "    sol = np.zeros((nf-ni, digits), dtype=np.int64)\n",
        "    for n in prange(ni, nf):\n",
        "        r = np.zeros(digits, dtype=np.int64)\n",
        "        ncop = n\n",
        "        idx = 0\n",
        "        while n != 0:\n",
        "            r[idx] = n % b\n",
        "            n = n // b\n",
        "            idx += 1\n",
        "        if digits is not None:\n",
        "            if idx < digits:\n",
        "                for i in range(idx, digits):\n",
        "                    r[i] = 0\n",
        "                idx = digits\n",
        "        sol[ncop-ni,:] = r[:idx]\n",
        "    return sol\n",
        "\n",
        "def tuple_to_int(t, d):\n",
        "    b = d-1\n",
        "    l = len(t)\n",
        "    s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "    return sum(s)\n",
        "\n",
        "def create_basis_(m, d, size):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 1000000\n",
        "    for x in range(0,(m+1)**d, chunk_size):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        arr = int_to_tuple_arr(start_index, end_index, m+1, d)\n",
        "        sums = np.sum(arr, axis=1)\n",
        "        rows = np.where(sums == m)[0]\n",
        "        for row in [arr[i] for i in rows]:\n",
        "            if np.all(np.logical_or(row == 0, row == 1)):\n",
        "                base.append(row)\n",
        "\n",
        "    # Como consecuencia de la paralelizacion, es necesario reordenar la base\n",
        "    sorted_base = sorted(base, key=lambda x: tuple_to_int(x, d), reverse=True)\n",
        "    assert len(base) == size\n",
        "\n",
        "    return sorted_base\n",
        "\n",
        "def custom_base_representation_tf(n_min, n_max, base, num_digits):\n",
        "    # Generate a range of numbers from n_min to n_max\n",
        "    numbers = tf.range(n_min, n_max + 1, dtype=tf.int64)\n",
        "    \n",
        "    # Calculate the digits in the custom base using broadcasting\n",
        "    digits = tf.pow(tf.cast(base, dtype=tf.float64), tf.cast(tf.range(num_digits), dtype=tf.float64))\n",
        "    \n",
        "    # Reshape the digits to [1, num_digits] for broadcasting\n",
        "    digits = tf.reshape(digits, [1, -1])\n",
        "    \n",
        "    # Reshape numbers to [batch_size, 1]\n",
        "    numbers = tf.reshape(tf.cast(numbers, dtype=tf.float64), [-1, 1])\n",
        "    \n",
        "    # Calculate the digits in the custom base for each number using broadcasting\n",
        "    result = tf.cast(tf.math.floormod(tf.math.floordiv(numbers, digits), base), dtype=tf.int32)\n",
        "    \n",
        "    # Pad the result to have exactly num_digits columns\n",
        "    result = tf.pad(result, paddings=[[0, 0], [0, num_digits - tf.shape(result)[1]]], constant_values=0)\n",
        "    \n",
        "    # Reverse the order of columns\n",
        "    #result = tf.reverse(result, axis=[1])\n",
        "\n",
        "    return result\n",
        "\n",
        "def select_rows_with_sum(arr, m):\n",
        "    # Create a mask based on the criteria\n",
        "    mask = tf.reduce_all(tf.math.logical_or(tf.equal(arr, 0), tf.equal(arr, 1)), axis=1) & (tf.reduce_sum(arr, axis=1) == m)\n",
        "    \n",
        "    # Use the mask to select the rows\n",
        "    result = tf.boolean_mask(arr, mask, axis=0)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def create_basis_tf_(m, d):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 10000000\n",
        "    for x in tqdm(range(0,(m+1)**d, chunk_size)):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        res = custom_base_representation_tf(start_index, end_index, m+1, d)\n",
        "        arr = select_rows_with_sum(res, m)\n",
        "        base.append(arr.numpy())\n",
        "\n",
        "    return np.concatenate(base)\n",
        "\n",
        "def create_fermionic_base_(m, d):\n",
        "    indices = list(range(d))\n",
        "    combinations_list = list(combinations(indices, m))\n",
        "    \n",
        "    vectors = []\n",
        "    for combo in combinations_list:\n",
        "        vector = [1 if i in combo else 0 for i in indices]\n",
        "        vectors.append(vector)\n",
        "    \n",
        "    return vectors\n",
        "\n",
        "# Dada una base, devuelve los vectores que estan dados de a pares\n",
        "def get_kkbar_indices_(base):\n",
        "    indices = []\n",
        "    for i, v in enumerate(base):\n",
        "        if np.all(v[::2] == v[1::2]):\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "class fixed_basis:\n",
        "\n",
        "    # Convierte a un enterno n a su escritura en base b\n",
        "    def _int_to_tuple(self, n, b, digits = None):\n",
        "        rep = np.base_repr(n, b)\n",
        "        rep_int = [int(x,b) for x in rep]\n",
        "        if digits is not None:\n",
        "            zeros = [0 for i in range(0,digits-len(rep))]\n",
        "            return zeros + rep_int\n",
        "        else:\n",
        "            return rep_int\n",
        "\n",
        "    # Revierte la transformacion anterior\n",
        "    def tuple_to_int(self, t):\n",
        "        b = self.d-1\n",
        "        l = len(t)\n",
        "        s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "        return sum(s)\n",
        "\n",
        "    # Convierte el vector en su representacion\n",
        "    def vect_to_repr(self, vect):\n",
        "        for i, k in enumerate(vect):\n",
        "            if k == 1. or k == 1:\n",
        "                break\n",
        "        else:\n",
        "            return 0\n",
        "        return self.base[i,:]\n",
        "\n",
        "    def rep_to_vect(self, rep):\n",
        "        rep = list(rep)\n",
        "        for i, r in [(j, self.base[j,:]) for j in range(0,self.size)]:\n",
        "            if list(r) == rep:\n",
        "                return self.canonicals[:,i]\n",
        "        else:\n",
        "            None\n",
        "\n",
        "    def rep_to_index(self, rep):\n",
        "        try:\n",
        "            return self.base.tolist().index(list(rep))\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def rep_to_exi(rep):\n",
        "        r = []\n",
        "        for i, k in enumerate(rep):\n",
        "            r += [i for x in range(0,k)]\n",
        "        return r\n",
        "\n",
        "    # Crea base de M particulas en D estados (repr y base canonica)\n",
        "    def create_basis(self, m, d, pairs = False):\n",
        "        #print(\"Creating basis: \", m, d)\n",
        "        #base = np.array(create_basis_tf_(m, d)) CASO GENERICO\n",
        "        base = np.array(create_fermionic_base_(m,d)) # UNICAMENTE FERMIONICO\n",
        "        if pairs:\n",
        "            base = base[get_kkbar_indices_(base)]\n",
        "        length = base.shape[0]\n",
        "        # Asignamos a cada uno de ellos un canónico\n",
        "        canonicals = np.eye(length)\n",
        "        return base, canonicals\n",
        "    \n",
        "    def __init__(self, m, d, pairs = False):\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        (self.base, self.canonicals) = self.create_basis(m, d, pairs)\n",
        "        self.size = self.base.shape[0]\n",
        "\n",
        "# Matrices de aniquilación y creación endomórficas. Estan fuera de la clase para poder ser cacheadas\n",
        "#@memory.cache\n",
        "def bdb(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0 and v[i] != 1:\n",
        "                #print(v)\n",
        "                dest = list(v.copy())\n",
        "                dest[j] -= 1\n",
        "                dest[i] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                if tar is None:\n",
        "                    pass\n",
        "                else:\n",
        "                    mat[tar, k] = np.sqrt(v[i]+1)*np.sqrt(v[j])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0:\n",
        "                mat[k, k] = v[i] \n",
        "    return mat\n",
        "\n",
        "#@memory.cache\n",
        "def bbd(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 0 and v[j] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[i] -= 1\n",
        "                dest[j] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[j]+1)*np.sqrt(v[i])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 1:\n",
        "                mat[k, k] = v[i]+1\n",
        "    return mat\n",
        "\n",
        "# Matrices de aniquilación y creación.Toman la base de origen y destino (basis_o, basis_d) resp\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def b_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 0:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] -= 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i])\n",
        "    return mat\n",
        "\n",
        "def b(basis_o, basis_d, i):\n",
        "    return b_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def bd_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 1:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd(basis_o, basis_d, i):\n",
        "    return bd_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "\n",
        "# Acepta una lista de indices a crear\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def bd_gen_aux(basis_o, basis_d, gen_list):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        conds = np.zeros(len(gen_list), dtype=np.int64)\n",
        "        for i in range(len(gen_list)):\n",
        "            if basis_o[k][gen_list[i]] != 1:\n",
        "                conds[i] = 1\n",
        "        if np.all(conds):\n",
        "            dest = list(basis_o[k].copy())\n",
        "            for i in gen_list:\n",
        "                dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd_gen(basis_o, basis_d, i):\n",
        "    return bd_gen_aux(basis_o.base, basis_d.base, np.array(i))\n",
        "\n",
        "def b_gen(basis_o, basis_d, i):\n",
        "    return np.transpose(bd_gen(basis_d, basis_o, i))\n",
        "\n",
        "# Volvemos a definir la función para compilarla\n",
        "@nb.jit(forceobj=True)\n",
        "def _rep_to_index(base, rep):\n",
        "    return base.tolist().index(list(rep))\n",
        "\n",
        "# Funciones auxiliares para calcular rho2kkbar y gamma_p\n",
        "@nb.jit(nopython=True)\n",
        "def rep_to_exi(rep):\n",
        "    r = []\n",
        "    for i in range(len(rep)):\n",
        "        for j in range(rep[i]):\n",
        "            r.append(i)\n",
        "    return r\n",
        "\n",
        "@nb.njit\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "@nb.njit\n",
        "def gamma_lamba(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.jit\n",
        "def gamma_lamba_inv(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / np.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.njit\n",
        "def rep_to_index_np(base, rep):\n",
        "    for i in range(len(base)):\n",
        "        if np.all(base[i] == rep):\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "\n",
        "def gamma_p(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    return gamma_p_aux(basis.base, vect, m_basis.base, nm_basis.base)\n",
        "\n",
        "@nb.njit()\n",
        "def gamma_p_aux(basis, vect, m_basis, nm_basis):\n",
        "    mat = np.zeros((len(m_basis), len(nm_basis)), dtype=np.float32)\n",
        "    for i in prange(len(m_basis)):\n",
        "        v = m_basis[i]\n",
        "        for j in prange(len(nm_basis)):\n",
        "            w = nm_basis[j]\n",
        "            targ = v + w\n",
        "            index = rep_to_index_np(basis, targ)\n",
        "            if index != -1:\n",
        "                coef = vect[index]\n",
        "                if coef != 0:\n",
        "                    coef = coef * gamma_lamba_inv(v) * gamma_lamba_inv(w) * gamma_lamba(targ)\n",
        "                mat[i, j] = coef\n",
        "    return mat\n",
        "# Devuelve la matriz rho M asociada al vector\n",
        "def rho_m(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    g = gamma_p(basis, m, vect, m_basis, nm_basis)\n",
        "    return np.dot(g,np.transpose(g))\n",
        "\n",
        "# Devuelve la matriz gamma asociada a la descomposición (M,N-M) del vector\n",
        "@jit(forceobj=True)\n",
        "def gamma(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    mat = dok_matrix((m_basis.size, nm_basis.size), dtype=np.float32)\n",
        "    for i, v in enumerate(m_basis.base):\n",
        "        for j, w in enumerate(nm_basis.base):\n",
        "            targ = v+w\n",
        "            # Revisamos que sea un estado fermionico valido\n",
        "            arr = np.asarray(targ)\n",
        "            if not np.all(np.logical_or(arr == 0, arr == 1)):\n",
        "                continue\n",
        "            index = _rep_to_index(basis.base, targ)\n",
        "            coef = vect[index]\n",
        "            if coef != 0:\n",
        "                aux = lambda x: np.prod(np.reciprocal(np.sqrt([np.math.factorial(o) for o in x])))\n",
        "                aux_inv = lambda x: np.prod(np.sqrt([np.math.factorial(o) for o in x]))\n",
        "                coef = coef * aux(v) * aux(w) * aux_inv(targ)\n",
        "                #coef = coef\n",
        "                #print(v,w,coef)\n",
        "            mat[i,j] = coef\n",
        "    return mat\n",
        "\n",
        "# Genera las matrices de rho1\n",
        "def rho_1_gen(basis):\n",
        "    d = basis.d\n",
        "    s = basis.size\n",
        "    mat = np.empty((d,d,s,s), dtype=np.float32)\n",
        "    for i in range(0, d):\n",
        "        for j in range(0, d):\n",
        "            mat[i,j,:,:] = np.array(bdb(basis,j, i).todense())\n",
        "    return mat\n",
        "\n",
        "#@jit(parallel=True, nopython=True)\n",
        "def rho_1(d, state, rho_1_arrays):\n",
        "    state_expanded = state[np.newaxis, np.newaxis, :, :]\n",
        "    product = state_expanded * rho_1_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "\n",
        "    return mat\n",
        "\n",
        "\n",
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "\n",
        "    return mat\n",
        "\n",
        "def rho_2(size, state, rho_2_arrays):\n",
        "    state_expanded = np.expand_dims(state, axis=1)\n",
        "    state_expanded = np.expand_dims(state_expanded, axis=1)\n",
        "    rho_2_arrays = rho_2_arrays[np.newaxis, :, :, :, :]\n",
        "    print(state_expanded.shape, rho_2_arrays.shape)\n",
        "    product = state_expanded * rho_2_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "    return mat\n",
        "\n",
        "def get_kkbar_indices(t_basis):\n",
        "    indices = []\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        if np.all(v[::2] == v[1::2]):\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def rho_2_kkbar_gen(t_basis, rho_2_arrays):\n",
        "    indices = get_kkbar_indices(t_basis)\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "\n",
        "    rho_2_arrays_kkbar = rho_2_arrays[i, j, :, :]\n",
        "\n",
        "    return rho_2_arrays_kkbar\n",
        "\n",
        "# Devuelve la matriz rho 2 asociada al bloque kkbar\n",
        "def rho_2_kkbar(basis, vect, ml_basis = None, mll_basis = None, t_basis = None):\n",
        "    d = basis.d\n",
        "    # Creo las bases si no están dadas\n",
        "    if ml_basis == None or mll_basis == None or t_basis == None:\n",
        "        ml_basis = fixed_basis(m-1,d)\n",
        "        mll_basis = fixed_basis(m-2,d)\n",
        "        t_basis = fixed_basis(2,d)\n",
        "    diag = []\n",
        "    for v in t_basis.base:\n",
        "        for j in range(0, d, 2):\n",
        "            if v[j] == v[j+1]:\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            diag.append(v)\n",
        "    diag = np.array(diag)\n",
        "    return rho_2_kkbar_aux(diag, vect, basis.base, ml_basis.base, mll_basis.base, t_basis.base)\n",
        "\n",
        "@nb.njit\n",
        "def rho_2_kkbar_lambda(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "#@nb.njit(parallel=True)\n",
        "def rho_2_kkbar_aux(diag, vect, basis, ml_basis, mll_basis, t_basis):\n",
        "    mat = np.zeros((len(diag), len(diag)), dtype=np.float32)\n",
        "    for i in prange(len(diag)):\n",
        "        for j in prange(len(diag)):\n",
        "            v = diag[i]\n",
        "            w = diag[j]\n",
        "            # Creacion de los a\n",
        "            i_set = rep_to_exi(v)\n",
        "            b_m = b_aux(ml_basis, mll_basis, i_set[1]) @ b_aux(basis, ml_basis, i_set[0])\n",
        "            # Creacion de los ad\n",
        "            i_set = rep_to_exi(w)\n",
        "            bd_m = bd_aux(ml_basis, basis, i_set[1]) @ bd_aux(mll_basis, ml_basis, i_set[0])\n",
        "            # v1 = vect @ bd_m @ b_m @ vect Para estados puros\n",
        "            # Mult de b's y filleo de mat\n",
        "            coef = np.trace(vect @ bd_m @ b_m)\n",
        "            mat[i,j] = coef * rho_2_kkbar_lambda(v) * rho_2_kkbar_lambda(w)\n",
        "    return mat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dga5Xx_5vDf"
      },
      "source": [
        "## Definicion de Hamiltoniano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiTq53L5E1U"
      },
      "source": [
        "Cargamos el código de creación y resolución de Hamiltonianos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h5FXWv849Mq",
        "outputId": "49dd47b5-8c16-4ad4-92e7-e172462229b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70\n"
          ]
        }
      ],
      "source": [
        "m = 4\n",
        "d = 2*m\n",
        "pairs = False # Usar solo para estados puros\n",
        "# Creo las bases para no tener que recrearlas luego\n",
        "basis = fixed_basis(m, d, pairs = pairs)\n",
        "#basis_m1 = fixed_basis(m-1, d, pairs = True)\n",
        "basis_m2 = fixed_basis(m-2, d, pairs = pairs)\n",
        "print(basis.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "id": "PToiSs915TXw"
      },
      "outputs": [],
      "source": [
        "## Usamos este approach si queremos guardar los generadores\n",
        "# Dados 1/2 (d^2+d) elementos, genera una mat de dxd:\n",
        "eps = 0.00001\n",
        "\n",
        "def sym_mat_gen(vect, d):\n",
        "    matrix = fill_matrix(vect, d)\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "@jit(nopython=True)\n",
        "def fill_matrix(vect, d):\n",
        "    matrix = np.zeros((d, d))\n",
        "    idx = 0\n",
        "    for i in prange(d):\n",
        "        for j in prange(i, d):\n",
        "            matrix[i, j] = vect[idx]\n",
        "            idx += 1\n",
        "    return matrix\n",
        "\n",
        "# Generamos una matrix aleatoria. Cuidado con la distribución, ver https://stackoverflow.com/questions/56605189/is-there-an-efficient-way-to-generate-a-symmetric-random-matrix\n",
        "def hamil_base_gen(d):\n",
        "    U = np.random.uniform(low=0, high=1.0, size=(d, d))\n",
        "    hamil_base = np.tril(U) + np.tril(U, -1).T\n",
        "    return hamil_base\n",
        "\n",
        "# Dada un a mat dxd simetrica, contruye el hamiltoniano de un cuerpo a_{ij} c^{dag}_i c_j\n",
        "# Alternativamente podemos construirlo a partir de rho_1_gen\n",
        "def base_hamiltonian_aux(mat, size, d, rho_1_gen):\n",
        "    # Construccion de H\n",
        "    rho_1_gen_transposed = rho_1_gen.transpose(1, 0, 2, 3)\n",
        "    mat_expanded = mat[:, :, np.newaxis, np.newaxis]\n",
        "    h = np.sum(mat_expanded * rho_1_gen_transposed[:, :, :, :], axis=(0, 1))\n",
        "    return h.astype(np.float32)\n",
        "\n",
        "def base_hamiltonian(mat, basis, rho_1_gen):\n",
        "    return base_hamiltonian_aux(mat, basis.size, basis.d, rho_1_gen)\n",
        "\n",
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2))) + eps * np.random.random((2*m,2*m))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    rho_1_arrays_t = tf.transpose(rho_1_arrays,perm=[1, 0, 2, 3])\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    rho_2_arrays_t = tf.transpose(rho_2_arrays,perm=[1, 0, 2, 3])\n",
        "\n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "    hi = np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "    return (h0, hi)\n",
        "\n",
        "def solve(h, last_step = None):\n",
        "    sol = linalg.eigsh(h, which='SA',k=19)\n",
        "    eigenspace_tol = 0.0001\n",
        "    if type(last_step) != type(None):\n",
        "        # Seleccionamos todos los autovects que difieren sus autovalores menos que tol (mismo autoespacio)\n",
        "        # y tomamos la proyección en el autoespacio de la solución del paso anterior (last_step)\n",
        "        eig = sol[0].real\n",
        "        eigv = sol[1]\n",
        "        cand = [eigv[:,i].real  for (i, x) in enumerate(eig) if abs(x-min(eig)) < eigenspace_tol]\n",
        "        cand_norm = [x/np.linalg.norm(x) for x in cand]\n",
        "        fund = np.zeros(len(cand[0]))\n",
        "        for x in cand_norm:\n",
        "            fund += np.dot(last_step,x) * x\n",
        "    else:\n",
        "        argmin = np.argmin(sol[0].real)\n",
        "        fund = sol[1][:,argmin]\n",
        "    fund = fund.real / np.linalg.norm(fund)\n",
        "    return fund\n",
        "\n",
        "# Generacion de H basada en TF\n",
        "\n",
        "# Funciones auxiliares de gen de H basado en TF\n",
        "## Dada matrix de indices, genera los indices de updates de TF\n",
        "def gen_update_indices(t_basis, batch_size):\n",
        "    # Calculamos los indices de kkbar en t_basis\n",
        "    indices = tf.constant(get_kkbar_indices(t_basis))\n",
        "    # Creamos el array de indices x indices\n",
        "    i, j = tf.meshgrid(indices, indices, indexing='ij')\n",
        "    matrix = tf.reshape(tf.stack([i, j], axis=-1), (-1, 2))\n",
        "\n",
        "    # Repeat the matrix along the first axis (axis=0) 'b' times\n",
        "    repeated_matrix = tf.repeat(tf.expand_dims(matrix, axis=0), repeats=batch_size, axis=0)\n",
        "\n",
        "    # Create an index array from 0 to b-1\n",
        "    indices = tf.range(batch_size, dtype=tf.int32)\n",
        "\n",
        "    # Expand the index array to have the same shape as the repeated matrix\n",
        "    indices = tf.expand_dims(indices, axis=-1)\n",
        "    indices = tf.expand_dims(indices, axis=-1)\n",
        "    indices = tf.tile(indices, multiples=[1,matrix.shape[0],1]) \n",
        "\n",
        "    # Concatenate the index array to the repeated matrix along a new axis\n",
        "    tiled_matrix = tf.concat([indices, repeated_matrix], axis=-1)\n",
        "    tiled_matrix = tf.reshape(tiled_matrix, [-1,3])\n",
        "    return tiled_matrix\n",
        "\n",
        "\n",
        "def two_body_hamiltonian_tf(t_basis, m, energy_batch, G_batched, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # SECCIÓN ENERGIAS\n",
        "    ## Dado un batch de niveles, lo pasamos a TF\n",
        "    #energy_matrix = tf.constant(energy_batch, dtype=tf.float32)\n",
        "    energy_matrix = energy_batch  \n",
        "    energy_matrix = tf.repeat(energy_matrix, repeats=2, axis=1) ## Repetimos los niveles para cada uno de los pares (por el nivel k y kbar)\n",
        "    ## Generamos la matrix diagonal y expandimos\n",
        "    energy_matrix_expanded = tf.linalg.diag(energy_matrix)\n",
        "    energy_matrix_expanded = energy_matrix_expanded[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    # Multiplicamos por los operadores C^dag C\n",
        "    h0_arr = tf.reduce_sum(energy_matrix_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    # SECCIÓN INTERACCIÓN\n",
        "    # Ya tenemos los indices de updates, ahora tomamos la mat en t_basis (una de zeros)\n",
        "    # y updateamos de acuerdo a la lista de G's cada uno flatteneados\n",
        "    # G_flatten = np.ndarray.flatten(np.array([np.ndarray.flatten(G) for G in G_batched])) cambiado por una versión compatible con TF\n",
        "\n",
        "    G_flatten = tf.reshape(G_batched, [-1])\n",
        "    G_flatten = tf.cast(G_flatten, tf.float32)\n",
        "    indices = tf.slice(indices, [0, 0], [tf.size(G_flatten), -1]) # puede que nos pasen menos updates en el loop de entrenamiento!\n",
        "\n",
        "    # Creamos la mat de t_basis y updateamos a partir de los indices de kkbar\n",
        "    mat = tf.zeros((len(energy_batch), t_basis.size, t_basis.size), dtype=tf.float32)\n",
        "    \n",
        "    mat = tf.tensor_scatter_nd_update(mat, indices, G_flatten)\n",
        "    # Preparamos las dimensiones y multiplicamos\n",
        "    mat_expanded = mat[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_2_gen_transposed = tf.transpose(rho_2_arrays, perm=[1, 0, 2, 3])\n",
        "    hi_arr = tf.reduce_sum(mat_expanded * rho_2_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    return h0_arr - hi_arr\n",
        "\n",
        "def two_body_hamiltonian_tf_arb(t_basis, m, energy_seed, G_batched, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # SECCIÓN ENERGIAS\n",
        "    ## Dado un seed de niveles diagonal construimos la mat simétrica dxd que multiplicara a c^dag_i c_j\n",
        "    diagonal = np.zeros((gpu_batch_size, 2 * m, 2 * m))\n",
        "    diagonal[:, np.arange(2 * m), np.arange(2 * m)] = energy_seed\n",
        "    energy_matrix_expanded = diagonal\n",
        "\n",
        "    # HARDODEADO SOLO CASO 2C!\n",
        "    #energy_matrix_expanded = np.array([np.eye(2*m)*4 for _ in range(gpu_batch_size)])\n",
        "\n",
        "    ## Generamos la matriz y expandimos\n",
        "    energy_matrix_expanded = energy_matrix_expanded[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "\n",
        "    # Multiplicamos por los operadores C^dag C\n",
        "    h0_arr = tf.reduce_sum(energy_matrix_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    # SECCIÓN INTERACCIÓN\n",
        "    # Ya tenemos los indices de updates, ahora tomamos la mat en t_basis (una de zeros)\n",
        "    # y updateamos de acuerdo a la lista de G's cada uno flatteneados\n",
        "    \n",
        "    # Creamos la mat de t_basis, nada más que hacer! los coeficientes están dados. Bueno, y simetrizar\n",
        "    int_mat = np.zeros((gpu_batch_size, t_basis.size, t_basis.size))\n",
        "\n",
        "    idx = np.triu_indices(t_basis.size)\n",
        "    int_mat[:, idx[0], idx[1]] = G_batched\n",
        "    diagonal = np.einsum('ijk,ijk->ijk', int_mat, np.eye(t_basis.size)[np.newaxis,::])\n",
        "    int_mat = int_mat + np.transpose(int_mat, axes=(0,2,1)) - diagonal \n",
        "\n",
        "    # Preparamos las dimensiones y multiplicamos\n",
        "    int_mat_expanded = int_mat[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_2_gen_transposed = tf.transpose(rho_2_arrays, perm=[1, 0, 2, 3])\n",
        "    hi_arr = tf.reduce_sum(int_mat_expanded * rho_2_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    return h0_arr - hi_arr\n",
        "\n",
        "def state_energy(state, h_arr):\n",
        "    return tf.linalg.trace(tf.matmul(state, h_arr))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emVBTg2QD-Fg"
      },
      "source": [
        "## Modelo de ML\n",
        "Basado en matrices densidad de 1 y 2 cuerpos como input, con hamiltoniano como salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "id": "aF_Ec_mCGX96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 14:39:40.613879: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 97,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.test.gpu_device_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDoa6LUJJ8O",
        "outputId": "73481454-fbcb-469f-d72f-cd0f8d534808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n",
            "[[1 1 0 0 0 0 0 0]\n",
            " [1 0 1 0 0 0 0 0]\n",
            " [1 0 0 1 0 0 0 0]\n",
            " [1 0 0 0 1 0 0 0]\n",
            " [1 0 0 0 0 1 0 0]\n",
            " [1 0 0 0 0 0 1 0]\n",
            " [1 0 0 0 0 0 0 1]\n",
            " [0 1 1 0 0 0 0 0]\n",
            " [0 1 0 1 0 0 0 0]\n",
            " [0 1 0 0 1 0 0 0]\n",
            " [0 1 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 0 1]\n",
            " [0 0 1 1 0 0 0 0]\n",
            " [0 0 1 0 1 0 0 0]\n",
            " [0 0 1 0 0 1 0 0]\n",
            " [0 0 1 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 0 1]\n",
            " [0 0 0 1 1 0 0 0]\n",
            " [0 0 0 1 0 1 0 0]\n",
            " [0 0 0 1 0 0 1 0]\n",
            " [0 0 0 1 0 0 0 1]\n",
            " [0 0 0 0 1 1 0 0]\n",
            " [0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 0 1 1 0]\n",
            " [0 0 0 0 0 1 0 1]\n",
            " [0 0 0 0 0 0 1 1]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nm = 1\\nm1_basis = fixed_basis(m, d)\\nprint(m1_basis.size)\\nprint(m1_basis.base)\\nnm1_basis = fixed_basis(basis.m-m, d)\\n'"
            ]
          },
          "execution_count": 98,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Construccion de bases para calculo de rho1 y rho2\n",
        "# rho2\n",
        "m = 2\n",
        "m2_basis = fixed_basis(m, d, pairs=pairs)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-m, d, pairs=pairs)\n",
        "print(nm2_basis.base)\n",
        "t_basis = fixed_basis(2, basis.d, pairs=pairs)\n",
        "# rho1\n",
        "\"\"\"\n",
        "m = 1\n",
        "m1_basis = fixed_basis(m, d)\n",
        "print(m1_basis.size)\n",
        "print(m1_basis.base)\n",
        "nm1_basis = fixed_basis(basis.m-m, d)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapxWkD16fHg"
      },
      "source": [
        "### Algunos benchmarks y funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "id": "umCIrxCZKXQd"
      },
      "outputs": [],
      "source": [
        "# Given h calculo en rho2 y rho1 máximo\n",
        "def rho1_rho2(h, beta):\n",
        "    fund = thermal_state(h, beta)\n",
        "    rho2 = np.array(rho_2(basis, m2_basis.size, state, rho_2_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho2).real)\n",
        "    rho_2_max = r[0]\n",
        "    rho1 = np.array(rho_1(basis, state, rho_1_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho1).real)\n",
        "    rho_1_max = r[0]\n",
        "\n",
        "    return (rho_1_max, rho_2_max)\n",
        "\n",
        "def fill_triangular_np(x):\n",
        "    m = x.shape[0]\n",
        "    n = np.int32(np.sqrt(.25 + 2 * m) - .5)\n",
        "    x_tail = x[(m - (n**2 - m)):]\n",
        "    return np.triu(np.concatenate([x, x_tail[::-1]], 0).reshape(n, n))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "QaNnIIc5bZux"
      },
      "outputs": [],
      "source": [
        "# TEST: Las funciones de TF y comunes coinciden\n",
        "\n",
        "# Dado h, \\beta, construyo el estado térmico\n",
        "from scipy.linalg import expm\n",
        "\n",
        "def thermal_state(h, beta):\n",
        "    quotient = expm(-beta*h)\n",
        "    return quotient / np.trace(quotient)\n",
        "\n",
        "## NO usar para mat no hermiticas\n",
        "@nb.jit(nopython=True)\n",
        "def thermal_state_eig(h, beta):\n",
        "    w, v = np.linalg.eigh(-beta*h)\n",
        "    D = np.diag(np.exp(w))\n",
        "    mat = v @ D @ v.T\n",
        "    mat = mat / np.trace(mat)\n",
        "    return mat\n",
        "    \n",
        "def gen_to_h(base, rho_1_arrays):\n",
        "    triag = fill_triangular_np(base)\n",
        "    body_gen = triag + np.transpose(triag)-np.diag(np.diag(triag))\n",
        "    h = np.array(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
        "    return h \n",
        "\n",
        "def gen_to_h_1b(hamil_base):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "    return body_gen\n",
        "\n",
        "def gen_to_h_tf(hamil_base, rho_1_arrays):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag)) # Simetrizamos y generamos la matriz de h\n",
        "    hamil_expanded = body_gen[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    h_arr = tf.reduce_sum(hamil_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "    return h_arr\n",
        "\n",
        "def thermal_state_tf(h):\n",
        "    # Assume beta=1\n",
        "    exp_hamiltonian = tf.linalg.expm(-h)\n",
        "    partition_function = tf.linalg.trace(exp_hamiltonian)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    \n",
        "    rho = exp_hamiltonian / partition_function\n",
        "\n",
        "    return rho\n",
        "\n",
        "def rho_1_tf(state, rho_1_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_1_arrays_expanded = tf.expand_dims(rho_1_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_1_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "def rho_2_tf(state, rho_2_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_2_arrays_expanded = tf.expand_dims(rho_2_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_2_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "# NOTA: para calcular el bloque rho2kkbar, utilizar en lugar\n",
        "\n",
        "def rho_1_gc_tf(hamil_base):\n",
        "    e, v = tf.linalg.eigh(gen_to_h_1b(hamil_base))\n",
        "    result = 1 / (1 + tf.exp(e))\n",
        "    result = tf.linalg.diag(result)\n",
        "    res = tf.linalg.matmul(v,result)\n",
        "    res = tf.linalg.matmul(res,v,adjoint_b=True)\n",
        "    \n",
        "    return tf.cast(res, tf.float32)\n",
        "\n",
        "# Aux function\n",
        "def outer_product(vector):\n",
        "    return tf.einsum('i,j->ij', vector, vector)\n",
        "\n",
        "def pure_state(h):\n",
        "    e, v = tf.linalg.eigh(h)\n",
        "    fund = v[:,:,0]\n",
        "    d = tf.map_fn(outer_product, fund)\n",
        "    return d\n",
        "\n",
        "# Casos de entrenamiento tipo mat gaussianas\n",
        "def gen_gauss_mat(G, sigma_sq, size):\n",
        "    indices = np.arange(size)\n",
        "    mat = G * np.exp(-((indices - indices[:, np.newaxis])**2) / (2 * sigma_sq))\n",
        "    return mat\n",
        "\n",
        "def gen_gauss_mat_np(G_values, sigma_sq_values, size):\n",
        "    indices = np.arange(size, dtype=np.float32)\n",
        "    indices_diff = indices - indices[:, np.newaxis]\n",
        "\n",
        "    mat = G_values[:, np.newaxis, np.newaxis] * np.exp(-np.square(indices_diff) / (2 * sigma_sq_values[:, np.newaxis, np.newaxis]))\n",
        "\n",
        "    return mat\n",
        "\n",
        "# Casos de entrenamiento tipo matriz vectorial\n",
        "def gen_vect_mat(size, g_init, g_stop, sym = True):\n",
        "    if sym:\n",
        "        vect = np.sort(np.random.uniform(g_init, g_stop, size // 2))[::-1]\n",
        "        vect = np.repeat(vect, 2)\n",
        "        if size % 2 != 0: # TODO: Agregar tipo en el medio\n",
        "            raise ValueError\n",
        "    else:\n",
        "        vect = np.sort(np.random.uniform(g_init, g_stop, size))[::-1]\n",
        "    indices = np.abs(np.arange(size)[:, np.newaxis] - np.arange(size))\n",
        "    mat = vect[indices]\n",
        "\n",
        "    return vect, mat\n",
        "\n",
        "def gen_gauss_plus_vect(G_values, sigma_sq_values, size):\n",
        "    indices = np.arange(size//2, dtype=np.float32)\n",
        "    vect = G_values[:, np.newaxis] * np.exp(-np.square(indices) / (2 * sigma_sq_values[:, np.newaxis]))\n",
        "    return vect\n",
        "\n",
        "def gen_random_arr(h_labels):\n",
        "    matrices = np.zeros((gpu_batch_size, basis.m, basis.m))\n",
        "    up_idx = np.triu_indices(basis.m, 1)\n",
        "    matrices[:, up_idx[0], up_idx[1]] = h_labels\n",
        "    matrices += matrices.transpose(0, 2, 1)\n",
        "\n",
        "    return matrices\n",
        "\n",
        "def random_fermi_arr(g_init, g_stop, s = basis.m):\n",
        "    # En primer lugar, construimos la mat simétrica con respecto a nivel de Fermi\n",
        "    seed = np.round(np.random.uniform(g_init, g_stop,(s//2, s//2)), 2)\n",
        "    mat = np.zeros((s, s))\n",
        "    for i in range(s):\n",
        "        for j in range(s):\n",
        "            conv = lambda x: s//2 - 1 - np.min([x,s-1-x]) \n",
        "            mat[i,j] = seed[conv(i), conv(j)]\n",
        "\n",
        "    # Simetrizamos\n",
        "    mat = (mat + mat.T)/2\n",
        "    # Volamos la diagonal + antidiagonal\n",
        "    mat = mat - np.diag(np.diag(mat)) - np.diag(np.diag(mat))[::-1]\n",
        " \n",
        "    # Los labels se buscan de la siguiente manera\n",
        "    #up_idx = np.triu_indices(basis.m//2, 1)\n",
        "    #mat[up_idx].reshape((8,8))\n",
        "\n",
        "def random_fermi_arr_inv(seed, s=basis.m, obj = False):\n",
        "    up_idx = np.triu_indices(s//2, 1)\n",
        "    reb = np.zeros((s//2,s//2))\n",
        "    if obj:\n",
        "        reb = np.zeros((s//2,s//2), dtype=object)\n",
        "    reb[up_idx] = seed\n",
        "    reb = reb + reb.T\n",
        "    rebsymm = reb[::-1]\n",
        "    res = np.block([[reb,np.flip(rebsymm)],[rebsymm,np.flip(reb)]])\n",
        "\n",
        "    return res"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylpy_BCw6jxF"
      },
      "source": [
        "### Construccion de dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Version sincrónica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "from typing import Literal\n",
        "\n",
        "# Config\n",
        "#num_samples = 1500\n",
        "gpu_batch_size = 512 # 256\n",
        "en_batch = [np.arange(0, basis.m) - basis.m//2 + 1/2 for _ in range(0,gpu_batch_size)] \n",
        "en_batch = tf.constant(en_batch, dtype=tf.float32)\n",
        "energy_batch = en_batch\n",
        "\n",
        "# Beta\n",
        "beta = 1\n",
        "\n",
        "# Construccion de parametros y matrices auxiliares\n",
        "#rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "rho2kkbar_size = basis.m\n",
        "input_shape = (basis.m,basis.m, 1) # Usando rho2kkbar como input batcheado\n",
        "fund_size = basis.size\n",
        "hamil_base_size = basis.d*(basis.d+1)//2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_1_arrays_tf = tf.constant(rho_1_arrays, dtype=tf.float32)\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "rho_2_arrays_kkbar = rho_2_kkbar_gen(t_basis, rho_2_arrays)\n",
        "rho_2_arrays_kkbar_tf = tf.constant(rho_2_arrays_kkbar, dtype=tf.float32)\n",
        "k_indices = get_kkbar_indices(t_basis)\n",
        "k_indices_tf = gen_update_indices(t_basis, gpu_batch_size)\n",
        "\n",
        "\n",
        "# Generación de dataset (params)\n",
        "# h_type = {const, gaussian, random}: const = proporcional a ones, gaussian = proporcional a mat gaussiana, random = full random \n",
        "# g_init, g_stop: rango de Gs (aplica a los 3 casos)\n",
        "# state_type = {thermal, gs}: tipo de estado (térmico o funalmental)\n",
        "# input_type = {rho2, rho1}: tipo de feature a calcular\n",
        "valid_h_type = Literal['const', 'gaussian', 'vect', 'gaussvect', 'random', 'vectnosymm', 'randomsymm', 'randomenerg']\n",
        "valid_state_type = Literal['thermal', 'gs']\n",
        "valid_input_type = Literal['rho2', 'rho1', 'rho1+rho2']\n",
        "\n",
        "# Funciones auxiliares\n",
        "indices = tf.abs(tf.range(basis.m)[:, tf.newaxis] - tf.range(basis.m))\n",
        "def gather_elements(x):\n",
        "    return tf.gather(x, indices)\n",
        "\n",
        "def gen_dataset(h_type: valid_h_type, g_init: float, g_stop: float, state_type: valid_state_type, input_type: valid_input_type, include_energy: bool, num_samples = 100000, arb = False, ph = 1):\n",
        "    print(tf.test.gpu_device_name())\n",
        "    datasets = []\n",
        "    for i in tqdm(range(num_samples//gpu_batch_size+1)):\n",
        "        size = basis.m*(basis.m+1)//2\n",
        "        # En una primera versión vamos a pasar una mat proporcional a range(0,m) para energias (DEFINIDO EN CONFIG)\n",
        "\n",
        "        ## Caso G proporcional a ones\n",
        "        if h_type == 'const':\n",
        "            label_size = 1 \n",
        "            h_labels = [np.random.uniform(g_init, g_stop) for _ in range(0,gpu_batch_size)]\n",
        "            g_arr = [np.ones((basis.m, basis.m))*g_seed for g_seed in h_labels]\n",
        "            g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "\n",
        "        ## Caso generico\n",
        "        elif h_type == 'random':\n",
        "            label_size = basis.m*(basis.m-1)// 2  # CASO GENERICO elementos independientes de una mat de m x m sin diagonal\n",
        "            h_labels = [np.random.uniform(g_init, g_stop, label_size) for _ in range(0,gpu_batch_size)] \n",
        "            # Construimos la mat G\n",
        "            g_arr = gen_random_arr(h_labels)\n",
        "            h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "\n",
        "        elif h_type == 'randomsymm':\n",
        "            label_size = len(np.triu_indices(basis.m//2, 1)[0])\n",
        "            g_arr = [random_fermi_arr(g_init, g_stop) for _ in range(gpu_batch_size)]\n",
        "            # Ahora extraemos los labels\n",
        "            up_idx = np.triu_indices(basis.m//2, 1)\n",
        "            h_labels = [mat[up_idx] for mat in g_arr]\n",
        "            h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "\n",
        "        elif h_type == 'vect':\n",
        "            symmetry = True # Necesario para la invesión de BCS\n",
        "            label_size = basis.m // 2 - 1 \n",
        "            #labels_gen = lambda x: np.sort(np.random.uniform(g_init, g_stop, basis.m // 2 - 1))[::-1]\n",
        "            labels_gen = lambda x: np.random.uniform(g_init, g_stop, basis.m // 2 - 1)\n",
        "            h_labels = [np.insert(labels_gen(0), 0, 0) for _ in range(0, gpu_batch_size)] # OJO CON EL DIAGONAL!\n",
        "            indices = np.abs(np.arange(basis.m)[:, np.newaxis] - np.arange(basis.m))\n",
        "            g_arr = [np.repeat(x,2)[indices] if symmetry else x[indices] for x in h_labels] \n",
        "            h_labels = [x[1:] for x in h_labels] # removemos el 0 agregado por el termino diagonal\n",
        "            h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "            g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "        elif h_type == 'vectnosymm':\n",
        "            label_size = basis.m - 1 \n",
        "            labels_gen = lambda x: np.sort(np.random.uniform(g_init, g_stop, basis.m - 1))[::-1]\n",
        "            h_labels = [np.insert(labels_gen(0), 0, 0) for _ in range(0, gpu_batch_size)] # OJO CON EL DIAGONAL!\n",
        "            indices = np.abs(np.arange(basis.m)[:, np.newaxis] - np.arange(basis.m))\n",
        "            g_arr = [x[indices] for x in h_labels] \n",
        "            h_labels = [x[1:] for x in h_labels] # removemos el 0 agregado por el termino diagonal\n",
        "            h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "            g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "        ## Caso reducido\n",
        "        elif h_type == 'gaussian':\n",
        "            label_size = 2\n",
        "            h_labels = np.array([[np.random.uniform(g_init, g_stop), np.random.random()*10 + 0.1] for _ in range(0, gpu_batch_size)])\n",
        "            g_arr = gen_gauss_mat_np(h_labels[:,0], h_labels[:,1], basis.m)\n",
        "            h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "            g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "        elif h_type == 'gaussvect':\n",
        "            label_size = 2\n",
        "            h_labels = np.array([[np.random.uniform(g_init, g_stop), np.random.random()*2 + 0.1] for _ in range(0, gpu_batch_size)])\n",
        "            vect_arr = gen_gauss_plus_vect(h_labels[:,0], h_labels[:,1], basis.m)\n",
        "            indices = np.abs(np.arange(basis.m)[:, np.newaxis] - np.arange(basis.m))\n",
        "            g_arr = [np.repeat(x,2)[indices] for x in vect_arr]\n",
        "            g_arr = [g_arr[k] - np.diag(np.diag(g_arr[k])) for k in range(gpu_batch_size)]\n",
        "            h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "            g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "\n",
        "        # HAMILTONIANOS GENERALES\n",
        "        elif h_type == 'randomenerg':\n",
        "            # Energias\n",
        "            label_size_en = 2*basis.m\n",
        "            en_batch = np.random.uniform(g_init*ph, g_stop*ph,(gpu_batch_size, label_size_en))\n",
        "            en_batch = tf.constant(en_batch, dtype=tf.float32)\n",
        "            h_labels_en = en_batch\n",
        "            # Interacción\n",
        "            label_size_int = t_basis.size * (t_basis.size + 1)//2\n",
        "            h_labels_int = np.random.uniform(g_init, g_stop,(gpu_batch_size, label_size_int))\n",
        "            h_labels_int = np.zeros((gpu_batch_size, label_size_int))\n",
        "            g_arr = tf.constant(h_labels_int, dtype=tf.float32)\n",
        "            # Combinamos\n",
        "            #label_size = label_size_en + label_size_int\n",
        "            #h_labels = tf.concat([h_labels_en, h_labels_int], axis=-1)\n",
        "            h_labels = h_labels_en\n",
        "            label_size = label_size_en\n",
        "\n",
        "        else:\n",
        "            raise ValueError\n",
        "        \n",
        "        # Construimos los hamiltonianos basados en g_arr\n",
        "        if not arb:\n",
        "            h_arr = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, g_arr, rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "        else:\n",
        "            h_arr = two_body_hamiltonian_tf_arb(t_basis, basis.m, en_batch, g_arr, rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "\n",
        "        # Calculamos los estados\n",
        "        if state_type == 'thermal':\n",
        "            state = thermal_state_tf(h_arr*beta) \n",
        "            state = tf.cast(state, dtype=tf.float32)\n",
        "        else:\n",
        "            state = pure_state(h_arr)\n",
        "        \n",
        "        # Calculamos la feature\n",
        "        if input_type == 'rho2':\n",
        "            rho_input = rho_2_tf(state, rho_2_arrays_kkbar_tf) \n",
        "        elif input_type == 'rho1+rho2':\n",
        "            rho_2_input = rho_2_tf(state, rho_2_arrays_tf) # ! CAMBIAR POR rho_2_arrays_kkbar_tf SI ES RHO2KKBAR\n",
        "            rho_1_input = rho_1_tf(state, rho_1_arrays_tf) \n",
        "        else:\n",
        "            rho_input = rho_1_tf(state, rho_1_arrays_tf)\n",
        "        \n",
        "        # Calculamos la enegia\n",
        "        if include_energy:\n",
        "            energy = state_energy(state, h_arr)\n",
        "\n",
        "        # OUTPUTS\n",
        "        # Caso input eigvals\n",
        "        #input_shape = (basis.m, 1)\n",
        "        #rho_2_input = tf.linalg.eigvals(rho_2_input)\n",
        "        #rho_2_input = tf.sort(tf.math.real(rho_2_input), axis=-1)\n",
        "\n",
        "        # Caso PCA\n",
        "        #input_shape = (num_gen, 1)\n",
        "        #rflat = np.array([np.ndarray.flatten(x) for x in rho_2_input.numpy()])\n",
        "        #rho_2_input = np.dot(rflat, P)\n",
        "\n",
        "        # Generación de dataset\n",
        "        # Tradicional (rho2 tipo matricial)\n",
        "        if input_type == 'rho1' or input_type == 'rho2':\n",
        "            if include_energy:\n",
        "                datasets.append(tf.data.Dataset.from_tensor_slices(((rho_input, energy), h_labels)))\n",
        "            else:\n",
        "                datasets.append(tf.data.Dataset.from_tensor_slices(((rho_input), h_labels)))\n",
        "        else:\n",
        "            datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input, energy), h_labels)))\n",
        "        # Rho2 flatteneada, requerido para DF\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((tf.reshape(rho_2_input, (gpu_batch_size,basis.m*basis.m))), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input, state), h_labels)))\n",
        "    ds = tf.data.Dataset.from_tensor_slices(datasets)\n",
        "    dataset = ds.interleave(\n",
        "        lambda x: x,\n",
        "        cycle_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "\n",
        "    return dataset, label_size\n",
        "\n",
        "\n",
        "#batch_size = 32\n",
        "#dataset = dataset.shuffle(buffer_size=num_samples).batch(batch_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Filleo de dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "8moZIlfabZuy"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Dividimos los datasets\\ntrain_size = int(0.8 * num_samples)\\n\\ntrain_dataset = dataset.take(train_size)\\nval_dataset = dataset.skip(train_size)\\n\\n\\nbatch_size = gpu_batch_size\\ntrain_dataset = train_dataset.batch(batch_size)\\nval_dataset = val_dataset.batch(batch_size)\\n\\n#beta_val = beta_input[train_size:]\\n'"
            ]
          },
          "execution_count": 102,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Dividimos los datasets\n",
        "train_size = int(0.8 * num_samples)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "\n",
        "batch_size = gpu_batch_size\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "#beta_val = beta_input[train_size:]\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\nval_size = tf.data.experimental.cardinality(val_dataset).numpy()\\nprint(\"Validation Dataset Size:\", val_size)\\n'"
            ]
          },
          "execution_count": 103,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Cardinality no funciona con los datasets generados por GPU\n",
        "\"\"\"\n",
        "val_size = tf.data.experimental.cardinality(val_dataset).numpy()\n",
        "print(\"Validation Dataset Size:\", val_size)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Correr una vez para definir la transformacion y lyego volver a correr la gen de dataset\\nnum_gen = 10\\nrflat = np.array([np.ndarray.flatten(x) for x in rho_input.numpy()])\\nrflat = rflat - rflat.mean()\\nrflat = rflat / rflat.std()\\nU, S, Vh = np.linalg.svd(rflat)\\nprint(S)\\n\\n# Determinado automáticamente\\nnum_gen = np.where(S < 0.1)[0][0]\\nprint(num_gen)\\n\\nZ = np.dot(rflat.T, rflat)\\neigenvalues, eigenvectors = np.linalg.eig(Z)\\nD = np.diag(eigenvalues)\\nP = eigenvectors[:,0:num_gen]\\nZ_new = np.dot(Z, P)\\nZ_new.shape\\n'"
            ]
          },
          "execution_count": 104,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PCA\n",
        "\"\"\"\n",
        "# Correr una vez para definir la transformacion y lyego volver a correr la gen de dataset\n",
        "num_gen = 10\n",
        "rflat = np.array([np.ndarray.flatten(x) for x in rho_input.numpy()])\n",
        "rflat = rflat - rflat.mean()\n",
        "rflat = rflat / rflat.std()\n",
        "U, S, Vh = np.linalg.svd(rflat)\n",
        "print(S)\n",
        "\n",
        "# Determinado automáticamente\n",
        "num_gen = np.where(S < 0.1)[0][0]\n",
        "print(num_gen)\n",
        "\n",
        "Z = np.dot(rflat.T, rflat)\n",
        "eigenvalues, eigenvectors = np.linalg.eig(Z)\n",
        "D = np.diag(eigenvalues)\n",
        "P = eigenvectors[:,0:num_gen]\n",
        "Z_new = np.dot(Z, P)\n",
        "Z_new.shape\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## DNN y CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYEEjNB-7b8y"
      },
      "source": [
        "### Definición de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gen_dnn_model(label_size, input_type, include_energy: bool, res = 1):\n",
        "    if input_type == 'rho1':\n",
        "        rho_layer =  tf.keras.layers.Input(shape=(basis.d, basis.d, 1), name='rho')\n",
        "    elif input_type == 'rho2':\n",
        "        rho_layer =  tf.keras.layers.Input(shape=(basis.m, basis.m, 1), name='rho')\n",
        "    else:\n",
        "        rho_1_layer =  tf.keras.layers.Input(shape=(basis.d, basis.d, 1), name='rho1')\n",
        "        rho_2_layer =  tf.keras.layers.Input(shape=(t_basis.size, t_basis.size, 1), name='rho2')\n",
        "\n",
        "    if include_energy:\n",
        "        energy_layer = tf.keras.layers.Input(shape=(1, ), name='energy')\n",
        "\n",
        "    if input_type == 'rho1' or input_type == 'rho2':\n",
        "        flatten_rho = tf.keras.layers.Flatten()(rho_layer)\n",
        "        #flatten_rho2 = tf.keras.layers.BatchNormalization()(flatten_rho2)\n",
        "        if include_energy:\n",
        "            dense1 = tf.keras.layers.concatenate([flatten_rho, energy_layer]) \n",
        "        else:\n",
        "            dense1 = tf.keras.layers.concatenate([flatten_rho]) \n",
        "    else:\n",
        "        flatten_rho_1 = tf.keras.layers.Flatten()(rho_1_layer)\n",
        "        flatten_rho_2 = tf.keras.layers.Flatten()(rho_2_layer)\n",
        "        #flatten_rho2 = tf.keras.layers.BatchNormalization()(flatten_rho2)\n",
        "        dense1 = tf.keras.layers.concatenate([flatten_rho_1, flatten_rho_2, energy_layer])    \n",
        "\n",
        "    local_size = label_size\n",
        "    l = 4 + (res-1)\n",
        "    layer_s = [64//i*2 * res for i in reversed(range(1,l))]\n",
        "    for i in range(0,l-1):\n",
        "        dense1 = tf.keras.layers.Dense(layer_s[i], activation='sigmoid')(dense1)\n",
        "        #dense1 = tf.keras.layers.Dense(layer_s[i], activation='sigmoid', kernel_regularizer=tf.keras.regularizers.L1(0.001))(dense1)\n",
        "        #dense1 = tf.keras.layers.Dropout(0.1)(dense1)\n",
        "\n",
        "    output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "    if input_type == 'rho1' or input_type == 'rho2':\n",
        "        if include_energy:\n",
        "            model = tf.keras.models.Model(inputs=[rho_layer, energy_layer], outputs=output)\n",
        "        else:\n",
        "            model = tf.keras.models.Model(inputs=[rho_layer], outputs=output)\n",
        "    else:\n",
        "        model = tf.keras.models.Model(inputs=[rho_1_layer, rho_2_layer, energy_layer], outputs=output)\n",
        "\n",
        "    model.summary()\n",
        "    \n",
        "    return model\n",
        "\n",
        "# NOT SUPPORTED FOR RHO1+RHO2\n",
        "def gen_cnn_model(label_size, input_type, include_energy: bool, res = 1):\n",
        "    if input_type == 'rho1':\n",
        "        rho_layer =  tf.keras.layers.Input(shape=(basis.d, basis.d, 1), name='rho')\n",
        "    elif input_type == 'rho2':\n",
        "        rho_layer =  tf.keras.layers.Input(shape=(basis.m, basis.m, 1), name='rho')\n",
        "    else:\n",
        "        rho_1_layer =  tf.keras.layers.Input(shape=(basis.d, basis.d, 1), name='rho1')\n",
        "        rho_layer =  tf.keras.layers.Input(shape=(t_basis.size, t_basis.size, 1), name='rho2')\n",
        "\n",
        "    if include_energy:\n",
        "        energy_layer = tf.keras.layers.Input(shape=(1, ), name='energy')\n",
        "\n",
        "    # CNN\n",
        "    # Factor de cantidad de filtros\n",
        "    lf = 2 * res\n",
        "    conv_limit = 2\n",
        "    fs = 1\n",
        "    conv_rho = tf.keras.layers.Conv2D(lf*2**conv_limit, (2*fs, 2*fs), activation='relu')(rho_layer)\n",
        "    #conv_rho = tf.keras.layers.BatchNormalization()(conv_rho)\n",
        "    for j in [(2**conv_limit - 2**k) for k in range(1,conv_limit)]:\n",
        "        conv_rho = tf.keras.layers.Conv2D(lf*j, (2*fs, 2*fs), activation='relu')(conv_rho)\n",
        "        #conv_rho = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(conv_rho)\n",
        "\n",
        "        #conv_rho = tf.keras.layers.BatchNormalization()(conv_rho)\n",
        "    \n",
        "    # A rho1, en el caso 1+2 solo le aplicamos un filtro, porque es muy chica. Luego concatenamos\n",
        "    if input_type == 'rho1+rho2':\n",
        "        conv_rho1 = tf.keras.layers.Conv2D(lf*2**conv_limit, (2*fs, 2*fs), activation='relu')(rho_1_layer)\n",
        "        conv_rho1 = tf.keras.layers.MaxPool2D(pool_size=(2, 2))(conv_rho1)\n",
        "        flatten_rho = tf.keras.layers.Flatten()(conv_rho)\n",
        "        flatten_rho_1 = tf.keras.layers.Flatten()(conv_rho1)\n",
        "        flatten_rho = tf.keras.layers.concatenate([flatten_rho, flatten_rho_1])\n",
        "\n",
        "    else:\n",
        "        flatten_rho = tf.keras.layers.Flatten()(conv_rho)\n",
        "\n",
        "    # DNN\n",
        "    #flatten_rho = tf.keras.layers.BatchNormalization()(flatten_rho)\n",
        "    if include_energy:\n",
        "        dense1 = tf.keras.layers.concatenate([flatten_rho, energy_layer]) \n",
        "    else:\n",
        "        dense1 = tf.keras.layers.concatenate([flatten_rho]) \n",
        "\n",
        "    local_size = label_size\n",
        "    l = 2 \n",
        "    layer_s = [32//i*2 * res for i in reversed(range(1,l))]\n",
        "    for i in range(0,l-1):\n",
        "        dense1 = tf.keras.layers.Dense(layer_s[i], activation='relu')(dense1)\n",
        "        #dense1 = tf.keras.layers.Dense(layer_s[i], activation='sigmoid', kernel_regularizer=tf.keras.regularizers.L1(0.001))(dense1)\n",
        "        #dense1 = tf.keras.layers.Dropout(0.1)(dense1)\n",
        "\n",
        "    output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "    \n",
        "    if include_energy and input_type != 'rho1+rho2':\n",
        "        model = tf.keras.models.Model(inputs=[rho_layer, energy_layer], outputs=output)\n",
        "    elif input_type == 'rho1+rho2' and include_energy:\n",
        "        model = tf.keras.models.Model(inputs=[rho_1_layer, rho_layer, energy_layer], outputs=output)\n",
        "    else:\n",
        "        model = tf.keras.models.Model(inputs=[rho_layer], outputs=output)\n",
        "    model.summary()\n",
        "\n",
        "\n",
        "    return model\n",
        "    \n",
        "\n",
        "\n",
        "# Custom loss functions\n",
        "def base_vec_to_h(h_labels):\n",
        "    #h_labels = tf.stack(h_labels)\n",
        "    g_arr = tf.map_fn(gather_elements, h_labels) # Construyo la matrix g desde los labels\n",
        "    h_arr = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, g_arr, rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "\n",
        "    return h_arr\n",
        "\n",
        "def base_vect_loss(base_pred, base_true):\n",
        "    h_true = base_vec_to_h(base_true)\n",
        "    h_pred = base_vec_to_h(base_pred)\n",
        "    return tf.math.reduce_mean(tf.norm(h_pred - h_true, axis=(-2,-1), ord='fro'))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWk9piJtNIZ"
      },
      "source": [
        "### Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhJCHf0fQdRl",
        "outputId": "1821cf27-9ff5-4d67-e9f5-956d20eda5e2"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam, Lion\n",
        "\n",
        "def dnn_fit(dataset, label_size, input_type, include_energy, cnn = True, loss = 'MSE', num_epochs = 50, res = 1):\n",
        "    if cnn:\n",
        "        model = gen_cnn_model(label_size, input_type, include_energy, res = res)\n",
        "    else:\n",
        "        model = gen_dnn_model(label_size, input_type, include_energy, res = res)\n",
        "\n",
        "    # Dividimos los datasets\n",
        "    train_size = int(0.8 * num_samples)\n",
        "\n",
        "    train_dataset = dataset.take(train_size)\n",
        "    val_dataset = dataset.skip(train_size)\n",
        "    \n",
        "    batch_size = gpu_batch_size//2\n",
        "    train_dataset = train_dataset.batch(batch_size)\n",
        "    val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(optimizer=Adam(),\n",
        "                loss=loss,\n",
        "                metrics=['accuracy', 'mean_squared_error'])\n",
        "\n",
        "    # Train the model\n",
        "    device_name = tf.test.gpu_device_name()\n",
        "\n",
        "    with tf.device('/gpu:0'):\n",
        "        history = model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)\n",
        "        #history = model.fit(train_dataset, epochs=num_epochs)\n",
        "\n",
        "    return model, val_dataset, history"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "cvpE_X1iTXcB",
        "outputId": "eff0e5f5-5b26-46ea-ec6b-491d1de9944c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "\"\\nimport matplotlib.pyplot as plt\\n#plt.plot(history.history['accuracy'], label='Training Accuracy')\\n#plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\\nplt.plot(history.history['mean_squared_error'][75:], label='Training MSE')\\nplt.plot(history.history['val_mean_squared_error'][75:], label='Validation MSE')\\n\\nplt.xlabel('Epoch')\\nplt.ylabel('MSE')\\nplt.title('MSE vs. Epoch')\\nplt.legend()\\nplt.show()\\n\\n# MIN LOSS = 0.0128 c/fund 50epochs MSE\\n##         = 0.0118 s/fund 50epochs MSE\\n##         = 0.0039 s/fund 50epochs MSE m=4 d=6\\n\\n\""
            ]
          },
          "execution_count": 107,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history.history['mean_squared_error'][75:], label='Training MSE')\n",
        "plt.plot(history.history['val_mean_squared_error'][75:], label='Validation MSE')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs. Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# MIN LOSS = 0.0128 c/fund 50epochs MSE\n",
        "##         = 0.0118 s/fund 50epochs MSE\n",
        "##         = 0.0039 s/fund 50epochs MSE m=4 d=6\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRlZuRUNa6Yb",
        "outputId": "85850559-311b-4cf4-ea5b-465a9ee8a7af"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\n# Assuming you have a validation dataset (val_dataset)\\niterador = iter(val_dataset)\\nsample = next(iterador)\\nnext_sample = next(iterador)\\ninput_data = sample[0]  # Assuming your dataset provides input data as the first element\\nactual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\\n\\n# Predict using the model\\npredictions = model.predict(input_data)\\n\\n#mean_squared_error(predictions, actual_values)\\n'"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "# Assuming you have a validation dataset (val_dataset)\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "next_sample = next(iterador)\n",
        "input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "actual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(input_data)\n",
        "\n",
        "#mean_squared_error(predictions, actual_values)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Diferencias en error RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "def dnn_error_coef(model, val_dataset):\n",
        "    # Assuming you have a validation dataset (val_dataset)\n",
        "    iterador = iter(val_dataset)\n",
        "    sample = next(iterador)\n",
        "    next_sample = next(iterador)\n",
        "    input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "    actual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\n",
        "\n",
        "    # Predict using the model\n",
        "    predictions = model.predict(input_data)\n",
        "\n",
        "    #mean_squared_error(predictions, actual_values)\n",
        "\n",
        "    # Vemos algunos valores\n",
        "    for e in val_dataset:\n",
        "        for i in range(0, 4):\n",
        "            print(e[1][i])\n",
        "            print(predictions[i])\n",
        "        break\n",
        "        \n",
        "    # Veamos el MSE de los valores de G      \n",
        "    #RMSE_pred = mean_squared_error(actual_values, predictions, squared=False)\n",
        "    #RMSE_rand = mean_squared_error(actual_values, next_sample[1], squared=False)\n",
        "    #print(RMSE_pred, RMSE_rand)\n",
        "    #rint(RMSE_rand/RMSE_pred)\n",
        "    # Veamos los errores en términos de MSE\n",
        "    if predictions.shape[1] == 1:\n",
        "        norm_pred = np.mean(np.abs(predictions.T-actual_values))\n",
        "        norm_rand = np.mean(np.abs(next_sample[1]-actual_values))\n",
        "    else:\n",
        "        norm_pred = np.mean(np.linalg.norm(predictions-actual_values,ord=2, axis=1))\n",
        "        norm_rand = np.mean(np.linalg.norm(next_sample[1]-actual_values,ord=2, axis=1))\n",
        "    print(norm_pred, norm_rand)\n",
        "    print(norm_rand / norm_pred)\n",
        "    # Veamos los errores en norma 2\n",
        "    if predictions.shape[1] == basis.m: # caso vectorial\n",
        "        norm_pred = base_vect_loss(predictions, actual_values)\n",
        "        norm_rand = base_vect_loss(next_sample[1], actual_values)\n",
        "    print(norm_pred, norm_rand)\n",
        "    print(norm_rand / norm_pred)\n",
        "\n",
        "    return(norm_rand / norm_pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\\niterador = iter(val_dataset)\\nsample = next(iterador)\\nnext_sample = next(iterador)\\ninput_data = sample[0]  # Assuming your dataset provides input data as the first element\\nactual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\\n\\n# Predict using the model\\npredictions = model.predict(input_data)\\npredictions.shape\\n'"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\"\"\"\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "next_sample = next(iterador)\n",
        "input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "actual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(input_data)\n",
        "predictions.shape\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Análisis rho2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reconstruye rho a partir de G\n",
        "# Codigo medio copiado de gen_dataset, not good\n",
        "def rho_reconstruction_tf(g_arr, h_type, state_type):\n",
        "    size = basis.m*(basis.m+1)//2\n",
        "    h_labels = g_arr\n",
        "    # A partir de aca es todo igual, salvo la parte de generación random\n",
        "\n",
        "    ## Caso G proporcional a ones\n",
        "    if h_type == 'const':\n",
        "        label_size = 1 \n",
        "        g_arr = [np.ones((basis.m, basis.m))*g_seed for g_seed in h_labels]\n",
        "        g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "    ## Caso generico\n",
        "    elif h_type == 'random':\n",
        "        label_size = basis.m*(basis.m+1)// 2 # CASO GENERICO elementos independientes de una mat de m x m\n",
        "        # Construimos la mat G\n",
        "        triag = tfp.math.fill_triangular(h_labels, upper=True)\n",
        "        g_arr = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "\n",
        "    elif h_type == 'vect':\n",
        "        symmetry = True # Necesario para la invesión de BCS\n",
        "        indices = np.abs(np.arange(basis.m)[:, np.newaxis] - np.arange(basis.m))\n",
        "        g_arr = [np.repeat(x,2)[indices] if symmetry else x[indices] for x in h_labels]\n",
        "        h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "        g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "    ## Caso reducido\n",
        "    elif h_type == 'gaussian':\n",
        "        g_arr = gen_gauss_mat_np(h_labels[:,0], h_labels[:,1], basis.m)\n",
        "        h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "        g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "    elif h_type == 'gaussvect':\n",
        "        label_size = 2\n",
        "        vect_arr = gen_gauss_plus_vect(h_labels[:,0], h_labels[:,1], basis.m)\n",
        "        indices = np.abs(np.arange(basis.m)[:, np.newaxis] - np.arange(basis.m))\n",
        "        g_arr = [np.repeat(x,2)[indices] for x in vect_arr]\n",
        "        g_arr = [g_arr[k] - np.diag(np.diag(g_arr[k])) for k in range(gpu_batch_size)]\n",
        "        h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "        g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    # Construimos los hamiltonianos basados en g_arr\n",
        "    h_arr = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, g_arr, rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "\n",
        "    # Calculamos los estados\n",
        "    if state_type == 'thermal':\n",
        "        state = thermal_state_tf(h_arr*beta) \n",
        "        state = tf.cast(state, dtype=tf.float32)\n",
        "    else:\n",
        "        state = pure_state(h_arr)\n",
        "\n",
        "    rho_input = rho_2_tf(state, rho_2_arrays_kkbar_tf)\n",
        "    \n",
        "    return rho_input\n",
        "\n",
        "# Vemos algunos valores\n",
        "def dnn_rho_reconstruction_error(model, val_dataset, h_type, state_type):\n",
        "    iterador = iter(val_dataset)\n",
        "    sample = next(iterador)\n",
        "    next_sample = next(iterador)\n",
        "    input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "    actual_values = sample[1].numpy()\n",
        "    predictions = model.predict(input_data)\n",
        "\n",
        "    # Calculamos los rho\n",
        "    rho_pred = rho_reconstruction_tf(predictions, h_type, state_type)\n",
        "    rho_true = rho_reconstruction_tf(actual_values, h_type, state_type)\n",
        "    rho_rand = rho_reconstruction_tf(next_sample[1].numpy(), h_type, state_type)\n",
        "\n",
        "    \n",
        "    rho_2_s = lambda x: np.sort(np.linalg.eigvals(x))\n",
        "\n",
        "    # Analisis RMSE\n",
        "    #RMSE_pred = mean_squared_error(rho_2_true, rho_2_pred, squared=False)\n",
        "    #RMSE_rand = mean_squared_error(rho_2_true, rho_2_rand, squared=False)\n",
        "    #print(RMSE_pred, RMSE_rand)\n",
        "    #print(RMSE_rand/RMSE_pred)\n",
        "    # Printeamos algunos valores\n",
        "    for i in range(0, 2):\n",
        "        print(\"true: \" + str(rho_2_s(rho_true[i])))\n",
        "        print(\"pred: \" + str(rho_2_s(rho_pred[i])))\n",
        "\n",
        "    print(rho_true, rho_pred)\n",
        "    norm_pred = np.mean(np.linalg.norm(rho_true-rho_pred, axis=(1,2)))\n",
        "    norm_rand = np.mean(np.linalg.norm(rho_true-rho_rand, axis=(1,2)))\n",
        "    print(norm_pred, norm_rand)\n",
        "    print(norm_rand / norm_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Main exe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 115,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 14:57:41.600849: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 7813/7813 [07:18<00:00, 17.83it/s]\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_14\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"functional_14\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)        </span>┃<span style=\"font-weight: bold\"> Output Shape      </span>┃<span style=\"font-weight: bold\">    Param # </span>┃<span style=\"font-weight: bold\"> Connected to      </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ rho (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_22 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)  │         <span style=\"color: #00af00; text-decoration-color: #00af00\">80</span> │ rho[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_23 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)   │        <span style=\"color: #00af00; text-decoration-color: #00af00\">520</span> │ conv2d_22[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_14          │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">288</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ conv2d_23[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ energy (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>) │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">289</span>)       │          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │ flatten_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       │                   │            │ energy[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_51 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       │     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,120</span> │ concatenate_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_52 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)         │      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,032</span> │ dense_51[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━┩\n",
              "│ rho (\u001b[38;5;33mInputLayer\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m1\u001b[0m)   │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_22 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m16\u001b[0m)  │         \u001b[38;5;34m80\u001b[0m │ rho[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ conv2d_23 (\u001b[38;5;33mConv2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m8\u001b[0m)   │        \u001b[38;5;34m520\u001b[0m │ conv2d_22[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ flatten_14          │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m288\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ conv2d_23[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   │\n",
              "│ (\u001b[38;5;33mFlatten\u001b[0m)           │                   │            │                   │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ energy (\u001b[38;5;33mInputLayer\u001b[0m) │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)         │          \u001b[38;5;34m0\u001b[0m │ -                 │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ concatenate_14      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m289\u001b[0m)       │          \u001b[38;5;34m0\u001b[0m │ flatten_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], │\n",
              "│ (\u001b[38;5;33mConcatenate\u001b[0m)       │                   │            │ energy[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_51 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       │     \u001b[38;5;34m37,120\u001b[0m │ concatenate_14[\u001b[38;5;34m0\u001b[0m… │\n",
              "├─────────────────────┼───────────────────┼────────────┼───────────────────┤\n",
              "│ dense_52 (\u001b[38;5;33mDense\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m)         │      \u001b[38;5;34m1,032\u001b[0m │ dense_51[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    │\n",
              "└─────────────────────┴───────────────────┴────────────┴───────────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,752</span> (151.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m38,752\u001b[0m (151.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">38,752</span> (151.38 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m38,752\u001b[0m (151.38 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:05:00.441890: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2021] Created device /device:GPU:0 with 38364 MB memory:  -> device: 0, name: NVIDIA A100-SXM4-40GB, pci bus id: 0000:00:04.0, compute capability: 8.0\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  12486/Unknown \u001b[1m23s\u001b[0m 2ms/step - accuracy: 0.9030 - loss: 0.0080 - mean_squared_error: 0.0080"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:05:23.133911: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n",
            "\t [[{{node IteratorGetNext}}]]\n",
            "\t [[IteratorGetNext/_4]]\n",
            "2024-09-13 15:05:23.133977: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:05:23.133985: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:05:23.134001: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 4ms/step - accuracy: 0.9031 - loss: 0.0080 - mean_squared_error: 0.0080 - val_accuracy: 0.9895 - val_loss: 2.6872e-05 - val_mean_squared_error: 2.6872e-05\n",
            "Epoch 2/10\n",
            "\u001b[1m   87/12500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9806 - loss: 4.5692e-05 - mean_squared_error: 4.5692e-05"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:05:47.070484: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:05:47.070574: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12472/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9851 - loss: 3.5626e-05 - mean_squared_error: 3.5626e-05"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:06:08.059146: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:06:08.059189: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:06:08.059207: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9851 - loss: 3.5617e-05 - mean_squared_error: 3.5617e-05 - val_accuracy: 0.9905 - val_loss: 2.1077e-05 - val_mean_squared_error: 2.1077e-05\n",
            "Epoch 3/10\n",
            "\u001b[1m   92/12500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9875 - loss: 2.2306e-05 - mean_squared_error: 2.2306e-05"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:06:31.938379: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:06:31.938426: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:06:31.938443: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9873 - loss: 2.1860e-05 - mean_squared_error: 2.1860e-05 - val_accuracy: 0.9914 - val_loss: 1.2836e-05 - val_mean_squared_error: 1.2836e-05\n",
            "Epoch 4/10\n",
            "\u001b[1m   91/12500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m20s\u001b[0m 2ms/step - accuracy: 0.9899 - loss: 1.5812e-05 - mean_squared_error: 1.5812e-05"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:07:16.582034: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:07:16.582090: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12495/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9890 - loss: 1.5997e-05 - mean_squared_error: 1.5997e-05"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:07:37.433833: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:07:37.433887: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:07:37.433903: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 4ms/step - accuracy: 0.9890 - loss: 1.5996e-05 - mean_squared_error: 1.5996e-05 - val_accuracy: 0.9915 - val_loss: 1.2794e-05 - val_mean_squared_error: 1.2794e-05\n",
            "Epoch 5/10\n",
            "\u001b[1m   90/12500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9906 - loss: 1.1124e-05 - mean_squared_error: 1.1124e-05"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:08:02.091435: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:08:02.091471: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:08:02.091488: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9902 - loss: 1.3452e-05 - mean_squared_error: 1.3452e-05 - val_accuracy: 0.9875 - val_loss: 1.5850e-05 - val_mean_squared_error: 1.5850e-05\n",
            "Epoch 6/10\n",
            "\u001b[1m   90/12500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9894 - loss: 1.1834e-05 - mean_squared_error: 1.1834e-05"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:08:47.091874: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:08:47.091929: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:08:47.091945: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12477/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9908 - loss: 1.1860e-05 - mean_squared_error: 1.1860e-05"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:09:07.997925: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9908 - loss: 1.1859e-05 - mean_squared_error: 1.1859e-05 - val_accuracy: 0.9908 - val_loss: 1.2255e-05 - val_mean_squared_error: 1.2255e-05\n",
            "Epoch 7/10\n",
            "\u001b[1m   88/12500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9922 - loss: 8.7597e-06 - mean_squared_error: 8.7597e-06"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:09:32.002201: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:09:32.002252: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:09:32.002275: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12483/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 1.0342e-05 - mean_squared_error: 1.0342e-05"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:09:53.233609: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:09:53.233652: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:09:53.233674: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9915 - loss: 1.0341e-05 - mean_squared_error: 1.0341e-05 - val_accuracy: 0.9950 - val_loss: 1.1252e-05 - val_mean_squared_error: 1.1252e-05\n",
            "Epoch 8/10\n",
            "\u001b[1m   88/12500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9915 - loss: 8.1207e-06 - mean_squared_error: 8.1207e-06"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:10:17.018167: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:10:17.018217: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:10:17.018235: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9916 - loss: 9.5984e-06 - mean_squared_error: 9.5984e-06 - val_accuracy: 0.9930 - val_loss: 9.4512e-06 - val_mean_squared_error: 9.4512e-06\n",
            "Epoch 9/10\n",
            "\u001b[1m   87/12500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m22s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 7.9184e-06 - mean_squared_error: 7.9184e-06"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:11:01.996968: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:11:01.997007: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:11:01.997025: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12493/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9917 - loss: 8.6795e-06 - mean_squared_error: 8.6795e-06"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:11:22.997436: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:11:22.997483: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9917 - loss: 8.6796e-06 - mean_squared_error: 8.6796e-06 - val_accuracy: 0.9916 - val_loss: 1.0775e-05 - val_mean_squared_error: 1.0775e-05\n",
            "Epoch 10/10\n",
            "\u001b[1m   88/12500\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m21s\u001b[0m 2ms/step - accuracy: 0.9911 - loss: 7.8072e-06 - mean_squared_error: 7.8072e-06"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:11:47.453692: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:11:47.453741: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:11:47.453758: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12481/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9920 - loss: 8.2470e-06 - mean_squared_error: 8.2470e-06"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:12:08.046175: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:12:08.046215: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:12:08.046232: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m12500/12500\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 4ms/step - accuracy: 0.9920 - loss: 8.2468e-06 - mean_squared_error: 8.2468e-06 - val_accuracy: 0.9943 - val_loss: 6.4138e-06 - val_mean_squared_error: 6.4138e-06\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-09-13 15:12:31.966055: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1778390060329220567\n",
            "2024-09-13 15:12:31.966100: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 1532323218746704801\n",
            "2024-09-13 15:12:31.966118: I tensorflow/core/framework/local_rendezvous.cc:423] Local rendezvous recv item cancelled. Key hash: 8212796265838466551\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step  \n",
            "tf.Tensor(\n",
            "[0.33941656 0.2502474  0.8977014  0.7289715  0.6536866  0.07336815\n",
            " 0.27329665 0.8931929 ], shape=(8,), dtype=float32)\n",
            "[0.33701992 0.25025547 0.89928675 0.72940445 0.65395486 0.07123034\n",
            " 0.27214032 0.89549905]\n",
            "tf.Tensor(\n",
            "[0.42579108 0.29362544 0.79103994 0.7657466  0.11485447 0.47395134\n",
            " 0.10669841 0.82615423], shape=(8,), dtype=float32)\n",
            "[0.4220258  0.29191458 0.7916852  0.7650021  0.11271292 0.4714067\n",
            " 0.10438433 0.8245086 ]\n",
            "tf.Tensor(\n",
            "[0.06950444 0.27810723 0.15811668 0.1908169  0.565189   0.6031968\n",
            " 0.59072435 0.20614223], shape=(8,), dtype=float32)\n",
            "[0.06823799 0.2755345  0.15644144 0.18787718 0.56213593 0.6003243\n",
            " 0.5871324  0.2040233 ]\n",
            "tf.Tensor(\n",
            "[0.44925472 0.99134046 0.32117292 0.14155838 0.7578348  0.19115658\n",
            " 0.49453583 0.52274394], shape=(8,), dtype=float32)\n",
            "[0.44509348 0.9865793  0.31966805 0.13968134 0.7554035  0.18798187\n",
            " 0.49185693 0.52169985]\n",
            "0.006298159 1.1286664\n",
            "179.20576\n",
            "0.006298159 1.1286664\n",
            "179.20576\n",
            "179.20576\n"
          ]
        }
      ],
      "source": [
        "num_samples = 4000000\n",
        "h_type = 'randomenerg'\n",
        "g_init = 0.01\n",
        "g_stop = 1\n",
        "state_type = 'thermal'\n",
        "input_type = 'rho1'\n",
        "include_energy = True\n",
        "cnn = True\n",
        "loss = 'MSE'\n",
        "num_epochs = 10\n",
        "arb = True # Usamos el hamiltoniano arbitrario? O 2 cuerpos?\n",
        "res = 2 # Resolución de la topología de la red (a mayor res, más parámetros)\n",
        "ph = 1 # Factor energía en randomenerg\n",
        "\n",
        "dataset, label_size = gen_dataset(h_type, g_init, g_stop, state_type, input_type, include_energy, num_samples, arb = arb, ph = ph)\n",
        "# DNN\n",
        "model, val_dataset, history = dnn_fit(dataset, label_size, input_type, include_energy, cnn = cnn, loss = loss, num_epochs = num_epochs, res = res)\n",
        "print(dnn_error_coef(model, val_dataset))\n",
        "#print(dnn_rho_reconstruction_error(model, val_dataset, h_type, state_type))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Comparación con BCS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Caso G = G"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "en_batch = [np.arange(0, basis.m) - basis.m//2 + 1/2 for _ in range(0,gpu_batch_size)]  # ojo si lo cambie en H\n",
        "en_batch = tf.constant(en_batch, dtype=tf.float32)\n",
        "\n",
        "energ = np.array(en_batch[0])\n",
        "e_mean = np.mean(energ)\n",
        "\n",
        "# Calcula rho2 ha partir del delta dado, en formato [delta]. Es por el optimize, perdon\n",
        "@nb.jit(nopython=True)\n",
        "def bcs_delta(delta: np.ndarray, m = basis.m):\n",
        "    delta = delta[0]\n",
        "\n",
        "    lambda_k = lambda k: np.sqrt((energ[k])**2 + delta**2)\n",
        "    f_k = lambda k: 1/2 * (1 - (energ[k])/lambda_k(k))\n",
        "    r_k = lambda k: delta/(2*lambda_k(k))\n",
        "   \n",
        "    rho = np.zeros((m, m))\n",
        "    for k in range(0, m):\n",
        "        for kp in range(0, m):\n",
        "            p = f_k(k)**2 if k == kp else 0.0\n",
        "            rho[k, kp] = r_k(k) * r_k(kp) + p\n",
        "\n",
        "    return rho \n",
        "        \n",
        "        \n",
        "# Calculamos g_BCS a partir de la rho2 calculada por BCS más cercana a rho dada\n",
        "def g_bcs(rho_init):\n",
        "    rho_dist = lambda x: np.linalg.norm(bcs_delta(x)-rho_init)\n",
        "    opti = scipy.optimize.minimize(rho_dist, 1, method='Nelder-Mead')\n",
        "    delta = opti.x\n",
        "    lambda_k = lambda k: np.sqrt((en_batch[0][k] - e_mean)**2 + delta**2)\n",
        "    G = 1/(np.sum([ 1/(2*lambda_k(x)) for x in range(0, basis.m)])) \n",
        "\n",
        "    return G\n",
        "\n",
        "# Cargamos elementos del conjunto de validación\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "input_data = sample[0]  \n",
        "actual_values = sample[1]\n",
        "predictions = model.predict(input_data)\n",
        "\n",
        "# Ordenamos los valores de G con el fin de plotear\n",
        "g_ids = actual_values.numpy().argsort()\n",
        "predictions_sort = predictions[g_ids]\n",
        "g_true_sort = actual_values.numpy()[g_ids]\n",
        "\n",
        "predictions_sort = predictions_sort.T[0]\n",
        "rho_pred = rho_reconstruction_tf(predictions_sort, h_type, state_type)\n",
        "\n",
        "# Calculamos ahora G BCS\n",
        "rho_actual = rho_reconstruction_tf(actual_values.numpy()[g_ids], h_type, state_type)\n",
        "g_bcs_sort = [g_bcs(x) for x in rho_actual.numpy()]\n",
        "rho_bcs = rho_reconstruction_tf(g_bcs_sort, h_type, state_type)\n",
        "\n",
        "rho_error = lambda x: np.linalg.norm(rho_actual.numpy()-x, ord=2, axis=(1,2))\n",
        "\n",
        "plt.rcParams['axes.labelsize'] = 16\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "plt.rcParams['legend.fontsize'] = 16\n",
        "plt.rcParams['axes.linewidth'] = 1.5\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "\n",
        "plt.plot(g_true_sort, rho_error(rho_pred), label='CNN')\n",
        "plt.plot(g_true_sort, rho_error(rho_bcs), label='BCS')\n",
        "\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"G\")\n",
        "plt.ylabel(r\"Error de reconstrucción $\\rho^{(2)}$\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bcs_deltak_rho(delta_r, state_type='thermal'), rho_init\n",
        "#print(actual_values)\n",
        "bcs_opti_cost(sample[1][idx], delta_r, h_type='gaussvect', state_type='thermal')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "G = 1\n",
        "sigma = 2\n",
        "G * np.exp(-np.arange(basis.m//2)**2/(2 * sigma))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.abs([x if x<0 else 0 for x in np.diff(term)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auxterm = np.zeros(basis.m)\n",
        "term = [1,2,3,6,5,6,7,2]\n",
        "for i in range(0,basis.m-1):\n",
        "    if term[i] > term[i+1]:\n",
        "        auxterm[i] = 1\n",
        "print(auxterm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "##### Caso G = G(k-k')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calcula rho_2 en función del delta_k dado\n",
        "import scipy.optimize\n",
        "from sympy import symbols, Function, diff, lambdify\n",
        "import sympy\n",
        "\n",
        "energ = np.array(en_batch[0])  \n",
        "\n",
        "# Dado delta_k simétrico (basis.m//2) devuelve rho asociada\n",
        "@nb.jit(nopython=True)\n",
        "def bcs_deltak_rho(delta_k, m = basis.m, state_type = 'gs'):\n",
        "    delta_k = np.concatenate((delta_k, np.flip(delta_k))) # impongo simetría\n",
        "\n",
        "    sq = lambda k: np.sqrt(energ[k]**2+delta_k[k]**2)\n",
        "    vk = lambda k: np.sqrt(1/2 * (1 - energ[k]/sq(k)))\n",
        "    uk = lambda k: np.sqrt(1/2 * (1 + energ[k]/sq(k)))\n",
        "    fk = lambda k: 1/(1+np.exp(beta*sq(k))) if state_type == 'thermal' else 0\n",
        "    ukvk = lambda k: uk(k)*vk(k)*(1-2*fk(k))\n",
        "    vksq = lambda k: vk(k)**2 * (1-2*fk(k)) + fk(k) \n",
        "\n",
        "    rho = np.zeros((m, m))\n",
        "    for k in range(0, m):\n",
        "        for kp in range(0, m):\n",
        "            p = vksq(k)**2 if k == kp else 0\n",
        "            rho[k, kp] = ukvk(k)*ukvk(kp) + p\n",
        "\n",
        "    return rho \n",
        "\n",
        "# Pasemos a la inversion, es decir, obtener G(delta_k)\n",
        "\n",
        "## Metodo exacto (caso vectorial)\n",
        "### Generamos las funciones para escribir M_ij\n",
        "def gen_sympy_func(m):\n",
        "    uv_s = symbols(f'uv0:{m}')\n",
        "    g_s = symbols(f'g0:{m}')\n",
        "    d_s = np.zeros(m, dtype=object)\n",
        "    for i in range(m):\n",
        "        d_s[i] = np.sum([g_s[np.abs((i-j))//2] * uv_s[j] for j in range(m)])\n",
        "\n",
        "    funcarr = np.zeros((m//2, m//2), dtype=object)\n",
        "    for i in range(m//2):\n",
        "        for j in range(m//2):\n",
        "            funcarr[i, j] = lambdify(uv_s, diff(d_s[i], g_s[j]), 'numpy')\n",
        "\n",
        "    return funcarr\n",
        "\n",
        "M_funcarr = gen_sympy_func(basis.m)\n",
        "\n",
        "def bcs_build_M(delta_k, m=basis.m):\n",
        "    delta_k = np.abs(np.concatenate((delta_k, np.flip(delta_k))))\n",
        "    sq = lambda k: np.sqrt(energ[k]**2+delta_k[k]**2)\n",
        "    vk = lambda k: np.sqrt(1/2 * (1 - energ[k]/sq(k)))\n",
        "    uk = lambda k: np.sqrt(1/2 * (1 + energ[k]/sq(k)))\n",
        "    ukvk = lambda k: uk(k)*vk(k)\n",
        "\n",
        "    M = np.zeros((m//2, m//2))\n",
        "    uv_vals = [ukvk(k) for k in range(basis.m)]    \n",
        "    for i in range(m//2):\n",
        "        for j in range(m//2):\n",
        "            M[i, j] = M_funcarr[i, j](*uv_vals)\n",
        "\n",
        "    M = np.linalg.inv(M)\n",
        "    return M\n",
        "\n",
        "## Inversion numérica, calculo de la función de costo a partir de autoconsistencia\n",
        "#@nb.jit(nopython=True)\n",
        "def bcs_opti_cost(g, delta_k, m=basis.m, state_type='gs', h_type='vect'):\n",
        "    if h_type == 'gaussvect':\n",
        "        G, sigma = g[0], g[1] # g = (G, sigma)\n",
        "        g_s = G * np.exp(-np.arange(m//2)**2/(2 * sigma))\n",
        "    else:\n",
        "        g_s = np.insert(g, 0, 0) # nada que hacer en el caso vectorial\n",
        "\n",
        "    # El choclo es por numba\n",
        "    delta_k = np.concatenate((delta_k, np.flip(delta_k)))\n",
        "    sq = lambda k: np.sqrt(energ[k]**2+delta_k[k]**2)\n",
        "    vk = lambda k: np.sqrt(1/2 * (1 - energ[k]/sq(k)))\n",
        "    uk = lambda k: np.sqrt(1/2 * (1 + energ[k]/sq(k)))\n",
        "    fk = lambda k: 1/(1+np.exp(beta*sq(k))) if state_type == 'thermal' else 0\n",
        "    ukvk = lambda k: uk(k)*vk(k)*(1-2*fk(k))\n",
        "    vksq = lambda k: vk(k)**2 * (1-2*fk(k)) + fk(k) \n",
        "\n",
        "    term = np.zeros(m)\n",
        "    for i in range(m):\n",
        "        if state_type == 'thermal':\n",
        "            #term[i] = delta_k[i] - sum([g_s[np.abs((i-j))//2] * delta_k[j] / (2 * sq(j)) * np.tanh(beta * sq(j)/2) for j in range(m)])\n",
        "            term[i] = delta_k[i] - sum([g_s[np.abs((i-j))] * ukvk(j) for j in range(m)])\n",
        "        else:\n",
        "            term[i] = delta_k[i] - sum([g_s[np.abs((i-j))//2] * ukvk(j) for j in range(m)]) # ojo con un factorcito por aca\n",
        "\n",
        "    #return term\n",
        "    return np.linalg.norm(term, ord=2)\n",
        "\n",
        "# Implementación de la función de inversión mediante ambas estrategias (exacto y numérico)\n",
        "def bcs_rho_g(rho_init, h_type = 'vect', state_type = 'gs', exact = False, energ_f=0, actual_energy=0, just_delta = False):\n",
        "    # Buscamos delta_k   TODO: CASO TERMICO ENERGIA\n",
        "    dist = lambda delta_k: np.linalg.norm(bcs_deltak_rho(delta_k, basis.m, state_type)-rho_init, ord=2) + energ_f * (delta_energ(delta_k, state_type)-actual_energy)**2 + 0 * np.linalg.norm([x if x<0 else 0 for x in np.diff(delta_k)])\n",
        "    bounds = [(0.01, 100) for _ in range(basis.m//2)] # Bounds de delta_k, TODO determinar o acotar\n",
        "    opti = scipy.optimize.dual_annealing(dist, bounds=bounds, maxiter=1000)\n",
        "    #print(opti)\n",
        "    delta_k = opti.x\n",
        "\n",
        "    if just_delta:\n",
        "        return 0, delta_k, opti\n",
        "\n",
        "    if exact and state_type == 'gs' and h_type == 'vect':\n",
        "        M = bcs_build_M(delta_k)\n",
        "        g_rebuild = M @ delta_k[:basis.m//2]\n",
        "        delta_k = delta_k[:basis.m//2]\n",
        "\n",
        "    else: \n",
        "        if h_type == 'gaussvect':\n",
        "            #g_dist = lambda g: bcs_opti_cost(g, delta_k, basis.m, state_type=state_type, h_type='gaussvect')[:2]\n",
        "            #optig = scipy.optimize.root(g_dist, np.random.rand(2), method='broyden1', options={'maxiter': 1000})\n",
        "            #print(optig)\n",
        "            g_dist = lambda g: bcs_opti_cost(g, delta_k, basis.m, state_type=state_type, h_type='gaussvect')\n",
        "            bounds = [(g_init, g_stop), (0.01, 2.1)]\n",
        "            optig = scipy.optimize.dual_annealing(g_dist, bounds=bounds, maxiter=1000)\n",
        "   \n",
        "        else:\n",
        "            g_dist = lambda g: bcs_opti_cost(g, delta_k, basis.m, state_type=state_type, h_type='vect')\n",
        "            bounds = [(g_init, g_stop) for _ in range(basis.m-1)]\n",
        "            optig = scipy.optimize.dual_annealing(g_dist, bounds=bounds, maxiter=1000)\n",
        "\n",
        "        #print(optig)\n",
        "        g_rebuild = optig.x\n",
        "\n",
        "    return g_rebuild, delta_k, opti\n",
        "\n",
        "# Calculo de energía en funcion de delta\n",
        "def delta_energ(delta_k, state_type = 'gs'):\n",
        "    delta_k = np.concatenate((delta_k, np.flip(delta_k)))\n",
        "    sq = lambda k: np.sqrt(energ[k]**2+delta_k[k]**2)\n",
        "    vk = lambda k: np.sqrt(1/2 * (1 - energ[k]/sq(k)))\n",
        "    uk = lambda k: np.sqrt(1/2 * (1 + energ[k]/sq(k)))\n",
        "    fk = lambda k: 1/(1+np.exp(beta*sq(k))) if state_type == 'thermal' else 0\n",
        "    ukvk = lambda k: uk(k)*vk(k)*(1-2*fk(k))\n",
        "    vksq = lambda k: vk(k)**2 * (1-2*fk(k)) + fk(k) \n",
        "\n",
        "    if state_type == 'thermal':\n",
        "        h0 = np.sum([2*energ[k]*vksq(k) for k in range(basis.m)])\n",
        "        hi = np.sum([delta_k[k]**2/(2*sq(k))*(1-2*fk(k)) for k in range(basis.m)])\n",
        "        return h0 - hi\n",
        "    else:\n",
        "        return 0 # TODO: RW CASO GS\n",
        "\n",
        "    # Termino de energía, el más fácil\n",
        "    t1 = np.sum([energ[j] * 2 * vk(j)**2 for j in range(basis.m)])\n",
        "\n",
        "    # Término de interacción, calcularemos G en función de este delta\n",
        "    M = bcs_build_M(lambda k: uk(k) * vk(k))\n",
        "    h_labels = M @ delta_k[:basis.m//2]\n",
        "    #h_labels = gex\n",
        "    indices = np.abs(np.arange(basis.m)[:, np.newaxis] - np.arange(basis.m))\n",
        "    g_arr = np.repeat(h_labels,2)[indices]\n",
        "    rho = bcs_deltak_rho(delta_k, basis.m).T\n",
        "    terms = np.multiply(g_arr, rho)\n",
        "    \n",
        "    t2 = np.sum(terms)\n",
        "\n",
        "    return t1-t2\n",
        "\n",
        "\n",
        "# Reduce el constraint en energia hasta alcanzar una distancia tolerable en rho\n",
        "def opti_delta(rho_init, exact, actual_energy, energ_f=0.1):\n",
        "    max_iter = 1\n",
        "    tol = 0.2\n",
        "    dist = lambda delta_k: np.linalg.norm(bcs_deltak_rho(delta_k, basis.m)-rho_init) \n",
        "    gf, deltaf = np.zeros(basis.m//2), np.zeros(basis.m//2)\n",
        "    i = 1\n",
        "    while i < max_iter:\n",
        "        g, delta, opti = bcs_rho_g(rho_init, exact, energ_f/i, actual_energy=actual_energy) # vamos de a poco reduciendo el constrain en energia\n",
        "        if dist(delta) < tol:\n",
        "            gf, deltaf = g, delta\n",
        "            #print(opti)\n",
        "            break\n",
        "        if dist(delta) < dist(deltaf):\n",
        "            gf, deltaf = g, delta\n",
        "        i += 1\n",
        "\n",
        "    return gf, deltaf\n",
        "\n",
        "# Función auxiliar: calculemos rho2 para esos otros g de la inversion. Recuperamos rho??\n",
        "def rho_reconstruction_vect(gex):\n",
        "    return rho_reconstruction_tf([gex], 'vect', state_type)[0]\n",
        "\n",
        "# Dado delta, obtengo G via la inversión y reconstruyo rho\n",
        "# delta -> G -> rho_reconstruction_tf\n",
        "def rho_reconstruction_from_delta(delta_k):\n",
        "    delta_k = np.abs(np.concatenate((delta_k, np.flip(delta_k))))\n",
        "    sq = lambda k: np.sqrt(energ[k]**2+delta_k[k]**2)\n",
        "    vk = lambda k: np.sqrt(1/2 * (1 - energ[k]/sq(k)))\n",
        "    uk = lambda k: np.sqrt(1/2 * (1 + energ[k]/sq(k)))\n",
        "\n",
        "    M = bcs_build_M(delta_k[:basis.m//2])\n",
        "    gex = M @ delta_k[:basis.m//2]\n",
        "\n",
        "    return rho_reconstruction_vect(gex)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_dist = lambda g: bcs_opti_cost(g, delta_r, basis.m, state_type=state_type, h_type='vect')\n",
        "bounds = [(g_init, g_stop) for _ in range(basis.m-1)]\n",
        "optig = scipy.optimize.dual_annealing(g_dist, bounds=bounds, maxiter=1000)\n",
        "optig, actual_values"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Autoconsistencia"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "idx = np.random.randint(0,100)\n",
        "#idx = 1\n",
        "\n",
        "# Cargamos los valores\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "input_data = sample[0][0][idx]\n",
        "rho_init = input_data\n",
        "rand_idx = np.random.randint(0,64)\n",
        "rho_rand = sample[0][0][rand_idx]\n",
        "actual_energy = sample[0][1][idx]\n",
        "\n",
        "# Compatibilizamos los dos casos\n",
        "if h_type == 'gaussvect':\n",
        "    s = sample[1]\n",
        "    actual_values = gen_gauss_plus_vect(s[:,0], s[:,1], basis.m)[idx]\n",
        "    p = model.predict(sample[0])\n",
        "    prediction = gen_gauss_plus_vect(p[:,0], p[:,1], basis.m)[idx]\n",
        "else:\n",
        "    actual_values = sample[1][idx]\n",
        "    prediction = model.predict(sample[0])[idx]\n",
        "\n",
        "\n",
        "# Calculamos el delta por autoconsitencia\n",
        "def auto_delta(delta_k, m = basis.m, state_type = 'thermal'):\n",
        "    delta_k = np.concatenate((delta_k, np.flip(delta_k)))\n",
        "    sq = lambda k: np.sqrt(energ[k]**2+delta_k[k]**2)\n",
        "    vk = lambda k: np.sqrt(1/2 * (1 - energ[k]/sq(k)))\n",
        "    uk = lambda k: np.sqrt(1/2 * (1 + energ[k]/sq(k)))\n",
        "    fk = lambda k: 1/(1+np.exp(beta*sq(k))) if state_type == 'thermal' else 0\n",
        "    ukvk = lambda k: uk(k)*vk(k)*(1-2*fk(k))\n",
        "    vksq = lambda k: vk(k)**2 * (1-2*fk(k)) + fk(k) \n",
        "\n",
        "    gt = np.insert(actual_values.numpy(), 0, 0)\n",
        "    term = np.zeros(m//2)\n",
        "    for i in range(m//2):\n",
        "        if state_type == 'thermal':\n",
        "            term[i] = sum([gt[np.abs((i-j))] * delta_k[j] / (2 * sq(j)) * np.tanh(beta * sq(j)/2) for j in range(m)])\n",
        "        else:\n",
        "            term[i] = sum([gt[np.abs((i-j))//2] * ukvk(j) for j in range(m)]) # ojo con un factorcito por aca\n",
        "\n",
        "    return term\n",
        "    \n",
        "gex = actual_values.numpy()\n",
        "delta_r = np.random.rand(basis.m//2)\n",
        "for k in range(0, 100):\n",
        "    delta_r = auto_delta(delta_r, state_type=state_type)\n",
        "\n",
        "dist = lambda delta_k, rho: np.linalg.norm(bcs_deltak_rho(delta_k, basis.m, state_type=state_type)-rho, ord=2) # delta_energ(delta_k)-sample[0][1][0])**2+\n",
        "#rho_error_from_delta = lambda delta, rho: np.linalg.norm(rho_reconstruction_from_delta(delta) - rho, ord=2)\n",
        "rho_error_from_ge = lambda ge, rho: np.linalg.norm(rho_reconstruction_vect(ge) - rho, ord=2)\n",
        "\n",
        "print(np.linalg.norm(rho_init, ord=2)/np.linalg.norm(delta_r, ord=2))\n",
        "print('>>Autoconsitencia a partir de g true')\n",
        "print(f'Delta {delta_r}')\n",
        "print(f'Dist {dist(delta_r, rho_init)} de rho')\n",
        "print('\\n>>Resultados de la inversión')\n",
        "gex, dex, opti = bcs_rho_g(rho_init, h_type, state_type, exact = False, energ_f=0.01, actual_energy=actual_energy)\n",
        "print(gex, dex, opti)\n",
        "print(np.linalg.norm(rho_init, ord=2)/np.linalg.norm(dex, ord=2))\n",
        "\n",
        "print(f'Delta {dex}')\n",
        "print(f'Dist {dist(dex, rho_init)} de rho')\n",
        "print(f'Energia {delta_energ(dex, state_type=state_type)}')\n",
        "#print(f'Reconstruccion rho {rho_error_from_delta(dex, rho_init)}')\n",
        "print('\\n>>Resultados random')\n",
        "print(f'Dist {dist(delta_r, rho_rand)} de rho random')\n",
        "print(f'Reconstruccion rho random {rho_error_from_ge(actual_values.numpy(), rho_rand)}')\n",
        "print('\\n>>Resultados predicción')\n",
        "print(f'Reconstruccion rho {rho_error_from_ge(prediction, rho_init)}')\n",
        "print('\\n>>Valores de G')\n",
        "print(f'True {sample[1][idx].numpy()}')\n",
        "print(f'Pred {gex}')\n",
        "print(f'Random {sample[1][rand_idx]}')\n",
        "print(f'Energia real {actual_energy}')\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Dado delta, mejor G?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def gen_sympy_func(m, label_size, h_type):\n",
        "    uv_s = symbols(f'uv0:{m}')\n",
        "    if h_type == 'randomsymm':\n",
        "        g_s = symbols(f'g0:{label_size}') # gs (semilla)\n",
        "    else:\n",
        "        g_s = symbols(f'g0:{label_size}')\n",
        "\n",
        "    d_s = np.zeros(m, dtype=object)\n",
        "\n",
        "    if h_type == 'vectnosymm' or h_type == 'vect':\n",
        "        for i in range(m):\n",
        "            d_s[i] = np.sum([g_s[np.abs((i-j))] * uv_s[j] for j in range(m)])\n",
        "\n",
        "    elif h_type == 'randomsymm':\n",
        "        # Generamos la matriz G_kk'\n",
        "        g_mat = random_fermi_arr_inv(g_s, m, obj = True)\n",
        "        for i in range(m):\n",
        "            d_s[i] = np.sum([g_mat[i,j] * uv_s[j] for j in range(m)]) \n",
        "    \n",
        "    else:\n",
        "        raise ValueError\n",
        "\n",
        "    for i in range(basis.m):\n",
        "        d_s[i] = d_s[i].subs({g_s[0]:0})\n",
        "    \n",
        "    funcarr = np.zeros((m, label_size), dtype=object)\n",
        "    for i in range(m):\n",
        "        for j in range(label_size):\n",
        "            funcarr[i, j] = lambdify(uv_s, diff(d_s[i], g_s[j]), 'numpy')\n",
        "\n",
        "    return funcarr\n",
        "\n",
        "M_funcarr = gen_sympy_func(basis.m, basis.m, h_type)\n",
        "\n",
        "def bcs_build_M_thermal(delta_k, label_size, m=basis.m):\n",
        "    delta_k = np.concatenate((delta_k, np.flip(delta_k)))\n",
        "    sq = lambda k: np.sqrt(energ[k]**2+delta_k[k]**2)\n",
        "    vk = lambda k: np.sqrt(1/2 * (1 - energ[k]/sq(k)))\n",
        "    uk = lambda k: np.sqrt(1/2 * (1 + energ[k]/sq(k)))\n",
        "    fk = lambda k: 1/(1+np.exp(beta*sq(k))) if state_type == 'thermal' else 0\n",
        "    ukvk = lambda k: uk(k)*vk(k)*(1-2*fk(k))\n",
        "    vksq = lambda k: vk(k)**2 * (1-2*fk(k)) + fk(k) \n",
        "\n",
        "    M = np.zeros((m//2, label_size))\n",
        "    uv_vals = [ukvk(k) for k in range(m)]    \n",
        "    for i in range(m//2):\n",
        "        for j in range(label_size):\n",
        "            M[i, j] = M_funcarr[i, j](*uv_vals)\n",
        "\n",
        "    return M\n",
        "\n",
        "\n",
        "#print(delta_r)\n",
        "gex, dex, opti = bcs_rho_g(rho_init, h_type, state_type, exact = False, energ_f=0.01, actual_energy=actual_energy, just_delta=True)\n",
        "#print(M @ np.repeat(actual_values, 2)) # deberiamos recuperar delta\n",
        "conv = lambda x: np.insert(x, 0, 0)\n",
        "#conv = lambda x: x\n",
        "\n",
        "\n",
        "print(opti)\n",
        "delta_o = dex\n",
        "ac = conv(actual_values)\n",
        "print(gex, delta_r)\n",
        "M = bcs_build_M_thermal(dex, basis.m)\n",
        "#print(M @ ac - delta_r)\n",
        "cost = lambda g: np.linalg.norm(g-ac)\n",
        "bounds = [(0.01, g_stop*2) for _ in range(basis.m)]\n",
        "eps = 0.001\n",
        "lin_const = scipy.optimize.LinearConstraint(M, delta_o-eps, delta_o+eps)\n",
        "\n",
        "opt = scipy.optimize.minimize(cost, np.random.rand(basis.m), constraints=lin_const, bounds=bounds, method='SLSQP') #COBYLA, SLSQP, \n",
        "print(opt)\n",
        "print(M @ opt.x - dex)\n",
        "opt.x, ac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import scipy.optimize\n",
        "\n",
        "# Cost function\n",
        "cost = lambda g: np.linalg.norm(g - ac)\n",
        "\n",
        "# Define bounds as inequality constraints for COBYLA\n",
        "bounds = [(0.01, g_stop * 2) for _ in range(basis.m)]\n",
        "ineq_bounds = [{'type': 'ineq', 'fun': lambda g, lb=lb, ub=ub: g - lb} for lb, ub in bounds] + \\\n",
        "              [{'type': 'ineq', 'fun': lambda g, lb=lb, ub=ub: ub - g} for lb, ub in bounds]\n",
        "\n",
        "# Convert linear equality constraint to inequality constraints for COBYLA\n",
        "def lin_const_lower(g):\n",
        "    return M @ g - (delta_o - eps)\n",
        "\n",
        "def lin_const_upper(g):\n",
        "    return (delta_o + eps) - M @ g\n",
        "\n",
        "ineq_constraints = [{'type': 'ineq', 'fun': lin_const_lower},\n",
        "                    {'type': 'ineq', 'fun': lin_const_upper}]\n",
        "\n",
        "# Combine all constraints\n",
        "constraints =  ineq_constraints\n",
        "\n",
        "# Run COBYLA optimization\n",
        "opt = scipy.optimize.minimize(cost, np.random.rand(basis.m), constraints=constraints, method='COBYLA')\n",
        "\n",
        "print(opt)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "ac"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(dex)\n",
        "#print(M @ np.repeat(actual_values, 2)) # deberiamos recuperar delta\n",
        "conv = lambda x: np.insert(x, 0, 0)\n",
        "#conv = lambda x: x\n",
        "\n",
        "eps = 0.001\n",
        "print(M.shape)\n",
        "#delta_o = np.concatenate((delta_o, np.flip(delta_o)))\n",
        "lin_const = scipy.optimize.LinearConstraint(M, delta_o-eps, delta_o+eps)\n",
        "#cost = lambda g: np.linalg.norm(g-np.repeat(actual_values,2)) caso simetrico\n",
        "print(actual_values)\n",
        "cost = lambda g: np.linalg.norm(g-conv(actual_values))\n",
        "bounds = [(0.01, 50) for _ in range(label_size)]\n",
        "\n",
        "opt = scipy.optimize.minimize(cost, np.random.rand(label_size), constraints=lin_const, bounds=bounds, method='SLSQP') #COBYLA, SLSQP, \n",
        "#opt = scipy.optimize.differential_evolution(cost, bounds=bounds, constraints=lin_const)\n",
        "#opt = scipy.optimize.shgo(cost, bounds=bounds, constraints=lin_const, iters=2, n=1000, sampling_method='halton')\n",
        "print(opt, opt.x)\n",
        "print(actual_values)\n",
        "print(M @ opt.x - delta_o)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ahora la idea es hacer todo lo anterior, de manera sistemática"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# TODO Reducir repetición de código con lo anterior\n",
        "\n",
        "# Cargamos valores\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "input_data_arr = sample[0][0].numpy()\n",
        "actual_energy_arr = sample[0][1].numpy()\n",
        "actual_values_arr = sample[1].numpy()\n",
        "prediction = model.predict(sample[0])\n",
        "#conv = lambda x: np.repeat(np.insert(x, 0, 0),2) caso simetrico\n",
        "conv = lambda x: np.insert(x, 0, 0)\n",
        "\n",
        "def min_opti_g(idx):\n",
        "    input_data = input_data_arr[idx]\n",
        "    rho_init = input_data\n",
        "    actual_energy = actual_energy_arr[idx]\n",
        "    #actual_values = conv(actual_values_arr[idx])\n",
        "    actual_values = actual_values_arr[idx]\n",
        "\n",
        "    # Optimizamos para hallar el delta\n",
        "    gex, dex, opti = bcs_rho_g(rho_init, h_type, state_type, exact = False, energ_f=0.01, actual_energy=actual_energy, just_delta=True)\n",
        "\n",
        "    delta_o = dex\n",
        "    M = bcs_build_M_thermal(delta_o, label_size)\n",
        "\n",
        "    eps = 0.01\n",
        "    lin_const = scipy.optimize.LinearConstraint(M, delta_o-eps, delta_o+eps)\n",
        "    cost = lambda g: np.linalg.norm(g-actual_values)\n",
        "    bounds = [(0.01, 200) for _ in range(label_size)]\n",
        "\n",
        "    #print(M.shape, delta_o)\n",
        "    opt = scipy.optimize.minimize(cost, np.random.rand(label_size), constraints=lin_const, bounds=bounds, method='SLSQP') \n",
        "    #print(opt)\n",
        "    #print(actual_values)\n",
        "    #print(M @ opt.x - delta_o)\n",
        "    return opt.x, actual_values, prediction[idx]\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_opti_g(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from concurrent.futures import ProcessPoolExecutor, as_completed\n",
        "from tqdm import tqdm\n",
        "\n",
        "min_actual_g2 = []\n",
        "min_num_g2 = []\n",
        "min_pred_g2 = []\n",
        "\n",
        "def task(i):\n",
        "    return min_opti_g(i)\n",
        "\n",
        "with ProcessPoolExecutor() as executor:\n",
        "    # Submit all the tasks to the executor\n",
        "    futures = [executor.submit(task, i) for i in range(256)]\n",
        "    \n",
        "    # Use tqdm to display progress\n",
        "    for future in tqdm(as_completed(futures), total=len(futures)):\n",
        "        num, actual, pred = future.result()\n",
        "        min_actual_g2.append(actual)\n",
        "        min_num_g2.append(num)\n",
        "        min_pred_g2.append(pred)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "min_actual_g = min_actual_g2 + min_actual_g\n",
        "min_num_g =  min_num_g2 + min_num_g\n",
        "min_pred_g = min_pred_g2 + min_pred_g"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "op1 = lambda g: [np.linalg.norm(x) for x in g]\n",
        "op2 = lambda g: [np.linalg.norm(x) for x in g]\n",
        "\n",
        "for i in range(len(min_actual_g)):\n",
        "    min_actual_gm = op1(min_actual_g)\n",
        "    min_num_gm = op2(min_num_g)\n",
        "    min_pred_gm = np.array(op2(min_pred_g))\n",
        "\n",
        "sortids = np.array(min_actual_gm).argsort().astype(int)\n",
        "x = np.array(min_actual_gm)[sortids]\n",
        "plt.plot(x, np.array(min_num_gm)[sortids], label='BCS')\n",
        "plt.plot(x, np.array(min_actual_gm)[sortids])\n",
        "plt.plot(x, min_pred_gm[sortids], label='ML')\n",
        "#plt.yscale(\"log\")\n",
        "#plt.ylim(0,5)\n",
        "plt.legend()\n",
        "plt.xlabel(\"Norma G_true\")\n",
        "plt.ylabel(\"Norma G_BCS\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "difop = lambda g: np.linalg.norm(np.array(g)[sortids] - np.array(min_actual_g)[sortids], axis=-1)\n",
        "plt.plot(x, difop(min_num_g), label='BCS')\n",
        "plt.plot(x, difop(min_pred_g), label='ML')\n",
        "plt.legend()\n",
        "plt.xlabel('Norma G_true')\n",
        "plt.ylabel('Norma diferencia G-G_true')\n",
        "plt.yscale(\"log\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "#### Caso h_type=randomenerg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step \n"
          ]
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Definición de estimadores\n",
        "def rho1_to_h_gc(rho, beta, mu = 0):\n",
        "    inv = scipy.linalg.inv(rho)\n",
        "    mat = scipy.linalg.logm(inv-np.eye(inv.shape[0]))\n",
        "    return (mat+mu)/beta\n",
        "\n",
        "idx = np.random.randint(0,100)\n",
        "\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "rho_arr = sample[0][0]\n",
        "prediction = model.predict(sample[0])\n",
        "actual_values = sample[1]\n",
        "\n",
        "# Ploteamos\n",
        "## Eje X\n",
        "sortids = np.array(np.linalg.norm(actual_values, axis=-1)).argsort().astype(int)\n",
        "x = np.array(np.linalg.norm(actual_values, axis=-1))[sortids]\n",
        "actual_values = actual_values.numpy()[sortids]\n",
        "\n",
        "# Gráficos\n",
        "inv_arr = np.array([np.diagonal(rho1_to_h_gc(r, beta, 0)) for r in rho_arr]).reshape(gpu_batch_size//2,basis.d)\n",
        "ml_arr = prediction[sortids]\n",
        "err = lambda a: np.linalg.norm(a-actual_values, axis=-1)\n",
        "\n",
        "#%matplotlib inline\n",
        "#plt.rcParams['text.usetex'] = True\n",
        "\n",
        "plt.plot(x, err(inv_arr)[sortids], label='Inv GC')\n",
        "plt.plot(x, err(ml_arr), label='ML')\n",
        "plt.rcParams['axes.labelsize'] = 16\n",
        "plt.rcParams['xtick.labelsize'] = 12\n",
        "plt.rcParams['ytick.labelsize'] = 12\n",
        "plt.rcParams['legend.fontsize'] = 16\n",
        "plt.rcParams['axes.linewidth'] = 1.5\n",
        "plt.rcParams['figure.dpi'] = 300\n",
        "plt.legend()\n",
        "plt.xlabel('|h|')\n",
        "plt.ylabel('Error (MSE)')\n",
        "plt.yscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for i, x in enumerate(min_actual_gm):\n",
        "    if np.linalg.norm(x) < 10:\n",
        "        print(x, min_num_gm[i])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pre_const = lambda g: bcs_opti_cost_alt(g, dex, basis.m, state_type=state_type, h_type=h_type)\n",
        "nl_const = scipy.optimize.NonlinearConstraint(pre_const, -0.1, 0.1)\n",
        "cost = lambda g: np.linalg.norm(g-np.repeat(actual_values,2))\n",
        "bounds = [(0.1, g_stop+0.5) for _ in range(basis.m)]\n",
        "\n",
        "#opt = scipy.optimize.minimize(cost, np.random.rand(basis.m), constraints=nl_const, bounds=bounds, method='SLSQP')\n",
        "opt = scipy.optimize.differential_evolution(cost, bounds=bounds, constraints=nl_const)\n",
        "print(opt)\n",
        "print(pre_const(opt.x), actual_values)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Buscamos delta_k   TODO: CASO TERMICO ENERGIA\n",
        "#dist = lambda delta_k: np.linalg.norm(bcs_deltak_rho(delta_k, basis.m, state_type)-rho_init, ord=2) + 0.01 * (delta_energ(delta_k, state_type)-actual_energy)**2\n",
        "#bounds = [(0, 50) for _ in range(basis.m//2)] # Bounds de delta_k, TODO determinar o acotar\n",
        "#opti = scipy.optimize.dual_annealing(dist, bounds=bounds, maxiter=1000)\n",
        "#delta_k = opti.x\n",
        "#print(delta_k, delta_r)\n",
        "\n",
        "g_dist = lambda g: bcs_opti_cost(g, delta_r, basis.m, state_type=state_type, h_type='vect')\n",
        "bounds = [(g_init, g_stop), (0.01, 2.1)]\n",
        "#optig = scipy.optimize.dual_annealing(g_dist, bounds=bounds, maxiter=1000) broyden1!!\n",
        "scipy.optimize.root(g_dist, (1,1), method='hybr', options={'maxiter': 10000})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "scipy.optimize.roots"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "auto_delta(delta_r, state_type=state_type), delta_r"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_dist = lambda g: bcs_opti_cost(g, delta_r, basis.m, state_type=state_type, h_type='vect')\n",
        "bounds = [(g_init, g_stop) for _ in range(basis.m//2)]\n",
        "optig = scipy.optimize.dual_annealing(g_dist, bounds=bounds, maxiter=1000)\n",
        "print(optig)\n",
        "optig.x, sample[1][idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dex, auto_delta(dex, state_type=state_type)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rbcs = bcs_deltak_rho(dex, state_type=state_type)\n",
        "np.linalg.eigvals(rbcs), np.linalg.eigvals(rho_init)\n",
        "plt.plot(np.linalg.eigvals(rbcs))\n",
        "plt.plot(np.linalg.eigvals(rho_init))\n",
        "plt.yscale('log')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nn = [0,1,2,None,np.inf,-1,-2]\n",
        "for x in nn:\n",
        "    d = dex\n",
        "    print(np.linalg.norm(d, ord=x))\n",
        "\n",
        "print(np.linalg.norm(d, ord=2)*2-np.linalg.norm(d, ord=1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bounds = [(0, 50) for _ in range(basis.m//2)]\n",
        "scipy.optimize.dual_annealing(dist, bounds=bounds, maxiter=10000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dist = lambda delta_k: (bcs_deltak_rho(delta_k, basis.m, state_type)-rho_init).numpy().flatten()\n",
        "op = scipy.optimize.root(dist, np.random.rand(4), method='lm', tol=1e-8, epsfcn = 0.1)\n",
        "op, delta_r\n",
        "#delta_k = op.x\n",
        "#type(dist(delta_r))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "op = scipy.optimize.fsolve(dist, np.random.rand(basis.m//2))\n",
        "op"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rho_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dist = lambda delta_k: np.linalg.norm(bcs_deltak_rho(delta_k, basis.m, state_type)-rho_init)+(np.linalg.norm(delta_k, ord=0)-basis.m//2)**2\n",
        "bounds = [(0,10) for _ in range(4)]\n",
        "opti = scipy.optimize.dual_annealing(dist, bounds=bounds, maxiter=10000)\n",
        "delta_k = opti.x\n",
        "print(dist(delta_r))\n",
        "\n",
        "opti, delta_r\n",
        "#g_dist = lambda g: bcs_opti_cost(g, delta_r, basis.m, state_type=state_type, h_type='gaussvect')\n",
        "#optig = scipy.optimize.dual_annealing(g_dist, bounds=[(0,10), (0,10)], maxiter=10000)\n",
        "#optig, sample[1][idx]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "np.linalg.norm(delta_k, ord=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "nn = [0,1,2,None,np.inf,-1,-2]\n",
        "for x in nn:\n",
        "    print(np.linalg.norm(delta_r, ord=x))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "opti +"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#opti = scipy.optimize.differential_evolution(dist, bounds=bounds)\n",
        "#opti\n",
        "opti = scipy.optimize.direct(dist, bounds=bounds, maxiter=1000)\n",
        "print(dist(delta_r))\n",
        "opti"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_dist = lambda g: bcs_opti_cost(g, delta_r, basis.m, state_type=state_type, h_type='gaussvect')\n",
        "boundss = [(0.01,20) for _ in range(2)]\n",
        "optig = scipy.optimize.dual_annealing(g_dist, bounds=boundss, maxiter=1000)\n",
        "sample[1][idx], optig, delta_r\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "bcs_opti_cost(sample[1][idx], delta_r, state_type=state_type, h_type='gaussvect')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_dist = lambda g: bcs_opti_cost(g, delta_r, basis.m, state_type=state_type, h_type='gaussvect')\n",
        "opti = scipy.optimize.minimize(g_dist, np.random.rand(2), method='Nelder-Mead', tol=1e-8)\n",
        "opti, sample[1][idx]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "g_dist(sample[1][rand_idx])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(np.linalg.eigvals(rho_init))\n",
        "\n",
        "plt.plot(np.linalg.eigvals(bcs_deltak_rho(dex, basis.m)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "delta_k = dex\n",
        "# Calculamos el sistema de ecs\n",
        "delta_k = np.abs(np.concatenate((delta_k, np.flip(delta_k)))) # pues el resultado son los delta indep\n",
        "sq = lambda k: np.sqrt(energ[k]**2+delta_k[k]**2)\n",
        "vk = lambda k: np.sqrt(1/2 * (1 - energ[k]/sq(k)))\n",
        "uk = lambda k: np.sqrt(1/2 * (1 + energ[k]/sq(k)))\n",
        "\n",
        "M = bcs_build_M(lambda k: uk(k) * vk(k))\n",
        "M @ delta_k[:basis.m//2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "arr = []\n",
        "for i in range(0, 100):\n",
        "    arr.append(rho_error_from_ge(actual_values.numpy(), sample[0][0][i]))\n",
        "np.mean(arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rho_init"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "maxval = 100\n",
        "# Cargamos elementos del conjunto de validación\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "\n",
        "input_rhos = sample[0][0].numpy()[:maxval]  \n",
        "input_energies = sample[0][1].numpy()[:maxval] \n",
        "actual_values = sample[1].numpy()[:maxval]\n",
        "input_data = sample[0]\n",
        "predictions = model.predict(input_data)\n",
        "\n",
        "# Ordenamos los valores de G con el fin de plotear\n",
        "g_ids = actual_values[:,0].argsort()\n",
        "g_ids = np.mean(actual_values, axis=-1).argsort()\n",
        "predictions_sort = predictions[g_ids]\n",
        "g_true_sort = actual_values[g_ids]\n",
        "rho_pred = rho_reconstruction(predictions_sort)\n",
        "rho_actual = input_rhos[g_ids]\n",
        "\n",
        "# Calculamos ahora G BCS\n",
        "rho_bcs_arr = []\n",
        "for l in tqdm(range(actual_values.shape[0])): # equiv al batch_size\n",
        "    rho = input_rhos[l]\n",
        "    actual_energy = input_energies[l]\n",
        "    gex, dex = opti_delta(rho, actual_energy,0)\n",
        "    rho_bcs = rho_reconstruction(gex)\n",
        "    #print(rho_bcs)\n",
        "    rho_bcs_arr.append(rho_bcs)\n",
        "\n",
        "rho_bcs = np.array(rho_bcs_arr)[g_ids]\n",
        "\n",
        "rho_error = lambda x: np.linalg.norm(rho_actual-x, ord='fro', axis=(1,2))\n",
        "\n",
        "plt.plot(g_true_sort[:,0], rho_error(rho_pred), label='DNN prediction') # ploteamos segun el primero\n",
        "plt.plot(g_true_sort[:,0], rho_error(rho_bcs), label='BCS')\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"g\")\n",
        "plt.ylabel(\"Rho2 reconstruction error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "plt.plot(np.sort(np.mean(actual_values, axis=-1)), rho_error(rho_pred), label='CNN prediction') # ploteamos segun el primero\n",
        "plt.plot(np.sort(np.mean(actual_values, axis=-1)), rho_error(rho_bcs), label='BCS')\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"g\")\n",
        "plt.ylabel(\"Rho2 reconstruction error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "rho_error = lambda x: np.linalg.norm(rho_actual-x, ord=2, axis=(1,2))\n",
        "\n",
        "plt.plot(g_true_sort[:,0], rho_error(rho_pred), label='DNN prediction') # ploteamos segun el primero\n",
        "plt.plot(g_true_sort[:,0], rho_error(rho_bcs), label='BCS')\n",
        "plt.yscale(\"log\")\n",
        "plt.xlabel(\"g\")\n",
        "plt.ylabel(\"Rho2 reconstruction error\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Análisis para G cte"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generacion de elementos, rho2 a partir de ellos, y comparación con la predicción\n",
        "# Nuevamente, el resultado depende pura y exclusivamente del modelo, y no de los ptos tomados\n",
        "h_labels = np.linspace(0.1,1,512)\n",
        "g_arr = [np.ones((basis.m, basis.m))*g_seed for g_seed in h_labels]\n",
        "g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "h_arr = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, g_arr.numpy(), rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "\n",
        "# Estados térmicos\n",
        "state = thermal_state_tf(h_arr*beta) \n",
        "state = tf.cast(state, dtype=tf.float32)\n",
        "# Estados puros\n",
        "#state = pure_state(h_arr)\n",
        "\n",
        "rho_2_input = rho_2_tf(state, rho_2_arrays_kkbar_tf)\n",
        "predictions = model.predict(rho_2_input).T\n",
        "G_err = np.abs(predictions-h_labels).T\n",
        "plt.plot(h_labels, G_err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ploteo de varios elementos de val_dataset\n",
        "# No sirve de mucho, depende del modelo y no la muestra\n",
        "max_plt = 10\n",
        "idx = 0\n",
        "for e in val_dataset:\n",
        "    predictions = model.predict(e[0])\n",
        "    pred_ids = predictions.T.argsort()\n",
        "    predictions_sort = predictions[pred_ids][0]\n",
        "    G_true_sorted = e[1].numpy()[pred_ids].T\n",
        "    G_err = np.abs(predictions_sort-G_true_sorted)\n",
        "    plt.plot(predictions_sort,G_err)\n",
        "    idx += 1\n",
        "    if idx > max_plt:  \n",
        "        break\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Modelos Random Forest"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Tenemos que trabajar con DataFrames para trabajar con xgboost, por eso inicialmente desempaquetamos el dataset "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow_decision_forests as tfdf\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_squared_error\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def rf_fit(dataset):\n",
        "    # Generación de dataset\n",
        "    ds_f = {} # features\n",
        "    ds_l = {} # labels\n",
        "\n",
        "    # Generamos las etiquetas\n",
        "    for i in range(basis.m*basis.m):\n",
        "        ds_f[f'{i}'] = []\n",
        "    # Generacion de labels TODO: Escribir todo en función del label size y fue\n",
        "    if label_size == 1:\n",
        "        ds_l['g'] = []\n",
        "    elif label_size == 2:\n",
        "        ds_l['g'] = []\n",
        "        ds_l['sigma'] = []  \n",
        "    else:\n",
        "        for i in range(0, label_size):\n",
        "            ds_l[f'l{i}'] = []\n",
        "\n",
        "    # Poblamos el DF\n",
        "    for e in list(dataset.as_numpy_iterator()):\n",
        "        # Elementos de rho2\n",
        "        for i in range(0,basis.m*basis.m):\n",
        "            ds_f[f'{i}'].append(np.ndarray.flatten(e[0])[i])\n",
        "        # Labels\n",
        "        if label_size == 1:\n",
        "            ds_l['g'].append(e[1])\n",
        "        elif label_size == 2:\n",
        "            ds_l['g'].append(e[1][0])\n",
        "            ds_l['sigma'].append(e[1][1])\n",
        "        else:\n",
        "            for i in range(0, label_size):\n",
        "                ds_l[f'l{i}'].append(e[1][i])\n",
        "\n",
        "    ds_l = pd.DataFrame(ds_l)\n",
        "    ds_f = pd.DataFrame(ds_f)\n",
        "\n",
        "    # Spliteamos los datasets\n",
        "    X_train, X_test, y_train, y_test = train_test_split(ds_f, ds_l, test_size=0.2, random_state=42)\n",
        "\n",
        "    # Entrenamos\n",
        "    regressor = xgb.XGBRegressor(objective='reg:squarederror', max_depth=20)\n",
        "    regressor.fit(X_train, y_train)\n",
        "    predictions = regressor.predict(X_test)\n",
        "\n",
        "    # Evaluamos\n",
        "    mse = mean_squared_error(y_test, predictions)\n",
        "    print(f'Mean Squared Error: {mse}')\n",
        "\n",
        "    return regressor, X_test, y_test, y_train\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Análicemos los resultados"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def rf_error_coef(regressor, X_test, y_test, y_train):\n",
        "    predictions = regressor.predict(X_test)\n",
        "    # Printeamos algunos valores\n",
        "    for i in range(0, 10):\n",
        "        print(predictions[i], y_test.to_numpy()[i])\n",
        "\n",
        "    if label_size == 1:\n",
        "        actual_values = y_test.to_numpy()\n",
        "        norm_pred = np.mean(np.abs(predictions-actual_values.T))\n",
        "        norm_rand = np.mean(np.abs(y_train.to_numpy()[:len(actual_values)]-actual_values))\n",
        "    elif label_size > 1:\n",
        "        norm_pred = np.mean(np.linalg.norm(predictions-y_test.to_numpy(),ord=2, axis=1))\n",
        "        norm_rand = np.mean(np.linalg.norm(y_train.to_numpy()[:len(predictions)]-y_test.to_numpy(),ord=2, axis=1))\n",
        "        \n",
        "    print(norm_pred, norm_rand)\n",
        "    print(norm_rand / norm_pred)\n",
        "    return norm_rand / norm_pred"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Análisis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Ejemplo de uso"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset, label_size = gen_dataset('const', 0.1, 5, 'thermal', 'rho1')\n",
        "# DNN\n",
        "#model, val_dataset = dnn_fit(dataset, label_size)\n",
        "#dnn_error_coef(model, val_dataset) \n",
        "# RF\n",
        "regressor, X_test, y_test, y_train = rf_fit(dataset)\n",
        "rf_error_coef(regressor, X_test, y_test, y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Barrido en intervalos de G para G cte\n",
        "g_init_range = np.linspace(0.01,10,20)\n",
        "err_arr = []\n",
        "for g_init in g_init_range:\n",
        "    print(g_init)\n",
        "    dataset, label_size, input_type = gen_dataset('const', g_init, g_init+0.5, 'gs', 'rho1')\n",
        "    # DNN\n",
        "    model, val_dataset, history = dnn_fit(dataset, label_size, input_type)\n",
        "    err = dnn_error_coef(model, val_dataset)\n",
        "    # RF\n",
        "    #regressor, X_test, y_test, y_train = rf_fit(dataset)\n",
        "    #err = rf_error_coef(regressor, X_test, y_test, y_train)\n",
        "    err_arr.append(err)\n",
        "\n",
        "plt.plot(g_init_range,err_arr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.xlabel('G init')\n",
        "plt.ylabel('Loss coef')\n",
        "plt.plot(g_init_range,err_arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Misc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from xgboost import plot_tree\n",
        "import matplotlib \n",
        "xgb.plot_tree(regressor, num_trees=20)\n",
        "fig = matplotlib.pyplot.gcf()\n",
        "fig.set_size_inches(150, 100)\n",
        "fig.savefig('tree.png')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Para G cte, error en función de G. Sí, es cualquier cosa\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "pred_ids = predictions.T.argsort()\n",
        "predictions_sort = predictions[pred_ids]\n",
        "G_true_sorted = y_test.to_numpy()[pred_ids].T[0]\n",
        "G_err = np.abs(predictions_sort-G_true_sorted)\n",
        "plt.plot(predictions_sort,G_err)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Spliteo de DataFrames y generacion de Datasets\n",
        "label = 'h_labels'\n",
        "\n",
        "def split_dataset(dataset, test_ratio=0.30):\n",
        "  \"\"\"Splits a panda dataframe in two.\"\"\"\n",
        "  test_indices = np.random.rand(len(dataset)) < test_ratio\n",
        "  return dataset[~test_indices], dataset[test_indices]\n",
        "\n",
        "\n",
        "train_ds_pd, test_ds_pd = split_dataset(df)\n",
        "print(\"{} examples in training, {} examples for testing.\".format(\n",
        "    len(train_ds_pd), len(test_ds_pd)))\n",
        "\n",
        "train_ds = tfdf.keras.pd_dataframe_to_tf_dataset(train_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\n",
        "test_ds = tfdf.keras.pd_dataframe_to_tf_dataset(test_ds_pd, label=label, task=tfdf.keras.Task.REGRESSION)\n",
        "\n",
        "# Entrenamiento\n",
        "model = tfdf.keras.RandomForestModel(task = tfdf.keras.Task.REGRESSION)\n",
        "model.compile(metrics=[\"mse\"]) \n",
        "model.fit(x=train_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tfdf.model_plotter.plot_model_in_colab(model, tree_idx=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.compile(metrics=[\"mse\"])\n",
        "evaluation = model.evaluate(test_ds, return_dict=True)\n",
        "print()\n",
        "\n",
        "for name, value in evaluation.items():\n",
        "  print(f\"{name}: {value:.4f}\")\n",
        "\n",
        "predictions = model.predict(test_ds)\n",
        "\n",
        "for e in test_ds:\n",
        "    for i in range(0, 10):\n",
        "        print(e[1][i])\n",
        "        print(predictions[i])\n",
        "    break\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "logs = model.make_inspector().training_logs()\n",
        "plt.plot([log.num_trees for log in logs], [log.evaluation.rmse for log in logs])\n",
        "plt.xlabel(\"Number of trees\")\n",
        "plt.ylabel(\"RMSE (out-of-bag)\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testeo barrido en G código anterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num = 100\n",
        "g_range = np.linspace(0.01,20,num)\n",
        "rho_range= {}\n",
        "gpu_batch_size = 2\n",
        "\n",
        "# Construccion de parametros y matrices auxiliares\n",
        "#rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "rho2kkbar_size = basis.m\n",
        "fund_size = basis.size\n",
        "hamil_base_size = basis.d*(basis.d+1)//2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_1_arrays_tf = tf.constant(rho_1_arrays, dtype=tf.float32)\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "rho_2_arrays_kkbar = rho_2_kkbar_gen(t_basis, rho_2_arrays)\n",
        "rho_2_arrays_kkbar_tf = tf.constant(rho_2_arrays_kkbar, dtype=tf.float32)\n",
        "k_indices = get_kkbar_indices(t_basis)\n",
        "k_indices_tf = gen_update_indices(t_basis, gpu_batch_size)\n",
        "\n",
        "batch_size = 2\n",
        "indices = tf.constant(get_kkbar_indices(t_basis))\n",
        "indices_tf = gen_update_indices(t_basis, batch_size)\n",
        "en_batch = [np.arange(0, basis.m) for _ in range(0,batch_size)]\n",
        "en_batch = tf.cast(en_batch, dtype=tf.float32)\n",
        "G_batched = [np.ones((basis.m,basis.m)) for _ in range(0, batch_size)]\n",
        "\n",
        "#h_arr = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, g_arr.numpy(), rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "#(h0, hi) = (t[0][0].numpy(), t[1][0].numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_g(g):\n",
        "    #print(g)\n",
        "    ## CONST\n",
        "    #G_batched = [g * np.ones((basis.m,basis.m)) for _ in range(0, batch_size)]\n",
        "    ## GAUSSIAN\n",
        "    h_labels = np.array([[g, 1] for _ in range(0, gpu_batch_size)])\n",
        "    g_arr = gen_gauss_mat_np(h_labels[:,0], h_labels[:,1], basis.m)\n",
        "    h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "    G_batched = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "    G_batched = tf.cast(G_batched, dtype=tf.float32)\n",
        "    t = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, G_batched, rho_1_arrays, rho_2_arrays, indices_tf)\n",
        "    state = pure_state(t)\n",
        "    #print(fund)\n",
        "    #print('rho')\n",
        "    #Toda la matriz\n",
        "    rho = rho_2_tf(state, rho_2_arrays_kkbar_tf)\n",
        "    #Solo el bloque kkbar\n",
        "    #rho = rho_2_kkbar(basis, fund, ml_basis, mll_basis, t_basis)\n",
        "    #Rho1\n",
        "    #rho = rho_1(basis, fund).todense()\n",
        "    r = np.sort(linalg_d.eigvals(rho[0]).real)\n",
        "    #print(r)\n",
        "    return (g, r)\n",
        "\n",
        "# Version sincrónica\n",
        "rho_range = {}\n",
        "\n",
        "for g in g_range:\n",
        "    print(g)\n",
        "    rho_range[g] = compute_g(g)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ploteamos\n",
        "rho_range = dict(rho_range)\n",
        "rho_range = dict(sorted(rho_range.items()))\n",
        "x_axis = list(g_range)\n",
        "values = list(rho_range.items())\n",
        "size = len(values[0][1])\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "\n",
        "# Plot using matplotlib\n",
        "# Use LaTeX to format all text\n",
        "\n",
        "plt.rcParams['text.usetex'] = False #True\n",
        "plt.rcParams['axes.labelsize'] = 30\n",
        "plt.rcParams['xtick.labelsize'] = 20\n",
        "plt.rcParams['ytick.labelsize'] = 20\n",
        "plt.rcParams['legend.fontsize'] = 20\n",
        "plt.rcParams['axes.linewidth'] = 1.5\n",
        "\n",
        "plt.cla()\n",
        "plt.figure(figsize=(8, 5))\n",
        "#%matplotlib qt\n",
        "%matplotlib inline \n",
        "for k in range(1,size):\n",
        "    plt.plot(x_axis, [values[j][1][k] for j in range(0,num)], linewidth=2)\n",
        "\n",
        "#plt.xlabel(r'$G/\\epsilon$', fontsize=18)\n",
        "#plt.ylabel(r'$\\lambda^{(2)}$', fontsize=18)\n",
        "plt.xlim(0, 20)  # Set x-axis limits from 0 to 6\n",
        "plt.ylim(0, 5)  # Set y-axis limits from 5 to 12\n",
        "\n",
        "#matplotlib.use('Agg')\n",
        "#matplotlib.use('GTK3Agg')\n",
        "\n",
        "plt.tick_params(axis='x', which='both', bottom=True, top=True, labelbottom=True)\n",
        "\n",
        "# Enable minor ticks on the x-axis\n",
        "plt.minorticks_on()\n",
        "\n",
        "# Customize the appearance of minor ticks on the x-axis\n",
        "plt.tick_params(axis='x', which='minor', width=1.5)\n",
        "plt.tick_params(axis='x', which='major', width=1.5)\n",
        "plt.tick_params(axis='y', which='major', width=1.5)\n",
        "\n",
        "plt.show()\n",
        "matplotlib.pyplot.savefig('filename.png')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oapxWkD16fHg"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
