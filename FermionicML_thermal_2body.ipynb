{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguschanchu/FermionicML/blob/main/FermionicML_thermal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXz5cOlVwrzZ"
      },
      "source": [
        "# FermionicML:\n",
        "\n",
        "Code based on aguschanchu/Bosonic.py\n",
        "\n",
        "A diferencia del código anterior, este modelo trabaja sobre estados térmicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD2Yai55rMm"
      },
      "source": [
        "## Código base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgf9ExZN4jA7"
      },
      "source": [
        "Cargamos el código de Bosonic.py básico, branch fermionic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gydz4kCH4l5w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/tmp/ipykernel_79583/1185515907.py:248: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  def gamma_lamba_inv(x):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import binom\n",
        "from scipy.sparse import dok_matrix, linalg\n",
        "from scipy import linalg as linalg_d\n",
        "from joblib import Memory\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from joblib import Parallel, delayed\n",
        "from numba import jit, prange, njit\n",
        "import numba as nb\n",
        "import pickle\n",
        "import math\n",
        "import tensorflow_probability as tfp\n",
        "\n",
        "# Funciones auxiliares optimiadas\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def int_to_tuple_arr(ni,nf, b, digits=None):\n",
        "    sol = np.zeros((nf-ni, digits), dtype=np.int64)\n",
        "    for n in prange(ni, nf):\n",
        "        r = np.zeros(digits, dtype=np.int64)\n",
        "        ncop = n\n",
        "        idx = 0\n",
        "        while n != 0:\n",
        "            r[idx] = n % b\n",
        "            n = n // b\n",
        "            idx += 1\n",
        "        if digits is not None:\n",
        "            if idx < digits:\n",
        "                for i in range(idx, digits):\n",
        "                    r[i] = 0\n",
        "                idx = digits\n",
        "        sol[ncop-ni,:] = r[:idx]\n",
        "    return sol\n",
        "\n",
        "def tuple_to_int(t, d):\n",
        "    b = d-1\n",
        "    l = len(t)\n",
        "    s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "    return sum(s)\n",
        "\n",
        "def create_basis_(m, d, size):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 1000000\n",
        "    for x in range(0,(m+1)**d, chunk_size):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        arr = int_to_tuple_arr(start_index, end_index, m+1, d)\n",
        "        sums = np.sum(arr, axis=1)\n",
        "        rows = np.where(sums == m)[0]\n",
        "        for row in [arr[i] for i in rows]:\n",
        "            if np.all(np.logical_or(row == 0, row == 1)):\n",
        "                base.append(row)\n",
        "\n",
        "    # Como consecuencia de la paralelizacion, es necesario reordenar la base\n",
        "    sorted_base = sorted(base, key=lambda x: tuple_to_int(x, d), reverse=True)\n",
        "    assert len(base) == size\n",
        "\n",
        "    return sorted_base\n",
        "\n",
        "class fixed_basis:\n",
        "\n",
        "    # Convierte a un enterno n a su escritura en base b\n",
        "    def _int_to_tuple(self, n, b, digits = None):\n",
        "        rep = np.base_repr(n, b)\n",
        "        rep_int = [int(x,b) for x in rep]\n",
        "        if digits is not None:\n",
        "            zeros = [0 for i in range(0,digits-len(rep))]\n",
        "            return zeros + rep_int\n",
        "        else:\n",
        "            return rep_int\n",
        "\n",
        "    # Revierte la transformacion anterior\n",
        "    def tuple_to_int(self, t):\n",
        "        b = self.d-1\n",
        "        l = len(t)\n",
        "        s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "        return sum(s)\n",
        "\n",
        "    # Convierte el vector en su representacion\n",
        "    def vect_to_repr(self, vect):\n",
        "        for i, k in enumerate(vect):\n",
        "            if k == 1. or k == 1:\n",
        "                break\n",
        "        else:\n",
        "            return 0\n",
        "        return self.base[i,:]\n",
        "\n",
        "    def rep_to_vect(self, rep):\n",
        "        rep = list(rep)\n",
        "        for i, r in [(j, self.base[j,:]) for j in range(0,self.size)]:\n",
        "            if list(r) == rep:\n",
        "                return self.canonicals[:,i]\n",
        "        else:\n",
        "            None\n",
        "\n",
        "    def rep_to_index(self, rep):\n",
        "        return self.base.tolist().index(list(rep))\n",
        "\n",
        "    @staticmethod\n",
        "    def rep_to_exi(rep):\n",
        "        r = []\n",
        "        for i, k in enumerate(rep):\n",
        "            r += [i for x in range(0,k)]\n",
        "        return r\n",
        "\n",
        "    # Crea base de M particulas en D estados (repr y base canonica)\n",
        "    def create_basis(self, m, d):\n",
        "        #print(\"Creating basis: \", m, d)\n",
        "        length = int(binom(d,m))\n",
        "        base = np.array(create_basis_(m, d, length))\n",
        "        # Asignamos a cada uno de ellos un canónico\n",
        "        canonicals = np.eye(length)\n",
        "        return base, canonicals\n",
        "\n",
        "    def __init__(self, m, d):\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        self.size = int(binom(d,m))\n",
        "        (self.base, self.canonicals) = self.create_basis(m, d)\n",
        "\n",
        "\n",
        "# Matrices de aniquilación y creación endomórficas. Estan fuera de la clase para poder ser cacheadas\n",
        "#@memory.cache\n",
        "def bdb(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0 and v[i] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[j] -= 1\n",
        "                dest[i] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[i]+1)*np.sqrt(v[j])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0:\n",
        "                mat[k, k] = v[i]\n",
        "    return mat\n",
        "\n",
        "#@memory.cache\n",
        "def bbd(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 0 and v[j] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[i] -= 1\n",
        "                dest[j] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[j]+1)*np.sqrt(v[i])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 1:\n",
        "                mat[k, k] = v[i]+1\n",
        "    return mat\n",
        "\n",
        "# Matrices de aniquilación y creación.Toman la base de origen y destino (basis_o, basis_d) resp\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def b_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 0:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] -= 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i])\n",
        "    return mat\n",
        "\n",
        "def b(basis_o, basis_d, i):\n",
        "    return b_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def bd_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 1:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd(basis_o, basis_d, i):\n",
        "    return bd_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "\n",
        "# Acepta una lista de indices a crear\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def bd_gen_aux(basis_o, basis_d, gen_list):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        conds = np.zeros(len(gen_list), dtype=np.int64)\n",
        "        for i in range(len(gen_list)):\n",
        "            if basis_o[k][gen_list[i]] != 1:\n",
        "                conds[i] = 1\n",
        "        if np.all(conds):\n",
        "            dest = list(basis_o[k].copy())\n",
        "            for i in gen_list:\n",
        "                dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd_gen(basis_o, basis_d, i):\n",
        "    return bd_gen_aux(basis_o.base, basis_d.base, np.array(i))\n",
        "\n",
        "def b_gen(basis_o, basis_d, i):\n",
        "    return np.transpose(bd_gen(basis_d, basis_o, i))\n",
        "\n",
        "# Volvemos a definir la función para compilarla\n",
        "@nb.jit(forceobj=True)\n",
        "def _rep_to_index(base, rep):\n",
        "    return base.tolist().index(list(rep))\n",
        "\n",
        "# Funciones auxiliares para calcular rho2kkbar y gamma_p\n",
        "@nb.jit(nopython=True)\n",
        "def rep_to_exi(rep):\n",
        "    r = []\n",
        "    for i in range(len(rep)):\n",
        "        for j in range(rep[i]):\n",
        "            r.append(i)\n",
        "    return r\n",
        "\n",
        "@nb.njit\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "@nb.njit\n",
        "def gamma_lamba(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.jit\n",
        "def gamma_lamba_inv(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / np.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.njit\n",
        "def rep_to_index_np(base, rep):\n",
        "    for i in range(len(base)):\n",
        "        if np.all(base[i] == rep):\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "\n",
        "def gamma_p(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    return gamma_p_aux(basis.base, vect, m_basis.base, nm_basis.base)\n",
        "\n",
        "@nb.njit()\n",
        "def gamma_p_aux(basis, vect, m_basis, nm_basis):\n",
        "    mat = np.zeros((len(m_basis), len(nm_basis)), dtype=np.float32)\n",
        "    for i in prange(len(m_basis)):\n",
        "        v = m_basis[i]\n",
        "        for j in prange(len(nm_basis)):\n",
        "            w = nm_basis[j]\n",
        "            targ = v + w\n",
        "            index = rep_to_index_np(basis, targ)\n",
        "            if index != -1:\n",
        "                coef = vect[index]\n",
        "                if coef != 0:\n",
        "                    coef = coef * gamma_lamba_inv(v) * gamma_lamba_inv(w) * gamma_lamba(targ)\n",
        "                mat[i, j] = coef\n",
        "    return mat\n",
        "# Devuelve la matriz rho M asociada al vector\n",
        "def rho_m(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    g = gamma_p(basis, m, vect, m_basis, nm_basis)\n",
        "    return np.dot(g,np.transpose(g))\n",
        "\n",
        "# Devuelve la matriz gamma asociada a la descomposición (M,N-M) del vector\n",
        "@jit(forceobj=True)\n",
        "def gamma(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    mat = dok_matrix((m_basis.size, nm_basis.size), dtype=np.float32)\n",
        "    for i, v in enumerate(m_basis.base):\n",
        "        for j, w in enumerate(nm_basis.base):\n",
        "            targ = v+w\n",
        "            # Revisamos que sea un estado fermionico valido\n",
        "            arr = np.asarray(targ)\n",
        "            if not np.all(np.logical_or(arr == 0, arr == 1)):\n",
        "                continue\n",
        "            index = _rep_to_index(basis.base, targ)\n",
        "            coef = vect[index]\n",
        "            if coef != 0:\n",
        "                aux = lambda x: np.prod(np.reciprocal(np.sqrt([np.math.factorial(o) for o in x])))\n",
        "                aux_inv = lambda x: np.prod(np.sqrt([np.math.factorial(o) for o in x]))\n",
        "                coef = coef * aux(v) * aux(w) * aux_inv(targ)\n",
        "                #coef = coef\n",
        "                #print(v,w,coef)\n",
        "            mat[i,j] = coef\n",
        "    return mat\n",
        "\n",
        "# Genera las matrices de rho1\n",
        "def rho_1_gen(basis):\n",
        "    d = basis.d\n",
        "    s = basis.size\n",
        "    mat = np.empty((d,d,s,s), dtype=np.float32)\n",
        "    for i in range(0, d):\n",
        "        for j in range(0, d):\n",
        "            mat[i,j,:,:] = np.array(bdb(basis,j, i).todense())\n",
        "    return mat\n",
        "\n",
        "#@jit(parallel=True, nopython=True)\n",
        "def rho_1(d, state, rho_1_arrays):\n",
        "    state_expanded = state[np.newaxis, np.newaxis, :, :]\n",
        "    product = state_expanded * rho_1_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "\n",
        "    return mat\n",
        "\n",
        "\n",
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "\n",
        "    return mat\n",
        "\n",
        "def rho_2(size, state, rho_2_arrays):\n",
        "    state_expanded = state[np.newaxis, np.newaxis, :, :]\n",
        "    product = state_expanded * rho_2_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "\n",
        "    return mat\n",
        "\n",
        "# Devuelve la matriz rho 2 asociada al bloque kkbar\n",
        "def rho_2_kkbar(basis, vect, ml_basis = None, mll_basis = None, t_basis = None):\n",
        "    d = basis.d\n",
        "    # Creo las bases si no están dadas\n",
        "    if ml_basis == None or mll_basis == None or t_basis == None:\n",
        "        ml_basis = fixed_basis(m-1,d)\n",
        "        mll_basis = fixed_basis(m-2,d)\n",
        "        t_basis = fixed_basis(2,d)\n",
        "    diag = []\n",
        "    for v in t_basis.base:\n",
        "        for j in range(0, d, 2):\n",
        "            if v[j] == v[j+1]:\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            diag.append(v)\n",
        "    diag = np.array(diag)\n",
        "    return rho_2_kkbar_aux(diag, vect, basis.base, ml_basis.base, mll_basis.base, t_basis.base)\n",
        "\n",
        "@nb.njit\n",
        "def rho_2_kkbar_lambda(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.njit(parallel=True)\n",
        "def rho_2_kkbar_aux(diag, vect, basis, ml_basis, mll_basis, t_basis):\n",
        "    mat = np.zeros((len(diag), len(diag)), dtype=np.float32)\n",
        "    for i in prange(len(diag)):\n",
        "        for j in prange(len(diag)):\n",
        "            v = diag[i]\n",
        "            w = diag[j]\n",
        "            # Creacion de los a\n",
        "            i_set = rep_to_exi(v)\n",
        "            b_m = b_aux(ml_basis, mll_basis, i_set[1]) @ b_aux(basis, ml_basis, i_set[0])\n",
        "            # Creacion de los ad\n",
        "            i_set = rep_to_exi(w)\n",
        "            bd_m = bd_aux(ml_basis, basis, i_set[1]) @ bd_aux(mll_basis, ml_basis, i_set[0])\n",
        "            v1 = bd_m @ b_m @ vect\n",
        "            # Mult de b's y filleo de mat\n",
        "            coef = vect @ v1\n",
        "            rho_2_kkbar_lambda(v)\n",
        "            mat[i,j] = coef * rho_2_kkbar_lambda(v) * rho_2_kkbar_lambda(w)\n",
        "    return mat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dga5Xx_5vDf"
      },
      "source": [
        "## Definicion de Hamiltoniano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiTq53L5E1U"
      },
      "source": [
        "Cargamos el código de creación y resolución de Hamiltonianos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h5FXWv849Mq",
        "outputId": "49dd47b5-8c16-4ad4-92e7-e172462229b3"
      },
      "outputs": [],
      "source": [
        "m = 3\n",
        "d = 6\n",
        "# Creo las bases para no tener que recrearlas luego\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "PToiSs915TXw"
      },
      "outputs": [],
      "source": [
        "## Usamos este approach si queremos guardar los generadores\n",
        "# Dados 1/2 (d^2+d) elementos, genera una mat de dxd:\n",
        "def sym_mat_gen(vect, d):\n",
        "    matrix = fill_matrix(vect, d)\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "@jit(nopython=True)\n",
        "def fill_matrix(vect, d):\n",
        "    matrix = np.zeros((d, d))\n",
        "    idx = 0\n",
        "    for i in prange(d):\n",
        "        for j in prange(i, d):\n",
        "            matrix[i, j] = vect[idx]\n",
        "            idx += 1\n",
        "    return matrix\n",
        "\n",
        "# Generamos una matrix aleatoria. Cuidado con la distribución, ver https://stackoverflow.com/questions/56605189/is-there-an-efficient-way-to-generate-a-symmetric-random-matrix\n",
        "def hamil_base_gen(d):\n",
        "    U = np.random.uniform(low=0, high=1.0, size=(d, d))\n",
        "    hamil_base = np.tril(U) + np.tril(U, -1).T\n",
        "    return hamil_base\n",
        "\n",
        "# Dada un a mat dxd simetrica, contruye el hamiltoniano de un cuerpo a_{ij} c^{dag}_i c_j\n",
        "# Alternativamente podemos construirlo a partir de rho_1_gen\n",
        "def base_hamiltonian_aux(mat, size, d, rho_1_gen):\n",
        "    # Construccion de H\n",
        "    rho_1_gen_transposed = rho_1_gen.transpose(1, 0, 2, 3)\n",
        "    mat_expanded = mat[:, :, np.newaxis, np.newaxis]\n",
        "    h = np.sum(mat_expanded * rho_1_gen_transposed[:, :, :, :], axis=(0, 1))\n",
        "    return h.astype(np.float32)\n",
        "\n",
        "def base_hamiltonian(mat, basis, rho_1_gen):\n",
        "    return base_hamiltonian_aux(mat, basis.size, basis.d, rho_1_gen)\n",
        "\n",
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2))) + eps * np.random.random((2*m,2*m))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    offset = 4*m+1\n",
        "    indices = [-(k-1)*(2*k-offset) for k in range(1,m+1)] # Lo saque de Mathmatica, vos confia\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    \n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "\n",
        "    hi = -np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    return (h0, hi)\n",
        "\n",
        "def solve(h, last_step = None):\n",
        "    sol = linalg.eigsh(h, which='SA',k=19)\n",
        "    eigenspace_tol = 0.0001\n",
        "    if type(last_step) != type(None):\n",
        "        # Seleccionamos todos los autovects que difieren sus autovalores menos que tol (mismo autoespacio)\n",
        "        # y tomamos la proyección en el autoespacio de la solución del paso anterior (last_step)\n",
        "        eig = sol[0].real\n",
        "        eigv = sol[1]\n",
        "        cand = [eigv[:,i].real  for (i, x) in enumerate(eig) if abs(x-min(eig)) < eigenspace_tol]\n",
        "        cand_norm = [x/np.linalg.norm(x) for x in cand]\n",
        "        fund = np.zeros(len(cand[0]))\n",
        "        for x in cand_norm:\n",
        "            fund += np.dot(last_step,x) * x\n",
        "    else:\n",
        "        argmin = np.argmin(sol[0].real)\n",
        "        fund = sol[1][:,argmin]\n",
        "    fund = fund.real / np.linalg.norm(fund)\n",
        "    return fund"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emVBTg2QD-Fg"
      },
      "source": [
        "## Modelo de ML\n",
        "Basado en matrices densidad de 1 y 2 cuerpos como input, con hamiltoniano como salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "id": "aF_Ec_mCGX96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-04 14:00:47.205080: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "''"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-04 14:00:47.205298: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.test.gpu_device_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDoa6LUJJ8O",
        "outputId": "73481454-fbcb-469f-d72f-cd0f8d534808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "15\n",
            "[[1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1]]\n",
            "6\n",
            "[[1 0 0 0 0 0]\n",
            " [0 1 0 0 0 0]\n",
            " [0 0 1 0 0 0]\n",
            " [0 0 0 1 0 0]\n",
            " [0 0 0 0 1 0]\n",
            " [0 0 0 0 0 1]]\n"
          ]
        }
      ],
      "source": [
        "# Construccion de bases para calculo de rho1 y rho2\n",
        "# rho2\n",
        "m = 2\n",
        "m2_basis = fixed_basis(m, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-m, d)\n",
        "print(nm2_basis.base)\n",
        "# rho1\n",
        "m = 1\n",
        "m1_basis = fixed_basis(m, d)\n",
        "print(m1_basis.size)\n",
        "print(m1_basis.base)\n",
        "nm1_basis = fixed_basis(basis.m-m, d)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapxWkD16fHg"
      },
      "source": [
        "### Algunos benchmarks y funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "umCIrxCZKXQd"
      },
      "outputs": [],
      "source": [
        "# Given h calculo en rho2 y rho1 máximo\n",
        "def rho1_rho2(h, beta):\n",
        "    fund = thermal_state(h, beta)\n",
        "    rho2 = np.array(rho_2(basis, m2_basis.size, state, rho_2_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho2).real)\n",
        "    rho_2_max = r[0]\n",
        "    rho1 = np.array(rho_1(basis, state, rho_1_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho1).real)\n",
        "    rho_1_max = r[0]\n",
        "\n",
        "    return (rho_1_max, rho_2_max)\n",
        "\n",
        "def fill_triangular_np(x):\n",
        "    m = x.shape[0]\n",
        "    n = np.int32(np.sqrt(.25 + 2 * m) - .5)\n",
        "    x_tail = x[(m - (n**2 - m)):]\n",
        "    return np.triu(np.concatenate([x, x_tail[::-1]], 0).reshape(n, n))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "QaNnIIc5bZux"
      },
      "outputs": [],
      "source": [
        "# TEST: Las funciones de TF y comunes coinciden\n",
        "\n",
        "# Dado h, \\beta, construyo el estado térmico\n",
        "from scipy.linalg import expm\n",
        "\n",
        "def thermal_state(h, beta):\n",
        "    quotient = expm(-beta*h)\n",
        "    return quotient / np.trace(quotient)\n",
        "\n",
        "## NO usar para mat no hermiticas\n",
        "@nb.jit(nopython=True)\n",
        "def thermal_state_eig(h, beta):\n",
        "    w, v = np.linalg.eigh(-beta*h)\n",
        "    D = np.diag(np.exp(w))\n",
        "    mat = v @ D @ v.T\n",
        "    mat = mat / np.trace(mat)\n",
        "    return mat\n",
        "    \n",
        "def gen_to_h(base, rho_1_arrays):\n",
        "    triag = fill_triangular_np(base)\n",
        "    body_gen = triag + np.transpose(triag)-np.diag(np.diag(triag))\n",
        "    h = np.array(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
        "    return h \n",
        "\n",
        "def gen_to_h_1b(hamil_base):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "    return body_gen\n",
        "\n",
        "def gen_to_h_tf(hamil_base, rho_1_arrays):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag)) # Simetrizamos y generamos la matriz de h\n",
        "    hamil_expanded = body_gen[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    h_arr = tf.reduce_sum(hamil_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "    return h_arr\n",
        "\n",
        "def thermal_state_tf(h):\n",
        "    # Assume beta=1\n",
        "    exp_hamiltonian = tf.linalg.expm(-h)\n",
        "    partition_function = tf.linalg.trace(exp_hamiltonian)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    \n",
        "    rho = exp_hamiltonian / partition_function\n",
        "\n",
        "    return rho\n",
        "\n",
        "def rho_1_tf(state, rho_1_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_1_arrays_expanded = tf.expand_dims(rho_1_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_1_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "def rho_2_tf(state, rho_2_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_2_arrays_expanded = tf.expand_dims(rho_2_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_2_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "def rho_1_gc_tf(hamil_base):\n",
        "    e, v = tf.linalg.eigh(gen_to_h_1b(hamil_base))\n",
        "    result = 1 / (1 + tf.exp(e))\n",
        "    result = tf.linalg.diag(result)\n",
        "    res = tf.linalg.matmul(v,result)\n",
        "    res = tf.linalg.matmul(res,v,adjoint_b=True)\n",
        "    \n",
        "    return tf.cast(res, tf.float32)\n",
        "\n",
        "# Aux function\n",
        "def outer_product(vector):\n",
        "    return tf.einsum('i,j->ij', vector, vector)\n",
        "\n",
        "def pure_state(h):\n",
        "    e, v = tf.linalg.eigh(h)\n",
        "    fund = v[:,:,0]\n",
        "    d = tf.map_fn(outer_product, fund)\n",
        "    return d\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylpy_BCw6jxF"
      },
      "source": [
        "### Construccion de dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Version sincrónica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2is_Eo_qGpEz",
        "outputId": "9a968190-59f2-4695-ef18-b99ff5b4a212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-04 14:28:29.387750: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-04 14:28:29.387956: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 1 1] [0 1 1 0 0 0]\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 49/49 [01:12<00:00,  1.49s/it]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "# Config\n",
        "num_samples = 50000\n",
        "use_gpu = True\n",
        "gpu_batch_size = 1024\n",
        "\n",
        "# Construccion de parametros y matrices auxiliares\n",
        "rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "fund_size = basis.size\n",
        "hamil_base_size = basis.d*(basis.d+1)//2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_1_arrays_tf = tf.constant(rho_1_arrays, dtype=tf.float32)\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "\n",
        "\n",
        "if use_gpu:\n",
        "    print(tf.test.gpu_device_name())\n",
        "    datasets = []\n",
        "    for i in tqdm(range(num_samples//gpu_batch_size+1)):\n",
        "        size = basis.d*(basis.d+1)//2\n",
        "        # En una primera versión vamos a pasar una mat proporcional a range(0,m) para energias\n",
        "        # y como interacción una cte G por ones(m,m)\n",
        "        h_labels = [(np.random.rand(), np.random.rand()) for _ in range(0,gpu_batch_size)] # Generamos los generadores\n",
        "        hamil_base = tf.constant(h_labels, dtype=tf.float32)\n",
        "        h_arr = np.zeros((gpu_batch_size, basis.size, basis.size))\n",
        "        for i, (e, g) in enumerate(h_labels):\n",
        "            (h0, hi) = two_body_hamiltonian(t_basis.size, basis.m, e*np.arange(0, basis.m), g * np.ones((m,m)), rho_1_arrays_tf, rho_2_arrays_tf)\n",
        "            h_arr[i,:,:] = h0 + hi\n",
        "        # Estados térmicos\n",
        "        state = thermal_state_tf(h_arr) \n",
        "        state = tf.cast(state, dtype=tf.float32)\n",
        "        # Estados puros\n",
        "        #state = pure_state(h_arr)\n",
        "        #rho_1_input = rho_1_tf(state, rho_1_arrays_tf)\n",
        "        rho_2_input = rho_2_tf(state, rho_2_arrays_tf)\n",
        "\n",
        "        datasets.append(tf.data.Dataset.from_tensor_slices(((rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input, state), h_labels)))\n",
        "    ds = tf.data.Dataset.from_tensor_slices(datasets)\n",
        "    dataset = ds.interleave(\n",
        "        lambda x: x,\n",
        "        cycle_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "\n",
        "#batch_size = 32\n",
        "#dataset = dataset.shuffle(buffer_size=num_samples).batch(batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tf.float64"
            ]
          },
          "execution_count": 86,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "thermal_state_tf(h_arr).dtype"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Filleo de dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Save and load dataset\n",
        "save_dataset = False\n",
        "load_dataset = False\n",
        "path = \"/home/agus/TF\"\n",
        "#num_samples = 5000000\n",
        "if save_dataset:\n",
        "    tf.data.Dataset.save(dataset, path)\n",
        "    with open(\"/home/agus/\"+'/file.pkl', 'wb') as file:\n",
        "        pickle.dump(beta_input, file)\n",
        "if load_dataset:\n",
        "    dataset = tf.data.Dataset.load(path)\n",
        "    with open(\"/home/agus/\"+'file.pkl', 'rb') as file:\n",
        "        beta_input = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "8moZIlfabZuy"
      },
      "outputs": [],
      "source": [
        "# Dividimos los datasets\n",
        "train_size = int(0.8 * num_samples)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "\n",
        "batch_size = 256\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "#beta_val = beta_input[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cardinality no funciona con los datasets generados por GPU\n",
        "val_size = tf.data.experimental.cardinality(val_dataset).numpy()\n",
        "print(\"Validation Dataset Size:\", val_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "state = thermal_state_tf(h_arr)\n",
        "mat = rho_1_gc_tf(h_labels) - rho_1_tf(state, rho_1_arrays_tf)\n",
        "\n",
        "np.mean(tf.norm(tf.reshape(mat, (-1,4,4)), ord='fro', axis=[-1,-2]))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYEEjNB-7b8y"
      },
      "source": [
        "### Definición de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZBtonvGbZuz",
        "outputId": "f197277e-a84b-4ffd-c81f-c81581707fb1"
      },
      "outputs": [],
      "source": [
        "# Modelo denso + fundamental\n",
        "rho1_layer =  tf.keras.layers.Input(shape=(rho1_size,rho1_size, 1), name='rho1')\n",
        "flatten_rho1 = tf.keras.layers.Flatten()(rho1_layer)\n",
        "#rho2_layer =  tf.keras.layers.Input(shape=(rho2_size,rho2_size, 1), name='rho2')\n",
        "#flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#fund_layer =  tf.keras.layers.Input(shape=(fund_size, fund_size, 1 ), name='fund')\n",
        "#flatten_fund = tf.keras.layers.Flatten()(fund_layer)\n",
        "\n",
        "dense1 = tf.keras.layers.concatenate([flatten_rho1])\n",
        "#dense1 = tf.keras.layers.concatenate([dense1, flatten_fund])\n",
        "dense1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(dense1)\n",
        "\n",
        "local_size = hamil_base_size\n",
        "l=10\n",
        "layer_s = [1024//i for i in range(1,l)]\n",
        "for i in range(0,l):\n",
        "    dense1 = tf.keras.layers.Dense(layer_s[-i], activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "# Creamos el modelo y compulamos\n",
        "model = tf.keras.models.Model(inputs=[rho1_layer], outputs=output)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "execution_count": 94,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "rho1_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8kkhJr5K0ZQ",
        "outputId": "f1b731f1-6a02-4181-f0b5-5677a2a85784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 15, 15, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_19 (Conv2D)          (None, 14, 14, 32)        160       \n",
            "                                                                 \n",
            " batch_normalization_18 (Ba  (None, 14, 14, 32)        128       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 13, 13, 16)        2064      \n",
            "                                                                 \n",
            " batch_normalization_19 (Ba  (None, 13, 13, 16)        64        \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " max_pooling2d_8 (MaxPoolin  (None, 6, 6, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 576)               0         \n",
            "                                                                 \n",
            " dense_24 (Dense)            (None, 24)                13848     \n",
            "                                                                 \n",
            " dense_25 (Dense)            (None, 2)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16314 (63.73 KB)\n",
            "Trainable params: 16218 (63.35 KB)\n",
            "Non-trainable params: 96 (384.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Definicion de layers basado en Conv 2D\n",
        "\n",
        "# Factor de cantidad de filtros\n",
        "lf = 8  \n",
        "conv_limit = (rho2_size - 4) // 4 \n",
        "initial_dense = (lf*2**(conv_limit-1)*((rho2_size-(conv_limit-1))//2)**2) // 8\n",
        "## rho 1\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(rho2_size,rho2_size, 1), name='rho2')\n",
        "\n",
        "# Procesamos el primer input\n",
        "conv_rho2 = tf.keras.layers.Conv2D(lf*2**conv_limit, (2, 2), activation='relu')(rho2_layer)\n",
        "conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "for j in [(2**conv_limit - 2**k) for k in range(1,conv_limit)]:\n",
        "    conv_rho2 = tf.keras.layers.Conv2D(lf*j, (2, 2), activation='relu')(conv_rho2 if 2**j != 1 else rho1_layer)\n",
        "    conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "\n",
        "conv_rho2 = tf.keras.layers.MaxPooling2D((2, 2))(conv_rho2)\n",
        "\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(conv_rho2)\n",
        "#flatten_rho1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(flatten_rho1)\n",
        "\n",
        "#local_size = basis.size*basis.size\n",
        "local_size = hamil_base_size\n",
        "\n",
        "#dense1 = tf.keras.layers.Dense(8*8*4*4, activation='relu')(dense1)\n",
        "#dense1 = tf.keras.layers.Dense(512, activation='relu')(flatten_rho1)\n",
        "#dense1 = tf.keras.layers.Dense(128, activation='relu')(flatten_rho1)\n",
        "dense1 = tf.keras.layers.Dense(initial_dense // 4, activation='relu')(flatten_rho2)\n",
        "#dense1 = tf.keras.layers.Dense(initial_dense//2, activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(2)(dense1)\n",
        "\n",
        "\n",
        "# Creamos el modelo y compulamos\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer, fund_layer], outputs=output)\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer], outputs=output)\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "id": "RgoMlCyyfBe-"
      },
      "outputs": [],
      "source": [
        "# LOSS FUNCTIONS\n",
        "r_size = basis.size\n",
        "\n",
        "# Custom loss function based on GS MSE\n",
        "def gs_loss(h_pred, h_true):\n",
        "    h_pred = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_pred)\n",
        "    gs_pred = v[:, 0]\n",
        "\n",
        "    h_true = tf.reshape(h_true, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_true)\n",
        "    gs_true = v[:, 0]\n",
        "\n",
        "    gs_diff = tf.norm(gs_true - gs_pred)\n",
        "\n",
        "    return gs_diff + tf.reduce_mean(tf.square(h_true - h_pred)) * 100\n",
        "\n",
        "def distance_to_hermitian(matrix):\n",
        "    hermitian_part = 0.5 * (matrix + tf.linalg.adjoint(matrix))\n",
        "    distance = tf.norm(matrix - hermitian_part, ord='euclidean')\n",
        "    return distance\n",
        "\n",
        "# Custom loss function based on MSE + non-hermitian penalization\n",
        "def herm_loss(h_pred, h_true):\n",
        "    h_pred_arr = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred)) + distance_to_hermitian(h_pred_arr)\n",
        "\n",
        "# Custom loss function based on h eigenvalues\n",
        "def eig_loss(h_pred, h_true):\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# MSE with a factor\n",
        "def mse_f(h_pred, h_true):\n",
        "    f = 100\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred))*f\n",
        "\n",
        "# Spectral radius loss\n",
        "def spectral_loss(h_pred, h_true):\n",
        "    eig = tf.math.real(tf.linalg.eigvals(tf.reshape(h_true-h_pred, (-1, fund_size, fund_size))))\n",
        "    return tf.math.reduce_max(tf.abs(eig))\n",
        "\n",
        "# Hamiltonian MSE loss (using generators)\n",
        "def base_mse_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    mat = tf.reshape(h_pred-h_true, (-1, fund_size, fund_size))\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on h eigenvalues (using generators)\n",
        "def base_eig_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals\n",
        "## Auxiliary function\n",
        "def base_to_rho_1_tf(base_pred):\n",
        "    h = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h = tf.reshape(h, (-1, fund_size, fund_size))\n",
        "    state = thermal_state_tf(h)\n",
        "    rho1 = rho_1_tf(state, rho_1_arrays_tf)\n",
        "    return rho1\n",
        "    \n",
        "def rho1_loss(base_pred, base_true):\n",
        "    mat = base_to_rho_1_tf(base_pred) - base_to_rho_1_tf(base_true)\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals (using generators)\n",
        "def base_rho1_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    return tf.reduce_mean(tf.square(rho_1_eig_tf(h_pred) - rho_1_eig_tf(h_true)))*1000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWk9piJtNIZ"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhJCHf0fQdRl",
        "outputId": "1821cf27-9ff5-4d67-e9f5-956d20eda5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-04 14:34:56.118791: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:995] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
            "2023-12-04 14:34:56.119084: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1960] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
            "Skipping registering GPU devices...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "157/157 [==============================] - 8s 42ms/step - loss: 0.0308 - accuracy: 0.9167 - mean_squared_error: 0.0308 - val_loss: 0.3442 - val_accuracy: 0.3978 - val_mean_squared_error: 0.3442\n",
            "Epoch 2/10\n",
            "157/157 [==============================] - 6s 36ms/step - loss: 4.4701e-04 - accuracy: 0.9799 - mean_squared_error: 4.4701e-04 - val_loss: 0.5016 - val_accuracy: 0.5043 - val_mean_squared_error: 0.5016\n",
            "Epoch 3/10\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 5.4513e-04 - accuracy: 0.9802 - mean_squared_error: 5.4513e-04 - val_loss: 0.3592 - val_accuracy: 0.9382 - val_mean_squared_error: 0.3592\n",
            "Epoch 4/10\n",
            "157/157 [==============================] - 6s 39ms/step - loss: 7.6620e-04 - accuracy: 0.9812 - mean_squared_error: 7.6620e-04 - val_loss: 0.1270 - val_accuracy: 0.9600 - val_mean_squared_error: 0.1270\n",
            "Epoch 5/10\n",
            "157/157 [==============================] - 6s 37ms/step - loss: 7.8765e-04 - accuracy: 0.9809 - mean_squared_error: 7.8765e-04 - val_loss: 0.0143 - val_accuracy: 0.9814 - val_mean_squared_error: 0.0143\n",
            "Epoch 6/10\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 7.1471e-04 - accuracy: 0.9820 - mean_squared_error: 7.1471e-04 - val_loss: 4.2524e-04 - val_accuracy: 0.9814 - val_mean_squared_error: 4.2524e-04\n",
            "Epoch 7/10\n",
            "157/157 [==============================] - 7s 43ms/step - loss: 6.6207e-04 - accuracy: 0.9834 - mean_squared_error: 6.6207e-04 - val_loss: 4.4649e-04 - val_accuracy: 0.9759 - val_mean_squared_error: 4.4649e-04\n",
            "Epoch 8/10\n",
            "157/157 [==============================] - 6s 39ms/step - loss: 5.8374e-04 - accuracy: 0.9850 - mean_squared_error: 5.8374e-04 - val_loss: 2.5087e-04 - val_accuracy: 0.9825 - val_mean_squared_error: 2.5087e-04\n",
            "Epoch 9/10\n",
            "157/157 [==============================] - 7s 47ms/step - loss: 5.4740e-04 - accuracy: 0.9847 - mean_squared_error: 5.4740e-04 - val_loss: 2.3875e-04 - val_accuracy: 0.9801 - val_mean_squared_error: 2.3875e-04\n",
            "Epoch 10/10\n",
            "157/157 [==============================] - 6s 38ms/step - loss: 5.5072e-04 - accuracy: 0.9851 - mean_squared_error: 5.5072e-04 - val_loss: 1.0159e-04 - val_accuracy: 0.9872 - val_mean_squared_error: 1.0159e-04\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam, Lion\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='MSE',  \n",
        "              metrics=['accuracy', 'mean_squared_error'])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 10\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    history = model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "cvpE_X1iTXcB",
        "outputId": "eff0e5f5-5b26-46ea-ec6b-491d1de9944c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history.history['mean_squared_error'], label='Training MSE')\n",
        "plt.plot(history.history['val_mean_squared_error'], label='Validation MSE')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs. Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# MIN LOSS = 0.0128 c/fund 50epochs MSE\n",
        "##         = 0.0118 s/fund 50epochs MSE\n",
        "##         = 0.0039 s/fund 50epochs MSE m=4 d=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRlZuRUNa6Yb",
        "outputId": "85850559-311b-4cf4-ea5b-465a9ee8a7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 3ms/step\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a validation dataset (val_dataset)\n",
        "sample = next(iter(val_dataset))\n",
        "input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "actual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 110,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.26914853, 0.67091185], dtype=float32)"
            ]
          },
          "execution_count": 110,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "e[1][i]\n",
        "predictions[i]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 114,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.16351028 0.5957195 ], shape=(2,), dtype=float32)\n",
            "[0.15788358 0.5940897 ]\n",
            "tf.Tensor([0.89310706 0.6147261 ], shape=(2,), dtype=float32)\n",
            "[0.891596  0.6365742]\n",
            "tf.Tensor([0.27309912 0.663904  ], shape=(2,), dtype=float32)\n",
            "[0.26914853 0.67091185]\n",
            "tf.Tensor([0.84069663 0.6104737 ], shape=(2,), dtype=float32)\n",
            "[0.8417415  0.62574387]\n",
            "tf.Tensor([0.33427617 0.46698666], shape=(2,), dtype=float32)\n",
            "[0.33122545 0.45590627]\n",
            "tf.Tensor([0.44975194 0.91498715], shape=(2,), dtype=float32)\n",
            "[0.44327474 0.9246604 ]\n",
            "tf.Tensor([0.71638596 0.36472017], shape=(2,), dtype=float32)\n",
            "[0.7078729 0.3692348]\n",
            "tf.Tensor([0.39848837 0.29656658], shape=(2,), dtype=float32)\n",
            "[0.39531022 0.29525703]\n",
            "tf.Tensor([0.53190243 0.13138205], shape=(2,), dtype=float32)\n",
            "[0.52604055 0.13820608]\n",
            "tf.Tensor([0.33070302 0.7470255 ], shape=(2,), dtype=float32)\n",
            "[0.33201957 0.75932515]\n",
            "tf.Tensor([0.60848725 0.40679607], shape=(2,), dtype=float32)\n",
            "[0.59941006 0.40859342]\n",
            "tf.Tensor([0.8430621  0.03523729], shape=(2,), dtype=float32)\n",
            "[0.8350687  0.04942579]\n",
            "tf.Tensor([0.8199744 0.8136481], shape=(2,), dtype=float32)\n",
            "[0.8167211  0.82834256]\n",
            "tf.Tensor([0.13914405 0.7791248 ], shape=(2,), dtype=float32)\n",
            "[0.13345456 0.803479  ]\n",
            "tf.Tensor([0.84558207 0.06702171], shape=(2,), dtype=float32)\n",
            "[0.83945066 0.07900199]\n",
            "tf.Tensor([0.9547835 0.4867137], shape=(2,), dtype=float32)\n",
            "[0.95153683 0.5078485 ]\n",
            "tf.Tensor([0.33409005 0.78356993], shape=(2,), dtype=float32)\n",
            "[0.33477485 0.7968121 ]\n",
            "tf.Tensor([0.90563726 0.64258385], shape=(2,), dtype=float32)\n",
            "[0.9057735 0.6658813]\n",
            "tf.Tensor([0.01545035 0.6471598 ], shape=(2,), dtype=float32)\n",
            "[0.01501995 0.65266746]\n",
            "tf.Tensor([0.65659666 0.5369665 ], shape=(2,), dtype=float32)\n",
            "[0.6474143  0.54601866]\n",
            "tf.Tensor([0.35964748 0.9484095 ], shape=(2,), dtype=float32)\n",
            "[0.3563376  0.96441203]\n",
            "tf.Tensor([0.6723874 0.605645 ], shape=(2,), dtype=float32)\n",
            "[0.6662035 0.6171937]\n",
            "tf.Tensor([0.25249192 0.5122833 ], shape=(2,), dtype=float32)\n",
            "[0.24740803 0.50542194]\n",
            "tf.Tensor([0.16140011 0.8203471 ], shape=(2,), dtype=float32)\n",
            "[0.15780836 0.84947044]\n",
            "tf.Tensor([0.47197    0.07515906], shape=(2,), dtype=float32)\n",
            "[0.46441954 0.07912687]\n",
            "tf.Tensor([0.10967183 0.10192786], shape=(2,), dtype=float32)\n",
            "[0.10982329 0.09588508]\n",
            "tf.Tensor([0.5951454 0.2559616], shape=(2,), dtype=float32)\n",
            "[0.6022342 0.2513169]\n",
            "tf.Tensor([0.34233728 0.65713114], shape=(2,), dtype=float32)\n",
            "[0.3426584  0.66891277]\n",
            "tf.Tensor([0.47678655 0.22930117], shape=(2,), dtype=float32)\n",
            "[0.47669035 0.23248382]\n",
            "tf.Tensor([0.02424753 0.8749441 ], shape=(2,), dtype=float32)\n",
            "[0.01836109 0.88969713]\n",
            "tf.Tensor([0.05223412 0.6287104 ], shape=(2,), dtype=float32)\n",
            "[0.04985422 0.6350468 ]\n",
            "tf.Tensor([0.61932707 0.23805977], shape=(2,), dtype=float32)\n",
            "[0.62665623 0.23135112]\n",
            "tf.Tensor([0.7342405 0.843023 ], shape=(2,), dtype=float32)\n",
            "[0.7262603  0.85511416]\n",
            "tf.Tensor([0.6209498  0.15593772], shape=(2,), dtype=float32)\n",
            "[0.6271721  0.15893853]\n",
            "tf.Tensor([0.31710055 0.6299388 ], shape=(2,), dtype=float32)\n",
            "[0.31476986 0.63733315]\n",
            "tf.Tensor([0.3364863 0.7585972], shape=(2,), dtype=float32)\n",
            "[0.33766055 0.7710919 ]\n",
            "tf.Tensor([0.65052235 0.6842391 ], shape=(2,), dtype=float32)\n",
            "[0.6427463  0.69335306]\n",
            "tf.Tensor([0.43784174 0.16370131], shape=(2,), dtype=float32)\n",
            "[0.43502998 0.16742884]\n",
            "tf.Tensor([0.30252522 0.869624  ], shape=(2,), dtype=float32)\n",
            "[0.30428785 0.88882965]\n",
            "tf.Tensor([0.4100892 0.835666 ], shape=(2,), dtype=float32)\n",
            "[0.404818  0.8464693]\n",
            "tf.Tensor([0.98407745 0.38072357], shape=(2,), dtype=float32)\n",
            "[0.9776827 0.400162 ]\n",
            "tf.Tensor([0.3841809 0.1084789], shape=(2,), dtype=float32)\n",
            "[0.37856048 0.11349811]\n",
            "tf.Tensor([0.26408356 0.04144195], shape=(2,), dtype=float32)\n",
            "[0.25753206 0.03000649]\n",
            "tf.Tensor([0.3447486  0.07312836], shape=(2,), dtype=float32)\n",
            "[0.3391027  0.07446008]\n",
            "tf.Tensor([0.9184713  0.89181966], shape=(2,), dtype=float32)\n",
            "[0.9084605  0.88980716]\n",
            "tf.Tensor([0.7807969  0.99946517], shape=(2,), dtype=float32)\n",
            "[0.7633432  0.98540133]\n",
            "tf.Tensor([0.16405828 0.03885948], shape=(2,), dtype=float32)\n",
            "[0.16336602 0.02510801]\n",
            "tf.Tensor([0.1733865 0.7649434], shape=(2,), dtype=float32)\n",
            "[0.1681903  0.78515637]\n",
            "tf.Tensor([0.12553468 0.608064  ], shape=(2,), dtype=float32)\n",
            "[0.11895412 0.60938656]\n",
            "tf.Tensor([0.53913474 0.42412642], shape=(2,), dtype=float32)\n",
            "[0.5285508  0.42666614]\n",
            "tf.Tensor([0.35640353 0.75066876], shape=(2,), dtype=float32)\n",
            "[0.3555925 0.7622567]\n",
            "tf.Tensor([0.09442115 0.23034321], shape=(2,), dtype=float32)\n",
            "[0.08642334 0.23475464]\n",
            "tf.Tensor([0.09393287 0.3343959 ], shape=(2,), dtype=float32)\n",
            "[0.07832652 0.33813864]\n",
            "tf.Tensor([0.871585   0.72536427], shape=(2,), dtype=float32)\n",
            "[0.87011266 0.74613875]\n",
            "tf.Tensor([0.35738212 0.29108143], shape=(2,), dtype=float32)\n",
            "[0.35164738 0.2918727 ]\n",
            "tf.Tensor([0.31407565 0.67019695], shape=(2,), dtype=float32)\n",
            "[0.31279087 0.679853  ]\n",
            "tf.Tensor([0.9767536  0.60580546], shape=(2,), dtype=float32)\n",
            "[0.972813  0.6263489]\n",
            "tf.Tensor([0.918142   0.60715556], shape=(2,), dtype=float32)\n",
            "[0.91675776 0.6317997 ]\n",
            "tf.Tensor([0.98250383 0.08770519], shape=(2,), dtype=float32)\n",
            "[0.95813465 0.10375846]\n",
            "tf.Tensor([0.29945645 0.65225565], shape=(2,), dtype=float32)\n",
            "[0.2965809 0.6609611]\n",
            "tf.Tensor([0.5237558  0.97443444], shape=(2,), dtype=float32)\n",
            "[0.504147   0.98314995]\n",
            "tf.Tensor([0.11786874 0.40110523], shape=(2,), dtype=float32)\n",
            "[0.09894484 0.40448993]\n",
            "tf.Tensor([0.97624516 0.4781637 ], shape=(2,), dtype=float32)\n",
            "[0.97219104 0.49928218]\n",
            "tf.Tensor([0.54049194 0.21769522], shape=(2,), dtype=float32)\n",
            "[0.541789   0.22211489]\n",
            "tf.Tensor([0.7021137 0.8641213], shape=(2,), dtype=float32)\n",
            "[0.6907536 0.8717963]\n",
            "tf.Tensor([0.6595852  0.59126025], shape=(2,), dtype=float32)\n",
            "[0.6530006 0.6031869]\n",
            "tf.Tensor([0.6033573  0.73171455], shape=(2,), dtype=float32)\n",
            "[0.59471333 0.74242216]\n",
            "tf.Tensor([0.7165893  0.47390202], shape=(2,), dtype=float32)\n",
            "[0.70818263 0.48233187]\n",
            "tf.Tensor([0.38238433 0.3191949 ], shape=(2,), dtype=float32)\n",
            "[0.37808526 0.3157612 ]\n",
            "tf.Tensor([0.8016274 0.1662986], shape=(2,), dtype=float32)\n",
            "[0.80078566 0.17359976]\n",
            "tf.Tensor([0.94899875 0.9254375 ], shape=(2,), dtype=float32)\n",
            "[0.93741244 0.9116234 ]\n",
            "tf.Tensor([0.58467084 0.4493341 ], shape=(2,), dtype=float32)\n",
            "[0.57299817 0.45353654]\n",
            "tf.Tensor([0.00389154 0.09530633], shape=(2,), dtype=float32)\n",
            "[0.01628571 0.07407009]\n",
            "tf.Tensor([0.9330121 0.5031673], shape=(2,), dtype=float32)\n",
            "[0.9312647 0.5231556]\n",
            "tf.Tensor([0.96793276 0.13807411], shape=(2,), dtype=float32)\n",
            "[0.94971436 0.14957605]\n",
            "tf.Tensor([0.8212023  0.65484744], shape=(2,), dtype=float32)\n",
            "[0.8244075 0.6736615]\n",
            "tf.Tensor([0.71931684 0.9560951 ], shape=(2,), dtype=float32)\n",
            "[0.7023793  0.95400995]\n",
            "tf.Tensor([0.22705759 0.9144982 ], shape=(2,), dtype=float32)\n",
            "[0.22589451 0.9419823 ]\n",
            "tf.Tensor([0.2761093  0.00704078], shape=(2,), dtype=float32)\n",
            "[ 0.26775485 -0.00515864]\n",
            "tf.Tensor([0.7304026  0.45612624], shape=(2,), dtype=float32)\n",
            "[0.72242117 0.46311182]\n",
            "tf.Tensor([0.86211413 0.47886655], shape=(2,), dtype=float32)\n",
            "[0.86239773 0.48720247]\n",
            "tf.Tensor([0.7811725 0.8003664], shape=(2,), dtype=float32)\n",
            "[0.7789113  0.81725925]\n",
            "tf.Tensor([0.5279678 0.8259668], shape=(2,), dtype=float32)\n",
            "[0.5175061  0.83489794]\n",
            "tf.Tensor([0.6855703  0.30118838], shape=(2,), dtype=float32)\n",
            "[0.68149173 0.3052745 ]\n",
            "tf.Tensor([0.41125545 0.19208786], shape=(2,), dtype=float32)\n",
            "[0.40904158 0.1958816 ]\n",
            "tf.Tensor([0.48312634 0.7684846 ], shape=(2,), dtype=float32)\n",
            "[0.4748941  0.77984244]\n",
            "tf.Tensor([0.61006   0.8895806], shape=(2,), dtype=float32)\n",
            "[0.59522015 0.89343745]\n",
            "tf.Tensor([0.3866831  0.47856724], shape=(2,), dtype=float32)\n",
            "[0.38680702 0.46985552]\n",
            "tf.Tensor([0.6909382 0.8850076], shape=(2,), dtype=float32)\n",
            "[0.67766136 0.8903031 ]\n",
            "tf.Tensor([0.46954817 0.30964518], shape=(2,), dtype=float32)\n",
            "[0.46927768 0.3057589 ]\n",
            "tf.Tensor([0.22765034 0.97942424], shape=(2,), dtype=float32)\n",
            "[0.22320604 0.99341255]\n",
            "tf.Tensor([0.29771775 0.07372279], shape=(2,), dtype=float32)\n",
            "[0.29234463 0.07013723]\n",
            "tf.Tensor([0.48267925 0.18110977], shape=(2,), dtype=float32)\n",
            "[0.48037225 0.18512355]\n",
            "tf.Tensor([0.7608244  0.79924035], shape=(2,), dtype=float32)\n",
            "[0.7570396  0.81640536]\n",
            "tf.Tensor([0.99193305 0.8000431 ], shape=(2,), dtype=float32)\n",
            "[0.98759127 0.7973466 ]\n",
            "tf.Tensor([0.449074 0.986668], shape=(2,), dtype=float32)\n",
            "[0.43929452 0.9967841 ]\n",
            "tf.Tensor([0.7515226  0.89236885], shape=(2,), dtype=float32)\n",
            "[0.74084604 0.898952  ]\n",
            "tf.Tensor([0.92928845 0.31097877], shape=(2,), dtype=float32)\n",
            "[0.92328066 0.32000908]\n",
            "tf.Tensor([0.82899445 0.07589938], shape=(2,), dtype=float32)\n",
            "[0.82503515 0.08609658]\n",
            "tf.Tensor([0.22777937 0.66634715], shape=(2,), dtype=float32)\n",
            "[0.22218037 0.6734882 ]\n",
            "tf.Tensor([0.17858636 0.10504024], shape=(2,), dtype=float32)\n",
            "[0.17467636 0.09884858]\n",
            "tf.Tensor([0.8839635 0.8644304], shape=(2,), dtype=float32)\n",
            "[0.87532693 0.8708058 ]\n",
            "tf.Tensor([0.6934814 0.6605215], shape=(2,), dtype=float32)\n",
            "[0.68850416 0.67179   ]\n",
            "tf.Tensor([0.908435  0.8177286], shape=(2,), dtype=float32)\n",
            "[0.9038999 0.8290319]\n",
            "tf.Tensor([0.6599262 0.0217999], shape=(2,), dtype=float32)\n",
            "[0.6545316 0.0344906]\n",
            "tf.Tensor([0.39250737 0.86766416], shape=(2,), dtype=float32)\n",
            "[0.38753492 0.87997365]\n",
            "tf.Tensor([0.11676218 0.831725  ], shape=(2,), dtype=float32)\n",
            "[0.10992277 0.85952514]\n",
            "tf.Tensor([0.4801976  0.52610105], shape=(2,), dtype=float32)\n",
            "[0.47414136 0.5326313 ]\n",
            "tf.Tensor([0.41841868 0.4410455 ], shape=(2,), dtype=float32)\n",
            "[0.4164858  0.43093908]\n",
            "tf.Tensor([0.1058857 0.381812 ], shape=(2,), dtype=float32)\n",
            "[0.08644754 0.38516614]\n",
            "tf.Tensor([0.22876614 0.6470417 ], shape=(2,), dtype=float32)\n",
            "[0.22356683 0.6531517 ]\n",
            "tf.Tensor([0.65757716 0.24778645], shape=(2,), dtype=float32)\n",
            "[0.66154784 0.24502468]\n",
            "tf.Tensor([0.84158885 0.5234606 ], shape=(2,), dtype=float32)\n",
            "[0.8417537 0.5343805]\n",
            "tf.Tensor([0.00974436 0.39331576], shape=(2,), dtype=float32)\n",
            "[-0.00280196  0.395936  ]\n",
            "tf.Tensor([0.85279953 0.5127287 ], shape=(2,), dtype=float32)\n",
            "[0.8526519  0.52298415]\n",
            "tf.Tensor([0.21753344 0.9654628 ], shape=(2,), dtype=float32)\n",
            "[0.21303147 0.9819029 ]\n",
            "tf.Tensor([0.47597852 0.49202785], shape=(2,), dtype=float32)\n",
            "[0.47038043 0.49409747]\n",
            "tf.Tensor([0.7328601 0.580461 ], shape=(2,), dtype=float32)\n",
            "[0.729695  0.5927831]\n",
            "tf.Tensor([0.22762178 0.28724894], shape=(2,), dtype=float32)\n",
            "[0.21581215 0.28900695]\n",
            "tf.Tensor([0.5949913  0.30253565], shape=(2,), dtype=float32)\n",
            "[0.5971403  0.30155236]\n",
            "tf.Tensor([0.6653913 0.2592463], shape=(2,), dtype=float32)\n",
            "[0.66750747 0.25876117]\n",
            "tf.Tensor([0.72411895 0.32127717], shape=(2,), dtype=float32)\n",
            "[0.71724653 0.32636544]\n",
            "tf.Tensor([0.958921   0.68255305], shape=(2,), dtype=float32)\n",
            "[0.9584125  0.70168984]\n",
            "tf.Tensor([0.03607398 0.9611905 ], shape=(2,), dtype=float32)\n",
            "[0.02802521 0.963162  ]\n",
            "tf.Tensor([0.38295934 0.4300173 ], shape=(2,), dtype=float32)\n",
            "[0.38024968 0.41790003]\n",
            "tf.Tensor([0.362742 0.611552], shape=(2,), dtype=float32)\n",
            "[0.3629533 0.6200844]\n",
            "tf.Tensor([0.9314969 0.8769173], shape=(2,), dtype=float32)\n",
            "[0.92380273 0.8764681 ]\n",
            "tf.Tensor([0.09137307 0.00282809], shape=(2,), dtype=float32)\n",
            "[ 0.10709673 -0.0008308 ]\n",
            "tf.Tensor([0.96381515 0.67372507], shape=(2,), dtype=float32)\n",
            "[0.96259683 0.69210625]\n",
            "tf.Tensor([0.898034   0.10869124], shape=(2,), dtype=float32)\n",
            "[0.88935184 0.12150488]\n",
            "tf.Tensor([0.66464883 0.6342169 ], shape=(2,), dtype=float32)\n",
            "[0.65811086 0.64429   ]\n",
            "tf.Tensor([0.22505693 0.35672712], shape=(2,), dtype=float32)\n",
            "[0.21001703 0.35363317]\n",
            "tf.Tensor([0.5800893  0.36170444], shape=(2,), dtype=float32)\n",
            "[0.5765703  0.36268646]\n",
            "tf.Tensor([0.4795978  0.37051654], shape=(2,), dtype=float32)\n",
            "[0.4806373  0.35882413]\n",
            "tf.Tensor([0.55423933 0.38050961], shape=(2,), dtype=float32)\n",
            "[0.54868674 0.380912  ]\n",
            "tf.Tensor([0.6473855  0.00946452], shape=(2,), dtype=float32)\n",
            "[0.6374707  0.02549247]\n",
            "tf.Tensor([0.54124796 0.9149853 ], shape=(2,), dtype=float32)\n",
            "[0.5261822 0.9213361]\n",
            "tf.Tensor([0.10608852 0.80928725], shape=(2,), dtype=float32)\n",
            "[0.10034162 0.83854467]\n",
            "tf.Tensor([0.20173684 0.8118265 ], shape=(2,), dtype=float32)\n",
            "[0.19884247 0.8356697 ]\n",
            "tf.Tensor([0.22264875 0.94825804], shape=(2,), dtype=float32)\n",
            "[0.2194382 0.9687739]\n",
            "tf.Tensor([0.6198474 0.7701535], shape=(2,), dtype=float32)\n",
            "[0.6098952  0.77726734]\n",
            "tf.Tensor([0.6075062 0.9393083], shape=(2,), dtype=float32)\n",
            "[0.58991176 0.94186157]\n",
            "tf.Tensor([0.20354155 0.62723947], shape=(2,), dtype=float32)\n",
            "[0.1980303  0.63205045]\n",
            "tf.Tensor([0.8533188 0.8876816], shape=(2,), dtype=float32)\n",
            "[0.8434138  0.89333385]\n",
            "tf.Tensor([0.21827888 0.15608817], shape=(2,), dtype=float32)\n",
            "[0.21263355 0.15630983]\n",
            "tf.Tensor([0.8783415 0.712668 ], shape=(2,), dtype=float32)\n",
            "[0.87772065 0.7347429 ]\n",
            "tf.Tensor([0.5926137 0.3556847], shape=(2,), dtype=float32)\n",
            "[0.5893596  0.35730836]\n",
            "tf.Tensor([0.7689195  0.10264635], shape=(2,), dtype=float32)\n",
            "[0.76941854 0.1038637 ]\n",
            "tf.Tensor([0.56317353 0.11121166], shape=(2,), dtype=float32)\n",
            "[0.55714667 0.12097376]\n",
            "tf.Tensor([0.16834441 0.96593916], shape=(2,), dtype=float32)\n",
            "[0.16020066 0.9782199 ]\n",
            "tf.Tensor([0.66946936 0.6461627 ], shape=(2,), dtype=float32)\n",
            "[0.6626564 0.6559095]\n",
            "tf.Tensor([0.03696683 0.08656042], shape=(2,), dtype=float32)\n",
            "[0.04592055 0.0665723 ]\n",
            "tf.Tensor([0.57390183 0.77299356], shape=(2,), dtype=float32)\n",
            "[0.5648172 0.7812552]\n",
            "tf.Tensor([0.4795585  0.02797028], shape=(2,), dtype=float32)\n",
            "[0.46684784 0.03272565]\n",
            "tf.Tensor([0.67809135 0.82326436], shape=(2,), dtype=float32)\n",
            "[0.66708636 0.83303994]\n",
            "tf.Tensor([0.01880021 0.4180183 ], shape=(2,), dtype=float32)\n",
            "[0.00635367 0.4213943 ]\n",
            "tf.Tensor([0.1808813 0.5705275], shape=(2,), dtype=float32)\n",
            "[0.17488241 0.56768394]\n",
            "tf.Tensor([0.6302437 0.7233103], shape=(2,), dtype=float32)\n",
            "[0.6213227 0.7326483]\n",
            "tf.Tensor([0.8012539  0.30162385], shape=(2,), dtype=float32)\n",
            "[0.79855525 0.31245196]\n",
            "tf.Tensor([0.9285525 0.2972884], shape=(2,), dtype=float32)\n",
            "[0.92211807 0.30425262]\n",
            "tf.Tensor([0.14753231 0.47703114], shape=(2,), dtype=float32)\n",
            "[0.13553351 0.4813496 ]\n",
            "tf.Tensor([0.92197263 0.00471241], shape=(2,), dtype=float32)\n",
            "[0.9034181  0.03172623]\n",
            "tf.Tensor([0.70197976 0.07980175], shape=(2,), dtype=float32)\n",
            "[0.70692897 0.07631683]\n",
            "tf.Tensor([0.7691674  0.37952507], shape=(2,), dtype=float32)\n",
            "[0.7643746  0.38879538]\n",
            "tf.Tensor([0.52391267 0.6490482 ], shape=(2,), dtype=float32)\n",
            "[0.51222646 0.6644035 ]\n",
            "tf.Tensor([0.79241794 0.8207552 ], shape=(2,), dtype=float32)\n",
            "[0.78908306 0.8363422 ]\n",
            "tf.Tensor([0.83359444 0.23024566], shape=(2,), dtype=float32)\n",
            "[0.83055127 0.23755172]\n",
            "tf.Tensor([0.54189616 0.06154679], shape=(2,), dtype=float32)\n",
            "[0.53068095 0.06966032]\n",
            "tf.Tensor([0.7728353 0.4996107], shape=(2,), dtype=float32)\n",
            "[0.76839226 0.5076256 ]\n",
            "tf.Tensor([0.54533356 0.9330877 ], shape=(2,), dtype=float32)\n",
            "[0.52857345 0.9391615 ]\n",
            "tf.Tensor([0.65271974 0.3553535 ], shape=(2,), dtype=float32)\n",
            "[0.6462033 0.3582529]\n",
            "tf.Tensor([0.80010223 0.02134679], shape=(2,), dtype=float32)\n",
            "[0.79399216 0.02925773]\n",
            "tf.Tensor([0.8184866 0.9159245], shape=(2,), dtype=float32)\n",
            "[0.8077751 0.9145201]\n",
            "tf.Tensor([0.39684653 0.5812968 ], shape=(2,), dtype=float32)\n",
            "[0.39719474 0.5896475 ]\n",
            "tf.Tensor([0.66994023 0.6799687 ], shape=(2,), dtype=float32)\n",
            "[0.66217965 0.689205  ]\n",
            "tf.Tensor([0.8965583  0.41916433], shape=(2,), dtype=float32)\n",
            "[0.89518327 0.42956716]\n",
            "tf.Tensor([0.00662034 0.42329773], shape=(2,), dtype=float32)\n",
            "[-0.00475019  0.42641622]\n",
            "tf.Tensor([0.79425347 0.7307958 ], shape=(2,), dtype=float32)\n",
            "[0.7959387  0.74994904]\n",
            "tf.Tensor([0.58376914 0.01029946], shape=(2,), dtype=float32)\n",
            "[0.5654335  0.02584827]\n",
            "tf.Tensor([0.07998321 0.5506693 ], shape=(2,), dtype=float32)\n",
            "[0.07248706 0.5567079 ]\n",
            "tf.Tensor([0.6427745  0.43415824], shape=(2,), dtype=float32)\n",
            "[0.6308396  0.43610358]\n",
            "tf.Tensor([0.53789145 0.06496919], shape=(2,), dtype=float32)\n",
            "[0.5272155  0.07279699]\n",
            "tf.Tensor([0.03819582 0.34133887], shape=(2,), dtype=float32)\n",
            "[0.02546697 0.34123203]\n",
            "tf.Tensor([0.7716385  0.36127958], shape=(2,), dtype=float32)\n",
            "[0.76692617 0.3707795 ]\n",
            "tf.Tensor([0.69074637 0.94632834], shape=(2,), dtype=float32)\n",
            "[0.67314744 0.9459799 ]\n",
            "tf.Tensor([0.7785412  0.39851138], shape=(2,), dtype=float32)\n",
            "[0.7747613  0.40745857]\n",
            "tf.Tensor([0.7547593 0.708025 ], shape=(2,), dtype=float32)\n",
            "[0.7544981  0.72696835]\n",
            "tf.Tensor([0.40931106 0.72554994], shape=(2,), dtype=float32)\n",
            "[0.40316677 0.7345434 ]\n",
            "tf.Tensor([0.7057206  0.14398354], shape=(2,), dtype=float32)\n",
            "[0.71060926 0.13730396]\n",
            "tf.Tensor([0.4709891  0.20364562], shape=(2,), dtype=float32)\n",
            "[0.46985525 0.20682625]\n",
            "tf.Tensor([0.8558499 0.4688997], shape=(2,), dtype=float32)\n",
            "[0.85668176 0.47648454]\n",
            "tf.Tensor([0.9225594 0.9901567], shape=(2,), dtype=float32)\n",
            "[0.9029686  0.96140915]\n",
            "tf.Tensor([0.93591505 0.45950067], shape=(2,), dtype=float32)\n",
            "[0.93406504 0.47898182]\n",
            "tf.Tensor([0.8957089 0.5355053], shape=(2,), dtype=float32)\n",
            "[0.89287937 0.5530082 ]\n",
            "tf.Tensor([0.7745195 0.0860914], shape=(2,), dtype=float32)\n",
            "[0.77405155 0.08780165]\n",
            "tf.Tensor([0.45359   0.6039167], shape=(2,), dtype=float32)\n",
            "[0.44720453 0.6124868 ]\n",
            "tf.Tensor([0.41500947 0.21693054], shape=(2,), dtype=float32)\n",
            "[0.4133768  0.22033411]\n",
            "tf.Tensor([0.76958215 0.4813553 ], shape=(2,), dtype=float32)\n",
            "[0.7650694  0.48851055]\n",
            "tf.Tensor([0.35573423 0.7623231 ], shape=(2,), dtype=float32)\n",
            "[0.35468686 0.77367574]\n",
            "tf.Tensor([0.23905732 0.6587041 ], shape=(2,), dtype=float32)\n",
            "[0.23384869 0.665338  ]\n",
            "tf.Tensor([0.43830732 0.6212424 ], shape=(2,), dtype=float32)\n",
            "[0.432446  0.6307849]\n",
            "tf.Tensor([0.11513953 0.8252584 ], shape=(2,), dtype=float32)\n",
            "[0.10840249 0.85359544]\n",
            "tf.Tensor([0.72432923 0.3216794 ], shape=(2,), dtype=float32)\n",
            "[0.71743584 0.3267725 ]\n",
            "tf.Tensor([0.21177313 0.15069258], shape=(2,), dtype=float32)\n",
            "[0.20620686 0.15023549]\n",
            "tf.Tensor([0.76734966 0.25330478], shape=(2,), dtype=float32)\n",
            "[0.764438  0.2594235]\n",
            "tf.Tensor([0.28730637 0.17113797], shape=(2,), dtype=float32)\n",
            "[0.2820149  0.17311324]\n",
            "tf.Tensor([0.93204015 0.5113688 ], shape=(2,), dtype=float32)\n",
            "[0.93025887 0.53151196]\n",
            "tf.Tensor([0.21476708 0.04632821], shape=(2,), dtype=float32)\n",
            "[0.21035463 0.03343736]\n",
            "tf.Tensor([0.5126979  0.62171465], shape=(2,), dtype=float32)\n",
            "[0.50125295 0.6340731 ]\n",
            "tf.Tensor([0.29796976 0.7370093 ], shape=(2,), dtype=float32)\n",
            "[0.2969724 0.7487132]\n",
            "tf.Tensor([0.97010636 0.32510972], shape=(2,), dtype=float32)\n",
            "[0.9631201 0.3400104]\n",
            "tf.Tensor([0.312943   0.46430367], shape=(2,), dtype=float32)\n",
            "[0.3080489  0.45452598]\n",
            "tf.Tensor([0.2869737  0.92663985], shape=(2,), dtype=float32)\n",
            "[0.2883953 0.9489376]\n",
            "tf.Tensor([0.8612201  0.70841366], shape=(2,), dtype=float32)\n",
            "[0.86049104 0.7295599 ]\n",
            "tf.Tensor([0.6861498 0.3836824], shape=(2,), dtype=float32)\n",
            "[0.67591673 0.38668016]\n",
            "tf.Tensor([0.16619864 0.2447398 ], shape=(2,), dtype=float32)\n",
            "[0.15591675 0.25182223]\n",
            "tf.Tensor([0.1540779  0.78331435], shape=(2,), dtype=float32)\n",
            "[0.14892638 0.80730003]\n",
            "tf.Tensor([0.81400275 0.59631205], shape=(2,), dtype=float32)\n",
            "[0.81599087 0.61084884]\n",
            "tf.Tensor([0.07479769 0.74272317], shape=(2,), dtype=float32)\n",
            "[0.07245505 0.7639132 ]\n",
            "tf.Tensor([0.77253395 0.34935376], shape=(2,), dtype=float32)\n",
            "[0.76771337 0.35900977]\n",
            "tf.Tensor([0.07506736 0.17300642], shape=(2,), dtype=float32)\n",
            "[0.07514042 0.17003237]\n",
            "tf.Tensor([0.7157836 0.9411528], shape=(2,), dtype=float32)\n",
            "[0.6999425  0.94089895]\n",
            "tf.Tensor([0.39807832 0.5074872 ], shape=(2,), dtype=float32)\n",
            "[0.39867878 0.5071724 ]\n",
            "tf.Tensor([0.5113073  0.06754671], shape=(2,), dtype=float32)\n",
            "[0.50175077 0.07375142]\n",
            "tf.Tensor([0.97986346 0.850847  ], shape=(2,), dtype=float32)\n",
            "[0.973728   0.84285736]\n",
            "tf.Tensor([0.50084114 0.14345674], shape=(2,), dtype=float32)\n",
            "[0.49614334 0.14911166]\n",
            "tf.Tensor([0.37240914 0.6591676 ], shape=(2,), dtype=float32)\n",
            "[0.37251902 0.6728975 ]\n",
            "tf.Tensor([0.91303295 0.9742939 ], shape=(2,), dtype=float32)\n",
            "[0.8951747 0.9519723]\n",
            "tf.Tensor([0.299133   0.14216627], shape=(2,), dtype=float32)\n",
            "[0.29434592 0.1446216 ]\n",
            "tf.Tensor([0.38039145 0.8665532 ], shape=(2,), dtype=float32)\n",
            "[0.3760497 0.879344 ]\n",
            "tf.Tensor([0.8740059  0.66703624], shape=(2,), dtype=float32)\n",
            "[0.8734968 0.6892751]\n",
            "tf.Tensor([0.12607165 0.283939  ], shape=(2,), dtype=float32)\n",
            "[0.11239916 0.28956708]\n",
            "tf.Tensor([0.7432295 0.4264014], shape=(2,), dtype=float32)\n",
            "[0.7363309  0.43436372]\n",
            "tf.Tensor([0.7044291  0.33170027], shape=(2,), dtype=float32)\n",
            "[0.696636  0.3358714]\n",
            "tf.Tensor([0.5207861 0.6618685], shape=(2,), dtype=float32)\n",
            "[0.50892943 0.677924  ]\n",
            "tf.Tensor([0.32845867 0.85224944], shape=(2,), dtype=float32)\n",
            "[0.32805955 0.86743385]\n",
            "tf.Tensor([0.0352496 0.3434658], shape=(2,), dtype=float32)\n",
            "[0.02255863 0.34329352]\n",
            "tf.Tensor([0.1840439  0.98589045], shape=(2,), dtype=float32)\n",
            "[0.17627811 0.9949543 ]\n",
            "tf.Tensor([0.70541805 0.04854284], shape=(2,), dtype=float32)\n",
            "[0.706978  0.0498147]\n",
            "tf.Tensor([0.5919525 0.7151771], shape=(2,), dtype=float32)\n",
            "[0.5832047 0.7275311]\n",
            "tf.Tensor([0.3030025  0.14689374], shape=(2,), dtype=float32)\n",
            "[0.2982145 0.1496776]\n",
            "tf.Tensor([0.31708142 0.14347528], shape=(2,), dtype=float32)\n",
            "[0.3125313 0.1468887]\n",
            "tf.Tensor([0.5978346  0.16135201], shape=(2,), dtype=float32)\n",
            "[0.60150594 0.16919158]\n",
            "tf.Tensor([0.5144471 0.7309744], shape=(2,), dtype=float32)\n",
            "[0.5039241 0.7462881]\n",
            "tf.Tensor([0.45453253 0.81146955], shape=(2,), dtype=float32)\n",
            "[0.44794512 0.82113665]\n",
            "tf.Tensor([0.8383205 0.8605728], shape=(2,), dtype=float32)\n",
            "[0.8312059  0.87018114]\n",
            "tf.Tensor([0.8221769  0.93226844], shape=(2,), dtype=float32)\n",
            "[0.8098472  0.92710227]\n",
            "tf.Tensor([0.07234123 0.76156604], shape=(2,), dtype=float32)\n",
            "[0.07030129 0.7860753 ]\n",
            "tf.Tensor([0.36025965 0.3702309 ], shape=(2,), dtype=float32)\n",
            "[0.35373318 0.36247462]\n",
            "tf.Tensor([0.40073943 0.82549614], shape=(2,), dtype=float32)\n",
            "[0.39520866 0.8360794 ]\n",
            "tf.Tensor([0.7562993  0.25761327], shape=(2,), dtype=float32)\n",
            "[0.75336057 0.26282454]\n",
            "tf.Tensor([0.36601615 0.73540545], shape=(2,), dtype=float32)\n",
            "[0.36458766 0.74679965]\n",
            "tf.Tensor([0.30351165 0.9635102 ], shape=(2,), dtype=float32)\n",
            "[0.30379587 0.9834485 ]\n",
            "tf.Tensor([0.15430708 0.14499518], shape=(2,), dtype=float32)\n",
            "[0.14924473 0.1411201 ]\n",
            "tf.Tensor([0.25683397 0.03992797], shape=(2,), dtype=float32)\n",
            "[0.25046128 0.0280774 ]\n",
            "tf.Tensor([0.26599538 0.1977915 ], shape=(2,), dtype=float32)\n",
            "[0.2596696  0.19924204]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-04 14:39:37.437824: W tensorflow/core/framework/op_kernel.cc:1828] OP_REQUIRES failed at strided_slice_op.cc:117 : INVALID_ARGUMENT: slice index 256 of dimension 0 out of bounds.\n"
          ]
        },
        {
          "ename": "InvalidArgumentError",
          "evalue": "{{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 256 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[1;32m/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb Cell 35\u001b[0m line \u001b[0;36m4\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y116sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m val_dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y116sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m1000\u001b[39m \u001b[39mif\u001b[39;00m printear \u001b[39melse\u001b[39;00m batch_size):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y116sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m         \u001b[39mprint\u001b[39m(e[\u001b[39m1\u001b[39;49m][i])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y116sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m         \u001b[39mprint\u001b[39m(predictions[i])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y116sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.9/site-packages/tensorflow/python/framework/ops.py:6656\u001b[0m, in \u001b[0;36mraise_from_not_ok_status\u001b[0;34m(e, name)\u001b[0m\n\u001b[1;32m   6654\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mraise_from_not_ok_status\u001b[39m(e, name):\n\u001b[1;32m   6655\u001b[0m   e\u001b[39m.\u001b[39mmessage \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39m name: \u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(name \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m-> 6656\u001b[0m   \u001b[39mraise\u001b[39;00m core\u001b[39m.\u001b[39m_status_to_exception(e) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: {{function_node __wrapped__StridedSlice_device_/job:localhost/replica:0/task:0/device:CPU:0}} slice index 256 of dimension 0 out of bounds. [Op:StridedSlice] name: strided_slice/"
          ]
        }
      ],
      "source": [
        "printear = True\n",
        "for e in val_dataset:\n",
        "    for i in range(0, if printear else batch_size):\n",
        "        print(e[1][i])\n",
        "        print(predictions[i])\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ds5iD1OMbZu3"
      },
      "outputs": [],
      "source": [
        "m_size = basis.size\n",
        "rho_1_pred = []\n",
        "rho_1_actual = []\n",
        "norm = []\n",
        "norm_rand = []\n",
        "printear =  False\n",
        "\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 3 if printear else batch_size):\n",
        "        # Valores actuales\n",
        "        #h = e[1][i].numpy().reshape(basis.size,basis.size)\n",
        "        h_true = gen_to_h(e[1][i], rho_1_arrays)\n",
        "        #print(h) if printear else 0\n",
        "        r = max(np.linalg.eigvals(e[0][i]))\n",
        "        rho_1_actual.append(r)\n",
        "\n",
        "        print(h_true) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "\n",
        "        # Valores predichos\n",
        "        #h = predictions[i].reshape(basis.size,basis.size)\n",
        "        h_pred = gen_to_h(predictions[i], rho_1_arrays)\n",
        "        beta = 1\n",
        "        # Estado térmico\n",
        "        state = thermal_state(h_pred, beta)\n",
        "        # Estado puro\n",
        "        #state = pure_state(h_pred)\n",
        "        rho1 = np.array(rho_1(basis.d, state, rho_1_arrays))\n",
        "        r = max(np.sort(linalg_d.eigvals(rho1).real))\n",
        "        rho_1_pred.append(r)\n",
        "\n",
        "        print(h_pred) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "        \n",
        "\n",
        "        # Normas\n",
        "        norm.append(np.linalg.norm(h_true-h_pred, ord='fro'))\n",
        "        print(f'Norma {norm[-1]}') if printear else 0\n",
        "        ## Vamos a comparar con un h aleatorio\n",
        "        size = basis.d*(basis.d+1)//2\n",
        "        base = np.random.uniform(low=0, high=1.0, size=(size,))\n",
        "        h_rand = gen_to_h(base, rho_1_arrays)\n",
        "        norm_rand.append(np.linalg.norm(h_true-h_rand, ord='fro'))\n",
        "        #print(f'Norma random {norm_rand[-1]}') if printear else 0\n",
        "        print('') if printear else 0\n",
        "        \n",
        "\n",
        "\n",
        "    # e contiene todo el batch y nos basta con uno\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(e[1][10])\n",
        "predictions[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "AL2EC9Ci-0HG",
        "outputId": "545ebe57-d3de-490f-f076-709d5c47b5f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f=1\n",
        "rho_1_actual = np.array(rho_1_actual)\n",
        "rho_1_pred = np.array(rho_1_pred)\n",
        "#print(mean_squared_error(rho_1_pred, rho_1_actual))\n",
        "\n",
        "print('Rho1 based statistics')\n",
        "print(np.mean(np.abs(rho_1_actual-rho_1_pred)))\n",
        "print(np.mean(rho_1_actual)*f)\n",
        "print('std')\n",
        "print(np.std(rho_1_actual-rho_1_pred)*f)\n",
        "print(np.std(rho_1_actual)*f)\n",
        "print(np.std(rho_1_pred)*f)\n",
        "plt.hist(np.array(rho_1_pred-rho_1_actual), bins=50)\n",
        "plt.show()\n",
        "print('H based statistics')\n",
        "print(np.mean(norm), np.mean(norm_rand))\n",
        "print(np.mean(norm_rand)/np.mean(norm))\n",
        "\n",
        "\n",
        "# BEST: FACTOR 1/8 c/fund\n",
        "## 500 epochs, 10M dataset\n",
        "# BEST: FACTOR 1/9 s/fund\n",
        "## 50 epochs, 5M dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "6.25/1.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 25 epochs d = m*2\n",
        "res = {}\n",
        "res[5] = 35/8.19 \n",
        "res[4] = 15/2.47\n",
        "res[3] = 6.2/1.73"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YioVllOX3M1N",
        "outputId": "b7715c37-1400-4c04-8be3-dd247b4b9db9"
      },
      "outputs": [],
      "source": [
        "# Get the weights of all dense layers in the model\n",
        "dense_weights = []\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Dense):\n",
        "        weights = layer.get_weights()\n",
        "        if len(weights) > 0:\n",
        "            dense_weights.append(weights[0])\n",
        "\n",
        "# Visualize the weights of each dense layer\n",
        "for i, weights in enumerate(dense_weights):\n",
        "    plt.figure()\n",
        "    plt.imshow(weights, cmap='viridis', aspect='auto')\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"Dense Layer {i+1} Weights Visualization\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 1 1] [0 1 1 0 0 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "            if mat[i,j,0,9] != 0:\n",
        "                print(v,w)\n",
        "\n",
        "    return mat\n",
        "\n",
        "r = rho_2_gen(basis, basis_m2, t_basis)\n",
        "r[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 1],\n",
              "       [1, 0, 1, 1, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 0],\n",
              "       [1, 0, 1, 0, 0, 1],\n",
              "       [1, 0, 0, 1, 1, 0],\n",
              "       [1, 0, 0, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 1],\n",
              "       [0, 1, 1, 1, 0, 0],\n",
              "       [0, 1, 1, 0, 1, 0],\n",
              "       [0, 1, 1, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 0, 1, 1],\n",
              "       [0, 0, 1, 1, 1, 0],\n",
              "       [0, 0, 1, 1, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 1],\n",
              "       [0, 0, 0, 1, 1, 1]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basis.base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 20)\n",
            "[array([0, 1, 0, 1, 1, 0])] [0 1 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "col = 1\n",
        "b = b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0]))\n",
        "print(b.shape)\n",
        "for x in range(0,b.shape[1]):\n",
        "    if b[col,x] != 0:\n",
        "        ind = x\n",
        "        break\n",
        "else:\n",
        "    ind = NaN\n",
        "\n",
        "print([basis.base[ind]], mll_basis.base[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "d = 2*m\n",
        "basis = fixed_basis(m, d)\n",
        "t_basis = fixed_basis(2, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "ml_basis = basis_m1\n",
        "mll_basis = basis_m2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_basis = fixed_basis(2, d)\n",
        "mll_basis = fixed_basis(basis.m-2, d)\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2)))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    offset = 4*m+1\n",
        "    indices = [-(k-1)*(2*k-offset) for k in range(1,m+1)] # Lo saque de Mathmatica, vos confia\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    \n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "\n",
        "    hi = -np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    return (h0, hi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "(h02,hi2) = two_body_hamiltonian(t_basis.size, m, [0,1,2], np.ones((3,3)), rho_1_arrays, rho_2_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]]]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "print(rho_2_arrays[9,0,0,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "\n",
        "A = np.array([0, 1, 2])  # Your list with d elements\n",
        "\n",
        "# Create a diagonal matrix with each element repeated twice\n",
        "result_matrix = np.diagflat(np.kron(A, np.ones(2)))\n",
        "\n",
        "print(result_matrix)\n",
        "np.kron(A, np.ones(2))\n",
        "\n",
        "mat = np.zeros((basis.size, basis.size))\n",
        "for i in range(0,2*d):\n",
        "    for j in range(0, 2*d):\n",
        "        mat += result_matrix[i,j] * rho_1_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mat = np.sum(result_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h0 == mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1]\n",
            "[0, 9, 14]\n",
            "[0, 9, 14]\n"
          ]
        }
      ],
      "source": [
        "d = 3\n",
        "t_basis = fixed_basis(2, 2*d)\n",
        "basis = fixed_basis(d, 2*d)\n",
        "size = t_basis.size\n",
        "#basis = fixed_basis(d, 2*d)\n",
        "diag_elem = []\n",
        "for x in t_basis.base:\n",
        "    if all([x[i] == x[i+1] for i in range(0, 2*d, 2)]):\n",
        "        print(x)\n",
        "        diag_elem.append(t_basis.rep_to_index(x))\n",
        "\n",
        "print(diag_elem)\n",
        "# Veamos el GALERAZO de Wolfram\n",
        "n = 4*d+1\n",
        "print([-(k-1)*(2*k-n) for k in range(1,d+1)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m2_basis = fixed_basis(2, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-2, d)\n",
        "print(nm2_basis.base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "index = [0,9,14]\n",
        "mat = np.zeros((size,size))\n",
        "for i in range(0,3):\n",
        "    for j in range(0,3):\n",
        "        mat[index[i], index[j]] = W[i,j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "#rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "\n",
        "W = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "W = np.ones((3,3))\n",
        "index = [0, 9, 14]\n",
        "size = 15  # Assuming size is the size of the matrix\n",
        "\n",
        "# Create a meshgrid of indices\n",
        "i, j = np.meshgrid(index, index, indexing='ij')\n",
        "\n",
        "# Use the meshgrid indices to assign values from W to the specified positions in mat\n",
        "mat = np.zeros((size, size))\n",
        "mat[i, j] = W\n",
        "\n",
        "# La mat... mat corresponde a los coeficientes en t_basis\n",
        "inte = np.zeros((basis.size, basis.size))\n",
        "for i in range(0, t_basis.size):\n",
        "    for j in range(0, t_basis.size):\n",
        "        inte += - mat[i, j] * rho_2_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inte == hi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "\n",
        "from numba import njit\n",
        "\n",
        "# Parametros hamiltoniano\n",
        "e = 1\n",
        "eps = 0\n",
        "e0 = np.zeros(2*d)\n",
        "eigenspace_tol = 0.0001\n",
        "for k in range(0, d):\n",
        "    r = random.random() * eps * 0\n",
        "    e0[2*k] = k*e+r\n",
        "    e0[2*k+1] = k*e+r\n",
        "\n",
        "@njit(parallel=True)\n",
        "def base_hamiltonian_aux(basis, size, d, basis_m1, basis_m2):\n",
        "    # Construccion de H\n",
        "    d = d//2\n",
        "    h0 = np.zeros((size,size), dtype=np.float32)\n",
        "    for k in prange(0,2*d):\n",
        "        h0 += e0[k] * np.dot(bd_aux(basis_m1, basis, k),b_aux(basis, basis_m1, k))\n",
        "    hi = np.zeros((size, size), dtype=np.float32)\n",
        "    for k in prange(0,d):\n",
        "        for kb in prange(0,d):\n",
        "            bd_terms = np.dot(bd_aux(basis_m1, basis, 2*k),bd_aux(basis_m2, basis_m1, 2*k+1))\n",
        "            b_terms = np.dot(b_aux(basis_m1, basis_m2, 2*kb+1),b_aux(basis, basis_m1, 2*kb))\n",
        "            hi += -1*np.dot(bd_terms,b_terms)\n",
        "\n",
        "    return (h0, hi)\n",
        "\n",
        "def base_hamiltonian(basis, basis_m1, basis_m2):\n",
        "    return base_hamiltonian_aux(basis.base, basis.size, basis.d, basis_m1.base, basis_m2.base)\n",
        "\n",
        "h0, hi = base_hamiltonian(basis, basis_m1, basis_m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oapxWkD16fHg"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
