{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguschanchu/FermionicML/blob/main/FermionicML_thermal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXz5cOlVwrzZ"
      },
      "source": [
        "# FermionicML:\n",
        "\n",
        "Code based on aguschanchu/Bosonic.py\n",
        "\n",
        "A diferencia del código anterior, este modelo trabaja sobre estados térmicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD2Yai55rMm"
      },
      "source": [
        "## Código base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgf9ExZN4jA7"
      },
      "source": [
        "Cargamos el código de Bosonic.py básico, branch fermionic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gydz4kCH4l5w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/tmp/ipykernel_3264/4156838298.py:296: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  def gamma_lamba_inv(x):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import binom\n",
        "from scipy.sparse import dok_matrix, linalg\n",
        "from scipy import linalg as linalg_d\n",
        "from joblib import Memory\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from joblib import Parallel, delayed\n",
        "from numba import jit, prange, njit\n",
        "import numba as nb\n",
        "import pickle\n",
        "import math\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Funciones auxiliares optimiadas\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def int_to_tuple_arr(ni,nf, b, digits=None):\n",
        "    sol = np.zeros((nf-ni, digits), dtype=np.int64)\n",
        "    for n in prange(ni, nf):\n",
        "        r = np.zeros(digits, dtype=np.int64)\n",
        "        ncop = n\n",
        "        idx = 0\n",
        "        while n != 0:\n",
        "            r[idx] = n % b\n",
        "            n = n // b\n",
        "            idx += 1\n",
        "        if digits is not None:\n",
        "            if idx < digits:\n",
        "                for i in range(idx, digits):\n",
        "                    r[i] = 0\n",
        "                idx = digits\n",
        "        sol[ncop-ni,:] = r[:idx]\n",
        "    return sol\n",
        "\n",
        "def tuple_to_int(t, d):\n",
        "    b = d-1\n",
        "    l = len(t)\n",
        "    s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "    return sum(s)\n",
        "\n",
        "def create_basis_(m, d, size):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 1000000\n",
        "    for x in range(0,(m+1)**d, chunk_size):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        arr = int_to_tuple_arr(start_index, end_index, m+1, d)\n",
        "        sums = np.sum(arr, axis=1)\n",
        "        rows = np.where(sums == m)[0]\n",
        "        for row in [arr[i] for i in rows]:\n",
        "            if np.all(np.logical_or(row == 0, row == 1)):\n",
        "                base.append(row)\n",
        "\n",
        "    # Como consecuencia de la paralelizacion, es necesario reordenar la base\n",
        "    sorted_base = sorted(base, key=lambda x: tuple_to_int(x, d), reverse=True)\n",
        "    assert len(base) == size\n",
        "\n",
        "    return sorted_base\n",
        "\n",
        "def custom_base_representation_tf(n_min, n_max, base, num_digits):\n",
        "    # Generate a range of numbers from n_min to n_max\n",
        "    numbers = tf.range(n_min, n_max + 1, dtype=tf.int64)\n",
        "    \n",
        "    # Calculate the digits in the custom base using broadcasting\n",
        "    digits = tf.pow(tf.cast(base, dtype=tf.float64), tf.cast(tf.range(num_digits), dtype=tf.float64))\n",
        "    \n",
        "    # Reshape the digits to [1, num_digits] for broadcasting\n",
        "    digits = tf.reshape(digits, [1, -1])\n",
        "    \n",
        "    # Reshape numbers to [batch_size, 1]\n",
        "    numbers = tf.reshape(tf.cast(numbers, dtype=tf.float64), [-1, 1])\n",
        "    \n",
        "    # Calculate the digits in the custom base for each number using broadcasting\n",
        "    result = tf.cast(tf.math.floormod(tf.math.floordiv(numbers, digits), base), dtype=tf.int32)\n",
        "    \n",
        "    # Pad the result to have exactly num_digits columns\n",
        "    result = tf.pad(result, paddings=[[0, 0], [0, num_digits - tf.shape(result)[1]]], constant_values=0)\n",
        "    \n",
        "    # Reverse the order of columns\n",
        "    #result = tf.reverse(result, axis=[1])\n",
        "\n",
        "    return result\n",
        "\n",
        "def select_rows_with_sum(arr, m):\n",
        "    # Create a mask based on the criteria\n",
        "    mask = tf.reduce_all(tf.math.logical_or(tf.equal(arr, 0), tf.equal(arr, 1)), axis=1) & (tf.reduce_sum(arr, axis=1) == m)\n",
        "    \n",
        "    # Use the mask to select the rows\n",
        "    result = tf.boolean_mask(arr, mask, axis=0)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def create_basis_tf_(m, d):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 10000000\n",
        "    for x in tqdm(range(0,(m+1)**d, chunk_size)):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        res = custom_base_representation_tf(start_index, end_index, m+1, d)\n",
        "        arr = select_rows_with_sum(res, m)\n",
        "        base.append(arr.numpy())\n",
        "\n",
        "    return np.concatenate(base)\n",
        "\n",
        "class fixed_basis:\n",
        "\n",
        "    # Convierte a un enterno n a su escritura en base b\n",
        "    def _int_to_tuple(self, n, b, digits = None):\n",
        "        rep = np.base_repr(n, b)\n",
        "        rep_int = [int(x,b) for x in rep]\n",
        "        if digits is not None:\n",
        "            zeros = [0 for i in range(0,digits-len(rep))]\n",
        "            return zeros + rep_int\n",
        "        else:\n",
        "            return rep_int\n",
        "\n",
        "    # Revierte la transformacion anterior\n",
        "    def tuple_to_int(self, t):\n",
        "        b = self.d-1\n",
        "        l = len(t)\n",
        "        s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "        return sum(s)\n",
        "\n",
        "    # Convierte el vector en su representacion\n",
        "    def vect_to_repr(self, vect):\n",
        "        for i, k in enumerate(vect):\n",
        "            if k == 1. or k == 1:\n",
        "                break\n",
        "        else:\n",
        "            return 0\n",
        "        return self.base[i,:]\n",
        "\n",
        "    def rep_to_vect(self, rep):\n",
        "        rep = list(rep)\n",
        "        for i, r in [(j, self.base[j,:]) for j in range(0,self.size)]:\n",
        "            if list(r) == rep:\n",
        "                return self.canonicals[:,i]\n",
        "        else:\n",
        "            None\n",
        "\n",
        "    def rep_to_index(self, rep):\n",
        "        return self.base.tolist().index(list(rep))\n",
        "\n",
        "    @staticmethod\n",
        "    def rep_to_exi(rep):\n",
        "        r = []\n",
        "        for i, k in enumerate(rep):\n",
        "            r += [i for x in range(0,k)]\n",
        "        return r\n",
        "\n",
        "    # Crea base de M particulas en D estados (repr y base canonica)\n",
        "    def create_basis(self, m, d):\n",
        "        #print(\"Creating basis: \", m, d)\n",
        "        length = int(binom(d,m))\n",
        "        base = np.array(create_basis_tf_(m, d))\n",
        "        # Asignamos a cada uno de ellos un canónico\n",
        "        canonicals = np.eye(length)\n",
        "        return base, canonicals\n",
        "\n",
        "    def __init__(self, m, d):\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        self.size = int(binom(d,m))\n",
        "        (self.base, self.canonicals) = self.create_basis(m, d)\n",
        "\n",
        "\n",
        "# Matrices de aniquilación y creación endomórficas. Estan fuera de la clase para poder ser cacheadas\n",
        "#@memory.cache\n",
        "def bdb(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0 and v[i] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[j] -= 1\n",
        "                dest[i] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[i]+1)*np.sqrt(v[j])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0:\n",
        "                mat[k, k] = v[i]\n",
        "    return mat\n",
        "\n",
        "#@memory.cache\n",
        "def bbd(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 0 and v[j] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[i] -= 1\n",
        "                dest[j] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[j]+1)*np.sqrt(v[i])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 1:\n",
        "                mat[k, k] = v[i]+1\n",
        "    return mat\n",
        "\n",
        "# Matrices de aniquilación y creación.Toman la base de origen y destino (basis_o, basis_d) resp\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def b_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 0:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] -= 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i])\n",
        "    return mat\n",
        "\n",
        "def b(basis_o, basis_d, i):\n",
        "    return b_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def bd_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 1:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd(basis_o, basis_d, i):\n",
        "    return bd_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "\n",
        "# Acepta una lista de indices a crear\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def bd_gen_aux(basis_o, basis_d, gen_list):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        conds = np.zeros(len(gen_list), dtype=np.int64)\n",
        "        for i in range(len(gen_list)):\n",
        "            if basis_o[k][gen_list[i]] != 1:\n",
        "                conds[i] = 1\n",
        "        if np.all(conds):\n",
        "            dest = list(basis_o[k].copy())\n",
        "            for i in gen_list:\n",
        "                dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd_gen(basis_o, basis_d, i):\n",
        "    return bd_gen_aux(basis_o.base, basis_d.base, np.array(i))\n",
        "\n",
        "def b_gen(basis_o, basis_d, i):\n",
        "    return np.transpose(bd_gen(basis_d, basis_o, i))\n",
        "\n",
        "# Volvemos a definir la función para compilarla\n",
        "@nb.jit(forceobj=True)\n",
        "def _rep_to_index(base, rep):\n",
        "    return base.tolist().index(list(rep))\n",
        "\n",
        "# Funciones auxiliares para calcular rho2kkbar y gamma_p\n",
        "@nb.jit(nopython=True)\n",
        "def rep_to_exi(rep):\n",
        "    r = []\n",
        "    for i in range(len(rep)):\n",
        "        for j in range(rep[i]):\n",
        "            r.append(i)\n",
        "    return r\n",
        "\n",
        "@nb.njit\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "@nb.njit\n",
        "def gamma_lamba(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.jit\n",
        "def gamma_lamba_inv(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / np.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.njit\n",
        "def rep_to_index_np(base, rep):\n",
        "    for i in range(len(base)):\n",
        "        if np.all(base[i] == rep):\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "\n",
        "def gamma_p(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    return gamma_p_aux(basis.base, vect, m_basis.base, nm_basis.base)\n",
        "\n",
        "@nb.njit()\n",
        "def gamma_p_aux(basis, vect, m_basis, nm_basis):\n",
        "    mat = np.zeros((len(m_basis), len(nm_basis)), dtype=np.float32)\n",
        "    for i in prange(len(m_basis)):\n",
        "        v = m_basis[i]\n",
        "        for j in prange(len(nm_basis)):\n",
        "            w = nm_basis[j]\n",
        "            targ = v + w\n",
        "            index = rep_to_index_np(basis, targ)\n",
        "            if index != -1:\n",
        "                coef = vect[index]\n",
        "                if coef != 0:\n",
        "                    coef = coef * gamma_lamba_inv(v) * gamma_lamba_inv(w) * gamma_lamba(targ)\n",
        "                mat[i, j] = coef\n",
        "    return mat\n",
        "# Devuelve la matriz rho M asociada al vector\n",
        "def rho_m(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    g = gamma_p(basis, m, vect, m_basis, nm_basis)\n",
        "    return np.dot(g,np.transpose(g))\n",
        "\n",
        "# Devuelve la matriz gamma asociada a la descomposición (M,N-M) del vector\n",
        "@jit(forceobj=True)\n",
        "def gamma(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    mat = dok_matrix((m_basis.size, nm_basis.size), dtype=np.float32)\n",
        "    for i, v in enumerate(m_basis.base):\n",
        "        for j, w in enumerate(nm_basis.base):\n",
        "            targ = v+w\n",
        "            # Revisamos que sea un estado fermionico valido\n",
        "            arr = np.asarray(targ)\n",
        "            if not np.all(np.logical_or(arr == 0, arr == 1)):\n",
        "                continue\n",
        "            index = _rep_to_index(basis.base, targ)\n",
        "            coef = vect[index]\n",
        "            if coef != 0:\n",
        "                aux = lambda x: np.prod(np.reciprocal(np.sqrt([np.math.factorial(o) for o in x])))\n",
        "                aux_inv = lambda x: np.prod(np.sqrt([np.math.factorial(o) for o in x]))\n",
        "                coef = coef * aux(v) * aux(w) * aux_inv(targ)\n",
        "                #coef = coef\n",
        "                #print(v,w,coef)\n",
        "            mat[i,j] = coef\n",
        "    return mat\n",
        "\n",
        "# Genera las matrices de rho1\n",
        "def rho_1_gen(basis):\n",
        "    d = basis.d\n",
        "    s = basis.size\n",
        "    mat = np.empty((d,d,s,s), dtype=np.float32)\n",
        "    for i in range(0, d):\n",
        "        for j in range(0, d):\n",
        "            mat[i,j,:,:] = np.array(bdb(basis,j, i).todense())\n",
        "    return mat\n",
        "\n",
        "#@jit(parallel=True, nopython=True)\n",
        "def rho_1(d, state, rho_1_arrays):\n",
        "    state_expanded = state[np.newaxis, np.newaxis, :, :]\n",
        "    product = state_expanded * rho_1_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "\n",
        "    return mat\n",
        "\n",
        "\n",
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "\n",
        "    return mat\n",
        "\n",
        "def rho_2(size, state, rho_2_arrays):\n",
        "    state_expanded = np.expand_dims(state, axis=1)\n",
        "    state_expanded = np.expand_dims(state_expanded, axis=1)\n",
        "    rho_2_arrays = rho_2_arrays[np.newaxis, :, :, :, :]\n",
        "    print(state_expanded.shape, rho_2_arrays.shape)\n",
        "    product = state_expanded * rho_2_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "    return mat\n",
        "\n",
        "def rho_2_kkbar_gen(m, rho_2_arrays):\n",
        "    offset = 4*m+1\n",
        "    indices = [-(k-1)*(2*k-offset) for k in range(1,m+1)] # Lo saque de Mathmatica, vos confia\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "\n",
        "    rho_2_arrays_kkbar = rho_2_arrays[i, j, :, :]\n",
        "\n",
        "    return rho_2_arrays_kkbar\n",
        "\n",
        "# Devuelve la matriz rho 2 asociada al bloque kkbar\n",
        "def rho_2_kkbar(basis, vect, ml_basis = None, mll_basis = None, t_basis = None):\n",
        "    d = basis.d\n",
        "    # Creo las bases si no están dadas\n",
        "    if ml_basis == None or mll_basis == None or t_basis == None:\n",
        "        ml_basis = fixed_basis(m-1,d)\n",
        "        mll_basis = fixed_basis(m-2,d)\n",
        "        t_basis = fixed_basis(2,d)\n",
        "    diag = []\n",
        "    for v in t_basis.base:\n",
        "        for j in range(0, d, 2):\n",
        "            if v[j] == v[j+1]:\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            diag.append(v)\n",
        "    diag = np.array(diag)\n",
        "    return rho_2_kkbar_aux(diag, vect, basis.base, ml_basis.base, mll_basis.base, t_basis.base)\n",
        "\n",
        "@nb.njit\n",
        "def rho_2_kkbar_lambda(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "#@nb.njit(parallel=True)\n",
        "def rho_2_kkbar_aux(diag, vect, basis, ml_basis, mll_basis, t_basis):\n",
        "    mat = np.zeros((len(diag), len(diag)), dtype=np.float32)\n",
        "    for i in prange(len(diag)):\n",
        "        for j in prange(len(diag)):\n",
        "            v = diag[i]\n",
        "            w = diag[j]\n",
        "            # Creacion de los a\n",
        "            i_set = rep_to_exi(v)\n",
        "            b_m = b_aux(ml_basis, mll_basis, i_set[1]) @ b_aux(basis, ml_basis, i_set[0])\n",
        "            # Creacion de los ad\n",
        "            i_set = rep_to_exi(w)\n",
        "            bd_m = bd_aux(ml_basis, basis, i_set[1]) @ bd_aux(mll_basis, ml_basis, i_set[0])\n",
        "            # v1 = vect @ bd_m @ b_m @ vect Para estados puros\n",
        "            # Mult de b's y filleo de mat\n",
        "            coef = np.trace(vect @ bd_m @ b_m)\n",
        "            mat[i,j] = coef * rho_2_kkbar_lambda(v) * rho_2_kkbar_lambda(w)\n",
        "    return mat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dga5Xx_5vDf"
      },
      "source": [
        "## Definicion de Hamiltoniano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiTq53L5E1U"
      },
      "source": [
        "Cargamos el código de creación y resolución de Hamiltonianos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h5FXWv849Mq",
        "outputId": "49dd47b5-8c16-4ad4-92e7-e172462229b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                                                                                                                                        | 0/1 [00:00<?, ?it/s]2023-12-14 19:57:15.356707: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.58s/it]\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 87.27it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 131.66it/s]\n"
          ]
        }
      ],
      "source": [
        "m = 4\n",
        "d = 8\n",
        "# Creo las bases para no tener que recrearlas luego\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PToiSs915TXw"
      },
      "outputs": [],
      "source": [
        "## Usamos este approach si queremos guardar los generadores\n",
        "# Dados 1/2 (d^2+d) elementos, genera una mat de dxd:\n",
        "eps = 0.00001\n",
        "\n",
        "def sym_mat_gen(vect, d):\n",
        "    matrix = fill_matrix(vect, d)\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "@jit(nopython=True)\n",
        "def fill_matrix(vect, d):\n",
        "    matrix = np.zeros((d, d))\n",
        "    idx = 0\n",
        "    for i in prange(d):\n",
        "        for j in prange(i, d):\n",
        "            matrix[i, j] = vect[idx]\n",
        "            idx += 1\n",
        "    return matrix\n",
        "\n",
        "# Generamos una matrix aleatoria. Cuidado con la distribución, ver https://stackoverflow.com/questions/56605189/is-there-an-efficient-way-to-generate-a-symmetric-random-matrix\n",
        "def hamil_base_gen(d):\n",
        "    U = np.random.uniform(low=0, high=1.0, size=(d, d))\n",
        "    hamil_base = np.tril(U) + np.tril(U, -1).T\n",
        "    return hamil_base\n",
        "\n",
        "# Dada un a mat dxd simetrica, contruye el hamiltoniano de un cuerpo a_{ij} c^{dag}_i c_j\n",
        "# Alternativamente podemos construirlo a partir de rho_1_gen\n",
        "def base_hamiltonian_aux(mat, size, d, rho_1_gen):\n",
        "    # Construccion de H\n",
        "    rho_1_gen_transposed = rho_1_gen.transpose(1, 0, 2, 3)\n",
        "    mat_expanded = mat[:, :, np.newaxis, np.newaxis]\n",
        "    h = np.sum(mat_expanded * rho_1_gen_transposed[:, :, :, :], axis=(0, 1))\n",
        "    return h.astype(np.float32)\n",
        "\n",
        "def base_hamiltonian(mat, basis, rho_1_gen):\n",
        "    return base_hamiltonian_aux(mat, basis.size, basis.d, rho_1_gen)\n",
        "\n",
        "def get_kkbar_indices(t_basis):\n",
        "    indices = []\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        if np.all(v[::2] == v[1::2]):\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2))) + eps * np.random.random((2*m,2*m))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    \n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "    hi = np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays[:, :, :, :], axis=(0, 1))\n",
        "    return (h0, hi)\n",
        "\n",
        "def solve(h, last_step = None):\n",
        "    sol = linalg.eigsh(h, which='SA',k=19)\n",
        "    eigenspace_tol = 0.0001\n",
        "    if type(last_step) != type(None):\n",
        "        # Seleccionamos todos los autovects que difieren sus autovalores menos que tol (mismo autoespacio)\n",
        "        # y tomamos la proyección en el autoespacio de la solución del paso anterior (last_step)\n",
        "        eig = sol[0].real\n",
        "        eigv = sol[1]\n",
        "        cand = [eigv[:,i].real  for (i, x) in enumerate(eig) if abs(x-min(eig)) < eigenspace_tol]\n",
        "        cand_norm = [x/np.linalg.norm(x) for x in cand]\n",
        "        fund = np.zeros(len(cand[0]))\n",
        "        for x in cand_norm:\n",
        "            fund += np.dot(last_step,x) * x\n",
        "    else:\n",
        "        argmin = np.argmin(sol[0].real)\n",
        "        fund = sol[1][:,argmin]\n",
        "    fund = fund.real / np.linalg.norm(fund)\n",
        "    return fund"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emVBTg2QD-Fg"
      },
      "source": [
        "## Modelo de ML\n",
        "Basado en matrices densidad de 1 y 2 cuerpos como input, con hamiltoniano como salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aF_Ec_mCGX96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-13 23:18:18.029755: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.test.gpu_device_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDoa6LUJJ8O",
        "outputId": "73481454-fbcb-469f-d72f-cd0f8d534808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 117.18it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 145.42it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 1 0 0 0 0 0 0]\n",
            " [1 0 1 0 0 0 0 0]\n",
            " [0 1 1 0 0 0 0 0]\n",
            " [1 0 0 1 0 0 0 0]\n",
            " [0 1 0 1 0 0 0 0]\n",
            " [0 0 1 1 0 0 0 0]\n",
            " [1 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0 0]\n",
            " [0 0 0 1 1 0 0 0]\n",
            " [1 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 1 0 0]\n",
            " [0 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 1 1 0 0]\n",
            " [1 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 1 0]\n",
            " [0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 1 1 0]\n",
            " [1 0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 0 1 0 1]\n",
            " [0 0 0 0 0 0 1 1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 148.11it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 146.82it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "[[1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 123.03it/s]\n"
          ]
        }
      ],
      "source": [
        "# Construccion de bases para calculo de rho1 y rho2\n",
        "# rho2\n",
        "m = 2\n",
        "m2_basis = fixed_basis(m, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-m, d)\n",
        "print(nm2_basis.base)\n",
        "t_basis = fixed_basis(2, basis.d)\n",
        "# rho1\n",
        "m = 1\n",
        "m1_basis = fixed_basis(m, d)\n",
        "print(m1_basis.size)\n",
        "print(m1_basis.base)\n",
        "nm1_basis = fixed_basis(basis.m-m, d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapxWkD16fHg"
      },
      "source": [
        "### Algunos benchmarks y funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "umCIrxCZKXQd"
      },
      "outputs": [],
      "source": [
        "# Given h calculo en rho2 y rho1 máximo\n",
        "def rho1_rho2(h, beta):\n",
        "    fund = thermal_state(h, beta)\n",
        "    rho2 = np.array(rho_2(basis, m2_basis.size, state, rho_2_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho2).real)\n",
        "    rho_2_max = r[0]\n",
        "    rho1 = np.array(rho_1(basis, state, rho_1_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho1).real)\n",
        "    rho_1_max = r[0]\n",
        "\n",
        "    return (rho_1_max, rho_2_max)\n",
        "\n",
        "def fill_triangular_np(x):\n",
        "    m = x.shape[0]\n",
        "    n = np.int32(np.sqrt(.25 + 2 * m) - .5)\n",
        "    x_tail = x[(m - (n**2 - m)):]\n",
        "    return np.triu(np.concatenate([x, x_tail[::-1]], 0).reshape(n, n))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "QaNnIIc5bZux"
      },
      "outputs": [],
      "source": [
        "# TEST: Las funciones de TF y comunes coinciden\n",
        "\n",
        "# Dado h, \\beta, construyo el estado térmico\n",
        "from scipy.linalg import expm\n",
        "\n",
        "def thermal_state(h, beta):\n",
        "    quotient = expm(-beta*h)\n",
        "    return quotient / np.trace(quotient)\n",
        "\n",
        "## NO usar para mat no hermiticas\n",
        "@nb.jit(nopython=True)\n",
        "def thermal_state_eig(h, beta):\n",
        "    w, v = np.linalg.eigh(-beta*h)\n",
        "    D = np.diag(np.exp(w))\n",
        "    mat = v @ D @ v.T\n",
        "    mat = mat / np.trace(mat)\n",
        "    return mat\n",
        "    \n",
        "def gen_to_h(base, rho_1_arrays):\n",
        "    triag = fill_triangular_np(base)\n",
        "    body_gen = triag + np.transpose(triag)-np.diag(np.diag(triag))\n",
        "    h = np.array(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
        "    return h \n",
        "\n",
        "def gen_to_h_1b(hamil_base):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "    return body_gen\n",
        "\n",
        "def gen_to_h_tf(hamil_base, rho_1_arrays):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag)) # Simetrizamos y generamos la matriz de h\n",
        "    hamil_expanded = body_gen[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    h_arr = tf.reduce_sum(hamil_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "    return h_arr\n",
        "\n",
        "def thermal_state_tf(h):\n",
        "    # Assume beta=1\n",
        "    exp_hamiltonian = tf.linalg.expm(-h)\n",
        "    partition_function = tf.linalg.trace(exp_hamiltonian)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    \n",
        "    rho = exp_hamiltonian / partition_function\n",
        "\n",
        "    return rho\n",
        "\n",
        "def rho_1_tf(state, rho_1_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_1_arrays_expanded = tf.expand_dims(rho_1_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_1_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "def rho_2_tf(state, rho_2_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_2_arrays_expanded = tf.expand_dims(rho_2_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_2_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "# NOTA: para calcular el bloque rho2kkbar, utilizar en lugar\n",
        "\n",
        "def rho_1_gc_tf(hamil_base):\n",
        "    e, v = tf.linalg.eigh(gen_to_h_1b(hamil_base))\n",
        "    result = 1 / (1 + tf.exp(e))\n",
        "    result = tf.linalg.diag(result)\n",
        "    res = tf.linalg.matmul(v,result)\n",
        "    res = tf.linalg.matmul(res,v,adjoint_b=True)\n",
        "    \n",
        "    return tf.cast(res, tf.float32)\n",
        "\n",
        "# Aux function\n",
        "def outer_product(vector):\n",
        "    return tf.einsum('i,j->ij', vector, vector)\n",
        "\n",
        "def pure_state(h):\n",
        "    e, v = tf.linalg.eigh(h)\n",
        "    fund = v[:,:,0]\n",
        "    d = tf.map_fn(outer_product, fund)\n",
        "    return d\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylpy_BCw6jxF"
      },
      "source": [
        "### Construccion de dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Version sincrónica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([3.9725304 , 3.06975448, 2.38074635, 4.39044418, 1.85643333,\n",
              "       0.1949102 , 1.01092209, 3.56701867, 4.07615566, 4.89806273,\n",
              "       0.10503122, 0.64057805, 3.49876287, 0.19066509, 0.03632029,\n",
              "       0.96042641])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "g = np.random.rand(basis.m,basis.m)*5\n",
        "np.ndarray.flatten(g)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2is_Eo_qGpEz",
        "outputId": "9a968190-59f2-4695-ef18-b99ff5b4a212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-13 23:17:16.648892: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                                                                                                                                       | 0/98 [00:00<?, ?it/s]2023-12-13 23:17:25.465497: I tensorflow/core/util/cuda_solvers.cc:179] Creating GpuSolver handles for stream 0x55e7ee706cc0\n",
            "  6%|██████████▋                                                                                                                                                                    | 6/98 [00:41<10:15,  6.69s/it]"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  7%|████████████▌                                                                                                                                                                  | 7/98 [00:48<10:02,  6.62s/it]"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "# Config\n",
        "num_samples = 100000\n",
        "use_gpu = True\n",
        "gpu_batch_size = 1024\n",
        "\n",
        "# Beta\n",
        "beta = 1\n",
        "\n",
        "# Construccion de parametros y matrices auxiliares\n",
        "rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "fund_size = basis.size\n",
        "hamil_base_size = basis.d*(basis.d+1)//2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_1_arrays_tf = tf.constant(rho_1_arrays, dtype=tf.float32)\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "rho_2_arrays_kkbar = rho_2_kkbar_gen(basis.m, rho_2_arrays)\n",
        "rho_2_arrays_kkbar_tf = tf.constant(rho_2_arrays_kkbar, dtype=tf.float32)\n",
        "k_indices = get_kkbar_indices(t_basis)\n",
        "\n",
        "# Generacion de hamiltoniano\n",
        "# (h0, hi) = two_body_hamiltonian(t_basis.size, basis.m, np.arange(0, basis.m), np.ones((basis.m,basis.m)), rho_1_arrays_tf, rho_2_arrays_tf) esto es para g cte\n",
        "\n",
        "\n",
        "if use_gpu:\n",
        "    print(tf.test.gpu_device_name())\n",
        "    datasets = []\n",
        "    for i in tqdm(range(num_samples//gpu_batch_size+1)):\n",
        "        size = basis.d*(basis.d+1)//2\n",
        "        # En una primera versión vamos a pasar una mat proporcional a range(0,m) para energias\n",
        "        # y como interacción una matriz G semidefinida positiva\n",
        "        g_seed = [np.random.rand(basis.m*basis.m)*5 for _ in range(0,gpu_batch_size)]\n",
        "        g_arr = [(g + g.T)/2 for g in g_seed]\n",
        "        h_labels = [np.ndarray.flatten(g) for g in g_arr] # Generamos los generadores\n",
        "        hamil_base = tf.constant(h_labels, dtype=tf.float32)\n",
        "        h_arr = np.zeros((gpu_batch_size, basis.size, basis.size))\n",
        "        for i, g in enumerate(g_arr):\n",
        "            (h0, hi) = two_body_hamiltonian(t_basis.size, basis.m, np.arange(0, basis.m), g, rho_1_arrays_tf, rho_2_arrays_tf, k_indices)\n",
        "            h_arr[i,:,:] = h0 - hi\n",
        "        # Estados térmicos\n",
        "        state = thermal_state_tf(h_arr*beta) \n",
        "        state = tf.cast(state, dtype=tf.float32)\n",
        "        # Estados puros\n",
        "        #state = pure_state(h_arr)\n",
        "        #rho_1_input = rho_1_tf(state, rho_1_arrays_tf)\n",
        "        rho_2_input = rho_2_tf(state, rho_2_arrays_kkbar_tf)\n",
        "\n",
        "        datasets.append(tf.data.Dataset.from_tensor_slices(((rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input, state), h_labels)))\n",
        "    ds = tf.data.Dataset.from_tensor_slices(datasets)\n",
        "    dataset = ds.interleave(\n",
        "        lambda x: x,\n",
        "        cycle_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "\n",
        "\n",
        "#batch_size = 32\n",
        "#dataset = dataset.shuffle(buffer_size=num_samples).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Filleo de dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Save and load dataset\n",
        "save_dataset = False\n",
        "load_dataset = False\n",
        "path = \"/home/agus/TF\"\n",
        "#num_samples = 5000000\n",
        "if save_dataset:\n",
        "    tf.data.Dataset.save(dataset, path)\n",
        "    with open(\"/home/agus/\"+'/file.pkl', 'wb') as file:\n",
        "        pickle.dump(beta_input, file)\n",
        "if load_dataset:\n",
        "    dataset = tf.data.Dataset.load(path)\n",
        "    with open(\"/home/agus/\"+'file.pkl', 'rb') as file:\n",
        "        beta_input = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "8moZIlfabZuy"
      },
      "outputs": [],
      "source": [
        "# Dividimos los datasets\n",
        "train_size = int(0.8 * num_samples)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "\n",
        "batch_size = 256\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "#beta_val = beta_input[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Dataset Size: -2\n"
          ]
        }
      ],
      "source": [
        "# Cardinality no funciona con los datasets generados por GPU\n",
        "val_size = tf.data.experimental.cardinality(val_dataset).numpy()\n",
        "print(\"Validation Dataset Size:\", val_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYEEjNB-7b8y"
      },
      "source": [
        "### Definición de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8kkhJr5K0ZQ",
        "outputId": "f1b731f1-6a02-4181-f0b5-5677a2a85784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 15, 15, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 14, 14, 32)        160       \n",
            "                                                                 \n",
            " batch_normalization_4 (Bat  (None, 14, 14, 32)        128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 13, 13, 16)        2064      \n",
            "                                                                 \n",
            " batch_normalization_5 (Bat  (None, 13, 13, 16)        64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 6, 6, 16)          0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten_11 (Flatten)        (None, 576)               0         \n",
            "                                                                 \n",
            " dense_44 (Dense)            (None, 24)                13848     \n",
            "                                                                 \n",
            " dense_45 (Dense)            (None, 2)                 50        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16314 (63.73 KB)\n",
            "Trainable params: 16218 (63.35 KB)\n",
            "Non-trainable params: 96 (384.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Definicion de layers basado en Conv 2D\n",
        "\n",
        "# Factor de cantidad de filtros\n",
        "lf = 8  \n",
        "conv_limit = (rho2_size - 4) // 4 \n",
        "initial_dense = (lf*2**(conv_limit-1)*((rho2_size-(conv_limit-1))//2)**2) // 8\n",
        "## rho 1\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(rho2_size,rho2_size, 1), name='rho2')\n",
        "\n",
        "# Procesamos el primer input\n",
        "conv_rho2 = tf.keras.layers.Conv2D(lf*2**conv_limit, (2, 2), activation='relu')(rho2_layer)\n",
        "conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "for j in [(2**conv_limit - 2**k) for k in range(1,conv_limit)]:\n",
        "    conv_rho2 = tf.keras.layers.Conv2D(lf*j, (2, 2), activation='relu')(conv_rho2 if 2**j != 1 else rho1_layer)\n",
        "    conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "\n",
        "conv_rho2 = tf.keras.layers.MaxPooling2D((2, 2))(conv_rho2)\n",
        "\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(conv_rho2)\n",
        "#flatten_rho1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(flatten_rho1)\n",
        "\n",
        "#local_size = basis.size*basis.size\n",
        "local_size = hamil_base_size\n",
        "\n",
        "#dense1 = tf.keras.layers.Dense(8*8*4*4, activation='relu')(dense1)\n",
        "#dense1 = tf.keras.layers.Dense(512, activation='relu')(flatten_rho1)\n",
        "#dense1 = tf.keras.layers.Dense(128, activation='relu')(flatten_rho1)\n",
        "dense1 = tf.keras.layers.Dense(initial_dense // 4, activation='relu')(flatten_rho2)\n",
        "#dense1 = tf.keras.layers.Dense(initial_dense//2, activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(2)(dense1)\n",
        "\n",
        "\n",
        "# Creamos el modelo y compulamos\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer, fund_layer], outputs=output)\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer], outputs=output)\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZBtonvGbZuz",
        "outputId": "f197277e-a84b-4ffd-c81f-c81581707fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho1 (InputLayer)           [(None, 4, 4, 1)]         0         \n",
            "                                                                 \n",
            " flatten_2 (Flatten)         (None, 16)                0         \n",
            "                                                                 \n",
            " concatenate_2 (Concatenate  (None, 16)                0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_9 (Dense)             (None, 16)                272       \n",
            "                                                                 \n",
            " dense_10 (Dense)            (None, 32)                544       \n",
            "                                                                 \n",
            " dense_11 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_12 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_13 (Dense)            (None, 16)                2064      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 13312 (52.00 KB)\n",
            "Trainable params: 13312 (52.00 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Modelo denso + fundamental\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(basis.m,basis.m, 1), name='rho1')\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#rho2_layer =  tf.keras.layers.Input(shape=(rho2_size,rho2_size, 1), name='rho2')\n",
        "#flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#fund_layer =  tf.keras.layers.Input(shape=(fund_size, fund_size, 1 ), name='fund')\n",
        "#flatten_fund = tf.keras.layers.Flatten()(fund_layer)\n",
        "\n",
        "dense1 = tf.keras.layers.concatenate([flatten_rho2])\n",
        "#dense1 = tf.keras.layers.concatenate([dense1, flatten_fund])\n",
        "#dense1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(dense1)\n",
        "\n",
        "local_size = basis.m*basis.m\n",
        "l=5\n",
        "layer_s = [256//2**i for i in reversed(range(1,l))]\n",
        "for i in range(0,l-1):\n",
        "    dense1 = tf.keras.layers.Dense(layer_s[i], activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "# Creamos el modelo y compulamos\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "RgoMlCyyfBe-"
      },
      "outputs": [],
      "source": [
        "# LOSS FUNCTIONS\n",
        "r_size = basis.size\n",
        "\n",
        "# Custom loss function based on GS MSE\n",
        "def gs_loss(h_pred, h_true):\n",
        "    h_pred = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_pred)\n",
        "    gs_pred = v[:, 0]\n",
        "\n",
        "    h_true = tf.reshape(h_true, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_true)\n",
        "    gs_true = v[:, 0]\n",
        "\n",
        "    gs_diff = tf.norm(gs_true - gs_pred)\n",
        "\n",
        "    return gs_diff + tf.reduce_mean(tf.square(h_true - h_pred)) * 100\n",
        "\n",
        "def distance_to_hermitian(matrix):\n",
        "    hermitian_part = 0.5 * (matrix + tf.linalg.adjoint(matrix))\n",
        "    distance = tf.norm(matrix - hermitian_part, ord='euclidean')\n",
        "    return distance\n",
        "\n",
        "# Custom loss function based on MSE + non-hermitian penalization\n",
        "def herm_loss(h_pred, h_true):\n",
        "    h_pred_arr = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred)) + distance_to_hermitian(h_pred_arr)\n",
        "\n",
        "# Custom loss function based on h eigenvalues\n",
        "def eig_loss(h_pred, h_true):\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# MSE with a factor\n",
        "def mse_f(h_pred, h_true):\n",
        "    f = 1000\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred))*f\n",
        "\n",
        "# Spectral radius loss\n",
        "def spectral_loss(h_pred, h_true):\n",
        "    eig = tf.math.real(tf.linalg.eigvals(tf.reshape(h_true-h_pred, (-1, fund_size, fund_size))))\n",
        "    return tf.math.reduce_max(tf.abs(eig))\n",
        "\n",
        "# Hamiltonian MSE loss (using generators)\n",
        "def base_mse_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    mat = tf.reshape(h_pred-h_true, (-1, fund_size, fund_size))\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on h eigenvalues (using generators)\n",
        "def base_eig_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals\n",
        "## Auxiliary function\n",
        "def base_to_rho_1_tf(base_pred):\n",
        "    h = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h = tf.reshape(h, (-1, fund_size, fund_size))\n",
        "    state = thermal_state_tf(h)\n",
        "    rho1 = rho_1_tf(state, rho_1_arrays_tf)\n",
        "    return rho1\n",
        "    \n",
        "def rho1_loss(base_pred, base_true):\n",
        "    mat = base_to_rho_1_tf(base_pred) - base_to_rho_1_tf(base_true)\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals (using generators)\n",
        "def base_rho1_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    return tf.reduce_mean(tf.square(rho_1_eig_tf(h_pred) - rho_1_eig_tf(h_true)))*1000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWk9piJtNIZ"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhJCHf0fQdRl",
        "outputId": "1821cf27-9ff5-4d67-e9f5-956d20eda5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-11 21:26:30.585164: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   1561/Unknown - 6s 3ms/step - loss: 1.3714 - accuracy: 0.2327 - mean_squared_error: 1.3714"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-11 21:26:36.284728: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4992103734482267331\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 8s 5ms/step - loss: 1.3710 - accuracy: 0.2328 - mean_squared_error: 1.3710 - val_loss: 0.9705 - val_accuracy: 0.2907 - val_mean_squared_error: 0.9705\n",
            "Epoch 2/50\n",
            "  57/1563 [>.............................] - ETA: 4s - loss: 0.9511 - accuracy: 0.2893 - mean_squared_error: 0.9511"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-12-11 21:26:39.069671: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 4992103734482267331\n",
            "2023-12-11 21:26:39.069725: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 5811829126200214974\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8197 - accuracy: 0.3270 - mean_squared_error: 0.8197 - val_loss: 0.7493 - val_accuracy: 0.3404 - val_mean_squared_error: 0.7493\n",
            "Epoch 3/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6982 - accuracy: 0.3582 - mean_squared_error: 0.6982 - val_loss: 0.6564 - val_accuracy: 0.3659 - val_mean_squared_error: 0.6564\n",
            "Epoch 4/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.6101 - accuracy: 0.3822 - mean_squared_error: 0.6101 - val_loss: 0.5813 - val_accuracy: 0.3886 - val_mean_squared_error: 0.5813\n",
            "Epoch 5/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5550 - accuracy: 0.4003 - mean_squared_error: 0.5550 - val_loss: 0.5432 - val_accuracy: 0.3995 - val_mean_squared_error: 0.5432\n",
            "Epoch 6/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5264 - accuracy: 0.4102 - mean_squared_error: 0.5264 - val_loss: 0.5203 - val_accuracy: 0.4061 - val_mean_squared_error: 0.5203\n",
            "Epoch 7/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.5069 - accuracy: 0.4164 - mean_squared_error: 0.5069 - val_loss: 0.5046 - val_accuracy: 0.4100 - val_mean_squared_error: 0.5046\n",
            "Epoch 8/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4919 - accuracy: 0.4208 - mean_squared_error: 0.4919 - val_loss: 0.4929 - val_accuracy: 0.4143 - val_mean_squared_error: 0.4929\n",
            "Epoch 9/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4802 - accuracy: 0.4248 - mean_squared_error: 0.4802 - val_loss: 0.4821 - val_accuracy: 0.4191 - val_mean_squared_error: 0.4821\n",
            "Epoch 10/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4700 - accuracy: 0.4290 - mean_squared_error: 0.4700 - val_loss: 0.4720 - val_accuracy: 0.4218 - val_mean_squared_error: 0.4720\n",
            "Epoch 11/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4615 - accuracy: 0.4320 - mean_squared_error: 0.4615 - val_loss: 0.4637 - val_accuracy: 0.4249 - val_mean_squared_error: 0.4637\n",
            "Epoch 12/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4546 - accuracy: 0.4345 - mean_squared_error: 0.4546 - val_loss: 0.4576 - val_accuracy: 0.4283 - val_mean_squared_error: 0.4576\n",
            "Epoch 13/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4488 - accuracy: 0.4363 - mean_squared_error: 0.4488 - val_loss: 0.4528 - val_accuracy: 0.4302 - val_mean_squared_error: 0.4528\n",
            "Epoch 14/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4436 - accuracy: 0.4383 - mean_squared_error: 0.4436 - val_loss: 0.4473 - val_accuracy: 0.4326 - val_mean_squared_error: 0.4473\n",
            "Epoch 15/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4390 - accuracy: 0.4399 - mean_squared_error: 0.4390 - val_loss: 0.4419 - val_accuracy: 0.4347 - val_mean_squared_error: 0.4419\n",
            "Epoch 16/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4346 - accuracy: 0.4414 - mean_squared_error: 0.4346 - val_loss: 0.4366 - val_accuracy: 0.4367 - val_mean_squared_error: 0.4366\n",
            "Epoch 17/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4304 - accuracy: 0.4433 - mean_squared_error: 0.4304 - val_loss: 0.4309 - val_accuracy: 0.4395 - val_mean_squared_error: 0.4309\n",
            "Epoch 18/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4264 - accuracy: 0.4447 - mean_squared_error: 0.4264 - val_loss: 0.4261 - val_accuracy: 0.4407 - val_mean_squared_error: 0.4261\n",
            "Epoch 19/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4224 - accuracy: 0.4455 - mean_squared_error: 0.4224 - val_loss: 0.4215 - val_accuracy: 0.4419 - val_mean_squared_error: 0.4215\n",
            "Epoch 20/50\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.4184 - accuracy: 0.4472 - mean_squared_error: 0.4184 - val_loss: 0.4183 - val_accuracy: 0.4440 - val_mean_squared_error: 0.4183\n",
            "Epoch 21/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4142 - accuracy: 0.4489 - mean_squared_error: 0.4142 - val_loss: 0.4140 - val_accuracy: 0.4462 - val_mean_squared_error: 0.4140\n",
            "Epoch 22/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.4100 - accuracy: 0.4507 - mean_squared_error: 0.4100 - val_loss: 0.4094 - val_accuracy: 0.4491 - val_mean_squared_error: 0.4094\n",
            "Epoch 23/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4056 - accuracy: 0.4530 - mean_squared_error: 0.4056 - val_loss: 0.4055 - val_accuracy: 0.4502 - val_mean_squared_error: 0.4055\n",
            "Epoch 24/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.4013 - accuracy: 0.4549 - mean_squared_error: 0.4013 - val_loss: 0.4019 - val_accuracy: 0.4513 - val_mean_squared_error: 0.4019\n",
            "Epoch 25/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3970 - accuracy: 0.4571 - mean_squared_error: 0.3970 - val_loss: 0.3979 - val_accuracy: 0.4527 - val_mean_squared_error: 0.3979\n",
            "Epoch 26/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3928 - accuracy: 0.4584 - mean_squared_error: 0.3928 - val_loss: 0.3937 - val_accuracy: 0.4545 - val_mean_squared_error: 0.3937\n",
            "Epoch 27/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3887 - accuracy: 0.4598 - mean_squared_error: 0.3887 - val_loss: 0.3923 - val_accuracy: 0.4549 - val_mean_squared_error: 0.3923\n",
            "Epoch 28/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3849 - accuracy: 0.4608 - mean_squared_error: 0.3849 - val_loss: 0.3889 - val_accuracy: 0.4567 - val_mean_squared_error: 0.3889\n",
            "Epoch 29/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3814 - accuracy: 0.4620 - mean_squared_error: 0.3814 - val_loss: 0.3878 - val_accuracy: 0.4563 - val_mean_squared_error: 0.3878\n",
            "Epoch 30/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3782 - accuracy: 0.4628 - mean_squared_error: 0.3782 - val_loss: 0.3857 - val_accuracy: 0.4567 - val_mean_squared_error: 0.3857\n",
            "Epoch 31/50\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.3752 - accuracy: 0.4639 - mean_squared_error: 0.3752 - val_loss: 0.3832 - val_accuracy: 0.4572 - val_mean_squared_error: 0.3832\n",
            "Epoch 32/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3725 - accuracy: 0.4650 - mean_squared_error: 0.3725 - val_loss: 0.3802 - val_accuracy: 0.4583 - val_mean_squared_error: 0.3802\n",
            "Epoch 33/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3699 - accuracy: 0.4658 - mean_squared_error: 0.3699 - val_loss: 0.3779 - val_accuracy: 0.4584 - val_mean_squared_error: 0.3779\n",
            "Epoch 34/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3675 - accuracy: 0.4670 - mean_squared_error: 0.3675 - val_loss: 0.3761 - val_accuracy: 0.4580 - val_mean_squared_error: 0.3761\n",
            "Epoch 35/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3652 - accuracy: 0.4677 - mean_squared_error: 0.3652 - val_loss: 0.3744 - val_accuracy: 0.4586 - val_mean_squared_error: 0.3744\n",
            "Epoch 36/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3630 - accuracy: 0.4682 - mean_squared_error: 0.3630 - val_loss: 0.3711 - val_accuracy: 0.4601 - val_mean_squared_error: 0.3711\n",
            "Epoch 37/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3609 - accuracy: 0.4690 - mean_squared_error: 0.3609 - val_loss: 0.3686 - val_accuracy: 0.4614 - val_mean_squared_error: 0.3686\n",
            "Epoch 38/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3589 - accuracy: 0.4696 - mean_squared_error: 0.3589 - val_loss: 0.3668 - val_accuracy: 0.4613 - val_mean_squared_error: 0.3668\n",
            "Epoch 39/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3570 - accuracy: 0.4697 - mean_squared_error: 0.3570 - val_loss: 0.3652 - val_accuracy: 0.4626 - val_mean_squared_error: 0.3652\n",
            "Epoch 40/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3551 - accuracy: 0.4706 - mean_squared_error: 0.3551 - val_loss: 0.3634 - val_accuracy: 0.4633 - val_mean_squared_error: 0.3634\n",
            "Epoch 41/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3533 - accuracy: 0.4710 - mean_squared_error: 0.3533 - val_loss: 0.3605 - val_accuracy: 0.4641 - val_mean_squared_error: 0.3605\n",
            "Epoch 42/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3516 - accuracy: 0.4714 - mean_squared_error: 0.3516 - val_loss: 0.3582 - val_accuracy: 0.4656 - val_mean_squared_error: 0.3582\n",
            "Epoch 43/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3500 - accuracy: 0.4720 - mean_squared_error: 0.3500 - val_loss: 0.3566 - val_accuracy: 0.4655 - val_mean_squared_error: 0.3566\n",
            "Epoch 44/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3485 - accuracy: 0.4724 - mean_squared_error: 0.3485 - val_loss: 0.3546 - val_accuracy: 0.4662 - val_mean_squared_error: 0.3546\n",
            "Epoch 45/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3471 - accuracy: 0.4728 - mean_squared_error: 0.3471 - val_loss: 0.3524 - val_accuracy: 0.4677 - val_mean_squared_error: 0.3524\n",
            "Epoch 46/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3457 - accuracy: 0.4736 - mean_squared_error: 0.3457 - val_loss: 0.3516 - val_accuracy: 0.4676 - val_mean_squared_error: 0.3516\n",
            "Epoch 47/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3445 - accuracy: 0.4740 - mean_squared_error: 0.3445 - val_loss: 0.3498 - val_accuracy: 0.4688 - val_mean_squared_error: 0.3498\n",
            "Epoch 48/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3433 - accuracy: 0.4743 - mean_squared_error: 0.3433 - val_loss: 0.3488 - val_accuracy: 0.4690 - val_mean_squared_error: 0.3488\n",
            "Epoch 49/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3421 - accuracy: 0.4744 - mean_squared_error: 0.3421 - val_loss: 0.3475 - val_accuracy: 0.4697 - val_mean_squared_error: 0.3475\n",
            "Epoch 50/50\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.3410 - accuracy: 0.4746 - mean_squared_error: 0.3410 - val_loss: 0.3466 - val_accuracy: 0.4697 - val_mean_squared_error: 0.3466\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam, Lion\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='MSE',  \n",
        "              metrics=['accuracy', 'mean_squared_error'])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 50\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    history = model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "cvpE_X1iTXcB",
        "outputId": "eff0e5f5-5b26-46ea-ec6b-491d1de9944c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history.history['mean_squared_error'], label='Training MSE')\n",
        "plt.plot(history.history['val_mean_squared_error'], label='Validation MSE')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs. Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# MIN LOSS = 0.0128 c/fund 50epochs MSE\n",
        "##         = 0.0118 s/fund 50epochs MSE\n",
        "##         = 0.0039 s/fund 50epochs MSE m=4 d=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRlZuRUNa6Yb",
        "outputId": "85850559-311b-4cf4-ea5b-465a9ee8a7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a validation dataset (val_dataset)\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "next_sample = next(iterador)\n",
        "input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "actual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[3.83095716 1.77937831 1.29032864 0.6377823  0.47274118 1.77833622\n",
            " 0.51191839 4.64635882 1.48832993 0.50550907 3.77975023 0.05176666\n",
            " 4.23684731 0.80813639 3.85897728 3.35963222], shape=(16,), dtype=float64)\n",
            "[4.619127   1.9000597  1.7876097  1.5259181  1.3899126  1.5995582\n",
            " 0.35962865 4.539487   1.3457476  0.49970716 4.179805   0.12439838\n",
            " 3.8678389  0.32151058 3.5388505  3.959848  ]\n",
            "tf.Tensor(\n",
            "[3.87528509 3.37179146 4.50390391 4.79198339 1.98682148 3.86878542\n",
            " 3.49061359 3.41262543 3.50918538 3.05714776 3.89616827 4.74672546\n",
            " 0.86942555 4.24697319 4.79889197 2.38597952], shape=(16,), dtype=float64)\n",
            "[3.6096532 3.3608432 3.6147194 4.124425  1.5032138 4.59916   3.0314255\n",
            " 2.8564544 2.6209383 2.5445633 4.392103  3.9902215 1.2750883 3.46746\n",
            " 4.335771  2.5413518]\n",
            "tf.Tensor(\n",
            "[0.91748    1.82378268 2.81123226 4.31715937 0.33846716 2.65214035\n",
            " 2.01504541 2.63107569 3.40600459 3.22361001 4.83516019 4.33843328\n",
            " 0.42765416 0.96972099 1.66990315 0.18283297], shape=(16,), dtype=float64)\n",
            "[0.20202501 1.7398602  2.614562   2.8729131  0.4450457  2.6900258\n",
            " 1.7130791  2.2450385  3.267102   2.6580205  4.581893   4.37516\n",
            " 0.38082227 1.0414234  1.6047163  0.72491115]\n",
            "tf.Tensor(\n",
            "[2.56946514 1.3875217  4.20318782 3.29021593 0.69088973 2.20401041\n",
            " 1.61420515 4.83050757 2.72281854 1.08250839 0.73121477 3.0858175\n",
            " 1.26714769 1.7231707  1.12546766 1.90465363], shape=(16,), dtype=float64)\n",
            "[3.5848641  2.320318   4.510502   3.182107   0.91770303 2.645523\n",
            " 1.6112047  4.3730235  3.0674343  1.0715193  1.0161176  2.6459985\n",
            " 1.2117611  1.5142585  1.8992231  2.1203172 ]\n",
            "0.5788063936647844 2.084322105561998\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Vemos algunos valores\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 4):\n",
        "        print(e[1][i])\n",
        "        print(predictions[i])\n",
        "    break\n",
        "    \n",
        "\n",
        "RMSE_pred = mean_squared_error(actual_values, predictions, squared=False)\n",
        "RMSE_rand = mean_squared_error(actual_values, next_sample[1], squared=False)\n",
        "print(RMSE_pred, RMSE_rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 95,
      "metadata": {
        "id": "ds5iD1OMbZu3"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 2 into shape (1,1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m val_dataset:\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m     \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m0\u001b[39m, \u001b[39m3\u001b[39m \u001b[39mif\u001b[39;00m printear \u001b[39melse\u001b[39;00m batch_size):\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m         \u001b[39m# Valores actuales\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m         \u001b[39m#h = e[1][i].numpy().reshape(basis.size,basis.size)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m         h_true \u001b[39m=\u001b[39m gen_to_h(e[\u001b[39m1\u001b[39;49m][i], rho_1_arrays)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m         \u001b[39m#print(h) if printear else 0\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m         r \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(np\u001b[39m.\u001b[39mlinalg\u001b[39m.\u001b[39meigvals(e[\u001b[39m0\u001b[39m][i]))\n",
            "\u001b[1;32m/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb Cell 33\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mgen_to_h\u001b[39m(base, rho_1_arrays):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     triag \u001b[39m=\u001b[39m fill_triangular_np(base)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     body_gen \u001b[39m=\u001b[39m triag \u001b[39m+\u001b[39m np\u001b[39m.\u001b[39mtranspose(triag)\u001b[39m-\u001b[39mnp\u001b[39m.\u001b[39mdiag(np\u001b[39m.\u001b[39mdiag(triag))\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     h \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
            "\u001b[1;32m/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb Cell 33\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m n \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mint32(np\u001b[39m.\u001b[39msqrt(\u001b[39m.25\u001b[39m \u001b[39m+\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m m) \u001b[39m-\u001b[39m \u001b[39m.5\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m x_tail \u001b[39m=\u001b[39m x[(m \u001b[39m-\u001b[39m (n\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m2\u001b[39m \u001b[39m-\u001b[39m m)):]\n\u001b[0;32m---> <a href='vscode-notebook-cell:/home/agus/Escritorio/UNLP/FermionicML/FermionicML_thermal_2body.ipynb#Y146sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mreturn\u001b[39;00m np\u001b[39m.\u001b[39mtriu(np\u001b[39m.\u001b[39;49mconcatenate([x, x_tail[::\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m]], \u001b[39m0\u001b[39;49m)\u001b[39m.\u001b[39;49mreshape(n, n))\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (1,1)"
          ]
        }
      ],
      "source": [
        "m_size = basis.size\n",
        "rho_1_pred = []\n",
        "rho_1_actual = []\n",
        "norm = []\n",
        "norm_rand = []\n",
        "printear =  False\n",
        "\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 3 if printear else batch_size):\n",
        "        # Valores actuales\n",
        "        #h = e[1][i].numpy().reshape(basis.size,basis.size)\n",
        "        h_true = gen_to_h(e[1][i], rho_1_arrays)\n",
        "        #print(h) if printear else 0\n",
        "        r = max(np.linalg.eigvals(e[0][i]))\n",
        "        rho_1_actual.append(r)\n",
        "\n",
        "        print(h_true) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "\n",
        "        # Valores predichos\n",
        "        #h = predictions[i].reshape(basis.size,basis.size)\n",
        "        h_pred = gen_to_h(predictions[i], rho_1_arrays)\n",
        "        beta = 1\n",
        "        # Estado térmico\n",
        "        state = thermal_state(h_pred, beta)\n",
        "        # Estado puro\n",
        "        #state = pure_state(h_pred)\n",
        "        rho1 = np.array(rho_1(basis.d, state, rho_1_arrays))\n",
        "        r = max(np.sort(linalg_d.eigvals(rho1).real))\n",
        "        rho_1_pred.append(r)\n",
        "\n",
        "        print(h_pred) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "        \n",
        "\n",
        "        # Normas\n",
        "        norm.append(np.linalg.norm(h_true-h_pred, ord='fro'))\n",
        "        print(f'Norma {norm[-1]}') if printear else 0\n",
        "        ## Vamos a comparar con un h aleatorio\n",
        "        size = basis.d*(basis.d+1)//2\n",
        "        base = np.random.uniform(low=0, high=1.0, size=(size,))\n",
        "        h_rand = gen_to_h(base, rho_1_arrays)\n",
        "        norm_rand.append(np.linalg.norm(h_true-h_rand, ord='fro'))\n",
        "        #print(f'Norma random {norm_rand[-1]}') if printear else 0\n",
        "        print('') if printear else 0\n",
        "        \n",
        "\n",
        "\n",
        "    # e contiene todo el batch y nos basta con uno\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(e[1][10])\n",
        "predictions[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "AL2EC9Ci-0HG",
        "outputId": "545ebe57-d3de-490f-f076-709d5c47b5f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f=1\n",
        "rho_1_actual = np.array(rho_1_actual)\n",
        "rho_1_pred = np.array(rho_1_pred)\n",
        "#print(mean_squared_error(rho_1_pred, rho_1_actual))\n",
        "\n",
        "print('Rho1 based statistics')\n",
        "print(np.mean(np.abs(rho_1_actual-rho_1_pred)))\n",
        "print(np.mean(rho_1_actual)*f)\n",
        "print('std')\n",
        "print(np.std(rho_1_actual-rho_1_pred)*f)\n",
        "print(np.std(rho_1_actual)*f)\n",
        "print(np.std(rho_1_pred)*f)\n",
        "plt.hist(np.array(rho_1_pred-rho_1_actual), bins=50)\n",
        "plt.show()\n",
        "print('H based statistics')\n",
        "print(np.mean(norm), np.mean(norm_rand))\n",
        "print(np.mean(norm_rand)/np.mean(norm))\n",
        "\n",
        "\n",
        "# BEST: FACTOR 1/8 c/fund\n",
        "## 500 epochs, 10M dataset\n",
        "# BEST: FACTOR 1/9 s/fund\n",
        "## 50 epochs, 5M dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "6.25/1.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 25 epochs d = m*2\n",
        "res = {}\n",
        "res[5] = 35/8.19 \n",
        "res[4] = 15/2.47\n",
        "res[3] = 6.2/1.73"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YioVllOX3M1N",
        "outputId": "b7715c37-1400-4c04-8be3-dd247b4b9db9"
      },
      "outputs": [],
      "source": [
        "# Get the weights of all dense layers in the model\n",
        "dense_weights = []\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Dense):\n",
        "        weights = layer.get_weights()\n",
        "        if len(weights) > 0:\n",
        "            dense_weights.append(weights[0])\n",
        "\n",
        "# Visualize the weights of each dense layer\n",
        "for i, weights in enumerate(dense_weights):\n",
        "    plt.figure()\n",
        "    plt.imshow(weights, cmap='viridis', aspect='auto')\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"Dense Layer {i+1} Weights Visualization\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 1 1] [0 1 1 0 0 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "            if mat[i,j,0,9] != 0:\n",
        "                print(v,w)\n",
        "\n",
        "    return mat\n",
        "\n",
        "r = rho_2_gen(basis, basis_m2, t_basis)\n",
        "r[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 1],\n",
              "       [1, 0, 1, 1, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 0],\n",
              "       [1, 0, 1, 0, 0, 1],\n",
              "       [1, 0, 0, 1, 1, 0],\n",
              "       [1, 0, 0, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 1],\n",
              "       [0, 1, 1, 1, 0, 0],\n",
              "       [0, 1, 1, 0, 1, 0],\n",
              "       [0, 1, 1, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 0, 1, 1],\n",
              "       [0, 0, 1, 1, 1, 0],\n",
              "       [0, 0, 1, 1, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 1],\n",
              "       [0, 0, 0, 1, 1, 1]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basis.base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 20)\n",
            "[array([0, 1, 0, 1, 1, 0])] [0 1 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "col = 1\n",
        "b = b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0]))\n",
        "print(b.shape)\n",
        "for x in range(0,b.shape[1]):\n",
        "    if b[col,x] != 0:\n",
        "        ind = x\n",
        "        break\n",
        "else:\n",
        "    ind = NaN\n",
        "\n",
        "print([basis.base[ind]], mll_basis.base[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "d = 2*m\n",
        "basis = fixed_basis(m, d)\n",
        "t_basis = fixed_basis(2, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "ml_basis = basis_m1\n",
        "mll_basis = basis_m2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_basis = fixed_basis(2, d)\n",
        "mll_basis = fixed_basis(basis.m-2, d)\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2)))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    offset = 4*m+1\n",
        "    indices = [-(k-1)*(2*k-offset) for k in range(1,m+1)] # Lo saque de Mathmatica, vos confia\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    \n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "\n",
        "    hi = -np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    return (h0, hi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(h02,hi2) = two_body_hamiltonian(t_basis.size, m, [0,1,2], np.ones((3,3)), rho_1_arrays, rho_2_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]]]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "print(rho_2_arrays[9,0,0,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "\n",
        "A = np.array([0, 1, 2])  # Your list with d elements\n",
        "\n",
        "# Create a diagonal matrix with each element repeated twice\n",
        "result_matrix = np.diagflat(np.kron(A, np.ones(2)))\n",
        "\n",
        "print(result_matrix)\n",
        "np.kron(A, np.ones(2))\n",
        "\n",
        "mat = np.zeros((basis.size, basis.size))\n",
        "for i in range(0,2*d):\n",
        "    for j in range(0, 2*d):\n",
        "        mat += result_matrix[i,j] * rho_1_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mat = np.sum(result_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h0 == mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1]\n",
            "[0, 9, 14]\n",
            "[0, 9, 14]\n"
          ]
        }
      ],
      "source": [
        "d = 3\n",
        "t_basis = fixed_basis(2, 2*d)\n",
        "basis = fixed_basis(d, 2*d)\n",
        "size = t_basis.size\n",
        "#basis = fixed_basis(d, 2*d)\n",
        "diag_elem = []\n",
        "for x in t_basis.base:\n",
        "    if all([x[i] == x[i+1] for i in range(0, 2*d, 2)]):\n",
        "        print(x)\n",
        "        diag_elem.append(t_basis.rep_to_index(x))\n",
        "\n",
        "print(diag_elem)\n",
        "# Veamos el GALERAZO de Wolfram\n",
        "n = 4*d+1\n",
        "print([-(k-1)*(2*k-n) for k in range(1,d+1)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m2_basis = fixed_basis(2, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-2, d)\n",
        "print(nm2_basis.base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "index = [0,9,14]\n",
        "mat = np.zeros((size,size))\n",
        "for i in range(0,3):\n",
        "    for j in range(0,3):\n",
        "        mat[index[i], index[j]] = W[i,j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "#rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "\n",
        "W = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "W = np.ones((3,3))\n",
        "index = [0, 9, 14]\n",
        "size = 15  # Assuming size is the size of the matrix\n",
        "\n",
        "# Create a meshgrid of indices\n",
        "i, j = np.meshgrid(index, index, indexing='ij')\n",
        "\n",
        "# Use the meshgrid indices to assign values from W to the specified positions in mat\n",
        "mat = np.zeros((size, size))\n",
        "mat[i, j] = W\n",
        "\n",
        "# La mat... mat corresponde a los coeficientes en t_basis\n",
        "inte = np.zeros((basis.size, basis.size))\n",
        "for i in range(0, t_basis.size):\n",
        "    for j in range(0, t_basis.size):\n",
        "        inte += - mat[i, j] * rho_2_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inte == hi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "\n",
        "from numba import njit\n",
        "\n",
        "# Parametros hamiltoniano\n",
        "e = 1\n",
        "eps = 0\n",
        "e0 = np.zeros(2*d)\n",
        "eigenspace_tol = 0.0001\n",
        "for k in range(0, d):\n",
        "    r = random.random() * eps * 0\n",
        "    e0[2*k] = k*e+r\n",
        "    e0[2*k+1] = k*e+r\n",
        "\n",
        "@njit(parallel=True)\n",
        "def base_hamiltonian_aux(basis, size, d, basis_m1, basis_m2):\n",
        "    # Construccion de H\n",
        "    d = d//2\n",
        "    h0 = np.zeros((size,size), dtype=np.float32)\n",
        "    for k in prange(0,2*d):\n",
        "        h0 += e0[k] * np.dot(bd_aux(basis_m1, basis, k),b_aux(basis, basis_m1, k))\n",
        "    hi = np.zeros((size, size), dtype=np.float32)\n",
        "    for k in prange(0,d):\n",
        "        for kb in prange(0,d):\n",
        "            bd_terms = np.dot(bd_aux(basis_m1, basis, 2*k),bd_aux(basis_m2, basis_m1, 2*k+1))\n",
        "            b_terms = np.dot(b_aux(basis_m1, basis_m2, 2*kb+1),b_aux(basis, basis_m1, 2*kb))\n",
        "            hi += -1*np.dot(bd_terms,b_terms)\n",
        "\n",
        "    return (h0, hi)\n",
        "\n",
        "def base_hamiltonian(basis, basis_m1, basis_m2):\n",
        "    return base_hamiltonian_aux(basis.base, basis.size, basis.d, basis_m1.base, basis_m2.base)\n",
        "\n",
        "h0, hi = base_hamiltonian(basis, basis_m1, basis_m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oapxWkD16fHg"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
