{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguschanchu/FermionicML/blob/main/FermionicML_thermal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXz5cOlVwrzZ"
      },
      "source": [
        "# FermionicML:\n",
        "\n",
        "Code based on aguschanchu/Bosonic.py\n",
        "\n",
        "A diferencia del código anterior, este modelo trabaja sobre estados térmicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD2Yai55rMm"
      },
      "source": [
        "## Código base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgf9ExZN4jA7"
      },
      "source": [
        "Cargamos el código de Bosonic.py básico, branch fermionic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "Gydz4kCH4l5w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/tmp/ipykernel_2852/990103985.py:296: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  def gamma_lamba_inv(x):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import binom\n",
        "from scipy.sparse import dok_matrix, linalg\n",
        "from scipy import linalg as linalg_d\n",
        "from joblib import Memory\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from joblib import Parallel, delayed\n",
        "from numba import jit, prange, njit\n",
        "import numba as nb\n",
        "import pickle\n",
        "import math\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Funciones auxiliares optimiadas\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def int_to_tuple_arr(ni,nf, b, digits=None):\n",
        "    sol = np.zeros((nf-ni, digits), dtype=np.int64)\n",
        "    for n in prange(ni, nf):\n",
        "        r = np.zeros(digits, dtype=np.int64)\n",
        "        ncop = n\n",
        "        idx = 0\n",
        "        while n != 0:\n",
        "            r[idx] = n % b\n",
        "            n = n // b\n",
        "            idx += 1\n",
        "        if digits is not None:\n",
        "            if idx < digits:\n",
        "                for i in range(idx, digits):\n",
        "                    r[i] = 0\n",
        "                idx = digits\n",
        "        sol[ncop-ni,:] = r[:idx]\n",
        "    return sol\n",
        "\n",
        "def tuple_to_int(t, d):\n",
        "    b = d-1\n",
        "    l = len(t)\n",
        "    s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "    return sum(s)\n",
        "\n",
        "def create_basis_(m, d, size):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 1000000\n",
        "    for x in range(0,(m+1)**d, chunk_size):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        arr = int_to_tuple_arr(start_index, end_index, m+1, d)\n",
        "        sums = np.sum(arr, axis=1)\n",
        "        rows = np.where(sums == m)[0]\n",
        "        for row in [arr[i] for i in rows]:\n",
        "            if np.all(np.logical_or(row == 0, row == 1)):\n",
        "                base.append(row)\n",
        "\n",
        "    # Como consecuencia de la paralelizacion, es necesario reordenar la base\n",
        "    sorted_base = sorted(base, key=lambda x: tuple_to_int(x, d), reverse=True)\n",
        "    assert len(base) == size\n",
        "\n",
        "    return sorted_base\n",
        "\n",
        "def custom_base_representation_tf(n_min, n_max, base, num_digits):\n",
        "    # Generate a range of numbers from n_min to n_max\n",
        "    numbers = tf.range(n_min, n_max + 1, dtype=tf.int64)\n",
        "    \n",
        "    # Calculate the digits in the custom base using broadcasting\n",
        "    digits = tf.pow(tf.cast(base, dtype=tf.float64), tf.cast(tf.range(num_digits), dtype=tf.float64))\n",
        "    \n",
        "    # Reshape the digits to [1, num_digits] for broadcasting\n",
        "    digits = tf.reshape(digits, [1, -1])\n",
        "    \n",
        "    # Reshape numbers to [batch_size, 1]\n",
        "    numbers = tf.reshape(tf.cast(numbers, dtype=tf.float64), [-1, 1])\n",
        "    \n",
        "    # Calculate the digits in the custom base for each number using broadcasting\n",
        "    result = tf.cast(tf.math.floormod(tf.math.floordiv(numbers, digits), base), dtype=tf.int32)\n",
        "    \n",
        "    # Pad the result to have exactly num_digits columns\n",
        "    result = tf.pad(result, paddings=[[0, 0], [0, num_digits - tf.shape(result)[1]]], constant_values=0)\n",
        "    \n",
        "    # Reverse the order of columns\n",
        "    #result = tf.reverse(result, axis=[1])\n",
        "\n",
        "    return result\n",
        "\n",
        "def select_rows_with_sum(arr, m):\n",
        "    # Create a mask based on the criteria\n",
        "    mask = tf.reduce_all(tf.math.logical_or(tf.equal(arr, 0), tf.equal(arr, 1)), axis=1) & (tf.reduce_sum(arr, axis=1) == m)\n",
        "    \n",
        "    # Use the mask to select the rows\n",
        "    result = tf.boolean_mask(arr, mask, axis=0)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def create_basis_tf_(m, d):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 10000000\n",
        "    for x in tqdm(range(0,(m+1)**d, chunk_size)):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        res = custom_base_representation_tf(start_index, end_index, m+1, d)\n",
        "        arr = select_rows_with_sum(res, m)\n",
        "        base.append(arr.numpy())\n",
        "\n",
        "    return np.concatenate(base)\n",
        "\n",
        "class fixed_basis:\n",
        "\n",
        "    # Convierte a un enterno n a su escritura en base b\n",
        "    def _int_to_tuple(self, n, b, digits = None):\n",
        "        rep = np.base_repr(n, b)\n",
        "        rep_int = [int(x,b) for x in rep]\n",
        "        if digits is not None:\n",
        "            zeros = [0 for i in range(0,digits-len(rep))]\n",
        "            return zeros + rep_int\n",
        "        else:\n",
        "            return rep_int\n",
        "\n",
        "    # Revierte la transformacion anterior\n",
        "    def tuple_to_int(self, t):\n",
        "        b = self.d-1\n",
        "        l = len(t)\n",
        "        s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "        return sum(s)\n",
        "\n",
        "    # Convierte el vector en su representacion\n",
        "    def vect_to_repr(self, vect):\n",
        "        for i, k in enumerate(vect):\n",
        "            if k == 1. or k == 1:\n",
        "                break\n",
        "        else:\n",
        "            return 0\n",
        "        return self.base[i,:]\n",
        "\n",
        "    def rep_to_vect(self, rep):\n",
        "        rep = list(rep)\n",
        "        for i, r in [(j, self.base[j,:]) for j in range(0,self.size)]:\n",
        "            if list(r) == rep:\n",
        "                return self.canonicals[:,i]\n",
        "        else:\n",
        "            None\n",
        "\n",
        "    def rep_to_index(self, rep):\n",
        "        return self.base.tolist().index(list(rep))\n",
        "\n",
        "    @staticmethod\n",
        "    def rep_to_exi(rep):\n",
        "        r = []\n",
        "        for i, k in enumerate(rep):\n",
        "            r += [i for x in range(0,k)]\n",
        "        return r\n",
        "\n",
        "    # Crea base de M particulas en D estados (repr y base canonica)\n",
        "    def create_basis(self, m, d):\n",
        "        #print(\"Creating basis: \", m, d)\n",
        "        length = int(binom(d,m))\n",
        "        base = np.array(create_basis_tf_(m, d))\n",
        "        # Asignamos a cada uno de ellos un canónico\n",
        "        canonicals = np.eye(length)\n",
        "        return base, canonicals\n",
        "\n",
        "    def __init__(self, m, d):\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        self.size = int(binom(d,m))\n",
        "        (self.base, self.canonicals) = self.create_basis(m, d)\n",
        "\n",
        "\n",
        "# Matrices de aniquilación y creación endomórficas. Estan fuera de la clase para poder ser cacheadas\n",
        "#@memory.cache\n",
        "def bdb(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0 and v[i] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[j] -= 1\n",
        "                dest[i] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[i]+1)*np.sqrt(v[j])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0:\n",
        "                mat[k, k] = v[i]\n",
        "    return mat\n",
        "\n",
        "#@memory.cache\n",
        "def bbd(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 0 and v[j] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[i] -= 1\n",
        "                dest[j] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[j]+1)*np.sqrt(v[i])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 1:\n",
        "                mat[k, k] = v[i]+1\n",
        "    return mat\n",
        "\n",
        "# Matrices de aniquilación y creación.Toman la base de origen y destino (basis_o, basis_d) resp\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def b_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 0:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] -= 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i])\n",
        "    return mat\n",
        "\n",
        "def b(basis_o, basis_d, i):\n",
        "    return b_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def bd_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 1:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd(basis_o, basis_d, i):\n",
        "    return bd_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "\n",
        "# Acepta una lista de indices a crear\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def bd_gen_aux(basis_o, basis_d, gen_list):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        conds = np.zeros(len(gen_list), dtype=np.int64)\n",
        "        for i in range(len(gen_list)):\n",
        "            if basis_o[k][gen_list[i]] != 1:\n",
        "                conds[i] = 1\n",
        "        if np.all(conds):\n",
        "            dest = list(basis_o[k].copy())\n",
        "            for i in gen_list:\n",
        "                dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd_gen(basis_o, basis_d, i):\n",
        "    return bd_gen_aux(basis_o.base, basis_d.base, np.array(i))\n",
        "\n",
        "def b_gen(basis_o, basis_d, i):\n",
        "    return np.transpose(bd_gen(basis_d, basis_o, i))\n",
        "\n",
        "# Volvemos a definir la función para compilarla\n",
        "@nb.jit(forceobj=True)\n",
        "def _rep_to_index(base, rep):\n",
        "    return base.tolist().index(list(rep))\n",
        "\n",
        "# Funciones auxiliares para calcular rho2kkbar y gamma_p\n",
        "@nb.jit(nopython=True)\n",
        "def rep_to_exi(rep):\n",
        "    r = []\n",
        "    for i in range(len(rep)):\n",
        "        for j in range(rep[i]):\n",
        "            r.append(i)\n",
        "    return r\n",
        "\n",
        "@nb.njit\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "@nb.njit\n",
        "def gamma_lamba(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.jit\n",
        "def gamma_lamba_inv(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / np.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.njit\n",
        "def rep_to_index_np(base, rep):\n",
        "    for i in range(len(base)):\n",
        "        if np.all(base[i] == rep):\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "\n",
        "def gamma_p(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    return gamma_p_aux(basis.base, vect, m_basis.base, nm_basis.base)\n",
        "\n",
        "@nb.njit()\n",
        "def gamma_p_aux(basis, vect, m_basis, nm_basis):\n",
        "    mat = np.zeros((len(m_basis), len(nm_basis)), dtype=np.float32)\n",
        "    for i in prange(len(m_basis)):\n",
        "        v = m_basis[i]\n",
        "        for j in prange(len(nm_basis)):\n",
        "            w = nm_basis[j]\n",
        "            targ = v + w\n",
        "            index = rep_to_index_np(basis, targ)\n",
        "            if index != -1:\n",
        "                coef = vect[index]\n",
        "                if coef != 0:\n",
        "                    coef = coef * gamma_lamba_inv(v) * gamma_lamba_inv(w) * gamma_lamba(targ)\n",
        "                mat[i, j] = coef\n",
        "    return mat\n",
        "# Devuelve la matriz rho M asociada al vector\n",
        "def rho_m(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    g = gamma_p(basis, m, vect, m_basis, nm_basis)\n",
        "    return np.dot(g,np.transpose(g))\n",
        "\n",
        "# Devuelve la matriz gamma asociada a la descomposición (M,N-M) del vector\n",
        "@jit(forceobj=True)\n",
        "def gamma(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    mat = dok_matrix((m_basis.size, nm_basis.size), dtype=np.float32)\n",
        "    for i, v in enumerate(m_basis.base):\n",
        "        for j, w in enumerate(nm_basis.base):\n",
        "            targ = v+w\n",
        "            # Revisamos que sea un estado fermionico valido\n",
        "            arr = np.asarray(targ)\n",
        "            if not np.all(np.logical_or(arr == 0, arr == 1)):\n",
        "                continue\n",
        "            index = _rep_to_index(basis.base, targ)\n",
        "            coef = vect[index]\n",
        "            if coef != 0:\n",
        "                aux = lambda x: np.prod(np.reciprocal(np.sqrt([np.math.factorial(o) for o in x])))\n",
        "                aux_inv = lambda x: np.prod(np.sqrt([np.math.factorial(o) for o in x]))\n",
        "                coef = coef * aux(v) * aux(w) * aux_inv(targ)\n",
        "                #coef = coef\n",
        "                #print(v,w,coef)\n",
        "            mat[i,j] = coef\n",
        "    return mat\n",
        "\n",
        "# Genera las matrices de rho1\n",
        "def rho_1_gen(basis):\n",
        "    d = basis.d\n",
        "    s = basis.size\n",
        "    mat = np.empty((d,d,s,s), dtype=np.float32)\n",
        "    for i in range(0, d):\n",
        "        for j in range(0, d):\n",
        "            mat[i,j,:,:] = np.array(bdb(basis,j, i).todense())\n",
        "    return mat\n",
        "\n",
        "#@jit(parallel=True, nopython=True)\n",
        "def rho_1(d, state, rho_1_arrays):\n",
        "    state_expanded = state[np.newaxis, np.newaxis, :, :]\n",
        "    product = state_expanded * rho_1_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "\n",
        "    return mat\n",
        "\n",
        "\n",
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "\n",
        "    return mat\n",
        "\n",
        "def rho_2(size, state, rho_2_arrays):\n",
        "    state_expanded = np.expand_dims(state, axis=1)\n",
        "    state_expanded = np.expand_dims(state_expanded, axis=1)\n",
        "    rho_2_arrays = rho_2_arrays[np.newaxis, :, :, :, :]\n",
        "    print(state_expanded.shape, rho_2_arrays.shape)\n",
        "    product = state_expanded * rho_2_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "    return mat\n",
        "\n",
        "def get_kkbar_indices(t_basis):\n",
        "    indices = []\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        if np.all(v[::2] == v[1::2]):\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def rho_2_kkbar_gen(t_basis, rho_2_arrays):\n",
        "    indices = get_kkbar_indices(t_basis)\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "\n",
        "    rho_2_arrays_kkbar = rho_2_arrays[i, j, :, :]\n",
        "\n",
        "    return rho_2_arrays_kkbar\n",
        "\n",
        "# Devuelve la matriz rho 2 asociada al bloque kkbar\n",
        "def rho_2_kkbar(basis, vect, ml_basis = None, mll_basis = None, t_basis = None):\n",
        "    d = basis.d\n",
        "    # Creo las bases si no están dadas\n",
        "    if ml_basis == None or mll_basis == None or t_basis == None:\n",
        "        ml_basis = fixed_basis(m-1,d)\n",
        "        mll_basis = fixed_basis(m-2,d)\n",
        "        t_basis = fixed_basis(2,d)\n",
        "    diag = []\n",
        "    for v in t_basis.base:\n",
        "        for j in range(0, d, 2):\n",
        "            if v[j] == v[j+1]:\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            diag.append(v)\n",
        "    diag = np.array(diag)\n",
        "    return rho_2_kkbar_aux(diag, vect, basis.base, ml_basis.base, mll_basis.base, t_basis.base)\n",
        "\n",
        "@nb.njit\n",
        "def rho_2_kkbar_lambda(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "#@nb.njit(parallel=True)\n",
        "def rho_2_kkbar_aux(diag, vect, basis, ml_basis, mll_basis, t_basis):\n",
        "    mat = np.zeros((len(diag), len(diag)), dtype=np.float32)\n",
        "    for i in prange(len(diag)):\n",
        "        for j in prange(len(diag)):\n",
        "            v = diag[i]\n",
        "            w = diag[j]\n",
        "            # Creacion de los a\n",
        "            i_set = rep_to_exi(v)\n",
        "            b_m = b_aux(ml_basis, mll_basis, i_set[1]) @ b_aux(basis, ml_basis, i_set[0])\n",
        "            # Creacion de los ad\n",
        "            i_set = rep_to_exi(w)\n",
        "            bd_m = bd_aux(ml_basis, basis, i_set[1]) @ bd_aux(mll_basis, ml_basis, i_set[0])\n",
        "            # v1 = vect @ bd_m @ b_m @ vect Para estados puros\n",
        "            # Mult de b's y filleo de mat\n",
        "            coef = np.trace(vect @ bd_m @ b_m)\n",
        "            mat[i,j] = coef * rho_2_kkbar_lambda(v) * rho_2_kkbar_lambda(w)\n",
        "    return mat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dga5Xx_5vDf"
      },
      "source": [
        "## Definicion de Hamiltoniano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiTq53L5E1U"
      },
      "source": [
        "Cargamos el código de creación y resolución de Hamiltonianos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h5FXWv849Mq",
        "outputId": "49dd47b5-8c16-4ad4-92e7-e172462229b3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|                                                                                                                                                                                        | 0/1 [00:00<?, ?it/s]2024-01-03 16:24:37.358331: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:04<00:00,  4.51s/it]\n",
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 88.97it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 132.78it/s]\n"
          ]
        }
      ],
      "source": [
        "m = 4\n",
        "d = 8\n",
        "# Creo las bases para no tener que recrearlas luego\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "PToiSs915TXw"
      },
      "outputs": [],
      "source": [
        "## Usamos este approach si queremos guardar los generadores\n",
        "# Dados 1/2 (d^2+d) elementos, genera una mat de dxd:\n",
        "eps = 0.00001\n",
        "\n",
        "def sym_mat_gen(vect, d):\n",
        "    matrix = fill_matrix(vect, d)\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "@jit(nopython=True)\n",
        "def fill_matrix(vect, d):\n",
        "    matrix = np.zeros((d, d))\n",
        "    idx = 0\n",
        "    for i in prange(d):\n",
        "        for j in prange(i, d):\n",
        "            matrix[i, j] = vect[idx]\n",
        "            idx += 1\n",
        "    return matrix\n",
        "\n",
        "# Generamos una matrix aleatoria. Cuidado con la distribución, ver https://stackoverflow.com/questions/56605189/is-there-an-efficient-way-to-generate-a-symmetric-random-matrix\n",
        "def hamil_base_gen(d):\n",
        "    U = np.random.uniform(low=0, high=1.0, size=(d, d))\n",
        "    hamil_base = np.tril(U) + np.tril(U, -1).T\n",
        "    return hamil_base\n",
        "\n",
        "# Dada un a mat dxd simetrica, contruye el hamiltoniano de un cuerpo a_{ij} c^{dag}_i c_j\n",
        "# Alternativamente podemos construirlo a partir de rho_1_gen\n",
        "def base_hamiltonian_aux(mat, size, d, rho_1_gen):\n",
        "    # Construccion de H\n",
        "    rho_1_gen_transposed = rho_1_gen.transpose(1, 0, 2, 3)\n",
        "    mat_expanded = mat[:, :, np.newaxis, np.newaxis]\n",
        "    h = np.sum(mat_expanded * rho_1_gen_transposed[:, :, :, :], axis=(0, 1))\n",
        "    return h.astype(np.float32)\n",
        "\n",
        "def base_hamiltonian(mat, basis, rho_1_gen):\n",
        "    return base_hamiltonian_aux(mat, basis.size, basis.d, rho_1_gen)\n",
        "\n",
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2))) + eps * np.random.random((2*m,2*m))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    rho_1_arrays_t = tf.transpose(rho_1_arrays,perm=[1, 0, 2, 3])\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    rho_2_arrays_t = tf.transpose(rho_2_arrays,perm=[1, 0, 2, 3])\n",
        "\n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "    hi = np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "    return (h0, hi)\n",
        "\n",
        "def solve(h, last_step = None):\n",
        "    sol = linalg.eigsh(h, which='SA',k=19)\n",
        "    eigenspace_tol = 0.0001\n",
        "    if type(last_step) != type(None):\n",
        "        # Seleccionamos todos los autovects que difieren sus autovalores menos que tol (mismo autoespacio)\n",
        "        # y tomamos la proyección en el autoespacio de la solución del paso anterior (last_step)\n",
        "        eig = sol[0].real\n",
        "        eigv = sol[1]\n",
        "        cand = [eigv[:,i].real  for (i, x) in enumerate(eig) if abs(x-min(eig)) < eigenspace_tol]\n",
        "        cand_norm = [x/np.linalg.norm(x) for x in cand]\n",
        "        fund = np.zeros(len(cand[0]))\n",
        "        for x in cand_norm:\n",
        "            fund += np.dot(last_step,x) * x\n",
        "    else:\n",
        "        argmin = np.argmin(sol[0].real)\n",
        "        fund = sol[1][:,argmin]\n",
        "    fund = fund.real / np.linalg.norm(fund)\n",
        "    return fund\n",
        "\n",
        "# Generacion de H basada en TF\n",
        "\n",
        "# Funciones auxiliares de gen de H basado en TF\n",
        "## Dada matrix de indices, genera los indices de updates de TF\n",
        "def gen_update_indices(t_basis, batch_size):\n",
        "    # Calculamos los indices de kkbar en t_basis\n",
        "    indices = tf.constant(get_kkbar_indices(t_basis))\n",
        "    # Creamos el array de indices x indices\n",
        "    i, j = tf.meshgrid(indices, indices, indexing='ij')\n",
        "    matrix = tf.reshape(tf.stack([i, j], axis=-1), (-1, 2))\n",
        "\n",
        "    # Repeat the matrix along the first axis (axis=0) 'b' times\n",
        "    repeated_matrix = tf.repeat(tf.expand_dims(matrix, axis=0), repeats=batch_size, axis=0)\n",
        "\n",
        "    # Create an index array from 0 to b-1\n",
        "    indices = tf.range(batch_size, dtype=tf.int32)\n",
        "\n",
        "    # Expand the index array to have the same shape as the repeated matrix\n",
        "    indices = tf.expand_dims(indices, axis=-1)\n",
        "    indices = tf.expand_dims(indices, axis=-1)\n",
        "    indices = tf.tile(indices, multiples=[1,matrix.shape[0],1]) \n",
        "\n",
        "    # Concatenate the index array to the repeated matrix along a new axis\n",
        "    tiled_matrix = tf.concat([indices, repeated_matrix], axis=-1)\n",
        "    tiled_matrix = tf.reshape(tiled_matrix, [-1,3])\n",
        "    return tiled_matrix\n",
        "\n",
        "\n",
        "def two_body_hamiltonian_tf(t_basis, m, energy_batch, G_batched, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # SECCIÓN ENERGIAS\n",
        "    ## Dado un batch de niveles, lo pasamos a TF\n",
        "    energy_matrix = tf.constant(energy_batch, dtype=tf.float32)\n",
        "    ## Repetimos los niveles para cada uno de los pares (por el nivel k y kbar)\n",
        "    energy_matrix = tf.repeat(energy_matrix, repeats=2, axis=1)\n",
        "    ## Generamos la matrix diagonal y expandimos\n",
        "    energy_matrix_expanded = tf.linalg.diag(energy_matrix)\n",
        "    energy_matrix_expanded = energy_matrix_expanded[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    # Multiplicamos por los operadores C^dag C\n",
        "    h0_arr = tf.reduce_sum(energy_matrix_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    # SECCIÓN INTERACCIÓN\n",
        "    # Ya tenemos los indices de updates, ahora tomamos la mat en t_basis (una de zeros)\n",
        "    # y updateamos de acuerdo a la lista de G's cada uno flatteneados\n",
        "    G_flatten = np.ndarray.flatten(np.array([np.ndarray.flatten(G) for G in G_batched]))\n",
        "    # Creamos la mat de t_basis y updateamos a partir de los indices de kkbar\n",
        "    mat = tf.zeros((len(energy_batch), t_basis.size, t_basis.size), dtype=tf.float32)\n",
        "    mat = tf.tensor_scatter_nd_update(mat, indices, G_flatten)\n",
        "    # Preparamos las dimensiones y multiplicamos\n",
        "    mat_expanded = mat[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_2_gen_transposed = tf.transpose(rho_2_arrays, perm=[1, 0, 2, 3])\n",
        "    hi_arr = tf.reduce_sum(mat_expanded * rho_2_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    return h0_arr - hi_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emVBTg2QD-Fg"
      },
      "source": [
        "## Modelo de ML\n",
        "Basado en matrices densidad de 1 y 2 cuerpos como input, con hamiltoniano como salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "aF_Ec_mCGX96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-03 16:24:40.407227: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.test.gpu_device_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDoa6LUJJ8O",
        "outputId": "73481454-fbcb-469f-d72f-cd0f8d534808"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 134.60it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "28\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 148.59it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[1 1 0 0 0 0 0 0]\n",
            " [1 0 1 0 0 0 0 0]\n",
            " [0 1 1 0 0 0 0 0]\n",
            " [1 0 0 1 0 0 0 0]\n",
            " [0 1 0 1 0 0 0 0]\n",
            " [0 0 1 1 0 0 0 0]\n",
            " [1 0 0 0 1 0 0 0]\n",
            " [0 1 0 0 1 0 0 0]\n",
            " [0 0 1 0 1 0 0 0]\n",
            " [0 0 0 1 1 0 0 0]\n",
            " [1 0 0 0 0 1 0 0]\n",
            " [0 1 0 0 0 1 0 0]\n",
            " [0 0 1 0 0 1 0 0]\n",
            " [0 0 0 1 0 1 0 0]\n",
            " [0 0 0 0 1 1 0 0]\n",
            " [1 0 0 0 0 0 1 0]\n",
            " [0 1 0 0 0 0 1 0]\n",
            " [0 0 1 0 0 0 1 0]\n",
            " [0 0 0 1 0 0 1 0]\n",
            " [0 0 0 0 1 0 1 0]\n",
            " [0 0 0 0 0 1 1 0]\n",
            " [1 0 0 0 0 0 0 1]\n",
            " [0 1 0 0 0 0 0 1]\n",
            " [0 0 1 0 0 0 0 1]\n",
            " [0 0 0 1 0 0 0 1]\n",
            " [0 0 0 0 1 0 0 1]\n",
            " [0 0 0 0 0 1 0 1]\n",
            " [0 0 0 0 0 0 1 1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 148.78it/s]\n",
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 150.27it/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "[[1 0 0 0 0 0 0 0]\n",
            " [0 1 0 0 0 0 0 0]\n",
            " [0 0 1 0 0 0 0 0]\n",
            " [0 0 0 1 0 0 0 0]\n",
            " [0 0 0 0 1 0 0 0]\n",
            " [0 0 0 0 0 1 0 0]\n",
            " [0 0 0 0 0 0 1 0]\n",
            " [0 0 0 0 0 0 0 1]]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 122.73it/s]\n"
          ]
        }
      ],
      "source": [
        "# Construccion de bases para calculo de rho1 y rho2\n",
        "# rho2\n",
        "m = 2\n",
        "m2_basis = fixed_basis(m, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-m, d)\n",
        "print(nm2_basis.base)\n",
        "t_basis = fixed_basis(2, basis.d)\n",
        "# rho1\n",
        "m = 1\n",
        "m1_basis = fixed_basis(m, d)\n",
        "print(m1_basis.size)\n",
        "print(m1_basis.base)\n",
        "nm1_basis = fixed_basis(basis.m-m, d)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapxWkD16fHg"
      },
      "source": [
        "### Algunos benchmarks y funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "umCIrxCZKXQd"
      },
      "outputs": [],
      "source": [
        "# Given h calculo en rho2 y rho1 máximo\n",
        "def rho1_rho2(h, beta):\n",
        "    fund = thermal_state(h, beta)\n",
        "    rho2 = np.array(rho_2(basis, m2_basis.size, state, rho_2_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho2).real)\n",
        "    rho_2_max = r[0]\n",
        "    rho1 = np.array(rho_1(basis, state, rho_1_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho1).real)\n",
        "    rho_1_max = r[0]\n",
        "\n",
        "    return (rho_1_max, rho_2_max)\n",
        "\n",
        "def fill_triangular_np(x):\n",
        "    m = x.shape[0]\n",
        "    n = np.int32(np.sqrt(.25 + 2 * m) - .5)\n",
        "    x_tail = x[(m - (n**2 - m)):]\n",
        "    return np.triu(np.concatenate([x, x_tail[::-1]], 0).reshape(n, n))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "id": "QaNnIIc5bZux"
      },
      "outputs": [],
      "source": [
        "# TEST: Las funciones de TF y comunes coinciden\n",
        "\n",
        "# Dado h, \\beta, construyo el estado térmico\n",
        "from scipy.linalg import expm\n",
        "\n",
        "def thermal_state(h, beta):\n",
        "    quotient = expm(-beta*h)\n",
        "    return quotient / np.trace(quotient)\n",
        "\n",
        "## NO usar para mat no hermiticas\n",
        "@nb.jit(nopython=True)\n",
        "def thermal_state_eig(h, beta):\n",
        "    w, v = np.linalg.eigh(-beta*h)\n",
        "    D = np.diag(np.exp(w))\n",
        "    mat = v @ D @ v.T\n",
        "    mat = mat / np.trace(mat)\n",
        "    return mat\n",
        "    \n",
        "def gen_to_h(base, rho_1_arrays):\n",
        "    triag = fill_triangular_np(base)\n",
        "    body_gen = triag + np.transpose(triag)-np.diag(np.diag(triag))\n",
        "    h = np.array(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
        "    return h \n",
        "\n",
        "def gen_to_h_1b(hamil_base):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "    return body_gen\n",
        "\n",
        "def gen_to_h_tf(hamil_base, rho_1_arrays):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag)) # Simetrizamos y generamos la matriz de h\n",
        "    hamil_expanded = body_gen[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    h_arr = tf.reduce_sum(hamil_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "    return h_arr\n",
        "\n",
        "def thermal_state_tf(h):\n",
        "    # Assume beta=1\n",
        "    exp_hamiltonian = tf.linalg.expm(-h)\n",
        "    partition_function = tf.linalg.trace(exp_hamiltonian)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    \n",
        "    rho = exp_hamiltonian / partition_function\n",
        "\n",
        "    return rho\n",
        "\n",
        "def rho_1_tf(state, rho_1_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_1_arrays_expanded = tf.expand_dims(rho_1_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_1_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "def rho_2_tf(state, rho_2_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_2_arrays_expanded = tf.expand_dims(rho_2_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_2_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "# NOTA: para calcular el bloque rho2kkbar, utilizar en lugar\n",
        "\n",
        "def rho_1_gc_tf(hamil_base):\n",
        "    e, v = tf.linalg.eigh(gen_to_h_1b(hamil_base))\n",
        "    result = 1 / (1 + tf.exp(e))\n",
        "    result = tf.linalg.diag(result)\n",
        "    res = tf.linalg.matmul(v,result)\n",
        "    res = tf.linalg.matmul(res,v,adjoint_b=True)\n",
        "    \n",
        "    return tf.cast(res, tf.float32)\n",
        "\n",
        "# Aux function\n",
        "def outer_product(vector):\n",
        "    return tf.einsum('i,j->ij', vector, vector)\n",
        "\n",
        "def pure_state(h):\n",
        "    e, v = tf.linalg.eigh(h)\n",
        "    fund = v[:,:,0]\n",
        "    d = tf.map_fn(outer_product, fund)\n",
        "    return d\n",
        "\n",
        "# Casos de entrenamiento tipo mat gaussianas\n",
        "def gen_gauss_mat(G, sigma_sq, size):\n",
        "    indices = np.arange(size)\n",
        "    mat = G * np.exp(-((indices - indices[:, np.newaxis])**2) / (2 * sigma_sq))\n",
        "    return mat\n",
        "\n",
        "def gen_gauss_mat_np(G_values, sigma_sq_values, size):\n",
        "    indices = np.arange(size, dtype=np.float32)\n",
        "    indices_diff = indices - indices[:, np.newaxis]\n",
        "\n",
        "    mat = G_values[:, np.newaxis, np.newaxis] * np.exp(-np.square(indices_diff) / (2 * sigma_sq_values[:, np.newaxis, np.newaxis]))\n",
        "\n",
        "    return mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylpy_BCw6jxF"
      },
      "source": [
        "### Construccion de dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Version sincrónica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2is_Eo_qGpEz",
        "outputId": "9a968190-59f2-4695-ef18-b99ff5b4a212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-03 19:06:14.025217: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 391/391 [00:24<00:00, 15.76it/s]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "# Config\n",
        "num_samples = 100000\n",
        "use_gpu = True\n",
        "gpu_batch_size = 256\n",
        "\n",
        "# Beta\n",
        "beta = 1\n",
        "\n",
        "# Construccion de parametros y matrices auxiliares\n",
        "rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "rho2kkbar_size = basis.m\n",
        "fund_size = basis.size\n",
        "hamil_base_size = basis.d*(basis.d+1)//2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_1_arrays_tf = tf.constant(rho_1_arrays, dtype=tf.float32)\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "rho_2_arrays_kkbar = rho_2_kkbar_gen(t_basis, rho_2_arrays)\n",
        "rho_2_arrays_kkbar_tf = tf.constant(rho_2_arrays_kkbar, dtype=tf.float32)\n",
        "k_indices = get_kkbar_indices(t_basis)\n",
        "k_indices_tf = gen_update_indices(t_basis, gpu_batch_size)\n",
        "\n",
        "# Generacion de hamiltoniano\n",
        "# (h0, hi) = two_body_hamiltonian(t_basis.size, basis.m, np.arange(0, basis.m), np.ones((basis.m,basis.m)), rho_1_arrays_tf, rho_2_arrays_tf) esto es para g cte\n",
        "\n",
        "\n",
        "if use_gpu:\n",
        "    print(tf.test.gpu_device_name())\n",
        "    datasets = []\n",
        "    for i in tqdm(range(num_samples//gpu_batch_size+1)):\n",
        "        size = basis.m*(basis.m+1)//2\n",
        "        # En una primera versión vamos a pasar una mat proporcional a range(0,m) para energias\n",
        "        en_batch = [np.arange(0, basis.m) for _ in range(0,gpu_batch_size)] \n",
        "        # Como interacción una matriz G semidefinida positiva\n",
        "        # Primero creamos las semillas, es decir, la diagonal superior de la matrix g\n",
        "        # Caso generico\n",
        "        #label_size = basis.m*(basis.m+1)// 2 # CASO GENERICO elementos independientes de una mat de m x m\n",
        "        #h_labels = [np.random.random()*np.ones(label_size) for _ in range(0,gpu_batch_size)] # TODO: Aumentar la amplitud de la interacción\n",
        "        # Construimos la mat G\n",
        "        #triag = tfp.math.fill_triangular(h_labels, upper=True)\n",
        "        #g_arr = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "        # Caso reducido\n",
        "        label_size = 2\n",
        "        h_labels = np.array([[np.random.random(), np.random.random()] for _ in range(0, gpu_batch_size)])\n",
        "        g_arr = gen_gauss_mat_np(h_labels[:,0], h_labels[:,1], basis.m)\n",
        "        h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "        g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "        # Construimos los hamiltonianos basados en g_arr\n",
        "        h_arr = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, g_arr.numpy(), rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "        # Estados térmicos\n",
        "        state = thermal_state_tf(h_arr*beta) \n",
        "        state = tf.cast(state, dtype=tf.float32)\n",
        "        # Estados puros\n",
        "        #state = pure_state(h_arr)\n",
        "        #rho_2_input = rho_2_tf(state, rho_2_arrays_tf)\n",
        "        rho_2_input = rho_2_tf(state, rho_2_arrays_kkbar_tf)\n",
        "\n",
        "        datasets.append(tf.data.Dataset.from_tensor_slices(((rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input, state), h_labels)))\n",
        "    ds = tf.data.Dataset.from_tensor_slices(datasets)\n",
        "    dataset = ds.interleave(\n",
        "        lambda x: x,\n",
        "        cycle_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "\n",
        "\n",
        "#batch_size = 32\n",
        "#dataset = dataset.shuffle(buffer_size=num_samples).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Filleo de dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Save and load dataset\n",
        "save_dataset = False\n",
        "load_dataset = False\n",
        "path = \"/home/agus/TF\"\n",
        "#num_samples = 5000000\n",
        "if save_dataset:\n",
        "    tf.data.Dataset.save(dataset, path)\n",
        "    with open(\"/home/agus/\"+'/file.pkl', 'wb') as file:\n",
        "        pickle.dump(beta_input, file)\n",
        "if load_dataset:\n",
        "    dataset = tf.data.Dataset.load(path)\n",
        "    with open(\"/home/agus/\"+'file.pkl', 'rb') as file:\n",
        "        beta_input = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "8moZIlfabZuy"
      },
      "outputs": [],
      "source": [
        "# Dividimos los datasets\n",
        "train_size = int(0.8 * num_samples)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "\n",
        "batch_size = 256\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "#beta_val = beta_input[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Dataset Size: -2\n"
          ]
        }
      ],
      "source": [
        "# Cardinality no funciona con los datasets generados por GPU\n",
        "val_size = tf.data.experimental.cardinality(val_dataset).numpy()\n",
        "print(\"Validation Dataset Size:\", val_size)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYEEjNB-7b8y"
      },
      "source": [
        "### Definición de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8kkhJr5K0ZQ",
        "outputId": "f1b731f1-6a02-4181-f0b5-5677a2a85784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_7\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 4, 4, 1)]         0         \n",
            "                                                                 \n",
            " conv2d_7 (Conv2D)           (None, 3, 3, 16)          80        \n",
            "                                                                 \n",
            " batch_normalization_7 (Bat  (None, 3, 3, 16)          64        \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " flatten_7 (Flatten)         (None, 144)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 32)                4640      \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                330       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5114 (19.98 KB)\n",
            "Trainable params: 5082 (19.85 KB)\n",
            "Non-trainable params: 32 (128.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Definicion de layers basado en Conv 2D\n",
        "\n",
        "# Factor de cantidad de filtros\n",
        "lf = 16 \n",
        "conv_limit = (rho2kkbar_size - 4)\n",
        "initial_dense = (lf*2**(conv_limit-1)*((rho2kkbar_size-(conv_limit-1))//2)**2)\n",
        "## rho 1\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(rho2kkbar_size,rho2kkbar_size, 1), name='rho2')\n",
        "\n",
        "# Procesamos el primer input\n",
        "conv_rho2 = tf.keras.layers.Conv2D(lf*2**conv_limit, (2, 2), activation='relu')(rho2_layer)\n",
        "conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "for j in [(2**conv_limit - 2**k) for k in range(1,conv_limit)]:\n",
        "    conv_rho2 = tf.keras.layers.Conv2D(lf*j, (2, 2), activation='relu')(conv_rho2 if 2**j != 1 else rho1_layer)\n",
        "    conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "\n",
        "#conv_rho2 = tf.keras.layers.MaxPooling2D((2, 2))(conv_rho2)\n",
        "\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(conv_rho2)\n",
        "#flatten_rho1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(flatten_rho1)\n",
        "\n",
        "#local_size = basis.size*basis.size\n",
        "local_size = label_size\n",
        "\n",
        "#dense1 = tf.keras.layers.Dense(8*8*4*4, activation='relu')(dense1)\n",
        "#dense1 = tf.keras.layers.Dense(512, activation='relu')(flatten_rho1)\n",
        "#dense1 = tf.keras.layers.Dense(128, activation='relu')(flatten_rho1)\n",
        "dense1 = tf.keras.layers.Dense(initial_dense, activation='relu')(flatten_rho2)\n",
        "#dense1 = tf.keras.layers.Dense(initial_dense//2, activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "\n",
        "\n",
        "# Creamos el modelo y compulamos\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer, fund_layer], outputs=output)\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer], outputs=output)\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 111,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZBtonvGbZuz",
        "outputId": "f197277e-a84b-4ffd-c81f-c81581707fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 4, 4, 1)]         0         \n",
            "                                                                 \n",
            " flatten_8 (Flatten)         (None, 16)                0         \n",
            "                                                                 \n",
            " concatenate_8 (Concatenate  (None, 16)                0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dense_34 (Dense)            (None, 20)                340       \n",
            "                                                                 \n",
            " dense_35 (Dense)            (None, 32)                672       \n",
            "                                                                 \n",
            " dense_36 (Dense)            (None, 64)                2112      \n",
            "                                                                 \n",
            " dense_37 (Dense)            (None, 2)                 130       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3254 (12.71 KB)\n",
            "Trainable params: 3254 (12.71 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Modelo denso + fundamental\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(basis.m,basis.m, 1), name='rho2')\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#rho2_layer =  tf.keras.layers.Input(shape=(rho2_size,rho2_size, 1), name='rho2')\n",
        "#flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#fund_layer =  tf.keras.layers.Input(shape=(fund_size, fund_size, 1 ), name='fund')\n",
        "#flatten_fund = tf.keras.layers.Flatten()(fund_layer)\n",
        "\n",
        "dense1 = tf.keras.layers.concatenate([flatten_rho2])\n",
        "#dense1 = tf.keras.layers.concatenate([dense1, flatten_fund])\n",
        "#dense1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(dense1)\n",
        "\n",
        "local_size = label_size\n",
        "l=4\n",
        "layer_s = [32//i*2 for i in reversed(range(1,l))]\n",
        "for i in range(0,l-1):\n",
        "    dense1 = tf.keras.layers.Dense(layer_s[i], activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "# Creamos el modelo y compulamos\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "RgoMlCyyfBe-"
      },
      "outputs": [],
      "source": [
        "# LOSS FUNCTIONS\n",
        "r_size = basis.size\n",
        "\n",
        "# Custom loss function based on GS MSE\n",
        "def gs_loss(h_pred, h_true):\n",
        "    h_pred = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_pred)\n",
        "    gs_pred = v[:, 0]\n",
        "\n",
        "    h_true = tf.reshape(h_true, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_true)\n",
        "    gs_true = v[:, 0]\n",
        "\n",
        "    gs_diff = tf.norm(gs_true - gs_pred)\n",
        "\n",
        "    return gs_diff + tf.reduce_mean(tf.square(h_true - h_pred)) * 100\n",
        "\n",
        "def distance_to_hermitian(matrix):\n",
        "    hermitian_part = 0.5 * (matrix + tf.linalg.adjoint(matrix))\n",
        "    distance = tf.norm(matrix - hermitian_part, ord='euclidean')\n",
        "    return distance\n",
        "\n",
        "# Custom loss function based on MSE + non-hermitian penalization\n",
        "def herm_loss(h_pred, h_true):\n",
        "    h_pred_arr = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred)) + distance_to_hermitian(h_pred_arr)\n",
        "\n",
        "# Custom loss function based on h eigenvalues\n",
        "def eig_loss(h_pred, h_true):\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# MSE with a factor\n",
        "def mse_f(h_pred, h_true):\n",
        "    f = 1000\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred))*f\n",
        "\n",
        "# Spectral radius loss\n",
        "def spectral_loss(h_pred, h_true):\n",
        "    eig = tf.math.real(tf.linalg.eigvals(tf.reshape(h_true-h_pred, (-1, fund_size, fund_size))))\n",
        "    return tf.math.reduce_max(tf.abs(eig))\n",
        "\n",
        "# Hamiltonian MSE loss (using generators)\n",
        "def base_mse_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    mat = tf.reshape(h_pred-h_true, (-1, fund_size, fund_size))\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on h eigenvalues (using generators)\n",
        "def base_eig_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals\n",
        "## Auxiliary function\n",
        "def base_to_rho_1_tf(base_pred):\n",
        "    h = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h = tf.reshape(h, (-1, fund_size, fund_size))\n",
        "    state = thermal_state_tf(h)\n",
        "    rho1 = rho_1_tf(state, rho_1_arrays_tf)\n",
        "    return rho1\n",
        "    \n",
        "def rho1_loss(base_pred, base_true):\n",
        "    mat = base_to_rho_1_tf(base_pred) - base_to_rho_1_tf(base_true)\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals (using generators)\n",
        "def base_rho1_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    return tf.reduce_mean(tf.square(rho_1_eig_tf(h_pred) - rho_1_eig_tf(h_true)))*1000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWk9piJtNIZ"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhJCHf0fQdRl",
        "outputId": "1821cf27-9ff5-4d67-e9f5-956d20eda5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-03 19:15:37.679291: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 3s 5ms/step - loss: 0.0537 - accuracy: 0.6222 - mean_squared_error: 0.0537 - val_loss: 0.0133 - val_accuracy: 0.9176 - val_mean_squared_error: 0.0133\n",
            "Epoch 2/100\n",
            " 54/313 [====>.........................] - ETA: 0s - loss: 0.0114 - accuracy: 0.9095 - mean_squared_error: 0.0114"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-03 19:15:40.864666: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 12335229202332282973\n",
            "2024-01-03 19:15:40.864708: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 1608166325971600071\n",
            "2024-01-03 19:15:40.864727: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 7527261280856842708\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0067 - accuracy: 0.9457 - mean_squared_error: 0.0067 - val_loss: 0.0035 - val_accuracy: 0.9703 - val_mean_squared_error: 0.0035\n",
            "Epoch 3/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0029 - accuracy: 0.9665 - mean_squared_error: 0.0029 - val_loss: 0.0022 - val_accuracy: 0.9758 - val_mean_squared_error: 0.0022\n",
            "Epoch 4/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0021 - accuracy: 0.9718 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_accuracy: 0.9821 - val_mean_squared_error: 0.0018\n",
            "Epoch 5/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0018 - accuracy: 0.9739 - mean_squared_error: 0.0018 - val_loss: 0.0015 - val_accuracy: 0.9855 - val_mean_squared_error: 0.0015\n",
            "Epoch 6/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0016 - accuracy: 0.9760 - mean_squared_error: 0.0016 - val_loss: 0.0012 - val_accuracy: 0.9867 - val_mean_squared_error: 0.0012\n",
            "Epoch 7/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0014 - accuracy: 0.9770 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_accuracy: 0.9872 - val_mean_squared_error: 0.0011\n",
            "Epoch 8/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0013 - accuracy: 0.9779 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_accuracy: 0.9875 - val_mean_squared_error: 0.0010\n",
            "Epoch 9/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0012 - accuracy: 0.9789 - mean_squared_error: 0.0012 - val_loss: 8.9803e-04 - val_accuracy: 0.9890 - val_mean_squared_error: 8.9803e-04\n",
            "Epoch 10/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9790 - mean_squared_error: 0.0011 - val_loss: 7.8579e-04 - val_accuracy: 0.9897 - val_mean_squared_error: 7.8579e-04\n",
            "Epoch 11/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0011 - accuracy: 0.9790 - mean_squared_error: 0.0011 - val_loss: 7.4792e-04 - val_accuracy: 0.9859 - val_mean_squared_error: 7.4792e-04\n",
            "Epoch 12/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 0.0010 - accuracy: 0.9791 - mean_squared_error: 0.0010 - val_loss: 9.2352e-04 - val_accuracy: 0.9785 - val_mean_squared_error: 9.2352e-04\n",
            "Epoch 13/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 9.9903e-04 - accuracy: 0.9799 - mean_squared_error: 9.9903e-04 - val_loss: 0.0013 - val_accuracy: 0.9690 - val_mean_squared_error: 0.0013\n",
            "Epoch 14/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 9.6624e-04 - accuracy: 0.9802 - mean_squared_error: 9.6624e-04 - val_loss: 0.0020 - val_accuracy: 0.9557 - val_mean_squared_error: 0.0020\n",
            "Epoch 15/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 9.2039e-04 - accuracy: 0.9808 - mean_squared_error: 9.2039e-04 - val_loss: 0.0019 - val_accuracy: 0.9597 - val_mean_squared_error: 0.0019\n",
            "Epoch 16/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 8.7981e-04 - accuracy: 0.9811 - mean_squared_error: 8.7981e-04 - val_loss: 0.0016 - val_accuracy: 0.9664 - val_mean_squared_error: 0.0016\n",
            "Epoch 17/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 8.7298e-04 - accuracy: 0.9814 - mean_squared_error: 8.7298e-04 - val_loss: 0.0014 - val_accuracy: 0.9673 - val_mean_squared_error: 0.0014\n",
            "Epoch 18/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 8.5789e-04 - accuracy: 0.9818 - mean_squared_error: 8.5789e-04 - val_loss: 0.0012 - val_accuracy: 0.9787 - val_mean_squared_error: 0.0012\n",
            "Epoch 19/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 8.2116e-04 - accuracy: 0.9842 - mean_squared_error: 8.2116e-04 - val_loss: 0.0011 - val_accuracy: 0.9749 - val_mean_squared_error: 0.0011\n",
            "Epoch 20/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 7.6908e-04 - accuracy: 0.9841 - mean_squared_error: 7.6908e-04 - val_loss: 8.1736e-04 - val_accuracy: 0.9801 - val_mean_squared_error: 8.1736e-04\n",
            "Epoch 21/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 7.9519e-04 - accuracy: 0.9829 - mean_squared_error: 7.9519e-04 - val_loss: 7.8633e-04 - val_accuracy: 0.9833 - val_mean_squared_error: 7.8633e-04\n",
            "Epoch 22/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 8.1120e-04 - accuracy: 0.9823 - mean_squared_error: 8.1120e-04 - val_loss: 7.5658e-04 - val_accuracy: 0.9831 - val_mean_squared_error: 7.5658e-04\n",
            "Epoch 23/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 7.6996e-04 - accuracy: 0.9830 - mean_squared_error: 7.6996e-04 - val_loss: 7.4707e-04 - val_accuracy: 0.9822 - val_mean_squared_error: 7.4707e-04\n",
            "Epoch 24/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 7.4374e-04 - accuracy: 0.9833 - mean_squared_error: 7.4374e-04 - val_loss: 7.5260e-04 - val_accuracy: 0.9833 - val_mean_squared_error: 7.5260e-04\n",
            "Epoch 25/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 7.7241e-04 - accuracy: 0.9822 - mean_squared_error: 7.7241e-04 - val_loss: 0.0011 - val_accuracy: 0.9760 - val_mean_squared_error: 0.0011\n",
            "Epoch 26/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 7.4362e-04 - accuracy: 0.9826 - mean_squared_error: 7.4362e-04 - val_loss: 0.0013 - val_accuracy: 0.9719 - val_mean_squared_error: 0.0013\n",
            "Epoch 27/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.7408e-04 - accuracy: 0.9837 - mean_squared_error: 6.7408e-04 - val_loss: 0.0011 - val_accuracy: 0.9775 - val_mean_squared_error: 0.0011\n",
            "Epoch 28/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.8982e-04 - accuracy: 0.9833 - mean_squared_error: 6.8982e-04 - val_loss: 9.2830e-04 - val_accuracy: 0.9793 - val_mean_squared_error: 9.2830e-04\n",
            "Epoch 29/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.6081e-04 - accuracy: 0.9835 - mean_squared_error: 6.6081e-04 - val_loss: 0.0011 - val_accuracy: 0.9767 - val_mean_squared_error: 0.0011\n",
            "Epoch 30/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 7.1802e-04 - accuracy: 0.9821 - mean_squared_error: 7.1802e-04 - val_loss: 6.0948e-04 - val_accuracy: 0.9874 - val_mean_squared_error: 6.0948e-04\n",
            "Epoch 31/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.5669e-04 - accuracy: 0.9832 - mean_squared_error: 6.5669e-04 - val_loss: 4.7406e-04 - val_accuracy: 0.9876 - val_mean_squared_error: 4.7406e-04\n",
            "Epoch 32/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.7367e-04 - accuracy: 0.9830 - mean_squared_error: 6.7367e-04 - val_loss: 0.0012 - val_accuracy: 0.9750 - val_mean_squared_error: 0.0012\n",
            "Epoch 33/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.3904e-04 - accuracy: 0.9836 - mean_squared_error: 6.3904e-04 - val_loss: 8.8990e-04 - val_accuracy: 0.9791 - val_mean_squared_error: 8.8990e-04\n",
            "Epoch 34/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.4441e-04 - accuracy: 0.9834 - mean_squared_error: 6.4441e-04 - val_loss: 7.7545e-04 - val_accuracy: 0.9806 - val_mean_squared_error: 7.7545e-04\n",
            "Epoch 35/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.5024e-04 - accuracy: 0.9832 - mean_squared_error: 6.5024e-04 - val_loss: 7.4202e-04 - val_accuracy: 0.9823 - val_mean_squared_error: 7.4202e-04\n",
            "Epoch 36/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.3517e-04 - accuracy: 0.9833 - mean_squared_error: 6.3517e-04 - val_loss: 0.0013 - val_accuracy: 0.9675 - val_mean_squared_error: 0.0013\n",
            "Epoch 37/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.7217e-04 - accuracy: 0.9842 - mean_squared_error: 5.7217e-04 - val_loss: 0.0014 - val_accuracy: 0.9748 - val_mean_squared_error: 0.0014\n",
            "Epoch 38/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.8712e-04 - accuracy: 0.9840 - mean_squared_error: 5.8712e-04 - val_loss: 0.0015 - val_accuracy: 0.9712 - val_mean_squared_error: 0.0015\n",
            "Epoch 39/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.8353e-04 - accuracy: 0.9840 - mean_squared_error: 5.8353e-04 - val_loss: 0.0014 - val_accuracy: 0.9742 - val_mean_squared_error: 0.0014\n",
            "Epoch 40/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.4095e-04 - accuracy: 0.9837 - mean_squared_error: 6.4095e-04 - val_loss: 8.4560e-04 - val_accuracy: 0.9814 - val_mean_squared_error: 8.4560e-04\n",
            "Epoch 41/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.1546e-04 - accuracy: 0.9841 - mean_squared_error: 6.1546e-04 - val_loss: 9.6063e-04 - val_accuracy: 0.9718 - val_mean_squared_error: 9.6063e-04\n",
            "Epoch 42/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.6865e-04 - accuracy: 0.9846 - mean_squared_error: 5.6865e-04 - val_loss: 7.1521e-04 - val_accuracy: 0.9782 - val_mean_squared_error: 7.1521e-04\n",
            "Epoch 43/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.3866e-04 - accuracy: 0.9850 - mean_squared_error: 5.3866e-04 - val_loss: 0.0011 - val_accuracy: 0.9767 - val_mean_squared_error: 0.0011\n",
            "Epoch 44/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.2111e-04 - accuracy: 0.9839 - mean_squared_error: 6.2111e-04 - val_loss: 0.0013 - val_accuracy: 0.9632 - val_mean_squared_error: 0.0013\n",
            "Epoch 45/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.0322e-04 - accuracy: 0.9857 - mean_squared_error: 5.0322e-04 - val_loss: 0.0013 - val_accuracy: 0.9749 - val_mean_squared_error: 0.0013\n",
            "Epoch 46/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.2592e-04 - accuracy: 0.9835 - mean_squared_error: 6.2592e-04 - val_loss: 0.0011 - val_accuracy: 0.9715 - val_mean_squared_error: 0.0011\n",
            "Epoch 47/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 5.0768e-04 - accuracy: 0.9854 - mean_squared_error: 5.0768e-04 - val_loss: 0.0011 - val_accuracy: 0.9789 - val_mean_squared_error: 0.0011\n",
            "Epoch 48/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.4405e-04 - accuracy: 0.9851 - mean_squared_error: 5.4405e-04 - val_loss: 9.6322e-04 - val_accuracy: 0.9818 - val_mean_squared_error: 9.6322e-04\n",
            "Epoch 49/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.2897e-04 - accuracy: 0.9835 - mean_squared_error: 6.2897e-04 - val_loss: 8.1182e-04 - val_accuracy: 0.9722 - val_mean_squared_error: 8.1182e-04\n",
            "Epoch 50/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 4.9929e-04 - accuracy: 0.9856 - mean_squared_error: 4.9929e-04 - val_loss: 6.4949e-04 - val_accuracy: 0.9848 - val_mean_squared_error: 6.4949e-04\n",
            "Epoch 51/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.0761e-04 - accuracy: 0.9856 - mean_squared_error: 5.0761e-04 - val_loss: 9.7456e-04 - val_accuracy: 0.9799 - val_mean_squared_error: 9.7456e-04\n",
            "Epoch 52/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.3009e-04 - accuracy: 0.9840 - mean_squared_error: 6.3009e-04 - val_loss: 8.3483e-04 - val_accuracy: 0.9722 - val_mean_squared_error: 8.3483e-04\n",
            "Epoch 53/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.8993e-04 - accuracy: 0.9859 - mean_squared_error: 4.8993e-04 - val_loss: 6.6047e-04 - val_accuracy: 0.9852 - val_mean_squared_error: 6.6047e-04\n",
            "Epoch 54/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.6632e-04 - accuracy: 0.9863 - mean_squared_error: 4.6632e-04 - val_loss: 0.0010 - val_accuracy: 0.9823 - val_mean_squared_error: 0.0010\n",
            "Epoch 55/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.7343e-04 - accuracy: 0.9857 - mean_squared_error: 4.7343e-04 - val_loss: 8.3146e-04 - val_accuracy: 0.9842 - val_mean_squared_error: 8.3146e-04\n",
            "Epoch 56/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.7430e-04 - accuracy: 0.9860 - mean_squared_error: 4.7430e-04 - val_loss: 0.0012 - val_accuracy: 0.9784 - val_mean_squared_error: 0.0012\n",
            "Epoch 57/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.6387e-04 - accuracy: 0.9842 - mean_squared_error: 5.6387e-04 - val_loss: 7.3211e-04 - val_accuracy: 0.9859 - val_mean_squared_error: 7.3211e-04\n",
            "Epoch 58/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.4086e-04 - accuracy: 0.9866 - mean_squared_error: 4.4086e-04 - val_loss: 9.6577e-04 - val_accuracy: 0.9836 - val_mean_squared_error: 9.6577e-04\n",
            "Epoch 59/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.6405e-04 - accuracy: 0.9859 - mean_squared_error: 4.6405e-04 - val_loss: 0.0010 - val_accuracy: 0.9809 - val_mean_squared_error: 0.0010\n",
            "Epoch 60/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.7900e-04 - accuracy: 0.9841 - mean_squared_error: 5.7900e-04 - val_loss: 6.5191e-04 - val_accuracy: 0.9797 - val_mean_squared_error: 6.5191e-04\n",
            "Epoch 61/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 6.2804e-04 - accuracy: 0.9831 - mean_squared_error: 6.2804e-04 - val_loss: 3.4789e-04 - val_accuracy: 0.9920 - val_mean_squared_error: 3.4789e-04\n",
            "Epoch 62/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.0147e-04 - accuracy: 0.9851 - mean_squared_error: 5.0147e-04 - val_loss: 5.4616e-04 - val_accuracy: 0.9861 - val_mean_squared_error: 5.4616e-04\n",
            "Epoch 63/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.4720e-04 - accuracy: 0.9839 - mean_squared_error: 5.4720e-04 - val_loss: 5.9815e-04 - val_accuracy: 0.9826 - val_mean_squared_error: 5.9815e-04\n",
            "Epoch 64/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.1564e-04 - accuracy: 0.9847 - mean_squared_error: 5.1564e-04 - val_loss: 6.1735e-04 - val_accuracy: 0.9831 - val_mean_squared_error: 6.1735e-04\n",
            "Epoch 65/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.5046e-04 - accuracy: 0.9863 - mean_squared_error: 4.5046e-04 - val_loss: 7.0766e-04 - val_accuracy: 0.9817 - val_mean_squared_error: 7.0766e-04\n",
            "Epoch 66/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.3179e-04 - accuracy: 0.9845 - mean_squared_error: 5.3179e-04 - val_loss: 6.5585e-04 - val_accuracy: 0.9823 - val_mean_squared_error: 6.5585e-04\n",
            "Epoch 67/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.5078e-04 - accuracy: 0.9864 - mean_squared_error: 4.5078e-04 - val_loss: 7.1040e-04 - val_accuracy: 0.9821 - val_mean_squared_error: 7.1040e-04\n",
            "Epoch 68/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.6007e-04 - accuracy: 0.9857 - mean_squared_error: 4.6007e-04 - val_loss: 5.8604e-04 - val_accuracy: 0.9844 - val_mean_squared_error: 5.8604e-04\n",
            "Epoch 69/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.6952e-04 - accuracy: 0.9859 - mean_squared_error: 4.6952e-04 - val_loss: 9.3238e-04 - val_accuracy: 0.9804 - val_mean_squared_error: 9.3238e-04\n",
            "Epoch 70/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.8907e-04 - accuracy: 0.9832 - mean_squared_error: 5.8907e-04 - val_loss: 3.9403e-04 - val_accuracy: 0.9907 - val_mean_squared_error: 3.9403e-04\n",
            "Epoch 71/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.8919e-04 - accuracy: 0.9851 - mean_squared_error: 4.8919e-04 - val_loss: 7.2294e-04 - val_accuracy: 0.9812 - val_mean_squared_error: 7.2294e-04\n",
            "Epoch 72/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.6345e-04 - accuracy: 0.9853 - mean_squared_error: 4.6345e-04 - val_loss: 6.4434e-04 - val_accuracy: 0.9838 - val_mean_squared_error: 6.4434e-04\n",
            "Epoch 73/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.5416e-04 - accuracy: 0.9858 - mean_squared_error: 4.5416e-04 - val_loss: 5.9921e-04 - val_accuracy: 0.9855 - val_mean_squared_error: 5.9921e-04\n",
            "Epoch 74/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.0508e-04 - accuracy: 0.9849 - mean_squared_error: 5.0508e-04 - val_loss: 6.1697e-04 - val_accuracy: 0.9835 - val_mean_squared_error: 6.1697e-04\n",
            "Epoch 75/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.1603e-04 - accuracy: 0.9847 - mean_squared_error: 5.1603e-04 - val_loss: 8.2049e-04 - val_accuracy: 0.9800 - val_mean_squared_error: 8.2049e-04\n",
            "Epoch 76/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 5.1118e-04 - accuracy: 0.9841 - mean_squared_error: 5.1118e-04 - val_loss: 6.9745e-04 - val_accuracy: 0.9816 - val_mean_squared_error: 6.9745e-04\n",
            "Epoch 77/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.4373e-04 - accuracy: 0.9858 - mean_squared_error: 4.4373e-04 - val_loss: 5.1012e-04 - val_accuracy: 0.9866 - val_mean_squared_error: 5.1012e-04\n",
            "Epoch 78/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.9804e-04 - accuracy: 0.9850 - mean_squared_error: 4.9804e-04 - val_loss: 3.7475e-04 - val_accuracy: 0.9891 - val_mean_squared_error: 3.7475e-04\n",
            "Epoch 79/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 3.9197e-04 - accuracy: 0.9873 - mean_squared_error: 3.9197e-04 - val_loss: 6.5927e-04 - val_accuracy: 0.9852 - val_mean_squared_error: 6.5927e-04\n",
            "Epoch 80/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.5061e-04 - accuracy: 0.9862 - mean_squared_error: 4.5061e-04 - val_loss: 6.2869e-04 - val_accuracy: 0.9831 - val_mean_squared_error: 6.2869e-04\n",
            "Epoch 81/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 4.4810e-04 - accuracy: 0.9857 - mean_squared_error: 4.4810e-04 - val_loss: 5.8393e-04 - val_accuracy: 0.9837 - val_mean_squared_error: 5.8393e-04\n",
            "Epoch 82/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.4092e-04 - accuracy: 0.9864 - mean_squared_error: 4.4092e-04 - val_loss: 8.6251e-04 - val_accuracy: 0.9791 - val_mean_squared_error: 8.6251e-04\n",
            "Epoch 83/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.2572e-04 - accuracy: 0.9863 - mean_squared_error: 4.2572e-04 - val_loss: 6.3589e-04 - val_accuracy: 0.9830 - val_mean_squared_error: 6.3589e-04\n",
            "Epoch 84/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.3078e-04 - accuracy: 0.9862 - mean_squared_error: 4.3078e-04 - val_loss: 6.9872e-04 - val_accuracy: 0.9848 - val_mean_squared_error: 6.9872e-04\n",
            "Epoch 85/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.6507e-04 - accuracy: 0.9856 - mean_squared_error: 4.6507e-04 - val_loss: 7.1094e-04 - val_accuracy: 0.9823 - val_mean_squared_error: 7.1094e-04\n",
            "Epoch 86/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.1615e-04 - accuracy: 0.9865 - mean_squared_error: 4.1615e-04 - val_loss: 5.8162e-04 - val_accuracy: 0.9853 - val_mean_squared_error: 5.8162e-04\n",
            "Epoch 87/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.8097e-04 - accuracy: 0.9847 - mean_squared_error: 4.8097e-04 - val_loss: 6.0390e-04 - val_accuracy: 0.9825 - val_mean_squared_error: 6.0390e-04\n",
            "Epoch 88/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.6651e-04 - accuracy: 0.9851 - mean_squared_error: 4.6651e-04 - val_loss: 6.0075e-04 - val_accuracy: 0.9841 - val_mean_squared_error: 6.0075e-04\n",
            "Epoch 89/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.3425e-04 - accuracy: 0.9854 - mean_squared_error: 4.3425e-04 - val_loss: 6.6542e-04 - val_accuracy: 0.9832 - val_mean_squared_error: 6.6542e-04\n",
            "Epoch 90/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.1219e-04 - accuracy: 0.9860 - mean_squared_error: 4.1219e-04 - val_loss: 6.2162e-04 - val_accuracy: 0.9826 - val_mean_squared_error: 6.2162e-04\n",
            "Epoch 91/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.1135e-04 - accuracy: 0.9864 - mean_squared_error: 4.1135e-04 - val_loss: 6.0016e-04 - val_accuracy: 0.9839 - val_mean_squared_error: 6.0016e-04\n",
            "Epoch 92/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.6626e-04 - accuracy: 0.9848 - mean_squared_error: 4.6626e-04 - val_loss: 6.9824e-04 - val_accuracy: 0.9826 - val_mean_squared_error: 6.9824e-04\n",
            "Epoch 93/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.3305e-04 - accuracy: 0.9858 - mean_squared_error: 4.3305e-04 - val_loss: 7.0204e-04 - val_accuracy: 0.9823 - val_mean_squared_error: 7.0204e-04\n",
            "Epoch 94/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.1230e-04 - accuracy: 0.9862 - mean_squared_error: 4.1230e-04 - val_loss: 7.3835e-04 - val_accuracy: 0.9817 - val_mean_squared_error: 7.3835e-04\n",
            "Epoch 95/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.4957e-04 - accuracy: 0.9855 - mean_squared_error: 4.4957e-04 - val_loss: 6.9436e-04 - val_accuracy: 0.9835 - val_mean_squared_error: 6.9436e-04\n",
            "Epoch 96/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 3.7935e-04 - accuracy: 0.9868 - mean_squared_error: 3.7935e-04 - val_loss: 7.9009e-04 - val_accuracy: 0.9809 - val_mean_squared_error: 7.9009e-04\n",
            "Epoch 97/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 4.5079e-04 - accuracy: 0.9849 - mean_squared_error: 4.5079e-04 - val_loss: 4.0343e-04 - val_accuracy: 0.9902 - val_mean_squared_error: 4.0343e-04\n",
            "Epoch 98/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 4.7061e-04 - accuracy: 0.9847 - mean_squared_error: 4.7061e-04 - val_loss: 3.1784e-04 - val_accuracy: 0.9916 - val_mean_squared_error: 3.1784e-04\n",
            "Epoch 99/100\n",
            "313/313 [==============================] - 1s 5ms/step - loss: 3.9094e-04 - accuracy: 0.9864 - mean_squared_error: 3.9094e-04 - val_loss: 7.2834e-04 - val_accuracy: 0.9821 - val_mean_squared_error: 7.2834e-04\n",
            "Epoch 100/100\n",
            "313/313 [==============================] - 2s 5ms/step - loss: 4.0245e-04 - accuracy: 0.9860 - mean_squared_error: 4.0245e-04 - val_loss: 7.8766e-04 - val_accuracy: 0.9816 - val_mean_squared_error: 7.8766e-04\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam, Lion\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(),\n",
        "              loss='MSE',  \n",
        "              metrics=['accuracy', 'mean_squared_error'])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 100\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    history = model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)\n",
        "\n",
        "# Dense: 1.3\n",
        "# CNN: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 105,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "cvpE_X1iTXcB",
        "outputId": "eff0e5f5-5b26-46ea-ec6b-491d1de9944c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history.history['mean_squared_error'], label='Training MSE')\n",
        "plt.plot(history.history['val_mean_squared_error'], label='Validation MSE')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs. Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# MIN LOSS = 0.0128 c/fund 50epochs MSE\n",
        "##         = 0.0118 s/fund 50epochs MSE\n",
        "##         = 0.0039 s/fund 50epochs MSE m=4 d=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRlZuRUNa6Yb",
        "outputId": "85850559-311b-4cf4-ea5b-465a9ee8a7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a validation dataset (val_dataset)\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "next_sample = next(iterador)\n",
        "input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "actual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(input_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor([0.21236584 0.50071627], shape=(2,), dtype=float32)\n",
            "[0.20802663 0.5141552 ]\n",
            "tf.Tensor([0.8052983 0.4897813], shape=(2,), dtype=float32)\n",
            "[0.7973895  0.49154449]\n",
            "tf.Tensor([0.56844366 0.36936653], shape=(2,), dtype=float32)\n",
            "[0.56346565 0.37442225]\n",
            "tf.Tensor([0.17301044 0.09794518], shape=(2,), dtype=float32)\n",
            "[0.16020682 0.10953262]\n",
            "0.019771598 0.41488874\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Vemos algunos valores\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 4):\n",
        "        print(e[1][i])\n",
        "        print(predictions[i])\n",
        "    break\n",
        "    \n",
        "\n",
        "RMSE_pred = mean_squared_error(actual_values, predictions, squared=False)\n",
        "RMSE_rand = mean_squared_error(actual_values, next_sample[1], squared=False)\n",
        "print(RMSE_pred, RMSE_rand)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 108,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "34.58333333333333"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "0.415/0.012"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "id": "ds5iD1OMbZu3"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "cannot reshape array of size 2 into shape (1,1)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[109], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m val_dataset:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m printear \u001b[38;5;28;01melse\u001b[39;00m batch_size):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Valores actuales\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m#h = e[1][i].numpy().reshape(basis.size,basis.size)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         h_true \u001b[38;5;241m=\u001b[39m \u001b[43mgen_to_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho_1_arrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m#print(h) if printear else 0\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigvals(e[\u001b[38;5;241m0\u001b[39m][i]))\n",
            "Cell \u001b[0;32mIn[67], line 20\u001b[0m, in \u001b[0;36mgen_to_h\u001b[0;34m(base, rho_1_arrays)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen_to_h\u001b[39m(base, rho_1_arrays):\n\u001b[0;32m---> 20\u001b[0m     triag \u001b[38;5;241m=\u001b[39m \u001b[43mfill_triangular_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     body_gen \u001b[38;5;241m=\u001b[39m triag \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(triag)\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mdiag(np\u001b[38;5;241m.\u001b[39mdiag(triag))\n\u001b[1;32m     22\u001b[0m     h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
            "Cell \u001b[0;32mIn[6], line 17\u001b[0m, in \u001b[0;36mfill_triangular_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     15\u001b[0m n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32(np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m.25\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m.5\u001b[39m)\n\u001b[1;32m     16\u001b[0m x_tail \u001b[38;5;241m=\u001b[39m x[(m \u001b[38;5;241m-\u001b[39m (n\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m m)):]\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mtriu(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_tail\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m)\u001b[49m)\n",
            "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 2 into shape (1,1)"
          ]
        }
      ],
      "source": [
        "m_size = basis.size\n",
        "rho_1_pred = []\n",
        "rho_1_actual = []\n",
        "norm = []\n",
        "norm_rand = []\n",
        "printear =  False\n",
        "\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 3 if printear else batch_size):\n",
        "        # Valores actuales\n",
        "        #h = e[1][i].numpy().reshape(basis.size,basis.size)\n",
        "        h_true = gen_to_h(e[1][i], rho_1_arrays)\n",
        "        #print(h) if printear else 0\n",
        "        r = max(np.linalg.eigvals(e[0][i]))\n",
        "        rho_1_actual.append(r)\n",
        "\n",
        "        print(h_true) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "\n",
        "        # Valores predichos\n",
        "        #h = predictions[i].reshape(basis.size,basis.size)\n",
        "        h_pred = gen_to_h(predictions[i], rho_1_arrays)\n",
        "        beta = 1\n",
        "        # Estado térmico\n",
        "        state = thermal_state(h_pred, beta)\n",
        "        # Estado puro\n",
        "        #state = pure_state(h_pred)\n",
        "        rho1 = np.array(rho_1(basis.d, state, rho_1_arrays))\n",
        "        r = max(np.sort(linalg_d.eigvals(rho1).real))\n",
        "        rho_1_pred.append(r)\n",
        "\n",
        "        print(h_pred) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "        \n",
        "\n",
        "        # Normas\n",
        "        norm.append(np.linalg.norm(h_true-h_pred, ord='fro'))\n",
        "        print(f'Norma {norm[-1]}') if printear else 0\n",
        "        ## Vamos a comparar con un h aleatorio\n",
        "        size = basis.d*(basis.d+1)//2\n",
        "        base = np.random.uniform(low=0, high=1.0, size=(size,))\n",
        "        h_rand = gen_to_h(base, rho_1_arrays)\n",
        "        norm_rand.append(np.linalg.norm(h_true-h_rand, ord='fro'))\n",
        "        #print(f'Norma random {norm_rand[-1]}') if printear else 0\n",
        "        print('') if printear else 0\n",
        "        \n",
        "\n",
        "\n",
        "    # e contiene todo el batch y nos basta con uno\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(e[1][10])\n",
        "predictions[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "AL2EC9Ci-0HG",
        "outputId": "545ebe57-d3de-490f-f076-709d5c47b5f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f=1\n",
        "rho_1_actual = np.array(rho_1_actual)\n",
        "rho_1_pred = np.array(rho_1_pred)\n",
        "#print(mean_squared_error(rho_1_pred, rho_1_actual))\n",
        "\n",
        "print('Rho1 based statistics')\n",
        "print(np.mean(np.abs(rho_1_actual-rho_1_pred)))\n",
        "print(np.mean(rho_1_actual)*f)\n",
        "print('std')\n",
        "print(np.std(rho_1_actual-rho_1_pred)*f)\n",
        "print(np.std(rho_1_actual)*f)\n",
        "print(np.std(rho_1_pred)*f)\n",
        "plt.hist(np.array(rho_1_pred-rho_1_actual), bins=50)\n",
        "plt.show()\n",
        "print('H based statistics')\n",
        "print(np.mean(norm), np.mean(norm_rand))\n",
        "print(np.mean(norm_rand)/np.mean(norm))\n",
        "\n",
        "\n",
        "# BEST: FACTOR 1/8 c/fund\n",
        "## 500 epochs, 10M dataset\n",
        "# BEST: FACTOR 1/9 s/fund\n",
        "## 50 epochs, 5M dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "6.25/1.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 25 epochs d = m*2\n",
        "res = {}\n",
        "res[5] = 35/8.19 \n",
        "res[4] = 15/2.47\n",
        "res[3] = 6.2/1.73"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YioVllOX3M1N",
        "outputId": "b7715c37-1400-4c04-8be3-dd247b4b9db9"
      },
      "outputs": [],
      "source": [
        "# Get the weights of all dense layers in the model\n",
        "dense_weights = []\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Dense):\n",
        "        weights = layer.get_weights()\n",
        "        if len(weights) > 0:\n",
        "            dense_weights.append(weights[0])\n",
        "\n",
        "# Visualize the weights of each dense layer\n",
        "for i, weights in enumerate(dense_weights):\n",
        "    plt.figure()\n",
        "    plt.imshow(weights, cmap='viridis', aspect='auto')\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"Dense Layer {i+1} Weights Visualization\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 1 1] [0 1 1 0 0 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "            if mat[i,j,0,9] != 0:\n",
        "                print(v,w)\n",
        "\n",
        "    return mat\n",
        "\n",
        "r = rho_2_gen(basis, basis_m2, t_basis)\n",
        "r[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 1],\n",
              "       [1, 0, 1, 1, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 0],\n",
              "       [1, 0, 1, 0, 0, 1],\n",
              "       [1, 0, 0, 1, 1, 0],\n",
              "       [1, 0, 0, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 1],\n",
              "       [0, 1, 1, 1, 0, 0],\n",
              "       [0, 1, 1, 0, 1, 0],\n",
              "       [0, 1, 1, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 0, 1, 1],\n",
              "       [0, 0, 1, 1, 1, 0],\n",
              "       [0, 0, 1, 1, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 1],\n",
              "       [0, 0, 0, 1, 1, 1]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basis.base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 20)\n",
            "[array([0, 1, 0, 1, 1, 0])] [0 1 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "col = 1\n",
        "b = b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0]))\n",
        "print(b.shape)\n",
        "for x in range(0,b.shape[1]):\n",
        "    if b[col,x] != 0:\n",
        "        ind = x\n",
        "        break\n",
        "else:\n",
        "    ind = NaN\n",
        "\n",
        "print([basis.base[ind]], mll_basis.base[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "d = 2*m\n",
        "basis = fixed_basis(m, d)\n",
        "t_basis = fixed_basis(2, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "ml_basis = basis_m1\n",
        "mll_basis = basis_m2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_basis = fixed_basis(2, d)\n",
        "mll_basis = fixed_basis(basis.m-2, d)\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2)))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    offset = 4*m+1\n",
        "    indices = [-(k-1)*(2*k-offset) for k in range(1,m+1)] # Lo saque de Mathmatica, vos confia\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    \n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "\n",
        "    hi = -np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    return (h0, hi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(h02,hi2) = two_body_hamiltonian(t_basis.size, m, [0,1,2], np.ones((3,3)), rho_1_arrays, rho_2_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]]]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "print(rho_2_arrays[9,0,0,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "\n",
        "A = np.array([0, 1, 2])  # Your list with d elements\n",
        "\n",
        "# Create a diagonal matrix with each element repeated twice\n",
        "result_matrix = np.diagflat(np.kron(A, np.ones(2)))\n",
        "\n",
        "print(result_matrix)\n",
        "np.kron(A, np.ones(2))\n",
        "\n",
        "mat = np.zeros((basis.size, basis.size))\n",
        "for i in range(0,2*d):\n",
        "    for j in range(0, 2*d):\n",
        "        mat += result_matrix[i,j] * rho_1_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mat = np.sum(result_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h0 == mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1]\n",
            "[0, 9, 14]\n",
            "[0, 9, 14]\n"
          ]
        }
      ],
      "source": [
        "d = 3\n",
        "t_basis = fixed_basis(2, 2*d)\n",
        "basis = fixed_basis(d, 2*d)\n",
        "size = t_basis.size\n",
        "#basis = fixed_basis(d, 2*d)\n",
        "diag_elem = []\n",
        "for x in t_basis.base:\n",
        "    if all([x[i] == x[i+1] for i in range(0, 2*d, 2)]):\n",
        "        print(x)\n",
        "        diag_elem.append(t_basis.rep_to_index(x))\n",
        "\n",
        "print(diag_elem)\n",
        "# Veamos el GALERAZO de Wolfram\n",
        "n = 4*d+1\n",
        "print([-(k-1)*(2*k-n) for k in range(1,d+1)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m2_basis = fixed_basis(2, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-2, d)\n",
        "print(nm2_basis.base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "index = [0,9,14]\n",
        "mat = np.zeros((size,size))\n",
        "for i in range(0,3):\n",
        "    for j in range(0,3):\n",
        "        mat[index[i], index[j]] = W[i,j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "#rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "\n",
        "W = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "W = np.ones((3,3))\n",
        "index = [0, 9, 14]\n",
        "size = 15  # Assuming size is the size of the matrix\n",
        "\n",
        "# Create a meshgrid of indices\n",
        "i, j = np.meshgrid(index, index, indexing='ij')\n",
        "\n",
        "# Use the meshgrid indices to assign values from W to the specified positions in mat\n",
        "mat = np.zeros((size, size))\n",
        "mat[i, j] = W\n",
        "\n",
        "# La mat... mat corresponde a los coeficientes en t_basis\n",
        "inte = np.zeros((basis.size, basis.size))\n",
        "for i in range(0, t_basis.size):\n",
        "    for j in range(0, t_basis.size):\n",
        "        inte += - mat[i, j] * rho_2_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inte == hi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "\n",
        "from numba import njit\n",
        "\n",
        "# Parametros hamiltoniano\n",
        "e = 1\n",
        "eps = 0\n",
        "e0 = np.zeros(2*d)\n",
        "eigenspace_tol = 0.0001\n",
        "for k in range(0, d):\n",
        "    r = random.random() * eps * 0\n",
        "    e0[2*k] = k*e+r\n",
        "    e0[2*k+1] = k*e+r\n",
        "\n",
        "@njit(parallel=True)\n",
        "def base_hamiltonian_aux(basis, size, d, basis_m1, basis_m2):\n",
        "    # Construccion de H\n",
        "    d = d//2\n",
        "    h0 = np.zeros((size,size), dtype=np.float32)\n",
        "    for k in prange(0,2*d):\n",
        "        h0 += e0[k] * np.dot(bd_aux(basis_m1, basis, k),b_aux(basis, basis_m1, k))\n",
        "    hi = np.zeros((size, size), dtype=np.float32)\n",
        "    for k in prange(0,d):\n",
        "        for kb in prange(0,d):\n",
        "            bd_terms = np.dot(bd_aux(basis_m1, basis, 2*k),bd_aux(basis_m2, basis_m1, 2*k+1))\n",
        "            b_terms = np.dot(b_aux(basis_m1, basis_m2, 2*kb+1),b_aux(basis, basis_m1, 2*kb))\n",
        "            hi += -1*np.dot(bd_terms,b_terms)\n",
        "\n",
        "    return (h0, hi)\n",
        "\n",
        "def base_hamiltonian(basis, basis_m1, basis_m2):\n",
        "    return base_hamiltonian_aux(basis.base, basis.size, basis.d, basis_m1.base, basis_m2.base)\n",
        "\n",
        "h0, hi = base_hamiltonian(basis, basis_m1, basis_m2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oapxWkD16fHg"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
