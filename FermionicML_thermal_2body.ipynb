{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/aguschanchu/FermionicML/blob/main/FermionicML_thermal.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NXz5cOlVwrzZ"
      },
      "source": [
        "# FermionicML:\n",
        "\n",
        "Code based on aguschanchu/Bosonic.py\n",
        "\n",
        "A diferencia del código anterior, este modelo trabaja sobre estados térmicos"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLD2Yai55rMm"
      },
      "source": [
        "## Código base"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rgf9ExZN4jA7"
      },
      "source": [
        "Cargamos el código de Bosonic.py básico, branch fermionic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Gydz4kCH4l5w"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-15 14:04:37.129704: I tensorflow/core/util/port.cc:111] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-01-15 14:04:37.179097: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-01-15 14:04:37.179130: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-01-15 14:04:37.179156: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-01-15 14:04:37.188049: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "/var/tmp/ipykernel_4845/3693791191.py:326: NumbaDeprecationWarning: \u001b[1mThe 'nopython' keyword argument was not supplied to the 'numba.jit' decorator. The implicit default value for this argument is currently False, but it will be changed to True in Numba 0.59.0. See https://numba.readthedocs.io/en/stable/reference/deprecation.html#deprecation-of-object-mode-fall-back-behaviour-when-using-jit for details.\u001b[0m\n",
            "  def gamma_lamba_inv(x):\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from scipy.special import binom\n",
        "from scipy.sparse import dok_matrix, linalg\n",
        "from scipy import linalg as linalg_d\n",
        "from joblib import Memory\n",
        "import random\n",
        "import plotly.graph_objects as go\n",
        "from joblib import Parallel, delayed\n",
        "from numba import jit, prange, njit\n",
        "import numba as nb\n",
        "import pickle\n",
        "import math\n",
        "import tensorflow_probability as tfp\n",
        "import tensorflow as tf\n",
        "from tqdm import tqdm\n",
        "from itertools import combinations\n",
        "\n",
        "\n",
        "# Funciones auxiliares optimiadas\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def int_to_tuple_arr(ni,nf, b, digits=None):\n",
        "    sol = np.zeros((nf-ni, digits), dtype=np.int64)\n",
        "    for n in prange(ni, nf):\n",
        "        r = np.zeros(digits, dtype=np.int64)\n",
        "        ncop = n\n",
        "        idx = 0\n",
        "        while n != 0:\n",
        "            r[idx] = n % b\n",
        "            n = n // b\n",
        "            idx += 1\n",
        "        if digits is not None:\n",
        "            if idx < digits:\n",
        "                for i in range(idx, digits):\n",
        "                    r[i] = 0\n",
        "                idx = digits\n",
        "        sol[ncop-ni,:] = r[:idx]\n",
        "    return sol\n",
        "\n",
        "def tuple_to_int(t, d):\n",
        "    b = d-1\n",
        "    l = len(t)\n",
        "    s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "    return sum(s)\n",
        "\n",
        "def create_basis_(m, d, size):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 1000000\n",
        "    for x in range(0,(m+1)**d, chunk_size):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        arr = int_to_tuple_arr(start_index, end_index, m+1, d)\n",
        "        sums = np.sum(arr, axis=1)\n",
        "        rows = np.where(sums == m)[0]\n",
        "        for row in [arr[i] for i in rows]:\n",
        "            if np.all(np.logical_or(row == 0, row == 1)):\n",
        "                base.append(row)\n",
        "\n",
        "    # Como consecuencia de la paralelizacion, es necesario reordenar la base\n",
        "    sorted_base = sorted(base, key=lambda x: tuple_to_int(x, d), reverse=True)\n",
        "    assert len(base) == size\n",
        "\n",
        "    return sorted_base\n",
        "\n",
        "def custom_base_representation_tf(n_min, n_max, base, num_digits):\n",
        "    # Generate a range of numbers from n_min to n_max\n",
        "    numbers = tf.range(n_min, n_max + 1, dtype=tf.int64)\n",
        "    \n",
        "    # Calculate the digits in the custom base using broadcasting\n",
        "    digits = tf.pow(tf.cast(base, dtype=tf.float64), tf.cast(tf.range(num_digits), dtype=tf.float64))\n",
        "    \n",
        "    # Reshape the digits to [1, num_digits] for broadcasting\n",
        "    digits = tf.reshape(digits, [1, -1])\n",
        "    \n",
        "    # Reshape numbers to [batch_size, 1]\n",
        "    numbers = tf.reshape(tf.cast(numbers, dtype=tf.float64), [-1, 1])\n",
        "    \n",
        "    # Calculate the digits in the custom base for each number using broadcasting\n",
        "    result = tf.cast(tf.math.floormod(tf.math.floordiv(numbers, digits), base), dtype=tf.int32)\n",
        "    \n",
        "    # Pad the result to have exactly num_digits columns\n",
        "    result = tf.pad(result, paddings=[[0, 0], [0, num_digits - tf.shape(result)[1]]], constant_values=0)\n",
        "    \n",
        "    # Reverse the order of columns\n",
        "    #result = tf.reverse(result, axis=[1])\n",
        "\n",
        "    return result\n",
        "\n",
        "def select_rows_with_sum(arr, m):\n",
        "    # Create a mask based on the criteria\n",
        "    mask = tf.reduce_all(tf.math.logical_or(tf.equal(arr, 0), tf.equal(arr, 1)), axis=1) & (tf.reduce_sum(arr, axis=1) == m)\n",
        "    \n",
        "    # Use the mask to select the rows\n",
        "    result = tf.boolean_mask(arr, mask, axis=0)\n",
        "    \n",
        "    return result\n",
        "\n",
        "def create_basis_tf_(m, d):\n",
        "    base = []\n",
        "    index = 0\n",
        "    chunk_size = 10000000\n",
        "    for x in tqdm(range(0,(m+1)**d, chunk_size)):\n",
        "        start_index = x\n",
        "        end_index = min(x + chunk_size, (m+1)**d)\n",
        "        res = custom_base_representation_tf(start_index, end_index, m+1, d)\n",
        "        arr = select_rows_with_sum(res, m)\n",
        "        base.append(arr.numpy())\n",
        "\n",
        "    return np.concatenate(base)\n",
        "\n",
        "def create_fermionic_base_(m, d):\n",
        "    indices = list(range(d))\n",
        "    combinations_list = list(combinations(indices, m))\n",
        "    \n",
        "    vectors = []\n",
        "    for combo in combinations_list:\n",
        "        vector = [1 if i in combo else 0 for i in indices]\n",
        "        vectors.append(vector)\n",
        "    \n",
        "    return vectors\n",
        "\n",
        "# Dada una base, devuelve los vectores que estan dados de a pares\n",
        "def get_kkbar_indices_(base):\n",
        "    indices = []\n",
        "    for i, v in enumerate(base):\n",
        "        if np.all(v[::2] == v[1::2]):\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "class fixed_basis:\n",
        "\n",
        "    # Convierte a un enterno n a su escritura en base b\n",
        "    def _int_to_tuple(self, n, b, digits = None):\n",
        "        rep = np.base_repr(n, b)\n",
        "        rep_int = [int(x,b) for x in rep]\n",
        "        if digits is not None:\n",
        "            zeros = [0 for i in range(0,digits-len(rep))]\n",
        "            return zeros + rep_int\n",
        "        else:\n",
        "            return rep_int\n",
        "\n",
        "    # Revierte la transformacion anterior\n",
        "    def tuple_to_int(self, t):\n",
        "        b = self.d-1\n",
        "        l = len(t)\n",
        "        s = [t[k]*b**(l-k-1) for k in range(0,l)]\n",
        "        return sum(s)\n",
        "\n",
        "    # Convierte el vector en su representacion\n",
        "    def vect_to_repr(self, vect):\n",
        "        for i, k in enumerate(vect):\n",
        "            if k == 1. or k == 1:\n",
        "                break\n",
        "        else:\n",
        "            return 0\n",
        "        return self.base[i,:]\n",
        "\n",
        "    def rep_to_vect(self, rep):\n",
        "        rep = list(rep)\n",
        "        for i, r in [(j, self.base[j,:]) for j in range(0,self.size)]:\n",
        "            if list(r) == rep:\n",
        "                return self.canonicals[:,i]\n",
        "        else:\n",
        "            None\n",
        "\n",
        "    def rep_to_index(self, rep):\n",
        "        try:\n",
        "            return self.base.tolist().index(list(rep))\n",
        "        except:\n",
        "            return None\n",
        "\n",
        "    @staticmethod\n",
        "    def rep_to_exi(rep):\n",
        "        r = []\n",
        "        for i, k in enumerate(rep):\n",
        "            r += [i for x in range(0,k)]\n",
        "        return r\n",
        "\n",
        "    # Crea base de M particulas en D estados (repr y base canonica)\n",
        "    def create_basis(self, m, d, pairs = False):\n",
        "        #print(\"Creating basis: \", m, d)\n",
        "        #base = np.array(create_basis_tf_(m, d)) CASO GENERICO\n",
        "        base = np.array(create_fermionic_base_(m,d)) # UNICAMENTE FERMIONICO\n",
        "        if pairs:\n",
        "            base = base[get_kkbar_indices_(base)]\n",
        "        length = base.shape[0]\n",
        "        # Asignamos a cada uno de ellos un canónico\n",
        "        canonicals = np.eye(length)\n",
        "        return base, canonicals\n",
        "    \n",
        "    def __init__(self, m, d, pairs = False):\n",
        "        self.m = m\n",
        "        self.d = d\n",
        "        (self.base, self.canonicals) = self.create_basis(m, d, pairs)\n",
        "        self.size = self.base.shape[0]\n",
        "\n",
        "# Matrices de aniquilación y creación endomórficas. Estan fuera de la clase para poder ser cacheadas\n",
        "#@memory.cache\n",
        "def bdb(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0 and v[i] != 1:\n",
        "                #print(v)\n",
        "                dest = list(v.copy())\n",
        "                dest[j] -= 1\n",
        "                dest[i] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                if tar is None:\n",
        "                    pass\n",
        "                else:\n",
        "                    mat[tar, k] = np.sqrt(v[i]+1)*np.sqrt(v[j])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[j] != 0:\n",
        "                mat[k, k] = v[i] \n",
        "    return mat\n",
        "\n",
        "#@memory.cache\n",
        "def bbd(basis, i, j):\n",
        "    mat = dok_matrix((basis.size, basis.size), dtype=np.float32)\n",
        "    if i != j:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 0 and v[j] != 1:\n",
        "                dest = list(v.copy())\n",
        "                dest[i] -= 1\n",
        "                dest[j] += 1\n",
        "                tar = basis.rep_to_index(dest)\n",
        "                mat[tar, k] = np.sqrt(v[j]+1)*np.sqrt(v[i])\n",
        "    else:\n",
        "        for k, v in enumerate(basis.base):\n",
        "            if v[i] != 1:\n",
        "                mat[k, k] = v[i]+1\n",
        "    return mat\n",
        "\n",
        "# Matrices de aniquilación y creación.Toman la base de origen y destino (basis_o, basis_d) resp\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def b_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 0:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] -= 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i])\n",
        "    return mat\n",
        "\n",
        "def b(basis_o, basis_d, i):\n",
        "    return b_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "#@nb.jit(nopython=True, parallel=True)\n",
        "@nb.jit(nopython=True)\n",
        "def bd_aux(basis_o, basis_d, i):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        if basis_o[k][i] != 1:\n",
        "            dest = list(basis_o[k].copy())\n",
        "            dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd(basis_o, basis_d, i):\n",
        "    return bd_aux(basis_o.base, basis_d.base, i)\n",
        "\n",
        "\n",
        "# Acepta una lista de indices a crear\n",
        "@nb.jit(nopython=True, parallel=True)\n",
        "def bd_gen_aux(basis_o, basis_d, gen_list):\n",
        "    mat = np.zeros((len(basis_d), len(basis_o)), dtype=np.float32)\n",
        "    for k in prange(len(basis_o)):\n",
        "        conds = np.zeros(len(gen_list), dtype=np.int64)\n",
        "        for i in range(len(gen_list)):\n",
        "            if basis_o[k][gen_list[i]] != 1:\n",
        "                conds[i] = 1\n",
        "        if np.all(conds):\n",
        "            dest = list(basis_o[k].copy())\n",
        "            for i in gen_list:\n",
        "                dest[i] += 1\n",
        "            for j in prange(len(basis_d)):\n",
        "                if list(basis_d[j]) == dest:\n",
        "                    tar = j\n",
        "                    mat[tar, k] = np.sqrt(basis_o[k][i]+1)\n",
        "    return mat\n",
        "\n",
        "def bd_gen(basis_o, basis_d, i):\n",
        "    return bd_gen_aux(basis_o.base, basis_d.base, np.array(i))\n",
        "\n",
        "def b_gen(basis_o, basis_d, i):\n",
        "    return np.transpose(bd_gen(basis_d, basis_o, i))\n",
        "\n",
        "# Volvemos a definir la función para compilarla\n",
        "@nb.jit(forceobj=True)\n",
        "def _rep_to_index(base, rep):\n",
        "    return base.tolist().index(list(rep))\n",
        "\n",
        "# Funciones auxiliares para calcular rho2kkbar y gamma_p\n",
        "@nb.jit(nopython=True)\n",
        "def rep_to_exi(rep):\n",
        "    r = []\n",
        "    for i in range(len(rep)):\n",
        "        for j in range(rep[i]):\n",
        "            r.append(i)\n",
        "    return r\n",
        "\n",
        "@nb.njit\n",
        "def factorial(n):\n",
        "    result = 1\n",
        "    for i in range(1, n + 1):\n",
        "        result *= i\n",
        "    return result\n",
        "\n",
        "@nb.njit\n",
        "def gamma_lamba(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.jit\n",
        "def gamma_lamba_inv(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / np.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "@nb.njit\n",
        "def rep_to_index_np(base, rep):\n",
        "    for i in range(len(base)):\n",
        "        if np.all(base[i] == rep):\n",
        "            return i\n",
        "    return -1\n",
        "\n",
        "\n",
        "def gamma_p(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    return gamma_p_aux(basis.base, vect, m_basis.base, nm_basis.base)\n",
        "\n",
        "@nb.njit()\n",
        "def gamma_p_aux(basis, vect, m_basis, nm_basis):\n",
        "    mat = np.zeros((len(m_basis), len(nm_basis)), dtype=np.float32)\n",
        "    for i in prange(len(m_basis)):\n",
        "        v = m_basis[i]\n",
        "        for j in prange(len(nm_basis)):\n",
        "            w = nm_basis[j]\n",
        "            targ = v + w\n",
        "            index = rep_to_index_np(basis, targ)\n",
        "            if index != -1:\n",
        "                coef = vect[index]\n",
        "                if coef != 0:\n",
        "                    coef = coef * gamma_lamba_inv(v) * gamma_lamba_inv(w) * gamma_lamba(targ)\n",
        "                mat[i, j] = coef\n",
        "    return mat\n",
        "# Devuelve la matriz rho M asociada al vector\n",
        "def rho_m(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    g = gamma_p(basis, m, vect, m_basis, nm_basis)\n",
        "    return np.dot(g,np.transpose(g))\n",
        "\n",
        "# Devuelve la matriz gamma asociada a la descomposición (M,N-M) del vector\n",
        "@jit(forceobj=True)\n",
        "def gamma(basis, m, vect, m_basis = None, nm_basis = None):\n",
        "    d = basis.d\n",
        "    if not m_basis or not nm_basis:\n",
        "        m_basis = fixed_basis(m, d)\n",
        "        nm_basis = fixed_basis(basis.m-m,d)\n",
        "    mat = dok_matrix((m_basis.size, nm_basis.size), dtype=np.float32)\n",
        "    for i, v in enumerate(m_basis.base):\n",
        "        for j, w in enumerate(nm_basis.base):\n",
        "            targ = v+w\n",
        "            # Revisamos que sea un estado fermionico valido\n",
        "            arr = np.asarray(targ)\n",
        "            if not np.all(np.logical_or(arr == 0, arr == 1)):\n",
        "                continue\n",
        "            index = _rep_to_index(basis.base, targ)\n",
        "            coef = vect[index]\n",
        "            if coef != 0:\n",
        "                aux = lambda x: np.prod(np.reciprocal(np.sqrt([np.math.factorial(o) for o in x])))\n",
        "                aux_inv = lambda x: np.prod(np.sqrt([np.math.factorial(o) for o in x]))\n",
        "                coef = coef * aux(v) * aux(w) * aux_inv(targ)\n",
        "                #coef = coef\n",
        "                #print(v,w,coef)\n",
        "            mat[i,j] = coef\n",
        "    return mat\n",
        "\n",
        "# Genera las matrices de rho1\n",
        "def rho_1_gen(basis):\n",
        "    d = basis.d\n",
        "    s = basis.size\n",
        "    mat = np.empty((d,d,s,s), dtype=np.float32)\n",
        "    for i in range(0, d):\n",
        "        for j in range(0, d):\n",
        "            mat[i,j,:,:] = np.array(bdb(basis,j, i).todense())\n",
        "    return mat\n",
        "\n",
        "#@jit(parallel=True, nopython=True)\n",
        "def rho_1(d, state, rho_1_arrays):\n",
        "    state_expanded = state[np.newaxis, np.newaxis, :, :]\n",
        "    product = state_expanded * rho_1_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "\n",
        "    return mat\n",
        "\n",
        "\n",
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "\n",
        "    return mat\n",
        "\n",
        "def rho_2(size, state, rho_2_arrays):\n",
        "    state_expanded = np.expand_dims(state, axis=1)\n",
        "    state_expanded = np.expand_dims(state_expanded, axis=1)\n",
        "    rho_2_arrays = rho_2_arrays[np.newaxis, :, :, :, :]\n",
        "    print(state_expanded.shape, rho_2_arrays.shape)\n",
        "    product = state_expanded * rho_2_arrays\n",
        "    mat = np.sum(product, axis=(-2, -1))\n",
        "    return mat\n",
        "\n",
        "def get_kkbar_indices(t_basis):\n",
        "    indices = []\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        if np.all(v[::2] == v[1::2]):\n",
        "            indices.append(i)\n",
        "    return indices\n",
        "\n",
        "def rho_2_kkbar_gen(t_basis, rho_2_arrays):\n",
        "    indices = get_kkbar_indices(t_basis)\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "\n",
        "    rho_2_arrays_kkbar = rho_2_arrays[i, j, :, :]\n",
        "\n",
        "    return rho_2_arrays_kkbar\n",
        "\n",
        "# Devuelve la matriz rho 2 asociada al bloque kkbar\n",
        "def rho_2_kkbar(basis, vect, ml_basis = None, mll_basis = None, t_basis = None):\n",
        "    d = basis.d\n",
        "    # Creo las bases si no están dadas\n",
        "    if ml_basis == None or mll_basis == None or t_basis == None:\n",
        "        ml_basis = fixed_basis(m-1,d)\n",
        "        mll_basis = fixed_basis(m-2,d)\n",
        "        t_basis = fixed_basis(2,d)\n",
        "    diag = []\n",
        "    for v in t_basis.base:\n",
        "        for j in range(0, d, 2):\n",
        "            if v[j] == v[j+1]:\n",
        "                continue\n",
        "            else:\n",
        "                break\n",
        "        else:\n",
        "            diag.append(v)\n",
        "    diag = np.array(diag)\n",
        "    return rho_2_kkbar_aux(diag, vect, basis.base, ml_basis.base, mll_basis.base, t_basis.base)\n",
        "\n",
        "@nb.njit\n",
        "def rho_2_kkbar_lambda(x):\n",
        "    res = 1.0\n",
        "    for o in x:\n",
        "        res *= 1.0 / math.sqrt(factorial(o))\n",
        "    return res\n",
        "\n",
        "#@nb.njit(parallel=True)\n",
        "def rho_2_kkbar_aux(diag, vect, basis, ml_basis, mll_basis, t_basis):\n",
        "    mat = np.zeros((len(diag), len(diag)), dtype=np.float32)\n",
        "    for i in prange(len(diag)):\n",
        "        for j in prange(len(diag)):\n",
        "            v = diag[i]\n",
        "            w = diag[j]\n",
        "            # Creacion de los a\n",
        "            i_set = rep_to_exi(v)\n",
        "            b_m = b_aux(ml_basis, mll_basis, i_set[1]) @ b_aux(basis, ml_basis, i_set[0])\n",
        "            # Creacion de los ad\n",
        "            i_set = rep_to_exi(w)\n",
        "            bd_m = bd_aux(ml_basis, basis, i_set[1]) @ bd_aux(mll_basis, ml_basis, i_set[0])\n",
        "            # v1 = vect @ bd_m @ b_m @ vect Para estados puros\n",
        "            # Mult de b's y filleo de mat\n",
        "            coef = np.trace(vect @ bd_m @ b_m)\n",
        "            mat[i,j] = coef * rho_2_kkbar_lambda(v) * rho_2_kkbar_lambda(w)\n",
        "    return mat\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dga5Xx_5vDf"
      },
      "source": [
        "## Definicion de Hamiltoniano"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "myiTq53L5E1U"
      },
      "source": [
        "Cargamos el código de creación y resolución de Hamiltonianos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-h5FXWv849Mq",
        "outputId": "49dd47b5-8c16-4ad4-92e7-e172462229b3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "70\n"
          ]
        }
      ],
      "source": [
        "m = 8\n",
        "d = 2*m\n",
        "pairs = True # Usar solo para estados puros\n",
        "# Creo las bases para no tener que recrearlas luego\n",
        "basis = fixed_basis(m, d, pairs = pairs)\n",
        "#basis_m1 = fixed_basis(m-1, d, pairs = True)\n",
        "basis_m2 = fixed_basis(m-2, d, pairs = pairs)\n",
        "print(basis.size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "PToiSs915TXw"
      },
      "outputs": [],
      "source": [
        "## Usamos este approach si queremos guardar los generadores\n",
        "# Dados 1/2 (d^2+d) elementos, genera una mat de dxd:\n",
        "eps = 0.00001\n",
        "\n",
        "def sym_mat_gen(vect, d):\n",
        "    matrix = fill_matrix(vect, d)\n",
        "    return matrix + matrix.T - np.diag(matrix.diagonal())\n",
        "\n",
        "@jit(nopython=True)\n",
        "def fill_matrix(vect, d):\n",
        "    matrix = np.zeros((d, d))\n",
        "    idx = 0\n",
        "    for i in prange(d):\n",
        "        for j in prange(i, d):\n",
        "            matrix[i, j] = vect[idx]\n",
        "            idx += 1\n",
        "    return matrix\n",
        "\n",
        "# Generamos una matrix aleatoria. Cuidado con la distribución, ver https://stackoverflow.com/questions/56605189/is-there-an-efficient-way-to-generate-a-symmetric-random-matrix\n",
        "def hamil_base_gen(d):\n",
        "    U = np.random.uniform(low=0, high=1.0, size=(d, d))\n",
        "    hamil_base = np.tril(U) + np.tril(U, -1).T\n",
        "    return hamil_base\n",
        "\n",
        "# Dada un a mat dxd simetrica, contruye el hamiltoniano de un cuerpo a_{ij} c^{dag}_i c_j\n",
        "# Alternativamente podemos construirlo a partir de rho_1_gen\n",
        "def base_hamiltonian_aux(mat, size, d, rho_1_gen):\n",
        "    # Construccion de H\n",
        "    rho_1_gen_transposed = rho_1_gen.transpose(1, 0, 2, 3)\n",
        "    mat_expanded = mat[:, :, np.newaxis, np.newaxis]\n",
        "    h = np.sum(mat_expanded * rho_1_gen_transposed[:, :, :, :], axis=(0, 1))\n",
        "    return h.astype(np.float32)\n",
        "\n",
        "def base_hamiltonian(mat, basis, rho_1_gen):\n",
        "    return base_hamiltonian_aux(mat, basis.size, basis.d, rho_1_gen)\n",
        "\n",
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2))) + eps * np.random.random((2*m,2*m))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    rho_1_arrays_t = tf.transpose(rho_1_arrays,perm=[1, 0, 2, 3])\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    rho_2_arrays_t = tf.transpose(rho_2_arrays,perm=[1, 0, 2, 3])\n",
        "\n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "    hi = np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays_t[:, :, :, :], axis=(0, 1))\n",
        "    return (h0, hi)\n",
        "\n",
        "def solve(h, last_step = None):\n",
        "    sol = linalg.eigsh(h, which='SA',k=19)\n",
        "    eigenspace_tol = 0.0001\n",
        "    if type(last_step) != type(None):\n",
        "        # Seleccionamos todos los autovects que difieren sus autovalores menos que tol (mismo autoespacio)\n",
        "        # y tomamos la proyección en el autoespacio de la solución del paso anterior (last_step)\n",
        "        eig = sol[0].real\n",
        "        eigv = sol[1]\n",
        "        cand = [eigv[:,i].real  for (i, x) in enumerate(eig) if abs(x-min(eig)) < eigenspace_tol]\n",
        "        cand_norm = [x/np.linalg.norm(x) for x in cand]\n",
        "        fund = np.zeros(len(cand[0]))\n",
        "        for x in cand_norm:\n",
        "            fund += np.dot(last_step,x) * x\n",
        "    else:\n",
        "        argmin = np.argmin(sol[0].real)\n",
        "        fund = sol[1][:,argmin]\n",
        "    fund = fund.real / np.linalg.norm(fund)\n",
        "    return fund\n",
        "\n",
        "# Generacion de H basada en TF\n",
        "\n",
        "# Funciones auxiliares de gen de H basado en TF\n",
        "## Dada matrix de indices, genera los indices de updates de TF\n",
        "def gen_update_indices(t_basis, batch_size):\n",
        "    # Calculamos los indices de kkbar en t_basis\n",
        "    indices = tf.constant(get_kkbar_indices(t_basis))\n",
        "    # Creamos el array de indices x indices\n",
        "    i, j = tf.meshgrid(indices, indices, indexing='ij')\n",
        "    matrix = tf.reshape(tf.stack([i, j], axis=-1), (-1, 2))\n",
        "\n",
        "    # Repeat the matrix along the first axis (axis=0) 'b' times\n",
        "    repeated_matrix = tf.repeat(tf.expand_dims(matrix, axis=0), repeats=batch_size, axis=0)\n",
        "\n",
        "    # Create an index array from 0 to b-1\n",
        "    indices = tf.range(batch_size, dtype=tf.int32)\n",
        "\n",
        "    # Expand the index array to have the same shape as the repeated matrix\n",
        "    indices = tf.expand_dims(indices, axis=-1)\n",
        "    indices = tf.expand_dims(indices, axis=-1)\n",
        "    indices = tf.tile(indices, multiples=[1,matrix.shape[0],1]) \n",
        "\n",
        "    # Concatenate the index array to the repeated matrix along a new axis\n",
        "    tiled_matrix = tf.concat([indices, repeated_matrix], axis=-1)\n",
        "    tiled_matrix = tf.reshape(tiled_matrix, [-1,3])\n",
        "    return tiled_matrix\n",
        "\n",
        "\n",
        "def two_body_hamiltonian_tf(t_basis, m, energy_batch, G_batched, rho_1_arrays, rho_2_arrays, indices):\n",
        "    # SECCIÓN ENERGIAS\n",
        "    ## Dado un batch de niveles, lo pasamos a TF\n",
        "    energy_matrix = tf.constant(energy_batch, dtype=tf.float32)\n",
        "    ## Repetimos los niveles para cada uno de los pares (por el nivel k y kbar)\n",
        "    energy_matrix = tf.repeat(energy_matrix, repeats=2, axis=1)\n",
        "    ## Generamos la matrix diagonal y expandimos\n",
        "    energy_matrix_expanded = tf.linalg.diag(energy_matrix)\n",
        "    energy_matrix_expanded = energy_matrix_expanded[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    # Multiplicamos por los operadores C^dag C\n",
        "    h0_arr = tf.reduce_sum(energy_matrix_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    # SECCIÓN INTERACCIÓN\n",
        "    # Ya tenemos los indices de updates, ahora tomamos la mat en t_basis (una de zeros)\n",
        "    # y updateamos de acuerdo a la lista de G's cada uno flatteneados\n",
        "    G_flatten = np.ndarray.flatten(np.array([np.ndarray.flatten(G) for G in G_batched]))\n",
        "    # Creamos la mat de t_basis y updateamos a partir de los indices de kkbar\n",
        "    mat = tf.zeros((len(energy_batch), t_basis.size, t_basis.size), dtype=tf.float32)\n",
        "    mat = tf.tensor_scatter_nd_update(mat, indices, G_flatten)\n",
        "    # Preparamos las dimensiones y multiplicamos\n",
        "    mat_expanded = mat[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_2_gen_transposed = tf.transpose(rho_2_arrays, perm=[1, 0, 2, 3])\n",
        "    hi_arr = tf.reduce_sum(mat_expanded * rho_2_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "\n",
        "    return h0_arr - hi_arr"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emVBTg2QD-Fg"
      },
      "source": [
        "## Modelo de ML\n",
        "Basado en matrices densidad de 1 y 2 cuerpos como input, con hamiltoniano como salida"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "aF_Ec_mCGX96"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-15 14:04:41.394277: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "tf.test.gpu_device_name()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mJDoa6LUJJ8O",
        "outputId": "73481454-fbcb-469f-d72f-cd0f8d534808"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "8\n",
            "[[1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 0 0 1 1 0 0 0 0 0 0 0 0]\n",
            " [1 1 1 1 0 0 0 0 1 1 0 0 0 0 0 0]\n",
            " [1 1 1 1 0 0 0 0 0 0 1 1 0 0 0 0]\n",
            " [1 1 1 1 0 0 0 0 0 0 0 0 1 1 0 0]\n",
            " [1 1 1 1 0 0 0 0 0 0 0 0 0 0 1 1]\n",
            " [1 1 0 0 1 1 1 1 0 0 0 0 0 0 0 0]\n",
            " [1 1 0 0 1 1 0 0 1 1 0 0 0 0 0 0]\n",
            " [1 1 0 0 1 1 0 0 0 0 1 1 0 0 0 0]\n",
            " [1 1 0 0 1 1 0 0 0 0 0 0 1 1 0 0]\n",
            " [1 1 0 0 1 1 0 0 0 0 0 0 0 0 1 1]\n",
            " [1 1 0 0 0 0 1 1 1 1 0 0 0 0 0 0]\n",
            " [1 1 0 0 0 0 1 1 0 0 1 1 0 0 0 0]\n",
            " [1 1 0 0 0 0 1 1 0 0 0 0 1 1 0 0]\n",
            " [1 1 0 0 0 0 1 1 0 0 0 0 0 0 1 1]\n",
            " [1 1 0 0 0 0 0 0 1 1 1 1 0 0 0 0]\n",
            " [1 1 0 0 0 0 0 0 1 1 0 0 1 1 0 0]\n",
            " [1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            " [1 1 0 0 0 0 0 0 0 0 1 1 1 1 0 0]\n",
            " [1 1 0 0 0 0 0 0 0 0 1 1 0 0 1 1]\n",
            " [1 1 0 0 0 0 0 0 0 0 0 0 1 1 1 1]\n",
            " [0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 0 0 1 1 0 0 0 0 0 0]\n",
            " [0 0 1 1 1 1 0 0 0 0 1 1 0 0 0 0]\n",
            " [0 0 1 1 1 1 0 0 0 0 0 0 1 1 0 0]\n",
            " [0 0 1 1 1 1 0 0 0 0 0 0 0 0 1 1]\n",
            " [0 0 1 1 0 0 1 1 1 1 0 0 0 0 0 0]\n",
            " [0 0 1 1 0 0 1 1 0 0 1 1 0 0 0 0]\n",
            " [0 0 1 1 0 0 1 1 0 0 0 0 1 1 0 0]\n",
            " [0 0 1 1 0 0 1 1 0 0 0 0 0 0 1 1]\n",
            " [0 0 1 1 0 0 0 0 1 1 1 1 0 0 0 0]\n",
            " [0 0 1 1 0 0 0 0 1 1 0 0 1 1 0 0]\n",
            " [0 0 1 1 0 0 0 0 1 1 0 0 0 0 1 1]\n",
            " [0 0 1 1 0 0 0 0 0 0 1 1 1 1 0 0]\n",
            " [0 0 1 1 0 0 0 0 0 0 1 1 0 0 1 1]\n",
            " [0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1]\n",
            " [0 0 0 0 1 1 1 1 1 1 0 0 0 0 0 0]\n",
            " [0 0 0 0 1 1 1 1 0 0 1 1 0 0 0 0]\n",
            " [0 0 0 0 1 1 1 1 0 0 0 0 1 1 0 0]\n",
            " [0 0 0 0 1 1 1 1 0 0 0 0 0 0 1 1]\n",
            " [0 0 0 0 1 1 0 0 1 1 1 1 0 0 0 0]\n",
            " [0 0 0 0 1 1 0 0 1 1 0 0 1 1 0 0]\n",
            " [0 0 0 0 1 1 0 0 1 1 0 0 0 0 1 1]\n",
            " [0 0 0 0 1 1 0 0 0 0 1 1 1 1 0 0]\n",
            " [0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1]\n",
            " [0 0 0 0 1 1 0 0 0 0 0 0 1 1 1 1]\n",
            " [0 0 0 0 0 0 1 1 1 1 1 1 0 0 0 0]\n",
            " [0 0 0 0 0 0 1 1 1 1 0 0 1 1 0 0]\n",
            " [0 0 0 0 0 0 1 1 1 1 0 0 0 0 1 1]\n",
            " [0 0 0 0 0 0 1 1 0 0 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 1 1 0 0 1 1 0 0 1 1]\n",
            " [0 0 0 0 0 0 1 1 0 0 0 0 1 1 1 1]\n",
            " [0 0 0 0 0 0 0 0 1 1 1 1 1 1 0 0]\n",
            " [0 0 0 0 0 0 0 0 1 1 1 1 0 0 1 1]\n",
            " [0 0 0 0 0 0 0 0 1 1 0 0 1 1 1 1]\n",
            " [0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1]]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'\\nm = 1\\nm1_basis = fixed_basis(m, d)\\nprint(m1_basis.size)\\nprint(m1_basis.base)\\nnm1_basis = fixed_basis(basis.m-m, d)\\n'"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Construccion de bases para calculo de rho1 y rho2\n",
        "# rho2\n",
        "m = 2\n",
        "m2_basis = fixed_basis(m, d, pairs=pairs)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-m, d, pairs=pairs)\n",
        "print(nm2_basis.base)\n",
        "t_basis = fixed_basis(2, basis.d, pairs=pairs)\n",
        "# rho1\n",
        "\"\"\"\n",
        "m = 1\n",
        "m1_basis = fixed_basis(m, d)\n",
        "print(m1_basis.size)\n",
        "print(m1_basis.base)\n",
        "nm1_basis = fixed_basis(basis.m-m, d)\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oapxWkD16fHg"
      },
      "source": [
        "### Algunos benchmarks y funciones auxiliares"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "umCIrxCZKXQd"
      },
      "outputs": [],
      "source": [
        "# Given h calculo en rho2 y rho1 máximo\n",
        "def rho1_rho2(h, beta):\n",
        "    fund = thermal_state(h, beta)\n",
        "    rho2 = np.array(rho_2(basis, m2_basis.size, state, rho_2_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho2).real)\n",
        "    rho_2_max = r[0]\n",
        "    rho1 = np.array(rho_1(basis, state, rho_1_arrays))\n",
        "    r = np.sort(linalg_d.eigvals(rho1).real)\n",
        "    rho_1_max = r[0]\n",
        "\n",
        "    return (rho_1_max, rho_2_max)\n",
        "\n",
        "def fill_triangular_np(x):\n",
        "    m = x.shape[0]\n",
        "    n = np.int32(np.sqrt(.25 + 2 * m) - .5)\n",
        "    x_tail = x[(m - (n**2 - m)):]\n",
        "    return np.triu(np.concatenate([x, x_tail[::-1]], 0).reshape(n, n))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "QaNnIIc5bZux"
      },
      "outputs": [],
      "source": [
        "# TEST: Las funciones de TF y comunes coinciden\n",
        "\n",
        "# Dado h, \\beta, construyo el estado térmico\n",
        "from scipy.linalg import expm\n",
        "\n",
        "def thermal_state(h, beta):\n",
        "    quotient = expm(-beta*h)\n",
        "    return quotient / np.trace(quotient)\n",
        "\n",
        "## NO usar para mat no hermiticas\n",
        "@nb.jit(nopython=True)\n",
        "def thermal_state_eig(h, beta):\n",
        "    w, v = np.linalg.eigh(-beta*h)\n",
        "    D = np.diag(np.exp(w))\n",
        "    mat = v @ D @ v.T\n",
        "    mat = mat / np.trace(mat)\n",
        "    return mat\n",
        "    \n",
        "def gen_to_h(base, rho_1_arrays):\n",
        "    triag = fill_triangular_np(base)\n",
        "    body_gen = triag + np.transpose(triag)-np.diag(np.diag(triag))\n",
        "    h = np.array(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
        "    return h \n",
        "\n",
        "def gen_to_h_1b(hamil_base):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "    return body_gen\n",
        "\n",
        "def gen_to_h_tf(hamil_base, rho_1_arrays):\n",
        "    triag = tfp.math.fill_triangular(hamil_base, upper=True)\n",
        "    body_gen = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag)) # Simetrizamos y generamos la matriz de h\n",
        "    hamil_expanded = body_gen[:, :, :, np.newaxis, np.newaxis]\n",
        "    rho_1_gen_transposed = tf.transpose(rho_1_arrays, perm=[1, 0, 2, 3])\n",
        "    h_arr = tf.reduce_sum(hamil_expanded * rho_1_gen_transposed[np.newaxis,:,:,:,:], axis=[1,2])\n",
        "    return h_arr\n",
        "\n",
        "def thermal_state_tf(h):\n",
        "    # Assume beta=1\n",
        "    exp_hamiltonian = tf.linalg.expm(-h)\n",
        "    partition_function = tf.linalg.trace(exp_hamiltonian)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    partition_function = tf.expand_dims(partition_function, axis=1)\n",
        "    \n",
        "    rho = exp_hamiltonian / partition_function\n",
        "\n",
        "    return rho\n",
        "\n",
        "def rho_1_tf(state, rho_1_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_1_arrays_expanded = tf.expand_dims(rho_1_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_1_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "def rho_2_tf(state, rho_2_arrays):\n",
        "    state = tf.expand_dims(state, axis=1)  # Shape: (5120, 10, 1, 10)\n",
        "    state_expanded = tf.expand_dims(state, axis=1)\n",
        "    rho_2_arrays_expanded = tf.expand_dims(rho_2_arrays, axis=0)  # Shape: (1, 5, 5, 10, 10)\n",
        "    product = state_expanded * rho_2_arrays_expanded  # Shape: (5120, 10, 5, 10, 10)\n",
        "    mat = tf.reduce_sum(product, axis=[-2, -1])  # Shape: (5120, 5, 5)\n",
        "    \n",
        "    return mat\n",
        "\n",
        "# NOTA: para calcular el bloque rho2kkbar, utilizar en lugar\n",
        "\n",
        "def rho_1_gc_tf(hamil_base):\n",
        "    e, v = tf.linalg.eigh(gen_to_h_1b(hamil_base))\n",
        "    result = 1 / (1 + tf.exp(e))\n",
        "    result = tf.linalg.diag(result)\n",
        "    res = tf.linalg.matmul(v,result)\n",
        "    res = tf.linalg.matmul(res,v,adjoint_b=True)\n",
        "    \n",
        "    return tf.cast(res, tf.float32)\n",
        "\n",
        "# Aux function\n",
        "def outer_product(vector):\n",
        "    return tf.einsum('i,j->ij', vector, vector)\n",
        "\n",
        "def pure_state(h):\n",
        "    e, v = tf.linalg.eigh(h)\n",
        "    fund = v[:,:,0]\n",
        "    d = tf.map_fn(outer_product, fund)\n",
        "    return d\n",
        "\n",
        "# Casos de entrenamiento tipo mat gaussianas\n",
        "def gen_gauss_mat(G, sigma_sq, size):\n",
        "    indices = np.arange(size)\n",
        "    mat = G * np.exp(-((indices - indices[:, np.newaxis])**2) / (2 * sigma_sq))\n",
        "    return mat\n",
        "\n",
        "def gen_gauss_mat_np(G_values, sigma_sq_values, size):\n",
        "    indices = np.arange(size, dtype=np.float32)\n",
        "    indices_diff = indices - indices[:, np.newaxis]\n",
        "\n",
        "    mat = G_values[:, np.newaxis, np.newaxis] * np.exp(-np.square(indices_diff) / (2 * sigma_sq_values[:, np.newaxis, np.newaxis]))\n",
        "\n",
        "    return mat"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ylpy_BCw6jxF"
      },
      "source": [
        "### Construccion de dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Version sincrónica"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2is_Eo_qGpEz",
        "outputId": "9a968190-59f2-4695-ef18-b99ff5b4a212"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-15 18:41:45.494160: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/device:GPU:0\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 489/489 [08:45<00:00,  1.07s/it]\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "# Config\n",
        "num_samples = 250000\n",
        "use_gpu = True\n",
        "gpu_batch_size = 512\n",
        "\n",
        "# Beta\n",
        "beta = 1\n",
        "\n",
        "# Construccion de parametros y matrices auxiliares\n",
        "#rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "rho2kkbar_size = basis.m\n",
        "input_shape = (basis.m,basis.m, 1) # Usando rho2kkbar como input batcheado\n",
        "fund_size = basis.size\n",
        "hamil_base_size = basis.d*(basis.d+1)//2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_1_arrays_tf = tf.constant(rho_1_arrays, dtype=tf.float32)\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "rho_2_arrays_kkbar = rho_2_kkbar_gen(t_basis, rho_2_arrays)\n",
        "rho_2_arrays_kkbar_tf = tf.constant(rho_2_arrays_kkbar, dtype=tf.float32)\n",
        "k_indices = get_kkbar_indices(t_basis)\n",
        "k_indices_tf = gen_update_indices(t_basis, gpu_batch_size)\n",
        "\n",
        "\n",
        "# Generacion de hamiltoniano\n",
        "# (h0, hi) = two_body_hamiltonian(t_basis.size, basis.m, np.arange(0, basis.m), np.ones((basis.m,basis.m)), rho_1_arrays_tf, rho_2_arrays_tf) esto es para g cte\n",
        "\n",
        "\n",
        "if use_gpu:\n",
        "    print(tf.test.gpu_device_name())\n",
        "    datasets = []\n",
        "    for i in tqdm(range(num_samples//gpu_batch_size+1)):\n",
        "        size = basis.m*(basis.m+1)//2\n",
        "        # En una primera versión vamos a pasar una mat proporcional a range(0,m) para energias\n",
        "        en_batch = [np.arange(0, basis.m) for _ in range(0,gpu_batch_size)] \n",
        "        # Como interacción una matriz G semidefinida positiva\n",
        "        # Primero creamos las semillas, es decir, la diagonal superior de la matrix g\n",
        "        # Caso G proporcional a ones\n",
        "        #label_size = 1 \n",
        "        #h_labels = [np.random.random()*10 for _ in range(0,gpu_batch_size)]\n",
        "        #g_arr = [np.ones((basis.m, basis.m))*g_seed for g_seed in h_labels]\n",
        "        #g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "\n",
        "        # Caso generico\n",
        "        label_size = basis.m*(basis.m+1)// 2 # CASO GENERICO elementos independientes de una mat de m x m\n",
        "        h_labels = [np.random.random(label_size)*5 for _ in range(0,gpu_batch_size)] # TODO: Aumentar la amplitud de la interacción\n",
        "        # Construimos la mat G\n",
        "        triag = tfp.math.fill_triangular(h_labels, upper=True)\n",
        "        g_arr = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "\n",
        "        # Caso reducido\n",
        "        #label_size = 2\n",
        "        #h_labels = np.array([[np.random.random()*5, np.random.random()*2 + 0.1] for _ in range(0, gpu_batch_size)])\n",
        "        #g_arr = gen_gauss_mat_np(h_labels[:,0], h_labels[:,1], basis.m)\n",
        "        #h_labels = tf.constant(h_labels, dtype=tf.float32)\n",
        "        #g_arr = tf.constant(g_arr, dtype=tf.float32)\n",
        "        \n",
        "        # Construimos los hamiltonianos basados en g_arr\n",
        "        h_arr = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, g_arr.numpy(), rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "        # Estados térmicos\n",
        "        #state = thermal_state_tf(h_arr*beta) \n",
        "        #state = tf.cast(state, dtype=tf.float32)\n",
        "        # Estados puros\n",
        "        state = pure_state(h_arr)\n",
        "        #rho_2_input = rho_2_tf(state, rho_2_arrays_tf)\n",
        "        rho_2_input = rho_2_tf(state, rho_2_arrays_kkbar_tf)\n",
        "\n",
        "        # OUTPUTS\n",
        "        # Caso input eigvals\n",
        "        #input_shape = (basis.m, 1)\n",
        "        #rho_2_input = tf.linalg.eigvals(rho_2_input)\n",
        "        #rho_2_input = tf.sort(tf.math.real(rho_2_input), axis=-1)\n",
        "\n",
        "        # Caso PCA\n",
        "        input_shape = (num_gen, 1)\n",
        "        rflat = np.array([np.ndarray.flatten(x) for x in rho_2_input.numpy()])\n",
        "        rho_2_input = np.dot(rflat, P)\n",
        "\n",
        "        datasets.append(tf.data.Dataset.from_tensor_slices(((rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input), h_labels)))\n",
        "        #datasets.append(tf.data.Dataset.from_tensor_slices(((rho_1_input, rho_2_input, state), h_labels)))\n",
        "    ds = tf.data.Dataset.from_tensor_slices(datasets)\n",
        "    dataset = ds.interleave(\n",
        "        lambda x: x,\n",
        "        cycle_length=1,\n",
        "        num_parallel_calls=tf.data.AUTOTUNE,\n",
        "    )\n",
        "\n",
        "\n",
        "#batch_size = 32\n",
        "#dataset = dataset.shuffle(buffer_size=num_samples).batch(batch_size)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Filleo de dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 251,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pickle\n",
        "# Save and load dataset\n",
        "save_dataset = False\n",
        "load_dataset = False\n",
        "path = \"/home/agus/TF\"\n",
        "#num_samples = 5000000\n",
        "if save_dataset:\n",
        "    tf.data.Dataset.save(dataset, path)\n",
        "    with open(\"/home/agus/\"+'/file.pkl', 'wb') as file:\n",
        "        pickle.dump(beta_input, file)\n",
        "if load_dataset:\n",
        "    dataset = tf.data.Dataset.load(path)\n",
        "    with open(\"/home/agus/\"+'file.pkl', 'rb') as file:\n",
        "        beta_input = pickle.load(file)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "id": "8moZIlfabZuy"
      },
      "outputs": [],
      "source": [
        "# Dividimos los datasets\n",
        "train_size = int(0.8 * num_samples)\n",
        "\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "\n",
        "batch_size = 512\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "val_dataset = val_dataset.batch(batch_size)\n",
        "\n",
        "#beta_val = beta_input[train_size:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 253,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Dataset Size: -2\n"
          ]
        }
      ],
      "source": [
        "# Cardinality no funciona con los datasets generados por GPU\n",
        "val_size = tf.data.experimental.cardinality(val_dataset).numpy()\n",
        "print(\"Validation Dataset Size:\", val_size)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1.7543033e+02 1.8015757e+01 1.6181339e+01 1.5627919e+01 1.3245350e+01\n",
            " 1.3003709e+01 1.2386569e+01 1.1689492e+01 6.4039726e+00 6.3677306e+00\n",
            " 6.1357002e+00 6.0195780e+00 5.7837515e+00 5.6817913e+00 5.5042334e+00\n",
            " 5.3083839e+00 5.1249261e+00 5.0009303e+00 4.8202271e+00 4.7753167e+00\n",
            " 4.4217453e+00 4.4156036e+00 4.2778425e+00 4.1761603e+00 3.7148805e+00\n",
            " 3.5941038e+00 3.4829767e+00 3.1571782e+00 2.6617942e+00 2.2353554e+00\n",
            " 1.7443160e+00 1.6822653e+00 1.5812799e+00 1.4925903e+00 1.3848879e+00\n",
            " 1.3384173e+00 4.1669496e-06 4.0018494e-06 3.9062656e-06 3.9006322e-06\n",
            " 3.7355931e-06 3.6475385e-06 3.5556861e-06 3.5315686e-06 3.3966719e-06\n",
            " 3.3498079e-06 3.3258691e-06 3.3113529e-06 3.2446646e-06 3.2187406e-06\n",
            " 3.1845050e-06 3.0669746e-06 3.0507867e-06 3.0145354e-06 2.9536409e-06\n",
            " 2.9025941e-06 2.7963540e-06 2.7357898e-06 2.6949633e-06 2.5975767e-06\n",
            " 2.5618524e-06 2.5144091e-06 2.3456132e-06 2.3050486e-06]\n",
            "36\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(64, 36)"
            ]
          },
          "execution_count": 92,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# PCA\n",
        "# Correr una vez para definir la transformacion y lyego volver a correr la gen de dataset\n",
        "num_gen = 10\n",
        "rflat = np.array([np.ndarray.flatten(x) for x in rho_2_input.numpy()])\n",
        "rflat = rflat - rflat.mean()\n",
        "rflat = rflat / rflat.std()\n",
        "U, S, Vh = np.linalg.svd(rflat)\n",
        "print(S)\n",
        "\n",
        "# Determinado automáticamente\n",
        "num_gen = np.where(S < 0.01)[0][0]\n",
        "print(num_gen)\n",
        "\n",
        "Z = np.dot(rflat.T, rflat)\n",
        "eigenvalues, eigenvectors = np.linalg.eig(Z)\n",
        "D = np.diag(eigenvalues)\n",
        "P = eigenvectors[:,0:num_gen]\n",
        "Z_new = np.dot(Z, P)\n",
        "Z_new.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pYEEjNB-7b8y"
      },
      "source": [
        "### Definición de modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 254,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A8kkhJr5K0ZQ",
        "outputId": "f1b731f1-6a02-4181-f0b5-5677a2a85784"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 8, 8, 1)]         0         \n",
            "                                                                 \n",
            " conv2d_20 (Conv2D)          (None, 7, 7, 256)         1280      \n",
            "                                                                 \n",
            " batch_normalization_20 (Ba  (None, 7, 7, 256)         1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_21 (Conv2D)          (None, 6, 6, 224)         229600    \n",
            "                                                                 \n",
            " batch_normalization_21 (Ba  (None, 6, 6, 224)         896       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_22 (Conv2D)          (None, 5, 5, 192)         172224    \n",
            "                                                                 \n",
            " batch_normalization_22 (Ba  (None, 5, 5, 192)         768       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " conv2d_23 (Conv2D)          (None, 4, 4, 128)         98432     \n",
            "                                                                 \n",
            " batch_normalization_23 (Ba  (None, 4, 4, 128)         512       \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " flatten_20 (Flatten)        (None, 2048)              0         \n",
            "                                                                 \n",
            " dense_70 (Dense)            (None, 512)               1049088   \n",
            "                                                                 \n",
            " dense_71 (Dense)            (None, 1)                 513       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1554337 (5.93 MB)\n",
            "Trainable params: 1552737 (5.92 MB)\n",
            "Non-trainable params: 1600 (6.25 KB)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Definicion de layers basado en Conv 2D\n",
        "\n",
        "# Factor de cantidad de filtros\n",
        "lf = 16 \n",
        "conv_limit = (rho2kkbar_size - 4)\n",
        "initial_dense = (lf*2**(conv_limit-1)*((rho2kkbar_size-(conv_limit-1))//2)**2)\n",
        "## rho 1\n",
        "rho2_layer =  tf.keras.layers.Input(shape=(rho2kkbar_size,rho2kkbar_size, 1), name='rho2')\n",
        "\n",
        "# Procesamos el primer input\n",
        "conv_rho2 = tf.keras.layers.Conv2D(lf*2**conv_limit, (2, 2), activation='relu')(rho2_layer)\n",
        "conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "for j in [(2**conv_limit - 2**k) for k in range(1,conv_limit)]:\n",
        "    conv_rho2 = tf.keras.layers.Conv2D(lf*j, (2, 2), activation='relu')(conv_rho2 if 2**j != 1 else rho1_layer)\n",
        "    conv_rho2 = tf.keras.layers.BatchNormalization()(conv_rho2)\n",
        "\n",
        "#conv_rho2 = tf.keras.layers.MaxPooling2D((2, 2))(conv_rho2)\n",
        "\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(conv_rho2)\n",
        "#flatten_rho1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(flatten_rho1)\n",
        "\n",
        "#local_size = basis.size*basis.size\n",
        "local_size = label_size\n",
        "\n",
        "#dense1 = tf.keras.layers.Dense(8*8*4*4, activation='relu')(dense1)\n",
        "#dense1 = tf.keras.layers.Dense(512, activation='relu')(flatten_rho1)\n",
        "#dense1 = tf.keras.layers.Dense(128, activation='relu')(flatten_rho1)\n",
        "dense1 = tf.keras.layers.Dense(initial_dense, activation='relu')(flatten_rho2)\n",
        "#dense1 = tf.keras.layers.Dense(initial_dense//2, activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "\n",
        "\n",
        "# Creamos el modelo y compulamos\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer, fund_layer], outputs=output)\n",
        "#model = tf.keras.models.Model(inputs=[rho1_layer, rho2_layer], outputs=output)\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "\n",
        "\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 96,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QZBtonvGbZuz",
        "outputId": "f197277e-a84b-4ffd-c81f-c81581707fb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " rho2 (InputLayer)           [(None, 36, 1)]           0         \n",
            "                                                                 \n",
            " flatten_18 (Flatten)        (None, 36)                0         \n",
            "                                                                 \n",
            " concatenate_18 (Concatenat  (None, 36)                0         \n",
            " e)                                                              \n",
            "                                                                 \n",
            " dense_88 (Dense)            (None, 42)                1554      \n",
            "                                                                 \n",
            " dense_89 (Dense)            (None, 64)                2752      \n",
            "                                                                 \n",
            " dense_90 (Dense)            (None, 128)               8320      \n",
            "                                                                 \n",
            " dense_91 (Dense)            (None, 36)                4644      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 17270 (67.46 KB)\n",
            "Trainable params: 17270 (67.46 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Modelo denso + fundamental\n",
        "rho2_layer =  tf.keras.layers.Input(shape=input_shape, name='rho2')\n",
        "flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#rho2_layer =  tf.keras.layers.Input(shape=(rho2_size,rho2_size, 1), name='rho2')\n",
        "#flatten_rho2 = tf.keras.layers.Flatten()(rho2_layer)\n",
        "#fund_layer =  tf.keras.layers.Input(shape=(fund_size, fund_size, 1 ), name='fund')\n",
        "#flatten_fund = tf.keras.layers.Flatten()(fund_layer)\n",
        "\n",
        "dense1 = tf.keras.layers.concatenate([flatten_rho2])\n",
        "#dense1 = tf.keras.layers.concatenate([dense1, flatten_fund])\n",
        "#dense1 = tf.keras.layers.Dense(rho1_size*rho1_size, activation='relu')(dense1)\n",
        "\n",
        "local_size = label_size\n",
        "l = 4\n",
        "layer_s = [64//i*2 for i in reversed(range(1,l))]\n",
        "for i in range(0,l-1):\n",
        "    dense1 = tf.keras.layers.Dense(layer_s[i], activation='relu')(dense1)\n",
        "\n",
        "output = tf.keras.layers.Dense(local_size)(dense1)\n",
        "# Creamos el modelo y compulamos\n",
        "model = tf.keras.models.Model(inputs=[rho2_layer], outputs=output)\n",
        "model.summary()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 280,
      "metadata": {
        "id": "RgoMlCyyfBe-"
      },
      "outputs": [],
      "source": [
        "# LOSS FUNCTIONS\n",
        "r_size = basis.size\n",
        "\n",
        "# Custom loss function based on GS MSE\n",
        "def gs_loss(h_pred, h_true):\n",
        "    h_pred = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_pred)\n",
        "    gs_pred = v[:, 0]\n",
        "\n",
        "    h_true = tf.reshape(h_true, shape=(-1,r_size,r_size))\n",
        "    e, v = tf.linalg.eigh(h_true)\n",
        "    gs_true = v[:, 0]\n",
        "\n",
        "    gs_diff = tf.norm(gs_true - gs_pred)\n",
        "\n",
        "    return gs_diff + tf.reduce_mean(tf.square(h_true - h_pred)) * 100\n",
        "\n",
        "def distance_to_hermitian(matrix):\n",
        "    hermitian_part = 0.5 * (matrix + tf.linalg.adjoint(matrix))\n",
        "    distance = tf.norm(matrix - hermitian_part, ord='euclidean')\n",
        "    return distance\n",
        "\n",
        "# Custom loss function based on MSE + non-hermitian penalization\n",
        "def herm_loss(h_pred, h_true):\n",
        "    h_pred_arr = tf.reshape(h_pred, shape=(-1,r_size,r_size))\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred)) + distance_to_hermitian(h_pred_arr)\n",
        "\n",
        "# Custom loss function based on h eigenvalues\n",
        "def eig_loss(h_pred, h_true):\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# MSE with a factor\n",
        "def mse_f(h_pred, h_true):\n",
        "    f = 1000\n",
        "    return tf.reduce_mean(tf.square(h_true - h_pred))*f\n",
        "\n",
        "# Spectral radius loss\n",
        "def spectral_loss(h_pred, h_true):\n",
        "    eig = tf.math.real(tf.linalg.eigvals(tf.reshape(h_true-h_pred, (-1, fund_size, fund_size))))\n",
        "    return tf.math.reduce_max(tf.abs(eig))\n",
        "\n",
        "# Hamiltonian MSE loss (using generators)\n",
        "def base_mse_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    mat = tf.reshape(h_pred-h_true, (-1, fund_size, fund_size))\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on h eigenvalues (using generators)\n",
        "def base_eig_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    eig_true = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_true, (-1, fund_size, fund_size)))))\n",
        "    eig_pred = tf.sort(tf.math.real(tf.linalg.eigvals(tf.reshape(h_pred, (-1, fund_size, fund_size)))))\n",
        "    return tf.reduce_mean(tf.square(eig_true - eig_pred))\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals\n",
        "## Auxiliary function\n",
        "def base_to_rho_1_tf(base_pred):\n",
        "    h = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h = tf.reshape(h, (-1, fund_size, fund_size))\n",
        "    state = thermal_state_tf(h)\n",
        "    rho1 = rho_1_tf(state, rho_1_arrays_tf)\n",
        "    return rho1\n",
        "    \n",
        "def rho1_loss(base_pred, base_true):\n",
        "    mat = base_to_rho_1_tf(base_pred) - base_to_rho_1_tf(base_true)\n",
        "    return tf.norm(mat, ord='fro', axis=[-1, -2])\n",
        "\n",
        "# Custom loss function based on rho1 eigenvals (using generators)\n",
        "def base_rho1_loss(base_pred, base_true):\n",
        "    h_pred = gen_to_h_tf(base_pred, rho_1_arrays_tf)\n",
        "    h_true = gen_to_h_tf(base_true, rho_1_arrays_tf)\n",
        "    return tf.reduce_mean(tf.square(rho_1_eig_tf(h_pred) - rho_1_eig_tf(h_true)))*1000\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aiWk9piJtNIZ"
      },
      "source": [
        "## Entrenamiento"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nhJCHf0fQdRl",
        "outputId": "1821cf27-9ff5-4d67-e9f5-956d20eda5e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-15 18:59:26.422520: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /device:GPU:0 with 20609 MB memory:  -> device: 0, name: NVIDIA L4, pci bus id: 0000:00:03.0, compute capability: 8.9\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 4s 7ms/step - loss: 0.4864 - accuracy: 0.2028 - mean_squared_error: 0.4864 - val_loss: 0.4855 - val_accuracy: 0.2021 - val_mean_squared_error: 0.4855\n",
            "Epoch 2/50\n",
            " 52/391 [==>...........................] - ETA: 1s - loss: 0.4864 - accuracy: 0.2010 - mean_squared_error: 0.4864"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-01-15 18:59:30.340857: I tensorflow/core/framework/local_rendezvous.cc:421] Local rendezvous recv item cancelled. Key hash: 10964206303533098306\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4860 - accuracy: 0.2030 - mean_squared_error: 0.4860 - val_loss: 0.4852 - val_accuracy: 0.2014 - val_mean_squared_error: 0.4852\n",
            "Epoch 3/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4857 - accuracy: 0.2029 - mean_squared_error: 0.4857 - val_loss: 0.4851 - val_accuracy: 0.2021 - val_mean_squared_error: 0.4851\n",
            "Epoch 4/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4853 - accuracy: 0.2032 - mean_squared_error: 0.4853 - val_loss: 0.4846 - val_accuracy: 0.2012 - val_mean_squared_error: 0.4846\n",
            "Epoch 5/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4850 - accuracy: 0.2030 - mean_squared_error: 0.4850 - val_loss: 0.4846 - val_accuracy: 0.2018 - val_mean_squared_error: 0.4846\n",
            "Epoch 6/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4846 - accuracy: 0.2034 - mean_squared_error: 0.4846 - val_loss: 0.4840 - val_accuracy: 0.2016 - val_mean_squared_error: 0.4840\n",
            "Epoch 7/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4843 - accuracy: 0.2032 - mean_squared_error: 0.4843 - val_loss: 0.4840 - val_accuracy: 0.2019 - val_mean_squared_error: 0.4840\n",
            "Epoch 8/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4840 - accuracy: 0.2032 - mean_squared_error: 0.4840 - val_loss: 0.4832 - val_accuracy: 0.2019 - val_mean_squared_error: 0.4832\n",
            "Epoch 9/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4837 - accuracy: 0.2031 - mean_squared_error: 0.4837 - val_loss: 0.4832 - val_accuracy: 0.2018 - val_mean_squared_error: 0.4832\n",
            "Epoch 10/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4834 - accuracy: 0.2032 - mean_squared_error: 0.4834 - val_loss: 0.4826 - val_accuracy: 0.2013 - val_mean_squared_error: 0.4826\n",
            "Epoch 11/50\n",
            "391/391 [==============================] - 3s 7ms/step - loss: 0.4831 - accuracy: 0.2031 - mean_squared_error: 0.4831 - val_loss: 0.4825 - val_accuracy: 0.2019 - val_mean_squared_error: 0.4825\n",
            "Epoch 12/50\n",
            "379/391 [============================>.] - ETA: 0s - loss: 0.4828 - accuracy: 0.2030 - mean_squared_error: 0.4828"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[104], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m device_name \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mtest\u001b[38;5;241m.\u001b[39mgpu_device_name()\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/gpu:0\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_epochs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_dataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Dense: 1.3\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# CNN: \u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:1832\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1816\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_eval_data_handler\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_eval_data_handler \u001b[38;5;241m=\u001b[39m data_adapter\u001b[38;5;241m.\u001b[39mget_data_handler(\n\u001b[1;32m   1818\u001b[0m         x\u001b[38;5;241m=\u001b[39mval_x,\n\u001b[1;32m   1819\u001b[0m         y\u001b[38;5;241m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1830\u001b[0m         pss_evaluation_shards\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pss_evaluation_shards,\n\u001b[1;32m   1831\u001b[0m     )\n\u001b[0;32m-> 1832\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1833\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_x\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1834\u001b[0m \u001b[43m    \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_y\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1835\u001b[0m \u001b[43m    \u001b[49m\u001b[43msample_weight\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_sample_weight\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1836\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_batch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1837\u001b[0m \u001b[43m    \u001b[49m\u001b[43msteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidation_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1838\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1839\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_queue_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_queue_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1840\u001b[0m \u001b[43m    \u001b[49m\u001b[43mworkers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mworkers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1841\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_multiprocessing\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_multiprocessing\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1842\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1843\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_use_cached_eval_dataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1844\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1845\u001b[0m val_logs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m   1846\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mval_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m name: val \u001b[38;5;28;01mfor\u001b[39;00m name, val \u001b[38;5;129;01min\u001b[39;00m val_logs\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m   1847\u001b[0m }\n\u001b[1;32m   1848\u001b[0m epoch_logs\u001b[38;5;241m.\u001b[39mupdate(val_logs)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:2272\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   2268\u001b[0m             \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   2269\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m, step_num\u001b[38;5;241m=\u001b[39mstep, _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[1;32m   2270\u001b[0m             ):\n\u001b[1;32m   2271\u001b[0m                 callbacks\u001b[38;5;241m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 2272\u001b[0m                 logs \u001b[38;5;241m=\u001b[39m \u001b[43mtest_function_runner\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_step\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2273\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2274\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mdata_handler\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2275\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2276\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pss_evaluation_shards\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2277\u001b[0m \u001b[43m                \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2279\u001b[0m logs \u001b[38;5;241m=\u001b[39m tf_utils\u001b[38;5;241m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[1;32m   2280\u001b[0m \u001b[38;5;66;03m# Override with model metrics instead of last step logs\u001b[39;00m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/keras/src/engine/training.py:4079\u001b[0m, in \u001b[0;36m_TestFunction.run_step\u001b[0;34m(self, dataset_or_iterator, data_handler, step, unused_shards)\u001b[0m\n\u001b[1;32m   4078\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_step\u001b[39m(\u001b[38;5;28mself\u001b[39m, dataset_or_iterator, data_handler, step, unused_shards):\n\u001b[0;32m-> 4079\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset_or_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4080\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   4081\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:831\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    828\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 831\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    833\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    834\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:876\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    873\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 876\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[1;32m    880\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    881\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1264\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1260\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1261\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1262\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1263\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1264\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1265\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1266\u001b[0m     args,\n\u001b[1;32m   1267\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1268\u001b[0m     executing_eagerly)\n\u001b[1;32m   1269\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:217\u001b[0m, in \u001b[0;36mAtomicFunction.flat_call\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mflat_call\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    216\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 217\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:252\u001b[0m, in \u001b[0;36mAtomicFunction.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    251\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 252\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    257\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    258\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    262\u001b[0m     )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/context.py:1479\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1477\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1478\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1479\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1480\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1481\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1482\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1483\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1484\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1485\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1486\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1487\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1488\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1489\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1493\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1494\u001b[0m   )\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/eager/execute.py:60\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     53\u001b[0m   \u001b[38;5;66;03m# Convert any objects of type core_types.Tensor to Tensor.\u001b[39;00m\n\u001b[1;32m     54\u001b[0m   inputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     55\u001b[0m       tensor_conversion_registry\u001b[38;5;241m.\u001b[39mconvert(t)\n\u001b[1;32m     56\u001b[0m       \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(t, core_types\u001b[38;5;241m.\u001b[39mTensor)\n\u001b[1;32m     57\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m t\n\u001b[1;32m     58\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m inputs\n\u001b[1;32m     59\u001b[0m   ]\n\u001b[0;32m---> 60\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     63\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.optimizers import RMSprop, Adam, Nadam, Lion\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Lion(),\n",
        "              loss='MSE',  \n",
        "              metrics=['accuracy', 'mean_squared_error'])\n",
        "\n",
        "# Train the model\n",
        "num_epochs = 50\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "with tf.device('/gpu:0'):\n",
        "    history = model.fit(train_dataset, epochs=num_epochs, validation_data=val_dataset)\n",
        "\n",
        "# Dense: 1.3\n",
        "# CNN: "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "cvpE_X1iTXcB",
        "outputId": "eff0e5f5-5b26-46ea-ec6b-491d1de9944c"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "#plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
        "#plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
        "plt.plot(history.history['mean_squared_error'], label='Training MSE')\n",
        "plt.plot(history.history['val_mean_squared_error'], label='Validation MSE')\n",
        "\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('MSE vs. Epoch')\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "# MIN LOSS = 0.0128 c/fund 50epochs MSE\n",
        "##         = 0.0118 s/fund 50epochs MSE\n",
        "##         = 0.0039 s/fund 50epochs MSE m=4 d=6"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BRlZuRUNa6Yb",
        "outputId": "85850559-311b-4cf4-ea5b-465a9ee8a7af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "16/16 [==============================] - 0s 1ms/step\n"
          ]
        }
      ],
      "source": [
        "# Assuming you have a validation dataset (val_dataset)\n",
        "iterador = iter(val_dataset)\n",
        "sample = next(iterador)\n",
        "next_sample = next(iterador)\n",
        "input_data = sample[0]  # Assuming your dataset provides input data as the first element\n",
        "actual_values = sample[1]  # Assuming your dataset provides actual labels as the second element\n",
        "\n",
        "# Predict using the model\n",
        "predictions = model.predict(input_data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Diferencias en error RMSE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tf.Tensor(\n",
            "[0.52517579 4.49461811 3.51316755 3.25186979 2.82823035 4.90859745\n",
            " 4.09653028 4.94807658 3.98540823 4.14701699 1.89579501 2.53848966\n",
            " 2.11349942 2.36851627 2.16361422 1.33100052 1.7077039  2.47985038\n",
            " 1.93070661 4.61080705 4.17449161 3.62170689 1.56263386 0.02672285\n",
            " 3.14551549 2.26798428 4.66833984 4.54741258 4.42418824 0.08149483\n",
            " 4.86934671 4.66972991 2.25683629 3.43542066 2.21662077 1.13014476], shape=(36,), dtype=float64)\n",
            "[-0.14575237  4.364818    2.9028997   2.2962003   2.2852118   4.5491595\n",
            "  3.6647387   4.8170714   2.6653087   3.7763739   2.161203    1.640496\n",
            "  1.8409252   2.729893    2.317075    1.8677803   2.263486    2.1565652\n",
            "  1.7816224   3.958267    4.097479    4.0564485   2.0184774   0.91449517\n",
            "  4.0390215   2.4177065   4.2566657   3.6647644   3.4208655   0.36926395\n",
            "  4.0546794   4.1669183   2.3673136   3.1990275   2.2383099   1.10644   ]\n",
            "tf.Tensor(\n",
            "[0.56100989 1.81810926 1.91168697 1.28918402 3.95191362 3.71677968\n",
            " 0.03976157 4.26290002 4.90837264 2.64664171 0.19438511 1.43406038\n",
            " 1.62492828 4.39143337 1.06511862 0.63026219 4.7855091  0.01927053\n",
            " 4.78142875 2.43661496 3.50704022 1.71970586 1.63904681 2.89375277\n",
            " 0.74433537 1.79265425 3.0776264  0.54807848 2.43370361 4.84396241\n",
            " 0.85068053 3.29730177 4.51931375 1.90817577 3.27612923 0.18869853], shape=(36,), dtype=float64)\n",
            "[1.2509708  3.029633   2.4151473  2.2152233  3.9850688  3.895643\n",
            " 0.20680833 5.0583644  4.8007574  3.244563   0.20991313 2.1297846\n",
            " 1.1625142  4.136914   1.0501959  0.7494619  3.8470783  1.4724494\n",
            " 4.0221252  2.6928217  2.9790056  0.979256   1.7573538  2.7474098\n",
            " 0.7577539  0.71063715 3.5893335  0.5580331  2.0065458  4.0099516\n",
            " 0.8193729  4.000566   4.044493   0.9957029  1.9152435  0.81356055]\n",
            "tf.Tensor(\n",
            "[1.70648515 3.23514677 0.90704305 3.91836542 0.05417785 3.001372\n",
            " 0.43548601 3.17460773 3.7353603  3.27229828 2.40974479 3.64340719\n",
            " 3.20236337 3.38018412 4.29504251 2.79875449 1.10190982 2.00168175\n",
            " 3.27980277 1.63510352 4.23631944 1.50830484 1.32794959 1.11042853\n",
            " 3.07802549 1.36529764 0.73178662 1.16898819 0.70525307 4.58449703\n",
            " 1.4953264  2.09193357 0.86583118 2.6120572  4.51135093 1.5123307 ], shape=(36,), dtype=float64)\n",
            "[2.8365636  2.6977856  0.88047564 4.3003063  0.0968408  2.9963167\n",
            " 0.8177705  4.217757   2.67732    2.431546   1.4429612  2.7948947\n",
            " 2.3805826  2.083262   3.8820355  2.6924548  2.1375     1.0952319\n",
            " 3.9170687  1.51867    4.1824946  1.1196722  2.357441   1.6235448\n",
            " 3.491691   1.4562212  2.196866   1.9160789  0.7812364  3.9764602\n",
            " 1.9346528  3.0851212  1.3752255  3.5994096  3.9251516  1.9409791 ]\n",
            "tf.Tensor(\n",
            "[0.95586896 3.72731603 0.42759464 0.31481266 4.11259125 4.39867254\n",
            " 4.10414407 3.23217101 4.0482766  4.76143045 0.62857309 3.00113101\n",
            " 0.61078281 4.78241195 1.3465882  2.6186206  0.01628658 1.83481402\n",
            " 0.26301615 0.89728217 3.88683863 2.33167822 0.79046089 4.96583348\n",
            " 3.90620755 4.88078154 3.37301739 4.76262576 4.36904385 1.69431213\n",
            " 0.125657   3.40792301 2.91223287 0.11079043 0.85284996 0.60543948], shape=(36,), dtype=float64)\n",
            "[ 0.92993546  3.8420386   0.9591334   0.63324964  3.2136865   4.144583\n",
            "  4.4072847   2.861646    4.3564215   3.2699044   0.9849147   2.1440704\n",
            " -0.12071869  3.7175193   2.1261494   2.15722     0.5161827   1.5339644\n",
            "  0.21371809  1.8165845   3.753421    2.131025    0.9286852   5.087656\n",
            "  2.708037    3.9614406   3.8194098   4.2367373   3.3582802   0.7682484\n",
            " -0.5694519   3.3239412   2.5948043  -0.5502098  -0.25791496  0.88387877]\n",
            "4.068290712775495 12.210608902055183\n",
            "3.001410116467509\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Vemos algunos valores\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 4):\n",
        "        print(e[1][i])\n",
        "        print(predictions[i])\n",
        "    break\n",
        "    \n",
        "# Veamos el MSE de los valores de G      \n",
        "#RMSE_pred = mean_squared_error(actual_values, predictions, squared=False)\n",
        "#RMSE_rand = mean_squared_error(actual_values, next_sample[1], squared=False)\n",
        "#print(RMSE_pred, RMSE_rand)\n",
        "#rint(RMSE_rand/RMSE_pred)\n",
        "# Veamos los errores en términos de norma 2 (equiv a lo anterior)\n",
        "if predictions.shape[1] == 1:\n",
        "    norm_pred = np.mean(np.abs(predictions.T-actual_values))\n",
        "    norm_rand = np.mean(np.abs(next_sample[1]-actual_values))\n",
        "else:\n",
        "    norm_pred = np.mean(np.linalg.norm(predictions-actual_values,ord=2, axis=1))\n",
        "    norm_rand = np.mean(np.linalg.norm(next_sample[1]-actual_values,ord=2, axis=1))\n",
        "print(norm_pred, norm_rand)\n",
        "print(norm_rand / norm_pred)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Análisis rho2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {},
      "outputs": [
        {
          "ename": "LinAlgError",
          "evalue": "Last 2 dimensions of the array must be square",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mLinAlgError\u001b[0m                               Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[103], line 30\u001b[0m\n\u001b[1;32m     28\u001b[0m rho_2_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39msort(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigvals(x))\n\u001b[1;32m     29\u001b[0m rho_2_pred \u001b[38;5;241m=\u001b[39m rho_2_s(rho_2_tf(state, rho_2_arrays_kkbar_tf))\n\u001b[0;32m---> 30\u001b[0m rho_2_true \u001b[38;5;241m=\u001b[39m \u001b[43mrho_2_s\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     31\u001b[0m rho_2_rand \u001b[38;5;241m=\u001b[39m rho_2_s(next_sample[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Printeamos algunos valores\u001b[39;00m\n",
            "Cell \u001b[0;32mIn[103], line 28\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     24\u001b[0m state \u001b[38;5;241m=\u001b[39m pure_state(h_arr)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m#rho_2_input = rho_2_tf(state, rho_2_arrays_tf)\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Calculo de estadistica\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m#rho_2_s = lambda x: [np.max(i) for i in np.linalg.eigvals(x)]\u001b[39;00m\n\u001b[0;32m---> 28\u001b[0m rho_2_s \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mlambda\u001b[39;00m x: np\u001b[38;5;241m.\u001b[39msort(\u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43meigvals\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     29\u001b[0m rho_2_pred \u001b[38;5;241m=\u001b[39m rho_2_s(rho_2_tf(state, rho_2_arrays_kkbar_tf))\n\u001b[1;32m     30\u001b[0m rho_2_true \u001b[38;5;241m=\u001b[39m rho_2_s(e[\u001b[38;5;241m0\u001b[39m])\n",
            "File \u001b[0;32m<__array_function__ internals>:180\u001b[0m, in \u001b[0;36meigvals\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/linalg/linalg.py:1056\u001b[0m, in \u001b[0;36meigvals\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m   1054\u001b[0m a, wrap \u001b[38;5;241m=\u001b[39m _makearray(a)\n\u001b[1;32m   1055\u001b[0m _assert_stacked_2d(a)\n\u001b[0;32m-> 1056\u001b[0m \u001b[43m_assert_stacked_square\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1057\u001b[0m _assert_finite(a)\n\u001b[1;32m   1058\u001b[0m t, result_t \u001b[38;5;241m=\u001b[39m _commonType(a)\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/linalg/linalg.py:204\u001b[0m, in \u001b[0;36m_assert_stacked_square\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    202\u001b[0m m, n \u001b[38;5;241m=\u001b[39m a\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m:]\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m m \u001b[38;5;241m!=\u001b[39m n:\n\u001b[0;32m--> 204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m LinAlgError(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLast 2 dimensions of the array must be square\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
            "\u001b[0;31mLinAlgError\u001b[0m: Last 2 dimensions of the array must be square"
          ]
        }
      ],
      "source": [
        "# Vemos algunos valores\n",
        "for e in val_dataset:\n",
        "    # Caso constante\n",
        "    if predictions.shape[1] == 1:\n",
        "        g_arr = [np.ones((basis.m, basis.m))*g_seed for g_seed in predictions]\n",
        "    # Caso Gaussiano\n",
        "    elif predictions.shape[1] == 2:\n",
        "        # Verificacion de rango de valores, la prediccion de sigma debe ser positiva\n",
        "        for p in predictions:\n",
        "            if p[0] < 0 or p[1] < 0:\n",
        "                print(p)\n",
        "        # Calculo de rho2 pred\n",
        "        g_arr = gen_gauss_mat_np(predictions[:,0], predictions[:,1], basis.m)\n",
        "    # Caso general\n",
        "    else:\n",
        "        triag = tfp.math.fill_triangular(predictions, upper=True)\n",
        "        g_arr = triag + tf.transpose(triag, perm=[0,2,1])-tf.linalg.diag(tf.linalg.diag_part(triag))\n",
        "        g_arr = g_arr.numpy()\n",
        "    h_arr = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, g_arr, rho_1_arrays, rho_2_arrays, k_indices_tf)\n",
        "    ## Estados térmicos\n",
        "    #state = thermal_state_tf(h_arr*beta) \n",
        "    state = tf.cast(state, dtype=tf.float32)\n",
        "    ## Estados puros\n",
        "    state = pure_state(h_arr)\n",
        "    #rho_2_input = rho_2_tf(state, rho_2_arrays_tf)\n",
        "    # Calculo de estadistica\n",
        "    #rho_2_s = lambda x: [np.max(i) for i in np.linalg.eigvals(x)]\n",
        "    rho_2_s = lambda x: np.sort(np.linalg.eigvals(x))\n",
        "    rho_2_pred = rho_2_s(rho_2_tf(state, rho_2_arrays_kkbar_tf))\n",
        "    rho_2_true = rho_2_s(e[0])\n",
        "    rho_2_rand = rho_2_s(next_sample[0])\n",
        "    # Printeamos algunos valores\n",
        "    for i in range(0, 4):\n",
        "        print(\"true: \" + str(rho_2_true[i]))\n",
        "        print(\"pred: \" + str(rho_2_pred[i]))\n",
        "    # Analisis RMSE\n",
        "    #RMSE_pred = mean_squared_error(rho_2_true, rho_2_pred, squared=False)\n",
        "    #RMSE_rand = mean_squared_error(rho_2_true, rho_2_rand, squared=False)\n",
        "    #print(RMSE_pred, RMSE_rand)\n",
        "    #print(RMSE_rand/RMSE_pred)\n",
        "    norm_pred = np.mean(np.linalg.norm(rho_2_true-rho_2_pred,ord=2, axis=1))\n",
        "    norm_rand = np.mean(np.linalg.norm(rho_2_true-rho_2_rand,ord=2, axis=1))\n",
        "    print(norm_pred, norm_rand)\n",
        "    print(norm_rand / norm_pred)\n",
        "    break\n",
        "\n",
        "# Veamos ahora en función de G\n",
        "if predictions.shape[1] == 1:\n",
        "    pred_ids = predictions.T.argsort()\n",
        "    predictions_sort = predictions[pred_ids][0]\n",
        "    G_true_sorted = e[1].numpy()[pred_ids].T\n",
        "else:\n",
        "    pred_ids = predictions[:,0].argsort()\n",
        "    predictions_sort = predictions[:,0][pred_ids]\n",
        "    G_true_sorted = e[1][:,0].numpy()[pred_ids]\n",
        "G_err = np.abs(predictions_sort-G_true_sorted)\n",
        "plt.plot(predictions_sort,G_err)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 286,
      "metadata": {
        "id": "ds5iD1OMbZu3"
      },
      "outputs": [
        {
          "ename": "IndexError",
          "evalue": "tuple index out of range",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[286], line 12\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m e \u001b[38;5;129;01min\u001b[39;00m val_dataset:\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m printear \u001b[38;5;28;01melse\u001b[39;00m batch_size):\n\u001b[1;32m     10\u001b[0m         \u001b[38;5;66;03m# Valores actuales\u001b[39;00m\n\u001b[1;32m     11\u001b[0m         \u001b[38;5;66;03m#h = e[1][i].numpy().reshape(basis.size,basis.size)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m         h_true \u001b[38;5;241m=\u001b[39m \u001b[43mgen_to_h\u001b[49m\u001b[43m(\u001b[49m\u001b[43me\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrho_1_arrays\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m         \u001b[38;5;66;03m#print(h) if printear else 0\u001b[39;00m\n\u001b[1;32m     14\u001b[0m         r \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(np\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39meigvals(e[\u001b[38;5;241m0\u001b[39m][i]))\n",
            "Cell \u001b[0;32mIn[82], line 20\u001b[0m, in \u001b[0;36mgen_to_h\u001b[0;34m(base, rho_1_arrays)\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgen_to_h\u001b[39m(base, rho_1_arrays):\n\u001b[0;32m---> 20\u001b[0m     triag \u001b[38;5;241m=\u001b[39m \u001b[43mfill_triangular_np\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbase\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     body_gen \u001b[38;5;241m=\u001b[39m triag \u001b[38;5;241m+\u001b[39m np\u001b[38;5;241m.\u001b[39mtranspose(triag)\u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39mdiag(np\u001b[38;5;241m.\u001b[39mdiag(triag))\n\u001b[1;32m     22\u001b[0m     h \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(base_hamiltonian(body_gen, basis, rho_1_arrays))  \n",
            "Cell \u001b[0;32mIn[81], line 14\u001b[0m, in \u001b[0;36mfill_triangular_np\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfill_triangular_np\u001b[39m(x):\n\u001b[0;32m---> 14\u001b[0m     m \u001b[38;5;241m=\u001b[39m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     15\u001b[0m     n \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mint32(np\u001b[38;5;241m.\u001b[39msqrt(\u001b[38;5;241m.25\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m m) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m.5\u001b[39m)\n\u001b[1;32m     16\u001b[0m     x_tail \u001b[38;5;241m=\u001b[39m x[(m \u001b[38;5;241m-\u001b[39m (n\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m-\u001b[39m m)):]\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/tensorflow/python/framework/tensor_shape.py:959\u001b[0m, in \u001b[0;36mTensorShape.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m    957\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    958\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_v2_behavior:\n\u001b[0;32m--> 959\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dims\u001b[49m\u001b[43m[\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    960\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdims[key]\n",
            "\u001b[0;31mIndexError\u001b[0m: tuple index out of range"
          ]
        }
      ],
      "source": [
        "m_size = basis.size\n",
        "rho_1_pred = []\n",
        "rho_1_actual = []\n",
        "norm = []\n",
        "norm_rand = []\n",
        "printear =  False\n",
        "\n",
        "for e in val_dataset:\n",
        "    for i in range(0, 3 if printear else batch_size):\n",
        "        # Valores actuales\n",
        "        #h = e[1][i].numpy().reshape(basis.size,basis.size)\n",
        "        h_true = gen_to_h(e[1][i], rho_1_arrays)\n",
        "        #print(h) if printear else 0\n",
        "        r = max(np.linalg.eigvals(e[0][i]))\n",
        "        rho_1_actual.append(r)\n",
        "\n",
        "        print(h_true) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "\n",
        "        # Valores predichos\n",
        "        #h = predictions[i].reshape(basis.size,basis.size)\n",
        "        h_pred = gen_to_h(predictions[i], rho_1_arrays)\n",
        "        beta = 1\n",
        "        # Estado térmico\n",
        "        state = thermal_state(h_pred, beta)\n",
        "        # Estado puro\n",
        "        #state = pure_state(h_pred)\n",
        "        rho1 = np.array(rho_1(basis.d, state, rho_1_arrays))\n",
        "        r = max(np.sort(linalg_d.eigvals(rho1).real))\n",
        "        rho_1_pred.append(r)\n",
        "\n",
        "        print(h_pred) if printear else 0\n",
        "        print(r) if printear else 0\n",
        "        \n",
        "\n",
        "        # Normas\n",
        "        norm.append(np.linalg.norm(h_true-h_pred, ord='fro'))\n",
        "        print(f'Norma {norm[-1]}') if printear else 0\n",
        "        ## Vamos a comparar con un h aleatorio\n",
        "        size = basis.d*(basis.d+1)//2\n",
        "        base = np.random.uniform(low=0, high=1.0, size=(size,))\n",
        "        h_rand = gen_to_h(base, rho_1_arrays)\n",
        "        norm_rand.append(np.linalg.norm(h_true-h_rand, ord='fro'))\n",
        "        #print(f'Norma random {norm_rand[-1]}') if printear else 0\n",
        "        print('') if printear else 0\n",
        "        \n",
        "\n",
        "\n",
        "    # e contiene todo el batch y nos basta con uno\n",
        "    break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(e[1][10])\n",
        "predictions[10]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 501
        },
        "id": "AL2EC9Ci-0HG",
        "outputId": "545ebe57-d3de-490f-f076-709d5c47b5f2"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "f=1\n",
        "rho_1_actual = np.array(rho_1_actual)\n",
        "rho_1_pred = np.array(rho_1_pred)\n",
        "#print(mean_squared_error(rho_1_pred, rho_1_actual))\n",
        "\n",
        "print('Rho1 based statistics')\n",
        "print(np.mean(np.abs(rho_1_actual-rho_1_pred)))\n",
        "print(np.mean(rho_1_actual)*f)\n",
        "print('std')\n",
        "print(np.std(rho_1_actual-rho_1_pred)*f)\n",
        "print(np.std(rho_1_actual)*f)\n",
        "print(np.std(rho_1_pred)*f)\n",
        "plt.hist(np.array(rho_1_pred-rho_1_actual), bins=50)\n",
        "plt.show()\n",
        "print('H based statistics')\n",
        "print(np.mean(norm), np.mean(norm_rand))\n",
        "print(np.mean(norm_rand)/np.mean(norm))\n",
        "\n",
        "\n",
        "# BEST: FACTOR 1/8 c/fund\n",
        "## 500 epochs, 10M dataset\n",
        "# BEST: FACTOR 1/9 s/fund\n",
        "## 50 epochs, 5M dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "6.25/1.30"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# 25 epochs d = m*2\n",
        "res = {}\n",
        "res[5] = 35/8.19 \n",
        "res[4] = 15/2.47\n",
        "res[3] = 6.2/1.73"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(res)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YioVllOX3M1N",
        "outputId": "b7715c37-1400-4c04-8be3-dd247b4b9db9"
      },
      "outputs": [],
      "source": [
        "# Get the weights of all dense layers in the model\n",
        "dense_weights = []\n",
        "for layer in model.layers:\n",
        "    if isinstance(layer, tf.keras.layers.Dense):\n",
        "        weights = layer.get_weights()\n",
        "        if len(weights) > 0:\n",
        "            dense_weights.append(weights[0])\n",
        "\n",
        "# Visualize the weights of each dense layer\n",
        "for i, weights in enumerate(dense_weights):\n",
        "    plt.figure()\n",
        "    plt.imshow(weights, cmap='viridis', aspect='auto')\n",
        "    plt.colorbar()\n",
        "    plt.title(f\"Dense Layer {i+1} Weights Visualization\")\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[0 0 0 0 1 1] [0 1 1 0 0 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "0.0"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Genera las matrices de rho2\n",
        "def rho_2_gen(basis, mll_basis, t_basis):\n",
        "    size = t_basis.size\n",
        "    s = basis.size\n",
        "    # La entrada i, j contiene C_j^\\dag C_i    i, j \\in t_basis\n",
        "    mat = np.empty((size, size, s, s), dtype=np.float32)\n",
        "    for i, v in enumerate(t_basis.base):\n",
        "        for j, w in enumerate(t_basis.base):\n",
        "            c_i = b_gen(basis, mll_basis, rep_to_exi(v))\n",
        "            cdag_j = bd_gen(mll_basis, basis, rep_to_exi(w))\n",
        "            mat[i, j, :, :] = np.dot(cdag_j, c_i)\n",
        "            if mat[i,j,0,9] != 0:\n",
        "                print(v,w)\n",
        "\n",
        "    return mat\n",
        "\n",
        "r = rho_2_gen(basis, basis_m2, t_basis)\n",
        "r[9,0,0,9]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[[0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]]\n"
          ]
        }
      ],
      "source": [
        "print(b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0])))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        1., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 0.],\n",
              "       [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
              "        0., 0., 0., 1.]], dtype=float32)"
            ]
          },
          "execution_count": 38,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[1, 1, 1, 0, 0, 0],\n",
              "       [1, 1, 0, 1, 0, 0],\n",
              "       [1, 1, 0, 0, 1, 0],\n",
              "       [1, 1, 0, 0, 0, 1],\n",
              "       [1, 0, 1, 1, 0, 0],\n",
              "       [1, 0, 1, 0, 1, 0],\n",
              "       [1, 0, 1, 0, 0, 1],\n",
              "       [1, 0, 0, 1, 1, 0],\n",
              "       [1, 0, 0, 1, 0, 1],\n",
              "       [1, 0, 0, 0, 1, 1],\n",
              "       [0, 1, 1, 1, 0, 0],\n",
              "       [0, 1, 1, 0, 1, 0],\n",
              "       [0, 1, 1, 0, 0, 1],\n",
              "       [0, 1, 0, 1, 1, 0],\n",
              "       [0, 1, 0, 1, 0, 1],\n",
              "       [0, 1, 0, 0, 1, 1],\n",
              "       [0, 0, 1, 1, 1, 0],\n",
              "       [0, 0, 1, 1, 0, 1],\n",
              "       [0, 0, 1, 0, 1, 1],\n",
              "       [0, 0, 0, 1, 1, 1]])"
            ]
          },
          "execution_count": 57,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "basis.base"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(6, 20)\n",
            "[array([0, 1, 0, 1, 1, 0])] [0 1 0 0 0 0]\n"
          ]
        }
      ],
      "source": [
        "col = 1\n",
        "b = b_gen(basis, mll_basis, rep_to_exi([0,0,0,1,1,0]))\n",
        "print(b.shape)\n",
        "for x in range(0,b.shape[1]):\n",
        "    if b[col,x] != 0:\n",
        "        ind = x\n",
        "        break\n",
        "else:\n",
        "    ind = NaN\n",
        "\n",
        "print([basis.base[ind]], mll_basis.base[col])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "d = 2*m\n",
        "basis = fixed_basis(m, d)\n",
        "t_basis = fixed_basis(2, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "ml_basis = basis_m1\n",
        "mll_basis = basis_m2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "t_basis = fixed_basis(2, d)\n",
        "mll_basis = fixed_basis(basis.m-2, d)\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_2_arrays = rho_2_gen(basis, mll_basis, t_basis)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def two_body_hamiltonian(t_basis_size, m, energy, G, rho_1_arrays, rho_2_arrays):\n",
        "    # Creamos la mat diagonal de d*d con los elementos de energy\n",
        "    # cada uno de estos, se contraen con los elementos de rho_1_arrays\n",
        "    # la mat energy contiene las energias de cada termino c^\\dag_k c_k para k kbar (iguales)\n",
        "    # por ello los elementos se repiten \n",
        "    energy_matrix = np.diagflat(np.kron(energy, np.ones(2)))\n",
        "    \n",
        "    # Construimos la mat de energía\n",
        "    h0 = np.sum(energy_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    # Pasamos ahora a la matrix de interacción con la misma estrategia\n",
        "    # dada G que indica la interacción entre los pares k' k'bar k kbar \n",
        "    # (que son elementos particulares de t_basis)\n",
        "    # transladamos estos coeficientes a una matriz en t_basis\n",
        "    # y multiplicamos por rho_2_arrays\n",
        "    \n",
        "    # Primero determinamos, dada t_basis, cuales son los indices de pares kkbar\n",
        "    offset = 4*m+1\n",
        "    indices = [-(k-1)*(2*k-offset) for k in range(1,m+1)] # Lo saque de Mathmatica, vos confia\n",
        "    i, j = np.meshgrid(indices, indices, indexing='ij') # Lo usamos para rellenar la mat deseada\n",
        "    \n",
        "    # Contruimos la mat que contraeremos con rho_2_arrays\n",
        "    mat = np.zeros((t_basis_size, t_basis_size))\n",
        "    mat[i, j] = G\n",
        "\n",
        "    hi = -np.sum(mat[:, :, np.newaxis, np.newaxis] * rho_2_arrays[:, :, :, :], axis=(0, 1))\n",
        "\n",
        "    return (h0, hi)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "(h02,hi2) = two_body_hamiltonian(t_basis.size, m, [0,1,2], np.ones((3,3)), rho_1_arrays, rho_2_arrays)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[[[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 1., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [1., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 1., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       ...,\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 1., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.]],\n",
              "\n",
              "        [[0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         ...,\n",
              "         [0., 0., 0., ..., 0., 0., 0.],\n",
              "         [0., 0., 0., ..., 0., 1., 0.],\n",
              "         [0., 0., 0., ..., 0., 0., 1.]]]], dtype=float32)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "rho_2_arrays"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.0\n"
          ]
        }
      ],
      "source": [
        "print(rho_2_arrays[9,0,0,9])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 1 1 0 0 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 0 0 1 1 0 0 0 0]\n",
            "[1 1 0 0 1 1 1 1 0 0 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[1 1 1 1 0 0 0 0 1 1 0 0]\n",
            "[1 1 0 0 1 1 0 0 1 1 0 0]\n",
            "[1 1 0 0 0 0 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 1 1 0 0]\n",
            "[0 0 1 1 0 0 1 1 1 1 0 0]\n",
            "[0 0 0 0 1 1 1 1 1 1 0 0]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 0 0 1 1 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 0 0 1 1 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 0 0 1 1 1 1]\n",
            "[0 0 0 0 1 1 0 0 1 1 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[1 1 1 1 0 0 0 0 0 0 1 1]\n",
            "[1 1 0 0 1 1 0 0 0 0 1 1]\n",
            "[1 1 0 0 0 0 1 1 0 0 1 1]\n",
            "[0 0 1 1 1 1 0 0 0 0 1 1]\n",
            "[0 0 1 1 0 0 1 1 0 0 1 1]\n",
            "[0 0 0 0 1 1 1 1 0 0 1 1]\n",
            "[[0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 0. 0. 0. 0.]\n",
            " [0. 0. 1. 0. 0. 0.]\n",
            " [0. 0. 0. 1. 0. 0.]\n",
            " [0. 0. 0. 0. 2. 0.]\n",
            " [0. 0. 0. 0. 0. 2.]]\n"
          ]
        },
        {
          "ename": "IndexError",
          "evalue": "index 6 is out of bounds for axis 1 with size 6",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[78], line 15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md):\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39md):\n\u001b[0;32m---> 15\u001b[0m         mat \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mresult_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;241m*\u001b[39m rho_1_arrays[i,j,:,:]\n",
            "\u001b[0;31mIndexError\u001b[0m: index 6 is out of bounds for axis 1 with size 6"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "\n",
        "A = np.array([0, 1, 2])  # Your list with d elements\n",
        "\n",
        "# Create a diagonal matrix with each element repeated twice\n",
        "result_matrix = np.diagflat(np.kron(A, np.ones(2)))\n",
        "\n",
        "print(result_matrix)\n",
        "np.kron(A, np.ones(2))\n",
        "\n",
        "mat = np.zeros((basis.size, basis.size))\n",
        "for i in range(0,2*d):\n",
        "    for j in range(0, 2*d):\n",
        "        mat += result_matrix[i,j] * rho_1_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "mat = np.sum(result_matrix[:, :, np.newaxis, np.newaxis] * rho_1_arrays[:, :, :, :], axis=(0, 1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "h0 == mat"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[1 1 0 0 0 0]\n",
            "[0 0 1 1 0 0]\n",
            "[0 0 0 0 1 1]\n",
            "[0, 9, 14]\n",
            "[0, 9, 14]\n"
          ]
        }
      ],
      "source": [
        "d = 3\n",
        "t_basis = fixed_basis(2, 2*d)\n",
        "basis = fixed_basis(d, 2*d)\n",
        "size = t_basis.size\n",
        "#basis = fixed_basis(d, 2*d)\n",
        "diag_elem = []\n",
        "for x in t_basis.base:\n",
        "    if all([x[i] == x[i+1] for i in range(0, 2*d, 2)]):\n",
        "        print(x)\n",
        "        diag_elem.append(t_basis.rep_to_index(x))\n",
        "\n",
        "print(diag_elem)\n",
        "# Veamos el GALERAZO de Wolfram\n",
        "n = 4*d+1\n",
        "print([-(k-1)*(2*k-n) for k in range(1,d+1)])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m2_basis = fixed_basis(2, d)\n",
        "print(m2_basis.size)\n",
        "nm2_basis = fixed_basis(basis.m-2, d)\n",
        "print(nm2_basis.base)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "W = np.array([[1,2,3],[4,5,6],[7,8,9]])\n",
        "index = [0,9,14]\n",
        "mat = np.zeros((size,size))\n",
        "for i in range(0,3):\n",
        "    for j in range(0,3):\n",
        "        mat[index[i], index[j]] = W[i,j]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "#rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "\n",
        "W = np.array([[1, 2, 3], [4, 5, 6], [7, 8, 9]])\n",
        "W = np.ones((3,3))\n",
        "index = [0, 9, 14]\n",
        "size = 15  # Assuming size is the size of the matrix\n",
        "\n",
        "# Create a meshgrid of indices\n",
        "i, j = np.meshgrid(index, index, indexing='ij')\n",
        "\n",
        "# Use the meshgrid indices to assign values from W to the specified positions in mat\n",
        "mat = np.zeros((size, size))\n",
        "mat[i, j] = W\n",
        "\n",
        "# La mat... mat corresponde a los coeficientes en t_basis\n",
        "inte = np.zeros((basis.size, basis.size))\n",
        "for i in range(0, t_basis.size):\n",
        "    for j in range(0, t_basis.size):\n",
        "        inte += - mat[i, j] * rho_2_arrays[i,j,:,:]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "inte == hi"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "m = 3\n",
        "basis = fixed_basis(m, d)\n",
        "basis_m1 = fixed_basis(m-1, d)\n",
        "basis_m2 = fixed_basis(m-2, d)\n",
        "\n",
        "from numba import njit\n",
        "\n",
        "# Parametros hamiltoniano\n",
        "e = 1\n",
        "eps = 0\n",
        "e0 = np.zeros(2*d)\n",
        "eigenspace_tol = 0.0001\n",
        "for k in range(0, d):\n",
        "    r = random.random() * eps * 0\n",
        "    e0[2*k] = k*e+r\n",
        "    e0[2*k+1] = k*e+r\n",
        "\n",
        "@njit(parallel=True)\n",
        "def base_hamiltonian_aux(basis, size, d, basis_m1, basis_m2):\n",
        "    # Construccion de H\n",
        "    d = d//2\n",
        "    h0 = np.zeros((size,size), dtype=np.float32)\n",
        "    for k in prange(0,2*d):\n",
        "        h0 += e0[k] * np.dot(bd_aux(basis_m1, basis, k),b_aux(basis, basis_m1, k))\n",
        "    hi = np.zeros((size, size), dtype=np.float32)\n",
        "    for k in prange(0,d):\n",
        "        for kb in prange(0,d):\n",
        "            bd_terms = np.dot(bd_aux(basis_m1, basis, 2*k),bd_aux(basis_m2, basis_m1, 2*k+1))\n",
        "            b_terms = np.dot(b_aux(basis_m1, basis_m2, 2*kb+1),b_aux(basis, basis_m1, 2*kb))\n",
        "            hi += -1*np.dot(bd_terms,b_terms)\n",
        "\n",
        "    return (h0, hi)\n",
        "\n",
        "def base_hamiltonian(basis, basis_m1, basis_m2):\n",
        "    return base_hamiltonian_aux(basis.base, basis.size, basis.d, basis_m1.base, basis_m2.base)\n",
        "\n",
        "h0, hi = base_hamiltonian(basis, basis_m1, basis_m2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testeo barrido en G código anterior"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "num = 50\n",
        "g_range = np.linspace(0.01,5,num)\n",
        "rho_range= {}\n",
        "gpu_batch_size = 2\n",
        "\n",
        "# Construccion de parametros y matrices auxiliares\n",
        "#rho1_size = m1_basis.size\n",
        "rho2_size = m2_basis.size\n",
        "rho2kkbar_size = basis.m\n",
        "fund_size = basis.size\n",
        "hamil_base_size = basis.d*(basis.d+1)//2\n",
        "rho_1_arrays = rho_1_gen(basis)\n",
        "rho_1_arrays_tf = tf.constant(rho_1_arrays, dtype=tf.float32)\n",
        "rho_2_arrays = rho_2_gen(basis, nm2_basis, m2_basis)\n",
        "rho_2_arrays_tf = tf.constant(rho_2_arrays, dtype=tf.float32)\n",
        "rho_2_arrays_kkbar = rho_2_kkbar_gen(t_basis, rho_2_arrays)\n",
        "rho_2_arrays_kkbar_tf = tf.constant(rho_2_arrays_kkbar, dtype=tf.float32)\n",
        "k_indices = get_kkbar_indices(t_basis)\n",
        "k_indices_tf = gen_update_indices(t_basis, gpu_batch_size)\n",
        "\n",
        "batch_size = 2\n",
        "indices = tf.constant(get_kkbar_indices(t_basis))\n",
        "indices_tf = gen_update_indices(t_basis, batch_size)\n",
        "en_batch = [np.arange(0, basis.m) for _ in range(0,batch_size)]\n",
        "G_batched = [np.ones((basis.m,basis.m)) for _ in range(0, batch_size)]\n",
        "\n",
        "t = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, G_batched, rho_1_arrays, rho_2_arrays, indices_tf)\n",
        "(h0, hi) = (t[0][0].numpy(), t[1][0].numpy())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0.01\n",
            "0.11183673469387755\n",
            "0.2136734693877551\n",
            "0.31551020408163266\n",
            "0.4173469387755102\n",
            "0.5191836734693878\n",
            "0.6210204081632653\n",
            "0.7228571428571429\n",
            "0.8246938775510204\n",
            "0.926530612244898\n",
            "1.0283673469387755\n",
            "1.130204081632653\n",
            "1.2320408163265306\n",
            "1.3338775510204082\n",
            "1.4357142857142857\n",
            "1.5375510204081633\n",
            "1.6393877551020408\n",
            "1.7412244897959184\n",
            "1.843061224489796\n",
            "1.9448979591836735\n",
            "2.046734693877551\n",
            "2.1485714285714286\n",
            "2.250408163265306\n",
            "2.3522448979591832\n",
            "2.454081632653061\n",
            "2.555918367346939\n",
            "2.657755102040816\n",
            "2.7595918367346934\n",
            "2.861428571428571\n",
            "2.963265306122449\n",
            "3.0651020408163263\n",
            "3.1669387755102036\n",
            "3.2687755102040814\n",
            "3.370612244897959\n",
            "3.4724489795918365\n",
            "3.574285714285714\n",
            "3.6761224489795916\n",
            "3.7779591836734694\n",
            "3.8797959183673467\n",
            "3.981632653061224\n",
            "4.083469387755102\n",
            "4.18530612244898\n",
            "4.287142857142857\n",
            "4.388979591836734\n",
            "4.490816326530612\n",
            "4.59265306122449\n",
            "4.694489795918367\n",
            "4.7963265306122445\n",
            "4.898163265306122\n",
            "5.0\n"
          ]
        }
      ],
      "source": [
        "def compute_g(g):\n",
        "    #print(g)\n",
        "    G_batched = [g * np.ones((basis.m,basis.m)) for _ in range(0, batch_size)]\n",
        "    t = two_body_hamiltonian_tf(t_basis, basis.m, en_batch, G_batched, rho_1_arrays, rho_2_arrays, indices_tf)\n",
        "    state = pure_state(t)\n",
        "    #print(fund)\n",
        "    #print('rho')\n",
        "    #Toda la matriz\n",
        "    rho = rho_2_tf(state, rho_2_arrays_kkbar_tf)\n",
        "    #Solo el bloque kkbar\n",
        "    #rho = rho_2_kkbar(basis, fund, ml_basis, mll_basis, t_basis)\n",
        "    #Rho1\n",
        "    #rho = rho_1(basis, fund).todense()\n",
        "    r = np.sort(linalg_d.eigvals(rho[0]).real)\n",
        "    #print(r)\n",
        "    return (g, r)\n",
        "\n",
        "# Version sincrónica\n",
        "rho_range = {}\n",
        "\n",
        "for g in g_range:\n",
        "    print(g)\n",
        "    rho_range[g] = compute_g(g)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 800x500 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "PermissionError",
          "evalue": "[Errno 13] Permission denied: 'filename.png'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[43], line 48\u001b[0m\n\u001b[1;32m     45\u001b[0m plt\u001b[38;5;241m.\u001b[39mtick_params(axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124my\u001b[39m\u001b[38;5;124m'\u001b[39m, which\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmajor\u001b[39m\u001b[38;5;124m'\u001b[39m, width\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.5\u001b[39m)\n\u001b[1;32m     47\u001b[0m plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[0;32m---> 48\u001b[0m \u001b[43mmatplotlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpyplot\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilename.png\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:1119\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1116\u001b[0m fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[1;32m   1117\u001b[0m \u001b[38;5;66;03m# savefig default implementation has no return, so mypy is unhappy\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;66;03m# presumably this is here because subclasses can return?\u001b[39;00m\n\u001b[0;32m-> 1119\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[func-returns-value]\u001b[39;00m\n\u001b[1;32m   1120\u001b[0m fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/figure.py:3390\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3388\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3389\u001b[0m         _recursively_make_axes_transparent(stack, ax)\n\u001b[0;32m-> 3390\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backend_bases.py:2187\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2183\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2184\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2185\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2186\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2187\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2188\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2189\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2190\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2191\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2192\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2193\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2194\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2195\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backend_bases.py:2043\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2039\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2040\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2041\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2042\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2043\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2044\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2045\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2046\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:497\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    451\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    453\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 497\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:446\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    442\u001b[0m \u001b[38;5;124;03mDraw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    443\u001b[0m \u001b[38;5;124;03m*pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    444\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    445\u001b[0m FigureCanvasAgg\u001b[38;5;241m.\u001b[39mdraw(\u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 446\u001b[0m \u001b[43mmpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimsave\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    447\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_rgba\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfmt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mupper\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    448\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/image.py:1656\u001b[0m, in \u001b[0;36mimsave\u001b[0;34m(fname, arr, vmin, vmax, cmap, format, origin, dpi, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m   1654\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mformat\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mformat\u001b[39m)\n\u001b[1;32m   1655\u001b[0m pil_kwargs\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, (dpi, dpi))\n\u001b[0;32m-> 1656\u001b[0m \u001b[43mimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/PIL/Image.py:2410\u001b[0m, in \u001b[0;36mImage.save\u001b[0;34m(self, fp, format, **params)\u001b[0m\n\u001b[1;32m   2408\u001b[0m         fp \u001b[38;5;241m=\u001b[39m builtins\u001b[38;5;241m.\u001b[39mopen(filename, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr+b\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   2409\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2410\u001b[0m         fp \u001b[38;5;241m=\u001b[39m \u001b[43mbuiltins\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mw+b\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2412\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2413\u001b[0m     save_handler(\u001b[38;5;28mself\u001b[39m, fp, filename)\n",
            "\u001b[0;31mPermissionError\u001b[0m: [Errno 13] Permission denied: 'filename.png'"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 0 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Ploteamos\n",
        "rho_range = dict(rho_range)\n",
        "rho_range = dict(sorted(rho_range.items()))\n",
        "x_axis = list(g_range)\n",
        "values = list(rho_range.items())\n",
        "size = len(values[0][1])\n",
        "num = 50\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib\n",
        "import numpy as np\n",
        "\n",
        "# Plot using matplotlib\n",
        "# Use LaTeX to format all text\n",
        "\n",
        "plt.rcParams['text.usetex'] = True\n",
        "plt.rcParams['axes.labelsize'] = 30\n",
        "plt.rcParams['xtick.labelsize'] = 20\n",
        "plt.rcParams['ytick.labelsize'] = 20\n",
        "plt.rcParams['legend.fontsize'] = 20\n",
        "plt.rcParams['axes.linewidth'] = 1.5\n",
        "\n",
        "plt.cla()\n",
        "plt.figure(figsize=(8, 5))\n",
        "#%matplotlib qt\n",
        "%matplotlib inline \n",
        "for k in range(1,size):\n",
        "    plt.plot(x_axis, [values[j][1][k] for j in range(0,num)], linewidth=2)\n",
        "\n",
        "plt.xlabel(r'$G/\\epsilon$', fontsize=18)\n",
        "plt.ylabel(r'$\\lambda^{(2)}$', fontsize=18)\n",
        "plt.xlim(0, 5)  # Set x-axis limits from 0 to 6\n",
        "plt.ylim(0, 2)  # Set y-axis limits from 5 to 12\n",
        "\n",
        "#matplotlib.use('Agg')\n",
        "#matplotlib.use('GTK3Agg')\n",
        "\n",
        "plt.tick_params(axis='x', which='both', bottom=True, top=True, labelbottom=True)\n",
        "\n",
        "# Enable minor ticks on the x-axis\n",
        "plt.minorticks_on()\n",
        "\n",
        "# Customize the appearance of minor ticks on the x-axis\n",
        "plt.tick_params(axis='x', which='minor', width=1.5)\n",
        "plt.tick_params(axis='x', which='major', width=1.5)\n",
        "plt.tick_params(axis='y', which='major', width=1.5)\n",
        "\n",
        "plt.show()\n",
        "matplotlib.pyplot.savefig('filename.png')\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "oapxWkD16fHg"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
